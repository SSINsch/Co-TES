{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 3) (7600, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   labels                                              title  \\\n0       3  Wall St. Bears Claw Back Into the Black (Reuters)   \n1       3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n2       3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n3       3  Iraq Halts Oil Exports from Main Southern Pipe...   \n4       3  Oil prices soar to all-time record, posing new...   \n\n                                                data  \n0  Reuters - Short-sellers, Wall Street's dwindli...  \n1  Reuters - Private investment firm Carlyle Grou...  \n2  Reuters - Soaring crude prices plus worries\\ab...  \n3  Reuters - Authorities have halted oil export\\f...  \n4  AFP - Tearaway world oil prices, toppling reco...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>title</th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n      <td>Reuters - Private investment firm Carlyle Grou...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n      <td>Reuters - Authorities have halted oil export\\f...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>Oil prices soar to all-time record, posing new...</td>\n      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "p_train = r'../data/ag_train.csv'\n",
    "p_test = r'../data/ag_test.csv'\n",
    "df_train = pd.read_csv(p_train, header=None)\n",
    "df_test = pd.read_csv(p_test, header=None)\n",
    "df_train.columns = ['labels', 'title', 'data']\n",
    "df_test.columns = ['labels', 'title', 'data']\n",
    "print(df_train.shape, df_test.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "        labels                                              title  \\\n0            2  Wall St. Bears Claw Back Into the Black (Reuters)   \n1            2  Carlyle Looks Toward Commercial Aerospace (Reu...   \n2            2    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n3            2  Iraq Halts Oil Exports from Main Southern Pipe...   \n4            2  Oil prices soar to all-time record, posing new...   \n...        ...                                                ...   \n119995       0  Pakistan's Musharraf Says Won't Quit as Army C...   \n119996       1                  Renteria signing a top-shelf deal   \n119997       1                    Saban not going to Dolphins yet   \n119998       1                                  Today's NFL games   \n119999       1                       Nets get Carter from Raptors   \n\n                                                     data  \\\n0       Reuters - Short-sellers, Wall Street's dwindli...   \n1       Reuters - Private investment firm Carlyle Grou...   \n2       Reuters - Soaring crude prices plus worries\\ab...   \n3       Reuters - Authorities have halted oil export\\f...   \n4       AFP - Tearaway world oil prices, toppling reco...   \n...                                                   ...   \n119995   KARACHI (Reuters) - Pakistani President Perve...   \n119996  Red Sox general manager Theo Epstein acknowled...   \n119997  The Miami Dolphins will put their courtship of...   \n119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...   \n119999  INDIANAPOLIS -- All-Star Vince Carter was trad...   \n\n                                                      raw  \n0       Wall St. Bears Claw Back Into the Black (Reute...  \n1       Carlyle Looks Toward Commercial Aerospace (Reu...  \n2       Oil and Economy Cloud Stocks' Outlook (Reuters...  \n3       Iraq Halts Oil Exports from Main Southern Pipe...  \n4       Oil prices soar to all-time record, posing new...  \n...                                                   ...  \n119995  Pakistan's Musharraf Says Won't Quit as Army C...  \n119996  Renteria signing a top-shelf deal Red Sox gene...  \n119997  Saban not going to Dolphins yet The Miami Dolp...  \n119998  Today's NFL games PITTSBURGH at NY GIANTS Time...  \n119999  Nets get Carter from Raptors INDIANAPOLIS -- A...  \n\n[120000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>title</th>\n      <th>data</th>\n      <th>raw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n      <td>Reuters - Private investment firm Carlyle Grou...</td>\n      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n      <td>Reuters - Authorities have halted oil export\\f...</td>\n      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Oil prices soar to all-time record, posing new...</td>\n      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n      <td>Oil prices soar to all-time record, posing new...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>119995</th>\n      <td>0</td>\n      <td>Pakistan's Musharraf Says Won't Quit as Army C...</td>\n      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n      <td>Pakistan's Musharraf Says Won't Quit as Army C...</td>\n    </tr>\n    <tr>\n      <th>119996</th>\n      <td>1</td>\n      <td>Renteria signing a top-shelf deal</td>\n      <td>Red Sox general manager Theo Epstein acknowled...</td>\n      <td>Renteria signing a top-shelf deal Red Sox gene...</td>\n    </tr>\n    <tr>\n      <th>119997</th>\n      <td>1</td>\n      <td>Saban not going to Dolphins yet</td>\n      <td>The Miami Dolphins will put their courtship of...</td>\n      <td>Saban not going to Dolphins yet The Miami Dolp...</td>\n    </tr>\n    <tr>\n      <th>119998</th>\n      <td>1</td>\n      <td>Today's NFL games</td>\n      <td>PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...</td>\n      <td>Today's NFL games PITTSBURGH at NY GIANTS Time...</td>\n    </tr>\n    <tr>\n      <th>119999</th>\n      <td>1</td>\n      <td>Nets get Carter from Raptors</td>\n      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n      <td>Nets get Carter from Raptors INDIANAPOLIS -- A...</td>\n    </tr>\n  </tbody>\n</table>\n<p>120000 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['raw'] = df_train['title'] + ' '+df_train['data']\n",
    "df_test['raw'] = df_test['title'] + ' '+df_test['data']\n",
    "\n",
    "# label이 1~4까지라서 => 0~3 까지로 변경해주어야 함\n",
    "df_train['labels'] = df_train['labels'] - 1\n",
    "df_test['labels'] = df_test['labels'] - 1\n",
    "\n",
    "df_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizing 미리 해서 저장해두기\n",
    "\n",
    "- train dataset에서 vocab 추출하고\n",
    "- 추출한 vocab, token2idx로 train_data 바꿔치기 하고\n",
    "- train_data의 max 길이로 패딩 (BasicCollator 참조)\n",
    "- train_data랑, train_labels 묶어서 ag_train.pkl 로 저장\n",
    "- 마찬가지로\n",
    "- 추출한 vocab, token2idx로 test_data 바꿔치기 하고\n",
    "- train_data의 max 길이로 패딩 (BasicCollator 참조)\n",
    "- test_data, test_labels 묶어서 ag_test.pkl 로 저장"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start tokenizing\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "start counting\n",
      "start sorting\n",
      "tokenizing done\n",
      "Vocab set size: 20000\n"
     ]
    },
    {
     "data": {
      "text/plain": "['.', 'the', ',', '-', 'to']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "from typing import List, Tuple, Dict\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "def build_tok_vocab(tokenize_target: List,\n",
    "                    tokenizer,\n",
    "                    min_freq: int = 1,\n",
    "                    max_vocab=19998) -> Tuple[List[str], Dict]:\n",
    "    vocab = []\n",
    "    print('start tokenizing')\n",
    "    for i, target in enumerate(tokenize_target):\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        try:\n",
    "            temp = tokenizer.tokenize(target)\n",
    "            vocab.extend(temp)\n",
    "        except Exception as e_msg:\n",
    "            error_target = f'idx: {i} \\t target:{target}'\n",
    "\n",
    "    print('start counting')\n",
    "    vocab = collections.Counter(vocab)\n",
    "    temp = {}\n",
    "    # min_freq보다 적은 단어 거르기\n",
    "    for key in vocab.keys():\n",
    "        if vocab[key] >= min_freq:\n",
    "            temp[key] = vocab[key]\n",
    "    vocab = temp\n",
    "\n",
    "    print('start sorting')\n",
    "    # 가장 많이 등장하는 순으로 정렬한 후, 적게 나온것 위주로 vocab set에서 빼기\n",
    "    vocab = sorted(vocab, key=lambda x: -vocab[x])\n",
    "    if len(vocab) > max_vocab:\n",
    "        vocab = vocab[:max_vocab]\n",
    "\n",
    "    tok2idx = {'<pad>': 0, '<unk>': 1}\n",
    "    for tok in vocab:\n",
    "        tok2idx[tok] = len(tok2idx)\n",
    "    vocab.extend(['<pad>', '<unk>'])\n",
    "    print('tokenizing done')\n",
    "\n",
    "    return vocab, tok2idx\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "data = [row['raw'] for i, row in df_train.iterrows()]\n",
    "vocab_set, tok2idx = build_tok_vocab(data, tokenizer, min_freq=1, max_vocab=19998)\n",
    "print(f'Vocab set size: {len(tok2idx)}')\n",
    "vocab_set[0:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 1012\n",
      "120000 1012\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in data:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "print(f'max length: {max_len}')\n",
    "\n",
    "tokenized_idx_data = []\n",
    "\n",
    "for sentence in data:\n",
    "    tokened_sentence = tokenizer.tokenize(sentence)\n",
    "    token_list = []\n",
    "    for word in tokened_sentence:\n",
    "        if word not in tok2idx.keys():\n",
    "            token_list.append(tok2idx['<unk>'])\n",
    "        else:\n",
    "            token_list.append(tok2idx[word])\n",
    "\n",
    "    padding_list = [0] * (max_len - len(token_list))\n",
    "    token_list = padding_list + token_list\n",
    "    tokenized_idx_data.append(token_list)\n",
    "\n",
    "print(len(tokenized_idx_data), len(tokenized_idx_data[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 1012)\n",
      "(120000,)\n",
      "now dumping pickle\n"
     ]
    }
   ],
   "source": [
    "train_tokenized_idx = np.array(tokenized_idx_data)\n",
    "train_labels_np = np.array(df_train['labels'])\n",
    "train_data = (train_tokenized_idx, train_labels_np)\n",
    "print(train_tokenized_idx.shape)\n",
    "print(train_labels_np.shape)\n",
    "\n",
    "print('now dumping pickle')\n",
    "with open(file='ag_train.pkl', mode='wb') as f:\n",
    "    pickle.dump(train_data, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test max length: 1012\n",
      "7600 1012\n"
     ]
    }
   ],
   "source": [
    "# - 마찬가지로 test 에 대해서도\n",
    "\n",
    "test_data = [row['raw'] for i, row in df_test.iterrows()]\n",
    "\n",
    "test_max_len = 0\n",
    "for i in data:\n",
    "    if len(i) > test_max_len:\n",
    "        test_max_len = len(i)\n",
    "print(f'test max length: {test_max_len}')\n",
    "if test_max_len > max_len:\n",
    "    print('test max length is bigger than train_max_len')\n",
    "\n",
    "tokenized_idx_test_data = []\n",
    "\n",
    "for sentence in test_data:\n",
    "    tokened_sentence = tokenizer.tokenize(sentence)\n",
    "    token_list = []\n",
    "    for word in tokened_sentence:\n",
    "        if word not in tok2idx.keys():\n",
    "            token_list.append(tok2idx['<unk>'])\n",
    "        else:\n",
    "            token_list.append(tok2idx[word])\n",
    "\n",
    "    padding_list = [0] * (max_len - len(token_list))\n",
    "    token_list = padding_list + token_list\n",
    "    tokenized_idx_test_data.append(token_list)\n",
    "\n",
    "print(len(tokenized_idx_test_data), len(tokenized_idx_test_data[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7600, 1012)\n",
      "(7600,)\n",
      "now dumping test pickle\n"
     ]
    }
   ],
   "source": [
    "test_tokenized_idx = np.array(tokenized_idx_test_data)\n",
    "test_labels_np = np.array(df_test['labels'])\n",
    "test_data = (test_tokenized_idx, test_labels_np)\n",
    "print(test_tokenized_idx.shape)\n",
    "print(test_labels_np.shape)\n",
    "\n",
    "print('now dumping test pickle')\n",
    "with open(file='ag_test.pkl', mode='wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
