{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 3) (7600, 3)\n",
      "3    30000\n",
      "4    30000\n",
      "2    30000\n",
      "1    30000\n",
      "Name: labels, dtype: int64\n",
      "3    1900\n",
      "4    1900\n",
      "2    1900\n",
      "1    1900\n",
      "Name: labels, dtype: int64\n",
      "               labels                                              title  \\\n",
      "labels                                                                     \n",
      "1      40546        1      Haitians Pray for 1,500 Killed by Jeanne (AP)   \n",
      "       48245        1      U.S.-Led Forces Tighten Grip, Draw Complaints   \n",
      "       118691       1  U.N. Says Bugging Device Found at Its Geneva H...   \n",
      "       33489        1            Kerry Questions Bush's Judgment on Iraq   \n",
      "       83190        1  Seoul Asks Bush to Focus on N.Korea Nuclear Cr...   \n",
      "\n",
      "                                                            data  \n",
      "labels                                                            \n",
      "1      40546   AP - In a cathedral ankle-deep in mud and over...  \n",
      "       48245    SAMARRA, Iraq (Reuters) - U.S.-led forces tig...  \n",
      "       118691  Reuters - The United Nations said on Thursday ...  \n",
      "       33489   NEW YORK - Sen. John Kerry said Monday that mi...  \n",
      "       83190   South Korean President Roh Moo-hyun called new...  \n",
      "   labels                                              title  \\\n",
      "0       2  Leafs veteran Alex Mogilny undergoes another h...   \n",
      "1       3         Borders Posts Third Quarter Loss (Reuters)   \n",
      "2       2        Britannia rules as baton again lets US down   \n",
      "3       1  Italy Calls To End Kyoto Climate Limits After ...   \n",
      "4       1                  Singapore warns of deadly illness   \n",
      "\n",
      "                                                data  \n",
      "0  TORONTO (CP) - Winger Alexander Mogilny of the...  \n",
      "1  Reuters - Book retailer Borders Group Inc.\\ on...  \n",
      "2  SINCE the United States started taking part in...  \n",
      "3  ROME - Italy has called for an end to the Kyot...  \n",
      "4  The authorities in Singapore voice concern abo...  \n",
      "(24000, 3)\n",
      "2    6000\n",
      "3    6000\n",
      "1    6000\n",
      "4    6000\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "   labels                                              title  \\\n0       2  Leafs veteran Alex Mogilny undergoes another h...   \n1       3         Borders Posts Third Quarter Loss (Reuters)   \n2       2        Britannia rules as baton again lets US down   \n3       1  Italy Calls To End Kyoto Climate Limits After ...   \n4       1                  Singapore warns of deadly illness   \n\n                                                data  \n0  TORONTO (CP) - Winger Alexander Mogilny of the...  \n1  Reuters - Book retailer Borders Group Inc.\\ on...  \n2  SINCE the United States started taking part in...  \n3  ROME - Italy has called for an end to the Kyot...  \n4  The authorities in Singapore voice concern abo...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>title</th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Leafs veteran Alex Mogilny undergoes another h...</td>\n      <td>TORONTO (CP) - Winger Alexander Mogilny of the...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Borders Posts Third Quarter Loss (Reuters)</td>\n      <td>Reuters - Book retailer Borders Group Inc.\\ on...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Britannia rules as baton again lets US down</td>\n      <td>SINCE the United States started taking part in...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Italy Calls To End Kyoto Climate Limits After ...</td>\n      <td>ROME - Italy has called for an end to the Kyot...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Singapore warns of deadly illness</td>\n      <td>The authorities in Singapore voice concern abo...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "p_train = r'../data/ag_train.csv'\n",
    "p_test = r'../data/ag_test.csv'\n",
    "df_train = pd.read_csv(p_train, header=None)\n",
    "df_test = pd.read_csv(p_test, header=None)\n",
    "df_train.columns = ['labels', 'title', 'data']\n",
    "df_test.columns = ['labels', 'title', 'data']\n",
    "print(df_train.shape, df_test.shape)\n",
    "print(df_train['labels'].value_counts())\n",
    "print(df_test['labels'].value_counts())\n",
    "\n",
    "# df_train_sample => 12만개 데이터에서 2만개만 추출\n",
    "sample_df = df_train.groupby('labels').apply(lambda x: x.sample(frac=0.2, random_state=1))\n",
    "print(sample_df.head())\n",
    "# sample_df = sample_df.sample(frac=1)\n",
    "sample_df = sample_df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "print(sample_df.shape)\n",
    "print(sample_df['labels'].value_counts())\n",
    "sample_df.to_csv('../data/ag_train_sample.csv')\n",
    "df_train = sample_df\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "       labels                                              title  \\\n0           1  Leafs veteran Alex Mogilny undergoes another h...   \n1           2         Borders Posts Third Quarter Loss (Reuters)   \n2           1        Britannia rules as baton again lets US down   \n3           0  Italy Calls To End Kyoto Climate Limits After ...   \n4           0                  Singapore warns of deadly illness   \n...       ...                                                ...   \n23995       1        Angry Kick Puts Cubs' Farnsworth on DL (AP)   \n23996       2  FASB delays new options expensing rule by 6 mo...   \n23997       0          Blasts, Gunfire Shake Najaf As Talks Drag   \n23998       2            1,500 Imperial Oil jobs leaving Toronto   \n23999       0                   UN summit to tackle world hunger   \n\n                                                    data  \\\n0      TORONTO (CP) - Winger Alexander Mogilny of the...   \n1      Reuters - Book retailer Borders Group Inc.\\ on...   \n2      SINCE the United States started taking part in...   \n3      ROME - Italy has called for an end to the Kyot...   \n4      The authorities in Singapore voice concern abo...   \n...                                                  ...   \n23995  AP - Chicago Cubs reliever Kyle Farnsworth too...   \n23996  Bowing to corporate pressure, the group that s...   \n23997  NAJAF, Iraq - Explosions and gunfire shook Naj...   \n23998  Imperial Oil Ltd. says it will shift its head ...   \n23999  World leaders prepare to meet at the UN in New...   \n\n                                                     raw  \n0      Leafs veteran Alex Mogilny undergoes another h...  \n1      Borders Posts Third Quarter Loss (Reuters) Reu...  \n2      Britannia rules as baton again lets US down SI...  \n3      Italy Calls To End Kyoto Climate Limits After ...  \n4      Singapore warns of deadly illness The authorit...  \n...                                                  ...  \n23995  Angry Kick Puts Cubs' Farnsworth on DL (AP) AP...  \n23996  FASB delays new options expensing rule by 6 mo...  \n23997  Blasts, Gunfire Shake Najaf As Talks Drag NAJA...  \n23998  1,500 Imperial Oil jobs leaving Toronto Imperi...  \n23999  UN summit to tackle world hunger World leaders...  \n\n[24000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>title</th>\n      <th>data</th>\n      <th>raw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Leafs veteran Alex Mogilny undergoes another h...</td>\n      <td>TORONTO (CP) - Winger Alexander Mogilny of the...</td>\n      <td>Leafs veteran Alex Mogilny undergoes another h...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Borders Posts Third Quarter Loss (Reuters)</td>\n      <td>Reuters - Book retailer Borders Group Inc.\\ on...</td>\n      <td>Borders Posts Third Quarter Loss (Reuters) Reu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Britannia rules as baton again lets US down</td>\n      <td>SINCE the United States started taking part in...</td>\n      <td>Britannia rules as baton again lets US down SI...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Italy Calls To End Kyoto Climate Limits After ...</td>\n      <td>ROME - Italy has called for an end to the Kyot...</td>\n      <td>Italy Calls To End Kyoto Climate Limits After ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Singapore warns of deadly illness</td>\n      <td>The authorities in Singapore voice concern abo...</td>\n      <td>Singapore warns of deadly illness The authorit...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23995</th>\n      <td>1</td>\n      <td>Angry Kick Puts Cubs' Farnsworth on DL (AP)</td>\n      <td>AP - Chicago Cubs reliever Kyle Farnsworth too...</td>\n      <td>Angry Kick Puts Cubs' Farnsworth on DL (AP) AP...</td>\n    </tr>\n    <tr>\n      <th>23996</th>\n      <td>2</td>\n      <td>FASB delays new options expensing rule by 6 mo...</td>\n      <td>Bowing to corporate pressure, the group that s...</td>\n      <td>FASB delays new options expensing rule by 6 mo...</td>\n    </tr>\n    <tr>\n      <th>23997</th>\n      <td>0</td>\n      <td>Blasts, Gunfire Shake Najaf As Talks Drag</td>\n      <td>NAJAF, Iraq - Explosions and gunfire shook Naj...</td>\n      <td>Blasts, Gunfire Shake Najaf As Talks Drag NAJA...</td>\n    </tr>\n    <tr>\n      <th>23998</th>\n      <td>2</td>\n      <td>1,500 Imperial Oil jobs leaving Toronto</td>\n      <td>Imperial Oil Ltd. says it will shift its head ...</td>\n      <td>1,500 Imperial Oil jobs leaving Toronto Imperi...</td>\n    </tr>\n    <tr>\n      <th>23999</th>\n      <td>0</td>\n      <td>UN summit to tackle world hunger</td>\n      <td>World leaders prepare to meet at the UN in New...</td>\n      <td>UN summit to tackle world hunger World leaders...</td>\n    </tr>\n  </tbody>\n</table>\n<p>24000 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['raw'] = df_train['title'] + ' '+df_train['data']\n",
    "df_test['raw'] = df_test['title'] + ' '+df_test['data']\n",
    "\n",
    "# label이 1~4까지라서 => 0~3 까지로 변경해주어야 함\n",
    "df_train['labels'] = df_train['labels'] - 1\n",
    "df_test['labels'] = df_test['labels'] - 1\n",
    "\n",
    "df_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizing 미리 해서 저장해두기\n",
    "\n",
    "- train dataset에서 vocab 추출하고\n",
    "- 추출한 vocab, token2idx로 train_data 바꿔치기 하고\n",
    "- train_data의 max 길이로 패딩 (BasicCollator 참조)\n",
    "- train_data랑, train_labels 묶어서 ag_train.pkl 로 저장\n",
    "- 마찬가지로\n",
    "- 추출한 vocab, token2idx로 test_data 바꿔치기 하고\n",
    "- train_data의 max 길이로 패딩 (BasicCollator 참조)\n",
    "- test_data, test_labels 묶어서 ag_test.pkl 로 저장"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start tokenizing\n",
      "0\n",
      "10000\n",
      "20000\n",
      "start counting\n",
      "start sorting\n",
      "tokenizing done\n",
      "Vocab set size: 20000\n",
      "['.', 'the', ',', '-', 'to']\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from typing import List, Tuple, Dict\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "def build_tok_vocab(tokenize_target: List,\n",
    "                    tokenizer,\n",
    "                    min_freq: int = 1,\n",
    "                    max_vocab=19998) -> Tuple[List[str], Dict]:\n",
    "    vocab = []\n",
    "    print('start tokenizing')\n",
    "    for i, target in enumerate(tokenize_target):\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        try:\n",
    "            temp = tokenizer.tokenize(target)\n",
    "            vocab.extend(temp)\n",
    "        except Exception as e_msg:\n",
    "            error_target = f'idx: {i} \\t target:{target}'\n",
    "\n",
    "    print('start counting')\n",
    "    vocab = collections.Counter(vocab)\n",
    "    temp = {}\n",
    "    # min_freq보다 적은 단어 거르기\n",
    "    for key in vocab.keys():\n",
    "        if vocab[key] >= min_freq:\n",
    "            temp[key] = vocab[key]\n",
    "    vocab = temp\n",
    "\n",
    "    print('start sorting')\n",
    "    # 가장 많이 등장하는 순으로 정렬한 후, 적게 나온것 위주로 vocab set에서 빼기\n",
    "    vocab = sorted(vocab, key=lambda x: -vocab[x])\n",
    "    if len(vocab) > max_vocab:\n",
    "        vocab = vocab[:max_vocab]\n",
    "\n",
    "    tok2idx = {'<pad>': 0, '<unk>': 1}\n",
    "    for tok in vocab:\n",
    "        tok2idx[tok] = len(tok2idx)\n",
    "    vocab.extend(['<pad>', '<unk>'])\n",
    "    print('tokenizing done')\n",
    "\n",
    "    return vocab, tok2idx\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# full\n",
    "data = [row['raw'] for _, row in df_train.iterrows()]\n",
    "vocab_set, tok2idx = build_tok_vocab(data, tokenizer, min_freq=1, max_vocab=19998)\n",
    "print(f'Vocab set size: {len(tok2idx)}')\n",
    "print(vocab_set[0:5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 996\n",
      "24000 996\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in data:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "print(f'max length: {max_len}')\n",
    "\n",
    "tokenized_idx_data = []\n",
    "\n",
    "for sentence in data:\n",
    "    tokened_sentence = tokenizer.tokenize(sentence)\n",
    "    token_list = []\n",
    "    for word in tokened_sentence:\n",
    "        if word not in tok2idx.keys():\n",
    "            token_list.append(tok2idx['<unk>'])\n",
    "        else:\n",
    "            token_list.append(tok2idx[word])\n",
    "\n",
    "    padding_list = [0] * (max_len - len(token_list))\n",
    "    token_list = padding_list + token_list\n",
    "    tokenized_idx_data.append(token_list)\n",
    "\n",
    "print(len(tokenized_idx_data), len(tokenized_idx_data[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 996)\n",
      "(24000,)\n",
      "now dumping pickle\n"
     ]
    }
   ],
   "source": [
    "train_tokenized_idx = np.array(tokenized_idx_data)\n",
    "train_labels_np = np.array(df_train['labels'])\n",
    "train_data = (train_tokenized_idx, train_labels_np)\n",
    "print(train_tokenized_idx.shape)\n",
    "print(train_labels_np.shape)\n",
    "\n",
    "print('now dumping pickle')\n",
    "# with open(file='ag_train.pkl', mode='wb') as f:\n",
    "with open(file='ag_train_sample.pkl', mode='wb') as f:\n",
    "    pickle.dump(train_data, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test max length: 892\n",
      "7600 996\n"
     ]
    }
   ],
   "source": [
    "# - 마찬가지로 test 에 대해서도\n",
    "\n",
    "test_data = [row['raw'] for i, row in df_test.iterrows()]\n",
    "\n",
    "test_max_len = 0\n",
    "for i in test_data:\n",
    "    if len(i) > test_max_len:\n",
    "        test_max_len = len(i)\n",
    "print(f'test max length: {test_max_len}')\n",
    "if test_max_len > max_len:\n",
    "    print('test max length is bigger than train_max_len')\n",
    "\n",
    "tokenized_idx_test_data = []\n",
    "\n",
    "for sentence in test_data:\n",
    "    tokened_sentence = tokenizer.tokenize(sentence)\n",
    "    token_list = []\n",
    "    for word in tokened_sentence:\n",
    "        if word not in tok2idx.keys():\n",
    "            token_list.append(tok2idx['<unk>'])\n",
    "        else:\n",
    "            token_list.append(tok2idx[word])\n",
    "\n",
    "    padding_list = [0] * (max_len - len(token_list))\n",
    "    token_list = padding_list + token_list\n",
    "    tokenized_idx_test_data.append(token_list)\n",
    "\n",
    "print(len(tokenized_idx_test_data), len(tokenized_idx_test_data[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7600, 996)\n",
      "(7600,)\n",
      "now dumping test pickle\n"
     ]
    }
   ],
   "source": [
    "test_tokenized_idx = np.array(tokenized_idx_test_data)\n",
    "test_labels_np = np.array(df_test['labels'])\n",
    "test_data = (test_tokenized_idx, test_labels_np)\n",
    "print(test_tokenized_idx.shape)\n",
    "print(test_labels_np.shape)\n",
    "\n",
    "print('now dumping test pickle')\n",
    "# with open(file='ag_test.pkl', mode='wb') as f:\n",
    "with open(file='ag_test_sample.pkl', mode='wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
