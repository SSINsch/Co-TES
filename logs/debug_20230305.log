2023-03-06 08:36:49 - utils._utils - DEBUG - [Args] (seed: 1), (model1: None), (model2: None), (noise_rate: 0.2)
2023-03-06 08:36:51 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 08:36:52 - utils._noise - DEBUG - 6, 7
2023-03-06 08:36:52 - utils._noise - DEBUG - 13997
2023-03-06 08:36:52 - utils._noise - INFO - Actual noise 0.20
2023-03-06 08:36:52 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-06 08:36:52 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-06 08:36:54 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 08:36:54 - __main__ - INFO - Loading dataset...
2023-03-06 08:36:54 - __main__ - INFO - Building model...
2023-03-06 08:36:58 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 08:36:58 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 08:36:58 - __main__ - INFO - log directory : logs/\news\coteaching_plus
2023-03-06 08:36:58 - __main__ - INFO - Start train & evaluate
2023-03-06 08:36:58 - __main__ - INFO - Epoch [0/100]
2023-03-06 08:39:58 - utils._utils - DEBUG - [Args] (seed: 1), (model1: None), (model2: None), (noise_rate: 0.2)
2023-03-06 08:40:14 - utils._utils - DEBUG - [Args] (seed: 1), (model1: None), (model2: None), (noise_rate: 0.2)
2023-03-06 08:40:16 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 08:40:16 - utils._noise - DEBUG - 6, 7
2023-03-06 08:40:16 - utils._noise - DEBUG - 13997
2023-03-06 08:40:16 - utils._noise - INFO - Actual noise 0.20
2023-03-06 08:40:16 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-06 08:40:16 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-06 08:40:18 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 08:40:18 - __main__ - INFO - Loading dataset...
2023-03-06 08:40:18 - __main__ - INFO - Building model...
2023-03-06 08:40:20 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 08:40:20 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 08:40:20 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-06 08:40:20 - __main__ - INFO - Start train & evaluate
2023-03-06 08:40:20 - __main__ - INFO - Epoch [0/100]
2023-03-06 08:40:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0158, Loss_2: 0.0160, Acc_1: 0.1016, Acc_2: 0.0938, 
2023-03-06 08:40:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0123, Loss_2: 0.0124, Acc_1: 0.5391, Acc_2: 0.5391, 
2023-03-06 08:40:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0120, Loss_2: 0.0123, Acc_1: 0.4844, Acc_2: 0.4609, 
2023-03-06 08:40:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0108, Loss_2: 0.0107, Acc_1: 0.5156, Acc_2: 0.4766, 
2023-03-06 08:40:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0111, Loss_2: 0.0109, Acc_1: 0.5625, Acc_2: 0.6016, 
2023-03-06 08:41:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0093, Loss_2: 0.0089, Acc_1: 0.6328, Acc_2: 0.6250, 
2023-03-06 08:41:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0099, Loss_2: 0.0100, Acc_1: 0.6484, Acc_2: 0.6719, 
2023-03-06 08:41:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0089, Loss_2: 0.0088, Acc_1: 0.6797, Acc_2: 0.6953, 
2023-03-06 08:41:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0100, Loss_2: 0.0095, Acc_1: 0.6094, Acc_2: 0.6328, 
2023-03-06 08:41:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0088, Loss_2: 0.0086, Acc_1: 0.6875, Acc_2: 0.7031, 
2023-03-06 08:41:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0101, Loss_2: 0.0101, Acc_1: 0.6172, Acc_2: 0.6406, 
2023-03-06 08:41:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0080, Loss_2: 0.0084, Acc_1: 0.7109, Acc_2: 0.7031, 
2023-03-06 08:42:41 - utils._utils - DEBUG - [Args] (seed: 1), (model1: None), (model2: None), (noise_rate: 0.2)
2023-03-06 08:42:43 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 08:42:43 - utils._noise - DEBUG - 6, 7
2023-03-06 08:42:43 - utils._noise - DEBUG - 13997
2023-03-06 08:42:43 - utils._noise - INFO - Actual noise 0.20
2023-03-06 08:42:43 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-06 08:42:43 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-06 08:42:45 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 08:42:45 - __main__ - INFO - Loading dataset...
2023-03-06 08:42:45 - __main__ - INFO - Building model...
2023-03-06 08:42:47 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 08:42:47 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 08:42:47 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-06 08:42:47 - __main__ - INFO - Start train & evaluate
2023-03-06 08:42:47 - __main__ - INFO - Epoch [0/100]
2023-03-06 08:42:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0158, Loss_2: 0.0160, Acc_1: 0.1016, Acc_2: 0.0938, 
2023-03-06 08:43:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0123, Loss_2: 0.0124, Acc_1: 0.5391, Acc_2: 0.5391, 
2023-03-06 08:43:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0120, Loss_2: 0.0123, Acc_1: 0.4844, Acc_2: 0.4609, 
2023-03-06 08:43:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0108, Loss_2: 0.0107, Acc_1: 0.5156, Acc_2: 0.4766, 
2023-03-06 08:43:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0111, Loss_2: 0.0109, Acc_1: 0.5625, Acc_2: 0.6016, 
2023-03-06 08:43:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0093, Loss_2: 0.0089, Acc_1: 0.6328, Acc_2: 0.6250, 
2023-03-06 08:43:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0099, Loss_2: 0.0100, Acc_1: 0.6484, Acc_2: 0.6719, 
2023-03-06 08:43:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0089, Loss_2: 0.0088, Acc_1: 0.6875, Acc_2: 0.7031, 
2023-03-06 08:43:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0100, Loss_2: 0.0095, Acc_1: 0.6094, Acc_2: 0.6328, 
2023-03-06 08:44:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0088, Loss_2: 0.0086, Acc_1: 0.6953, Acc_2: 0.7031, 
2023-03-06 08:44:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0101, Loss_2: 0.0101, Acc_1: 0.6172, Acc_2: 0.6406, 
2023-03-06 08:44:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0080, Loss_2: 0.0084, Acc_1: 0.7188, Acc_2: 0.7109, 
2023-03-06 08:44:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0059, Loss_2: 0.0059, Acc_1: 0.8585, Acc_2: 0.8597, F1-score_1: 0.8120, F1-score_2: 0.8107
2023-03-06 08:44:40 - __main__ - INFO - Epoch [1/100]
2023-03-06 08:44:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0073, Loss_2: 0.0074, Acc_1: 0.7500, Acc_2: 0.7578, 
2023-03-06 08:44:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0074, Loss_2: 0.0074, Acc_1: 0.6953, Acc_2: 0.7031, 
2023-03-06 08:45:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0063, Loss_2: 0.0063, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-06 08:45:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0079, Loss_2: 0.0075, Acc_1: 0.6875, Acc_2: 0.7266, 
2023-03-06 08:45:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0073, Loss_2: 0.0072, Acc_1: 0.7344, Acc_2: 0.7344, 
2023-03-06 08:45:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0079, Loss_2: 0.0079, Acc_1: 0.6797, Acc_2: 0.6797, 
2023-03-06 08:45:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0071, Loss_2: 0.0070, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-06 08:45:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0076, Loss_2: 0.0076, Acc_1: 0.7344, Acc_2: 0.7188, 
2023-03-06 08:45:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0060, Loss_2: 0.0061, Acc_1: 0.8125, Acc_2: 0.7734, 
2023-03-06 08:45:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0079, Loss_2: 0.0073, Acc_1: 0.7500, Acc_2: 0.7578, 
2023-03-06 08:46:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0078, Loss_2: 0.0080, Acc_1: 0.6719, Acc_2: 0.6797, 
2023-03-06 08:46:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0080, Loss_2: 0.0077, Acc_1: 0.6953, Acc_2: 0.7109, 
2023-03-06 08:46:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0049, Loss_2: 0.0048, Acc_1: 0.8704, Acc_2: 0.8663, F1-score_1: 0.8230, F1-score_2: 0.8099
2023-03-06 08:46:32 - __main__ - INFO - Epoch [2/100]
2023-03-06 08:46:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0052, Loss_2: 0.0055, Acc_1: 0.7188, Acc_2: 0.7578, 
2023-03-06 08:46:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0051, Loss_2: 0.0050, Acc_1: 0.7578, Acc_2: 0.7422, 
2023-03-06 08:46:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0052, Loss_2: 0.0054, Acc_1: 0.7109, Acc_2: 0.7031, 
2023-03-06 08:47:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0039, Loss_2: 0.0038, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-06 08:47:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0048, Loss_2: 0.0043, Acc_1: 0.7578, Acc_2: 0.7969, 
2023-03-06 08:47:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0051, Loss_2: 0.0046, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-06 08:47:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0038, Loss_2: 0.0034, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 08:47:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0051, Loss_2: 0.0053, Acc_1: 0.7891, Acc_2: 0.7734, 
2023-03-06 08:47:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0045, Loss_2: 0.0044, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-06 08:47:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0065, Loss_2: 0.0064, Acc_1: 0.7109, Acc_2: 0.7188, 
2023-03-06 08:47:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0064, Loss_2: 0.0067, Acc_1: 0.6875, Acc_2: 0.7188, 
2023-03-06 08:48:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0056, Loss_2: 0.0053, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-06 08:48:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0036, Loss_2: 0.0035, Acc_1: 0.8719, Acc_2: 0.8723, F1-score_1: 0.8244, F1-score_2: 0.8274
2023-03-06 08:48:24 - __main__ - INFO - Epoch [3/100]
2023-03-06 08:48:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0038, Loss_2: 0.0038, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-06 08:48:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0027, Loss_2: 0.0024, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 08:48:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0027, Loss_2: 0.0026, Acc_1: 0.8125, Acc_2: 0.8594, 
2023-03-06 08:48:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0022, Loss_2: 0.0021, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 08:49:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0029, Loss_2: 0.0027, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-06 08:49:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0021, Loss_2: 0.0023, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-06 08:49:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0034, Loss_2: 0.0034, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-06 08:49:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0039, Loss_2: 0.0047, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-06 08:49:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0033, Loss_2: 0.0030, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-06 08:49:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0036, Loss_2: 0.0038, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-06 08:49:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0036, Loss_2: 0.0035, Acc_1: 0.8203, Acc_2: 0.7656, 
2023-03-06 08:49:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0028, Loss_2: 0.0027, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 08:50:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0032, Acc_1: 0.8558, Acc_2: 0.8567, F1-score_1: 0.8157, F1-score_2: 0.8150
2023-03-06 08:50:14 - __main__ - INFO - Epoch [4/100]
2023-03-06 08:50:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0016, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-06 08:50:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0014, Loss_2: 0.0016, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 08:50:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0020, Loss_2: 0.0017, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 08:50:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0015, Loss_2: 0.0013, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 08:50:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 08:50:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0014, Loss_2: 0.0016, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 08:51:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0013, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-06 08:51:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 08:51:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0013, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 08:51:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0014, Loss_2: 0.0014, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-06 08:51:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0031, Loss_2: 0.0031, Acc_1: 0.7812, Acc_2: 0.8125, 
2023-03-06 08:51:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0014, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-06 08:51:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0023, Loss_2: 0.0026, Acc_1: 0.8619, Acc_2: 0.8572, F1-score_1: 0.8202, F1-score_2: 0.8169
2023-03-06 08:51:55 - __main__ - INFO - Epoch [5/100]
2023-03-06 08:52:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0016, Loss_2: 0.0019, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 08:52:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9609, Acc_2: 0.9766, 
2023-03-06 08:52:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 08:52:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 08:52:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.9297, 
2023-03-06 08:52:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 08:52:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 08:52:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 08:52:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0014, Loss_2: 0.0015, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 08:53:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0015, Loss_2: 0.0019, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-06 08:53:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 08:53:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 08:53:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0017, Acc_1: 0.8604, Acc_2: 0.8560, F1-score_1: 0.8182, F1-score_2: 0.8156
2023-03-06 08:53:36 - __main__ - INFO - Epoch [6/100]
2023-03-06 08:53:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.9531, Acc_2: 0.9609, 
2023-03-06 08:53:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 08:53:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 08:54:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 08:54:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 08:54:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 08:54:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-06 08:54:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 08:54:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 08:54:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 08:54:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-06 08:54:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 08:55:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0014, Acc_1: 0.8606, Acc_2: 0.8568, F1-score_1: 0.8214, F1-score_2: 0.8178
2023-03-06 08:55:18 - __main__ - INFO - Epoch [7/100]
2023-03-06 08:55:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 08:55:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 08:55:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-06 08:55:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9688, Acc_2: 0.9609, 
2023-03-06 08:55:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 08:55:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 08:56:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 08:56:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 08:56:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 08:56:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 08:56:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 08:56:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.9141, 
2023-03-06 08:56:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0008, Acc_1: 0.8662, Acc_2: 0.8643, F1-score_1: 0.8279, F1-score_2: 0.8267
2023-03-06 08:56:59 - __main__ - INFO - Epoch [8/100]
2023-03-06 08:57:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 08:57:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 08:57:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 08:57:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 08:57:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 08:57:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 08:57:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 08:57:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 08:58:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-06 08:58:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 08:58:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 08:58:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 08:58:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8657, Acc_2: 0.8658, F1-score_1: 0.8266, F1-score_2: 0.8281
2023-03-06 08:58:41 - __main__ - INFO - Epoch [9/100]
2023-03-06 08:58:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9297, 
2023-03-06 08:58:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9766, Acc_2: 0.9766, 
2023-03-06 08:59:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 08:59:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 08:59:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 08:59:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 08:59:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 08:59:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 08:59:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 08:59:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 08:59:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 09:00:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 09:00:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8660, Acc_2: 0.8660, F1-score_1: 0.8281, F1-score_2: 0.8287
2023-03-06 09:00:23 - __main__ - INFO - Epoch [10/100]
2023-03-06 09:00:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 09:00:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 09:00:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-06 09:00:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 09:00:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 09:01:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 09:01:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 09:01:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 09:01:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-06 09:01:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 09:01:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 09:01:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9688, Acc_2: 0.9609, 
2023-03-06 09:02:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8675, Acc_2: 0.8672, F1-score_1: 0.8318, F1-score_2: 0.8303
2023-03-06 09:02:04 - __main__ - INFO - Epoch [11/100]
2023-03-06 09:02:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 09:02:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-06 09:02:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:02:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 09:02:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 09:02:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 09:02:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 09:02:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 09:03:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 09:03:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 09:03:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-06 09:03:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 09:03:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8623, Acc_2: 0.8650, F1-score_1: 0.8260, F1-score_2: 0.8266
2023-03-06 09:03:46 - __main__ - INFO - Epoch [12/100]
2023-03-06 09:03:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 09:03:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 09:04:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 09:04:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:04:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:04:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 09:04:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 09:04:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 09:04:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:04:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9375, 
2023-03-06 09:05:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:05:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9141, 
2023-03-06 09:05:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8636, Acc_2: 0.8650, F1-score_1: 0.8278, F1-score_2: 0.8296
2023-03-06 09:05:27 - __main__ - INFO - Epoch [13/100]
2023-03-06 09:05:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 09:05:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 09:05:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 09:05:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:06:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 09:06:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:06:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:06:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 09:06:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 09:06:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9453, 
2023-03-06 09:06:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 09:06:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 09:07:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8651, Acc_2: 0.8684, F1-score_1: 0.8283, F1-score_2: 0.8319
2023-03-06 09:07:09 - __main__ - INFO - Epoch [14/100]
2023-03-06 09:07:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 09:07:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 09:07:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 09:07:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:07:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 09:07:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:07:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:08:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:08:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:08:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 09:08:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 09:08:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 09:08:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8646, Acc_2: 0.8650, F1-score_1: 0.8295, F1-score_2: 0.8260
2023-03-06 09:08:50 - __main__ - INFO - Epoch [15/100]
2023-03-06 09:08:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 09:09:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 09:09:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 09:09:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 09:09:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 09:09:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 09:09:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 09:09:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 09:09:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 09:09:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:10:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 09:10:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:10:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8643, Acc_2: 0.8667, F1-score_1: 0.8257, F1-score_2: 0.8310
2023-03-06 09:10:32 - __main__ - INFO - Epoch [16/100]
2023-03-06 09:10:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 09:10:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:10:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9297, 
2023-03-06 09:10:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 09:11:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:11:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 09:11:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 09:11:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 09:11:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 09:11:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 09:11:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 09:11:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 09:12:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8624, Acc_2: 0.8665, F1-score_1: 0.8276, F1-score_2: 0.8271
2023-03-06 09:12:13 - __main__ - INFO - Epoch [17/100]
2023-03-06 09:12:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 09:12:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 09:12:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 09:12:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:12:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 09:12:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 09:13:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:13:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:13:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 09:13:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:13:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:13:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 09:13:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8655, Acc_2: 0.8638, F1-score_1: 0.8285, F1-score_2: 0.8251
2023-03-06 09:13:55 - __main__ - INFO - Epoch [18/100]
2023-03-06 09:14:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 09:14:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 09:14:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 09:14:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 09:14:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-06 09:14:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 09:14:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 09:14:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 09:14:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 09:15:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 09:15:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:15:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 09:15:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8628, Acc_2: 0.8662, F1-score_1: 0.8265, F1-score_2: 0.8301
2023-03-06 09:15:36 - __main__ - INFO - Epoch [19/100]
2023-03-06 09:15:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 09:15:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 09:15:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 09:16:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 09:16:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 09:16:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 09:16:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-06 09:16:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 09:16:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 09:16:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 09:16:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:16:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 09:17:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8657, Acc_2: 0.8633, F1-score_1: 0.8294, F1-score_2: 0.8236
2023-03-06 09:17:18 - __main__ - INFO - Epoch [20/100]
2023-03-06 09:17:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 09:17:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 09:17:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 09:17:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:17:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 09:17:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 09:18:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 09:18:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 09:18:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 09:18:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-06 09:18:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 09:18:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 09:18:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8646, Acc_2: 0.8629, F1-score_1: 0.8283, F1-score_2: 0.8254
2023-03-06 09:18:59 - __main__ - INFO - Epoch [21/100]
2023-03-06 09:19:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:19:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 09:19:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:19:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 09:19:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 09:19:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 09:19:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 09:19:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 09:20:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:20:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 09:20:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 09:20:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:20:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8679, Acc_2: 0.8663, F1-score_1: 0.8328, F1-score_2: 0.8289
2023-03-06 09:20:40 - __main__ - INFO - Epoch [22/100]
2023-03-06 09:20:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 09:20:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 09:21:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 09:21:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 09:21:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 09:21:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 09:21:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 09:21:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 09:21:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 09:21:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:21:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 09:22:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 09:22:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8665, Acc_2: 0.8653, F1-score_1: 0.8298, F1-score_2: 0.8284
2023-03-06 09:22:22 - __main__ - INFO - Epoch [23/100]
2023-03-06 09:22:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 09:22:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 09:22:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 09:22:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 09:22:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:23:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 09:23:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 09:23:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-06 09:23:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:23:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 09:23:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 09:23:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 09:24:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8662, Acc_2: 0.8611, F1-score_1: 0.8285, F1-score_2: 0.8208
2023-03-06 09:24:03 - __main__ - INFO - Epoch [24/100]
2023-03-06 09:24:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-06 09:24:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 09:24:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:24:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 09:24:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 09:24:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 09:24:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:24:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 09:25:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 09:25:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-06 09:25:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 09:25:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 09:25:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0009, Acc_1: 0.8614, Acc_2: 0.8497, F1-score_1: 0.8211, F1-score_2: 0.8086
2023-03-06 09:25:44 - __main__ - INFO - Epoch [25/100]
2023-03-06 09:25:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 09:25:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:26:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 09:26:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 09:26:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 09:26:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 09:26:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 09:26:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 09:26:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0013, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 09:26:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-06 09:27:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 09:27:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 09:27:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0013, Acc_1: 0.8477, Acc_2: 0.8519, F1-score_1: 0.8063, F1-score_2: 0.8073
2023-03-06 09:27:26 - __main__ - INFO - Epoch [26/100]
2023-03-06 09:27:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-06 09:27:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 09:27:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-06 09:27:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-06 09:28:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:28:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 09:28:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0017, Loss_2: 0.0017, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-06 09:28:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-06 09:28:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-06 09:28:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:28:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 09:28:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0011, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 09:29:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0010, Acc_1: 0.8507, Acc_2: 0.8405, F1-score_1: 0.8092, F1-score_2: 0.7977
2023-03-06 09:29:07 - __main__ - INFO - Epoch [27/100]
2023-03-06 09:29:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:29:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 09:29:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-06 09:29:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 09:29:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 09:29:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 09:29:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-06 09:30:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0017, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-06 09:30:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 09:30:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 09:30:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0014, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-06 09:30:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0019, Loss_2: 0.0010, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 09:30:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.8354, Acc_2: 0.8264, F1-score_1: 0.7855, F1-score_2: 0.7794
2023-03-06 09:30:49 - __main__ - INFO - Epoch [28/100]
2023-03-06 09:30:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0017, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-06 09:31:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 09:31:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0011, Loss_2: 0.0015, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 09:31:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0012, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-06 09:31:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 09:31:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0013, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-06 09:31:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0019, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-06 09:31:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0030, Loss_2: 0.0017, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 09:31:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0015, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8984, 
2023-03-06 09:31:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0015, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8750, 
2023-03-06 09:32:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0026, Loss_2: 0.0010, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-06 09:32:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:32:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0022, Acc_1: 0.8417, Acc_2: 0.8218, F1-score_1: 0.8031, F1-score_2: 0.7794
2023-03-06 09:32:30 - __main__ - INFO - Epoch [29/100]
2023-03-06 09:32:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 09:32:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 09:32:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 09:32:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 09:33:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0016, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-06 09:33:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 09:33:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0017, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8672, 
2023-03-06 09:33:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:33:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 09:33:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 09:33:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 09:33:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 09:34:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.8410, Acc_2: 0.8387, F1-score_1: 0.8027, F1-score_2: 0.8021
2023-03-06 09:34:12 - __main__ - INFO - Epoch [30/100]
2023-03-06 09:34:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:34:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 09:34:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 09:34:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 09:34:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 09:34:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 09:35:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 09:35:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 09:35:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 09:35:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-06 09:35:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0013, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:35:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-06 09:35:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0013, Acc_1: 0.8402, Acc_2: 0.8409, F1-score_1: 0.7952, F1-score_2: 0.7982
2023-03-06 09:35:53 - __main__ - INFO - Epoch [31/100]
2023-03-06 09:35:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 09:36:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-06 09:36:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9531, 
2023-03-06 09:36:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 09:36:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 09:36:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 09:36:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:36:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 09:36:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 09:37:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 09:37:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 09:37:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0012, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 09:37:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0013, Acc_1: 0.8412, Acc_2: 0.8448, F1-score_1: 0.7986, F1-score_2: 0.8040
2023-03-06 09:37:35 - __main__ - INFO - Epoch [32/100]
2023-03-06 09:37:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:37:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 09:37:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:38:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:38:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 09:38:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 09:38:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 09:38:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 09:38:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 09:38:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 09:38:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:38:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 09:39:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0005, Acc_1: 0.8337, Acc_2: 0.8488, F1-score_1: 0.7903, F1-score_2: 0.8085
2023-03-06 09:39:16 - __main__ - INFO - Epoch [33/100]
2023-03-06 09:39:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 09:39:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-06 09:39:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-06 09:39:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:39:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 09:39:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:40:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 09:40:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 09:40:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 09:40:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 09:40:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 09:40:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-06 09:40:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0011, Acc_1: 0.8429, Acc_2: 0.8415, F1-score_1: 0.8034, F1-score_2: 0.7997
2023-03-06 09:40:58 - __main__ - INFO - Epoch [34/100]
2023-03-06 09:41:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 09:41:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 09:41:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 09:41:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 09:41:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 09:41:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:41:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 09:41:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 09:42:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 09:42:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:42:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 09:42:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 09:42:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0008, Acc_1: 0.8434, Acc_2: 0.8371, F1-score_1: 0.8023, F1-score_2: 0.7951
2023-03-06 09:42:39 - __main__ - INFO - Epoch [35/100]
2023-03-06 09:42:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 09:42:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 09:42:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 09:43:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 09:43:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:43:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 09:43:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:43:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:43:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 09:43:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 09:43:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0010, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 09:44:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 09:44:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0015, Acc_1: 0.8341, Acc_2: 0.8432, F1-score_1: 0.7904, F1-score_2: 0.8029
2023-03-06 09:44:20 - __main__ - INFO - Epoch [36/100]
2023-03-06 09:44:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 09:44:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-06 09:44:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:44:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 09:44:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 09:45:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 09:45:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:45:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 09:45:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 09:45:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-06 09:45:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 09:45:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:46:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0004, Acc_1: 0.8427, Acc_2: 0.8477, F1-score_1: 0.8028, F1-score_2: 0.8078
2023-03-06 09:46:02 - __main__ - INFO - Epoch [37/100]
2023-03-06 09:46:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:46:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 09:46:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:46:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 09:46:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:46:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:46:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 09:46:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:47:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 09:47:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:47:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-06 09:47:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 09:47:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0014, Acc_1: 0.8300, Acc_2: 0.8353, F1-score_1: 0.7888, F1-score_2: 0.7916
2023-03-06 09:47:43 - __main__ - INFO - Epoch [38/100]
2023-03-06 09:47:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 09:47:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 09:48:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 09:48:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 09:48:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 09:48:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:48:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 09:48:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 09:48:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:48:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:48:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 09:49:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-06 09:49:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0011, Loss_2: 0.0016, Acc_1: 0.8388, Acc_2: 0.8395, F1-score_1: 0.7972, F1-score_2: 0.8016
2023-03-06 09:49:25 - __main__ - INFO - Epoch [39/100]
2023-03-06 09:49:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:49:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 09:49:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 09:49:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 09:49:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:50:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 09:50:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 09:50:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 09:50:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-06 09:50:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 09:50:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 09:50:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 09:51:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0017, Acc_1: 0.8397, Acc_2: 0.8471, F1-score_1: 0.7986, F1-score_2: 0.8068
2023-03-06 09:51:06 - __main__ - INFO - Epoch [40/100]
2023-03-06 09:51:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 09:51:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 09:51:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 09:51:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 09:51:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:51:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:51:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 09:52:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 09:52:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 09:52:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 09:52:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 09:52:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 09:52:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0017, Acc_1: 0.8427, Acc_2: 0.8478, F1-score_1: 0.8039, F1-score_2: 0.8072
2023-03-06 09:52:48 - __main__ - INFO - Epoch [41/100]
2023-03-06 09:52:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 09:53:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 09:53:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 09:53:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 09:53:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 09:53:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-06 09:53:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 09:53:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:53:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 09:53:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 09:54:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 09:54:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 09:54:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0008, Acc_1: 0.8407, Acc_2: 0.8473, F1-score_1: 0.7995, F1-score_2: 0.8075
2023-03-06 09:54:29 - __main__ - INFO - Epoch [42/100]
2023-03-06 09:54:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 09:54:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-06 09:54:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:54:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 09:55:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 09:55:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 09:55:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 09:55:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 09:55:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-06 09:55:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:55:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 09:55:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 09:56:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0013, Acc_1: 0.8381, Acc_2: 0.8465, F1-score_1: 0.7970, F1-score_2: 0.8061
2023-03-06 09:56:10 - __main__ - INFO - Epoch [43/100]
2023-03-06 09:56:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 09:56:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9609, 
2023-03-06 09:56:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 09:56:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 09:56:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 09:56:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 09:56:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 09:57:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 09:57:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 09:57:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 09:57:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 09:57:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 09:57:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0011, Acc_1: 0.8436, Acc_2: 0.8410, F1-score_1: 0.8021, F1-score_2: 0.8034
2023-03-06 09:57:52 - __main__ - INFO - Epoch [44/100]
2023-03-06 09:57:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 09:58:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 09:58:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 09:58:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 09:58:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-06 09:58:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-06 09:58:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:58:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:58:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 09:59:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 09:59:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 09:59:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 09:59:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0016, Acc_1: 0.8436, Acc_2: 0.8385, F1-score_1: 0.8030, F1-score_2: 0.7968
2023-03-06 09:59:33 - __main__ - INFO - Epoch [45/100]
2023-03-06 09:59:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 09:59:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 09:59:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 10:00:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 10:00:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 10:00:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 10:00:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 10:00:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 10:00:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 10:00:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 10:00:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 10:00:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 10:01:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0013, Acc_1: 0.8370, Acc_2: 0.8453, F1-score_1: 0.7965, F1-score_2: 0.8087
2023-03-06 10:01:15 - __main__ - INFO - Epoch [46/100]
2023-03-06 10:01:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:01:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 10:01:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 10:01:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 10:01:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-06 10:01:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 10:02:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 10:02:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:02:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-06 10:02:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 10:02:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 10:02:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 10:02:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0006, Acc_1: 0.8439, Acc_2: 0.8453, F1-score_1: 0.8041, F1-score_2: 0.8051
2023-03-06 10:02:56 - __main__ - INFO - Epoch [47/100]
2023-03-06 10:03:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 10:03:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:03:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 10:03:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 10:03:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 10:03:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 10:03:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:03:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:03:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 10:04:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 10:04:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 10:04:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 10:04:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0005, Acc_1: 0.8466, Acc_2: 0.8419, F1-score_1: 0.8059, F1-score_2: 0.7968
2023-03-06 10:04:37 - __main__ - INFO - Epoch [48/100]
2023-03-06 10:04:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:04:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 10:04:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 10:05:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 10:05:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 10:05:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:05:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 10:05:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 10:05:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 10:05:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-06 10:05:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 10:05:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 10:06:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0001, Acc_1: 0.8388, Acc_2: 0.8453, F1-score_1: 0.7963, F1-score_2: 0.8063
2023-03-06 10:06:19 - __main__ - INFO - Epoch [49/100]
2023-03-06 10:06:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:06:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 10:06:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 10:06:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:06:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:07:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-06 10:07:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 10:07:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 10:07:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 10:07:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 10:07:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-06 10:07:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:08:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0007, Acc_1: 0.8395, Acc_2: 0.8397, F1-score_1: 0.7974, F1-score_2: 0.8019
2023-03-06 10:08:01 - __main__ - INFO - Epoch [50/100]
2023-03-06 10:08:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 10:08:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 10:08:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:08:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 10:08:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 10:08:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 10:08:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 10:08:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 10:09:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:09:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 10:09:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 10:09:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:09:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0026, Acc_1: 0.8492, Acc_2: 0.8402, F1-score_1: 0.8111, F1-score_2: 0.8031
2023-03-06 10:09:42 - __main__ - INFO - Epoch [51/100]
2023-03-06 10:09:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9688, Acc_2: 0.9688, 
2023-03-06 10:09:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 10:10:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 10:10:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-06 10:10:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 10:10:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:10:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0010, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-06 10:10:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:10:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 10:10:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 10:10:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 10:11:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 10:11:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0030, Acc_1: 0.8407, Acc_2: 0.8331, F1-score_1: 0.8001, F1-score_2: 0.7881
2023-03-06 10:11:23 - __main__ - INFO - Epoch [52/100]
2023-03-06 10:11:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:11:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 10:11:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 10:11:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 10:11:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 10:12:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:12:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:12:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:12:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 10:12:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:12:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0010, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:12:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 10:13:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0011, Acc_1: 0.8193, Acc_2: 0.8444, F1-score_1: 0.7779, F1-score_2: 0.8046
2023-03-06 10:13:05 - __main__ - INFO - Epoch [53/100]
2023-03-06 10:13:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 10:13:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 10:13:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 10:13:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 10:13:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:13:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:13:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 10:14:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 10:14:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:14:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 10:14:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 10:14:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:14:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0008, Acc_1: 0.8319, Acc_2: 0.8393, F1-score_1: 0.7893, F1-score_2: 0.8000
2023-03-06 10:14:46 - __main__ - INFO - Epoch [54/100]
2023-03-06 10:14:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 10:14:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-06 10:15:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 10:15:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 10:15:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:15:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:15:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:15:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:15:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 10:15:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 10:16:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9688, Acc_2: 0.9609, 
2023-03-06 10:16:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 10:16:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0026, Acc_1: 0.8424, Acc_2: 0.8332, F1-score_1: 0.8016, F1-score_2: 0.7897
2023-03-06 10:16:28 - __main__ - INFO - Epoch [55/100]
2023-03-06 10:16:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 10:16:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 10:16:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0015, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 10:16:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:17:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 10:17:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 10:17:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:17:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 10:17:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 10:17:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 10:17:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:17:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:18:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0016, Acc_1: 0.8393, Acc_2: 0.8405, F1-score_1: 0.7961, F1-score_2: 0.8017
2023-03-06 10:18:09 - __main__ - INFO - Epoch [56/100]
2023-03-06 10:18:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 10:18:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 10:18:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 10:18:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 10:18:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:18:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 10:18:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 10:19:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:19:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:19:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 10:19:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 10:19:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 10:19:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0003, Acc_1: 0.8446, Acc_2: 0.8346, F1-score_1: 0.8061, F1-score_2: 0.7929
2023-03-06 10:19:51 - __main__ - INFO - Epoch [57/100]
2023-03-06 10:19:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:20:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8672, 
2023-03-06 10:20:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-06 10:20:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-06 10:20:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 10:20:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-06 10:20:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 10:20:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:20:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 10:20:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:21:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:21:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:21:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0016, Acc_1: 0.8342, Acc_2: 0.8336, F1-score_1: 0.7922, F1-score_2: 0.7930
2023-03-06 10:21:32 - __main__ - INFO - Epoch [58/100]
2023-03-06 10:21:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:21:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:21:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-06 10:21:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:22:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 10:22:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 10:22:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 10:22:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 10:22:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 10:22:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 10:22:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 10:22:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 10:23:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.8434, Acc_2: 0.8388, F1-score_1: 0.7978, F1-score_2: 0.7946
2023-03-06 10:23:13 - __main__ - INFO - Epoch [59/100]
2023-03-06 10:23:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:23:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:23:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 10:23:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-06 10:23:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 10:23:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 10:24:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:24:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 10:24:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 10:24:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 10:24:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:24:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:24:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0015, Acc_1: 0.8349, Acc_2: 0.8286, F1-score_1: 0.7911, F1-score_2: 0.7872
2023-03-06 10:24:54 - __main__ - INFO - Epoch [60/100]
2023-03-06 10:25:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 10:25:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 10:25:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:25:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-06 10:25:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:25:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:25:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 10:25:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-06 10:25:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 10:26:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 10:26:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 10:26:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:26:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0025, Acc_1: 0.8422, Acc_2: 0.8278, F1-score_1: 0.8004, F1-score_2: 0.7870
2023-03-06 10:26:36 - __main__ - INFO - Epoch [61/100]
2023-03-06 10:26:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 10:26:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-06 10:26:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 10:27:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 10:27:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 10:27:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:27:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 10:27:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 10:27:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 10:27:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 10:27:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:27:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 10:28:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0006, Acc_1: 0.8468, Acc_2: 0.8353, F1-score_1: 0.8062, F1-score_2: 0.7957
2023-03-06 10:28:17 - __main__ - INFO - Epoch [62/100]
2023-03-06 10:28:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 10:28:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-06 10:28:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 10:28:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 10:28:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 10:28:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:29:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:29:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:29:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:29:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:29:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:29:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 10:29:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0009, Acc_1: 0.8400, Acc_2: 0.8371, F1-score_1: 0.8014, F1-score_2: 0.7984
2023-03-06 10:29:59 - __main__ - INFO - Epoch [63/100]
2023-03-06 10:30:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 10:30:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 10:30:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0019, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 10:30:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:30:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 10:30:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 10:30:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:30:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:31:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 10:31:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 10:31:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 10:31:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:31:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0048, Acc_1: 0.8392, Acc_2: 0.8308, F1-score_1: 0.7976, F1-score_2: 0.7900
2023-03-06 10:31:40 - __main__ - INFO - Epoch [64/100]
2023-03-06 10:31:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:31:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 10:32:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:32:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:32:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 10:32:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 10:32:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-06 10:32:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 10:32:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-06 10:32:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 10:32:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 10:33:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 10:33:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0011, Loss_2: 0.0019, Acc_1: 0.8410, Acc_2: 0.8312, F1-score_1: 0.7996, F1-score_2: 0.7897
2023-03-06 10:33:21 - __main__ - INFO - Epoch [65/100]
2023-03-06 10:33:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 10:33:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:33:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 10:33:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:33:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 10:34:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 10:34:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:34:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:34:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:34:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 10:34:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 10:34:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:35:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0021, Acc_1: 0.8254, Acc_2: 0.8336, F1-score_1: 0.7865, F1-score_2: 0.7917
2023-03-06 10:35:03 - __main__ - INFO - Epoch [66/100]
2023-03-06 10:35:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 10:35:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9141, 
2023-03-06 10:35:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 10:35:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 10:35:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 10:35:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:35:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0010, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 10:35:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 10:36:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 10:36:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 10:36:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:36:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:36:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0023, Acc_1: 0.8347, Acc_2: 0.8213, F1-score_1: 0.7946, F1-score_2: 0.7810
2023-03-06 10:36:44 - __main__ - INFO - Epoch [67/100]
2023-03-06 10:36:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0009, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 10:36:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 10:37:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:37:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:37:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:37:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 10:37:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 10:37:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 10:37:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 10:37:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:38:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 10:38:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 10:38:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0013, Acc_1: 0.8359, Acc_2: 0.8336, F1-score_1: 0.7942, F1-score_2: 0.7940
2023-03-06 10:38:26 - __main__ - INFO - Epoch [68/100]
2023-03-06 10:38:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:38:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 10:38:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 10:38:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 10:38:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 10:39:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 10:39:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-06 10:39:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 10:39:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:39:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 10:39:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 10:39:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 10:40:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0025, Acc_1: 0.8334, Acc_2: 0.8242, F1-score_1: 0.7902, F1-score_2: 0.7828
2023-03-06 10:40:07 - __main__ - INFO - Epoch [69/100]
2023-03-06 10:40:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:40:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 10:40:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 10:40:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 10:40:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:40:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:40:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 10:41:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 10:41:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:41:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:41:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 10:41:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:41:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0017, Acc_1: 0.8383, Acc_2: 0.8314, F1-score_1: 0.7944, F1-score_2: 0.7874
2023-03-06 10:41:49 - __main__ - INFO - Epoch [70/100]
2023-03-06 10:41:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 10:42:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 10:42:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:42:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 10:42:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 10:42:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 10:42:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 10:42:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:42:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:42:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:43:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 10:43:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 10:43:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0031, Acc_1: 0.8314, Acc_2: 0.8184, F1-score_1: 0.7911, F1-score_2: 0.7709
2023-03-06 10:43:30 - __main__ - INFO - Epoch [71/100]
2023-03-06 10:43:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:43:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 10:43:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 10:43:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:44:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 10:44:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 10:44:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:44:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0023, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 10:44:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9531, Acc_2: 0.9297, 
2023-03-06 10:44:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 10:44:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 10:44:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:45:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0014, Acc_1: 0.8378, Acc_2: 0.8280, F1-score_1: 0.7948, F1-score_2: 0.7904
2023-03-06 10:45:11 - __main__ - INFO - Epoch [72/100]
2023-03-06 10:45:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:45:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0014, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 10:45:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 10:45:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 10:45:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 10:45:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 10:45:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 10:46:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 10:46:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 10:46:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-06 10:46:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 10:46:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:46:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8424, Acc_2: 0.8315, F1-score_1: 0.7982, F1-score_2: 0.7886
2023-03-06 10:46:53 - __main__ - INFO - Epoch [73/100]
2023-03-06 10:46:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 10:47:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 10:47:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:47:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 10:47:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 10:47:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 10:47:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:47:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:47:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:48:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 10:48:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 10:48:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-06 10:48:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0029, Acc_1: 0.8354, Acc_2: 0.8319, F1-score_1: 0.7916, F1-score_2: 0.7915
2023-03-06 10:48:34 - __main__ - INFO - Epoch [74/100]
2023-03-06 10:48:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 10:48:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 10:48:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:49:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:49:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 10:49:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 10:49:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 10:49:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 10:49:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 10:49:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:49:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-06 10:49:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0021, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-06 10:50:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0055, Acc_1: 0.8315, Acc_2: 0.8178, F1-score_1: 0.7882, F1-score_2: 0.7701
2023-03-06 10:50:16 - __main__ - INFO - Epoch [75/100]
2023-03-06 10:50:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 10:50:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 10:50:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 10:50:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 10:50:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 10:50:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 10:51:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 10:51:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 10:51:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 10:51:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 10:51:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 10:51:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:51:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0001, Acc_1: 0.8283, Acc_2: 0.8263, F1-score_1: 0.7863, F1-score_2: 0.7834
2023-03-06 10:51:57 - __main__ - INFO - Epoch [76/100]
2023-03-06 10:52:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 10:52:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 10:52:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 10:52:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:52:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 10:52:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 10:52:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:52:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 10:52:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 10:53:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 10:53:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 10:53:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 10:53:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0040, Acc_1: 0.8317, Acc_2: 0.8247, F1-score_1: 0.7864, F1-score_2: 0.7780
2023-03-06 10:53:39 - __main__ - INFO - Epoch [77/100]
2023-03-06 10:53:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 10:53:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:53:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 10:54:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:54:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 10:54:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 10:54:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 10:54:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 10:54:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 10:54:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 10:54:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 10:55:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 10:55:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0041, Acc_1: 0.8319, Acc_2: 0.8356, F1-score_1: 0.7893, F1-score_2: 0.7907
2023-03-06 10:55:20 - __main__ - INFO - Epoch [78/100]
2023-03-06 10:55:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 10:55:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 10:55:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:55:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:55:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 10:56:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 10:56:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 10:56:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:56:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:56:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 10:56:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:56:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 10:57:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0013, Acc_1: 0.8305, Acc_2: 0.8342, F1-score_1: 0.7851, F1-score_2: 0.7910
2023-03-06 10:57:01 - __main__ - INFO - Epoch [79/100]
2023-03-06 10:57:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 10:57:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 10:57:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 10:57:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 10:57:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:57:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 10:57:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:57:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 10:58:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 10:58:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 10:58:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 10:58:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 10:58:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0016, Acc_1: 0.8290, Acc_2: 0.8334, F1-score_1: 0.7846, F1-score_2: 0.7906
2023-03-06 10:58:43 - __main__ - INFO - Epoch [80/100]
2023-03-06 10:58:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 10:58:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 10:59:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 10:59:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 10:59:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 10:59:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 10:59:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 10:59:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 10:59:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 10:59:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 10:59:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 11:00:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:00:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0018, Acc_1: 0.8266, Acc_2: 0.8308, F1-score_1: 0.7837, F1-score_2: 0.7865
2023-03-06 11:00:24 - __main__ - INFO - Epoch [81/100]
2023-03-06 11:00:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:00:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-06 11:00:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 11:00:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 11:00:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:01:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 11:01:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:01:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:01:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:01:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 11:01:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 11:01:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0028, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 11:02:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0023, Loss_2: 0.0038, Acc_1: 0.8132, Acc_2: 0.8268, F1-score_1: 0.7680, F1-score_2: 0.7831
2023-03-06 11:02:06 - __main__ - INFO - Epoch [82/100]
2023-03-06 11:02:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 11:02:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:02:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:02:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 11:02:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 11:02:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 11:02:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 11:03:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 11:03:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:03:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 11:03:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 11:03:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 11:03:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0040, Acc_1: 0.8278, Acc_2: 0.8288, F1-score_1: 0.7882, F1-score_2: 0.7858
2023-03-06 11:03:47 - __main__ - INFO - Epoch [83/100]
2023-03-06 11:03:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 11:03:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:04:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:04:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:04:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 11:04:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:04:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-06 11:04:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 11:04:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:04:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-06 11:05:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:05:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0015, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 11:05:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0013, Acc_1: 0.8256, Acc_2: 0.8266, F1-score_1: 0.7790, F1-score_2: 0.7832
2023-03-06 11:05:28 - __main__ - INFO - Epoch [84/100]
2023-03-06 11:05:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:05:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 11:05:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 11:05:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 11:06:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:06:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 11:06:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:06:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 11:06:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:06:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:06:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 11:06:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:07:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0025, Acc_1: 0.8210, Acc_2: 0.8232, F1-score_1: 0.7751, F1-score_2: 0.7771
2023-03-06 11:07:10 - __main__ - INFO - Epoch [85/100]
2023-03-06 11:07:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:07:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 11:07:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:07:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 11:07:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:07:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 11:07:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:08:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 11:08:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 11:08:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:08:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:08:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:08:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0028, Loss_2: 0.0032, Acc_1: 0.8307, Acc_2: 0.8298, F1-score_1: 0.7870, F1-score_2: 0.7854
2023-03-06 11:08:51 - __main__ - INFO - Epoch [86/100]
2023-03-06 11:08:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 11:09:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:09:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 11:09:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 11:09:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-06 11:09:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 11:09:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 11:09:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:09:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:10:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:10:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:10:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 11:10:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0011, Acc_1: 0.8308, Acc_2: 0.8259, F1-score_1: 0.7884, F1-score_2: 0.7814
2023-03-06 11:10:33 - __main__ - INFO - Epoch [87/100]
2023-03-06 11:10:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:10:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:10:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 11:10:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:11:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 11:11:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 11:11:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:11:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 11:11:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 11:11:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 11:11:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 11:11:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 11:12:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0016, Acc_1: 0.8319, Acc_2: 0.8315, F1-score_1: 0.7871, F1-score_2: 0.7881
2023-03-06 11:12:14 - __main__ - INFO - Epoch [88/100]
2023-03-06 11:12:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:12:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:12:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:12:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 11:12:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:12:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:13:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 11:13:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 11:13:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:13:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:13:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 11:13:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 11:13:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0023, Acc_1: 0.8341, Acc_2: 0.8290, F1-score_1: 0.7903, F1-score_2: 0.7845
2023-03-06 11:13:55 - __main__ - INFO - Epoch [89/100]
2023-03-06 11:14:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:14:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:14:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:14:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 11:14:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:14:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:14:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 11:14:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 11:14:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 11:15:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 11:15:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:15:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 11:15:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0015, Acc_1: 0.8259, Acc_2: 0.8271, F1-score_1: 0.7798, F1-score_2: 0.7840
2023-03-06 11:15:37 - __main__ - INFO - Epoch [90/100]
2023-03-06 11:15:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 11:15:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:15:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 11:16:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:16:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:16:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:16:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:16:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:16:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:16:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 11:16:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 11:16:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 11:17:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0014, Acc_1: 0.8286, Acc_2: 0.8280, F1-score_1: 0.7856, F1-score_2: 0.7837
2023-03-06 11:17:18 - __main__ - INFO - Epoch [91/100]
2023-03-06 11:17:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 11:17:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:17:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 11:17:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:17:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:17:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 11:18:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:18:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:18:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:18:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:18:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:18:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:19:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8297, Acc_2: 0.8244, F1-score_1: 0.7858, F1-score_2: 0.7798
2023-03-06 11:19:00 - __main__ - INFO - Epoch [92/100]
2023-03-06 11:19:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 11:19:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:19:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-06 11:19:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 11:19:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 11:19:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:19:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 11:19:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:20:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:20:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:20:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:20:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:20:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8285, Acc_2: 0.8247, F1-score_1: 0.7839, F1-score_2: 0.7815
2023-03-06 11:20:41 - __main__ - INFO - Epoch [93/100]
2023-03-06 11:20:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 11:20:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:21:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:21:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:21:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 11:21:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 11:21:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:21:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:21:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:21:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 11:21:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:22:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:22:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0009, Acc_1: 0.8286, Acc_2: 0.8303, F1-score_1: 0.7848, F1-score_2: 0.7862
2023-03-06 11:22:23 - __main__ - INFO - Epoch [94/100]
2023-03-06 11:22:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:22:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:22:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:22:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 11:22:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 11:23:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 11:23:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:23:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:23:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 11:23:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:23:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:23:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 11:24:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0008, Acc_1: 0.8312, Acc_2: 0.8319, F1-score_1: 0.7881, F1-score_2: 0.7881
2023-03-06 11:24:04 - __main__ - INFO - Epoch [95/100]
2023-03-06 11:24:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:24:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:24:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 11:24:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:24:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:24:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 11:24:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:24:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 11:25:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 11:25:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:25:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 11:25:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:25:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0010, Acc_1: 0.8302, Acc_2: 0.8329, F1-score_1: 0.7855, F1-score_2: 0.7894
2023-03-06 11:25:45 - __main__ - INFO - Epoch [96/100]
2023-03-06 11:25:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:25:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 11:26:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 11:26:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 11:26:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:26:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 11:26:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:26:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:26:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:26:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:27:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 11:27:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:27:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0010, Acc_1: 0.8303, Acc_2: 0.8325, F1-score_1: 0.7851, F1-score_2: 0.7879
2023-03-06 11:27:27 - __main__ - INFO - Epoch [97/100]
2023-03-06 11:27:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:27:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:27:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 11:27:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 11:28:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 11:28:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 11:28:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 11:28:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:28:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 11:28:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 11:28:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 11:28:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 11:29:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.8297, Acc_2: 0.8337, F1-score_1: 0.7854, F1-score_2: 0.7899
2023-03-06 11:29:08 - __main__ - INFO - Epoch [98/100]
2023-03-06 11:29:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:29:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 11:29:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 11:29:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:29:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 11:29:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 11:29:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 11:30:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 11:30:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:30:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:30:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:30:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 11:30:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.8300, Acc_2: 0.8320, F1-score_1: 0.7859, F1-score_2: 0.7881
2023-03-06 11:30:50 - __main__ - INFO - Epoch [99/100]
2023-03-06 11:30:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:31:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:31:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 11:31:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:31:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 11:31:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:31:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 11:31:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 11:31:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 11:31:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:32:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:32:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:32:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.8312, Acc_2: 0.8322, F1-score_1: 0.7860, F1-score_2: 0.7882
2023-03-06 11:32:33 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 11:32:34 - utils._noise - DEBUG - 6, 7
2023-03-06 11:32:34 - utils._noise - DEBUG - 13997
2023-03-06 11:32:34 - utils._noise - INFO - Actual noise 0.20
2023-03-06 11:32:34 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-06 11:32:34 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-06 11:32:36 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 11:32:36 - __main__ - INFO - Loading dataset...
2023-03-06 11:32:36 - __main__ - INFO - Building model...
2023-03-06 11:32:36 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 11:32:36 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 11:32:36 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-06 11:32:36 - __main__ - INFO - Start train & evaluate
2023-03-06 11:32:36 - __main__ - INFO - Epoch [0/100]
2023-03-06 11:32:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0155, Loss_2: 0.0156, Acc_1: 0.1328, Acc_2: 0.1719, 
2023-03-06 11:32:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0129, Loss_2: 0.0127, Acc_1: 0.4062, Acc_2: 0.4141, 
2023-03-06 11:32:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0115, Loss_2: 0.0112, Acc_1: 0.5391, Acc_2: 0.5703, 
2023-03-06 11:33:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0101, Loss_2: 0.0103, Acc_1: 0.6016, Acc_2: 0.5859, 
2023-03-06 11:33:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0101, Loss_2: 0.0104, Acc_1: 0.6094, Acc_2: 0.6094, 
2023-03-06 11:33:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0105, Loss_2: 0.0102, Acc_1: 0.6172, Acc_2: 0.6406, 
2023-03-06 11:33:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0083, Loss_2: 0.0083, Acc_1: 0.7031, Acc_2: 0.6719, 
2023-03-06 11:33:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0113, Loss_2: 0.0111, Acc_1: 0.6172, Acc_2: 0.6484, 
2023-03-06 11:33:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0097, Loss_2: 0.0100, Acc_1: 0.6797, Acc_2: 0.6484, 
2023-03-06 11:33:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0078, Loss_2: 0.0081, Acc_1: 0.7422, Acc_2: 0.7344, 
2023-03-06 11:33:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0101, Loss_2: 0.0100, Acc_1: 0.6250, Acc_2: 0.6328, 
2023-03-06 11:33:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0091, Loss_2: 0.0089, Acc_1: 0.6484, Acc_2: 0.6875, 
2023-03-06 11:34:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0057, Acc_1: 0.8597, Acc_2: 0.8587, F1-score_1: 0.8006, F1-score_2: 0.7999
2023-03-06 11:34:17 - __main__ - INFO - Epoch [1/100]
2023-03-06 11:34:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0071, Loss_2: 0.0071, Acc_1: 0.7422, Acc_2: 0.7266, 
2023-03-06 11:34:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0061, Loss_2: 0.0058, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-06 11:34:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0070, Loss_2: 0.0070, Acc_1: 0.7031, Acc_2: 0.7266, 
2023-03-06 11:34:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0085, Loss_2: 0.0088, Acc_1: 0.6719, Acc_2: 0.6719, 
2023-03-06 11:34:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0070, Loss_2: 0.0071, Acc_1: 0.7188, Acc_2: 0.7188, 
2023-03-06 11:34:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0076, Loss_2: 0.0073, Acc_1: 0.6875, Acc_2: 0.6797, 
2023-03-06 11:35:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0064, Loss_2: 0.0068, Acc_1: 0.7422, Acc_2: 0.7344, 
2023-03-06 11:35:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0063, Loss_2: 0.0060, Acc_1: 0.7422, Acc_2: 0.7266, 
2023-03-06 11:35:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0080, Loss_2: 0.0076, Acc_1: 0.7344, Acc_2: 0.7422, 
2023-03-06 11:35:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0068, Loss_2: 0.0070, Acc_1: 0.7500, Acc_2: 0.7500, 
2023-03-06 11:35:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0063, Loss_2: 0.0064, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-06 11:35:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0071, Loss_2: 0.0070, Acc_1: 0.7188, Acc_2: 0.7500, 
2023-03-06 11:35:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0046, Loss_2: 0.0048, Acc_1: 0.8702, Acc_2: 0.8662, F1-score_1: 0.8266, F1-score_2: 0.8234
2023-03-06 11:35:59 - __main__ - INFO - Epoch [2/100]
2023-03-06 11:36:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0049, Loss_2: 0.0048, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-06 11:36:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0047, Loss_2: 0.0043, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-06 11:36:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0052, Loss_2: 0.0053, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-06 11:36:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0051, Loss_2: 0.0051, Acc_1: 0.7734, Acc_2: 0.7891, 
2023-03-06 11:36:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0062, Loss_2: 0.0060, Acc_1: 0.7031, Acc_2: 0.7031, 
2023-03-06 11:36:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0039, Loss_2: 0.0037, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-06 11:36:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0040, Loss_2: 0.0044, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-06 11:36:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0043, Loss_2: 0.0040, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-06 11:37:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0068, Loss_2: 0.0069, Acc_1: 0.6953, Acc_2: 0.6953, 
2023-03-06 11:37:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0053, Loss_2: 0.0053, Acc_1: 0.7578, Acc_2: 0.7422, 
2023-03-06 11:37:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0050, Loss_2: 0.0047, Acc_1: 0.7578, Acc_2: 0.7891, 
2023-03-06 11:37:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0056, Loss_2: 0.0054, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-06 11:37:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0034, Acc_1: 0.8743, Acc_2: 0.8762, F1-score_1: 0.8301, F1-score_2: 0.8308
2023-03-06 11:37:40 - __main__ - INFO - Epoch [3/100]
2023-03-06 11:37:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0030, Loss_2: 0.0027, Acc_1: 0.8125, Acc_2: 0.8438, 
2023-03-06 11:37:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0021, Loss_2: 0.0020, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:37:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0025, Loss_2: 0.0022, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 11:38:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0031, Loss_2: 0.0033, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-06 11:38:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0032, Loss_2: 0.0031, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-06 11:38:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0036, Loss_2: 0.0037, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-06 11:38:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0034, Loss_2: 0.0029, Acc_1: 0.8047, Acc_2: 0.8359, 
2023-03-06 11:38:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0034, Loss_2: 0.0038, Acc_1: 0.7812, Acc_2: 0.8125, 
2023-03-06 11:38:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0038, Loss_2: 0.0037, Acc_1: 0.7578, Acc_2: 0.7891, 
2023-03-06 11:38:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0038, Loss_2: 0.0039, Acc_1: 0.7969, Acc_2: 0.7578, 
2023-03-06 11:38:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0034, Loss_2: 0.0033, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-06 11:39:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0045, Loss_2: 0.0038, Acc_1: 0.7578, Acc_2: 0.7891, 
2023-03-06 11:39:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0027, Acc_1: 0.8640, Acc_2: 0.8621, F1-score_1: 0.8195, F1-score_2: 0.8196
2023-03-06 11:39:21 - __main__ - INFO - Epoch [4/100]
2023-03-06 11:39:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0015, Loss_2: 0.0017, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-06 11:39:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0033, Loss_2: 0.0029, Acc_1: 0.7969, Acc_2: 0.8359, 
2023-03-06 11:39:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0016, Loss_2: 0.0015, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 11:39:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0014, Loss_2: 0.0014, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 11:39:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0022, Loss_2: 0.0019, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:40:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0021, Loss_2: 0.0021, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 11:40:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0025, Loss_2: 0.0024, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-06 11:40:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0021, Loss_2: 0.0025, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 11:40:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0013, Loss_2: 0.0012, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 11:40:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0014, Loss_2: 0.0015, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 11:40:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 11:40:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:41:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0019, Acc_1: 0.8677, Acc_2: 0.8646, F1-score_1: 0.8253, F1-score_2: 0.8200
2023-03-06 11:41:03 - __main__ - INFO - Epoch [5/100]
2023-03-06 11:41:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0011, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 11:41:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 11:41:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 11:41:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:41:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0010, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 11:41:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0012, Loss_2: 0.0011, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:41:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 11:41:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0011, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:42:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 11:42:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0010, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.9141, 
2023-03-06 11:42:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:42:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0014, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 11:42:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0013, Acc_1: 0.8685, Acc_2: 0.8675, F1-score_1: 0.8271, F1-score_2: 0.8271
2023-03-06 11:42:44 - __main__ - INFO - Epoch [6/100]
2023-03-06 11:42:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 11:42:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:43:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 11:43:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 11:43:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 11:43:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-06 11:43:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-06 11:43:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 11:43:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:43:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:44:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 11:44:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 11:44:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0011, Acc_1: 0.8679, Acc_2: 0.8674, F1-score_1: 0.8281, F1-score_2: 0.8289
2023-03-06 11:44:25 - __main__ - INFO - Epoch [7/100]
2023-03-06 11:44:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 11:44:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 11:44:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 11:44:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 11:44:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 11:45:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 11:45:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:45:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 11:45:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.9219, 
2023-03-06 11:45:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 11:45:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 11:45:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 11:46:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0013, Acc_1: 0.8711, Acc_2: 0.8655, F1-score_1: 0.8327, F1-score_2: 0.8276
2023-03-06 11:46:07 - __main__ - INFO - Epoch [8/100]
2023-03-06 11:46:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 11:46:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 11:46:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9609, Acc_2: 0.9688, 
2023-03-06 11:46:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 11:46:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 11:46:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 11:46:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 11:47:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9375, 
2023-03-06 11:47:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 11:47:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 11:47:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 11:47:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 11:47:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0010, Acc_1: 0.8684, Acc_2: 0.8663, F1-score_1: 0.8290, F1-score_2: 0.8260
2023-03-06 11:47:51 - __main__ - INFO - Epoch [9/100]
2023-03-06 11:47:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 11:48:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 11:48:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 11:48:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 11:48:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-06 11:48:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 11:48:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 11:48:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 11:48:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 11:49:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 11:49:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 11:49:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 11:49:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8701, Acc_2: 0.8702, F1-score_1: 0.8321, F1-score_2: 0.8328
2023-03-06 11:49:33 - __main__ - INFO - Epoch [10/100]
2023-03-06 11:49:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 11:49:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 11:49:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 11:49:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 11:50:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 11:50:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:50:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 11:50:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 11:50:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 11:50:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:50:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 11:50:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 11:51:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8753, Acc_2: 0.8709, F1-score_1: 0.8376, F1-score_2: 0.8351
2023-03-06 11:51:14 - __main__ - INFO - Epoch [11/100]
2023-03-06 11:51:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-06 11:51:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 11:51:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 11:51:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 11:51:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 11:51:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:52:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 11:52:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 11:52:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 11:52:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 11:52:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 11:52:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 11:52:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8719, Acc_2: 0.8651, F1-score_1: 0.8366, F1-score_2: 0.8286
2023-03-06 11:52:56 - __main__ - INFO - Epoch [12/100]
2023-03-06 11:53:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:53:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 11:53:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 11:53:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 11:53:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 11:53:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 11:53:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:53:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 11:53:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-06 11:54:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:54:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 11:54:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 11:54:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8735, Acc_2: 0.8680, F1-score_1: 0.8372, F1-score_2: 0.8324
2023-03-06 11:54:37 - __main__ - INFO - Epoch [13/100]
2023-03-06 11:54:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 11:54:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 11:54:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 11:55:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 11:55:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 11:55:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-06 11:55:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 11:55:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 11:55:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-06 11:55:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 11:55:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 11:55:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 11:56:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8736, Acc_2: 0.8684, F1-score_1: 0.8383, F1-score_2: 0.8348
2023-03-06 11:56:19 - __main__ - INFO - Epoch [14/100]
2023-03-06 11:56:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 11:56:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 11:56:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-06 11:56:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:56:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 11:56:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-06 11:57:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 11:57:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 11:57:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 11:57:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 11:57:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 11:57:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 11:58:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8726, Acc_2: 0.8699, F1-score_1: 0.8364, F1-score_2: 0.8312
2023-03-06 11:58:00 - __main__ - INFO - Epoch [15/100]
2023-03-06 11:58:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 11:58:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 11:58:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 11:58:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:58:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 11:58:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 11:58:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 11:58:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 11:59:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 11:59:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 11:59:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 11:59:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 11:59:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8708, Acc_2: 0.8672, F1-score_1: 0.8326, F1-score_2: 0.8289
2023-03-06 11:59:41 - __main__ - INFO - Epoch [16/100]
2023-03-06 11:59:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 11:59:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:00:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 12:00:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 12:00:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:00:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-06 12:00:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-06 12:00:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 12:00:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 12:00:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-06 12:00:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 12:01:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:01:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.8716, Acc_2: 0.8631, F1-score_1: 0.8355, F1-score_2: 0.8260
2023-03-06 12:01:23 - __main__ - INFO - Epoch [17/100]
2023-03-06 12:01:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 12:01:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 12:01:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 12:01:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 12:01:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-06 12:02:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 12:02:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:02:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 12:02:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 12:02:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 12:02:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 12:02:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 12:03:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8697, Acc_2: 0.8677, F1-score_1: 0.8309, F1-score_2: 0.8300
2023-03-06 12:03:04 - __main__ - INFO - Epoch [18/100]
2023-03-06 12:03:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 12:03:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 12:03:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 12:03:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:03:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 12:03:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 12:03:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 12:03:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 12:04:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 12:04:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 12:04:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 12:04:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-06 12:04:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8714, Acc_2: 0.8675, F1-score_1: 0.8358, F1-score_2: 0.8312
2023-03-06 12:04:46 - __main__ - INFO - Epoch [19/100]
2023-03-06 12:04:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 12:04:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9609, 
2023-03-06 12:05:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:05:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 12:05:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 12:05:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 12:05:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:05:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:05:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 12:05:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:06:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 12:06:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:06:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8665, Acc_2: 0.8584, F1-score_1: 0.8290, F1-score_2: 0.8217
2023-03-06 12:06:27 - __main__ - INFO - Epoch [20/100]
2023-03-06 12:06:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 12:06:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-06 12:06:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 12:06:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 12:07:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:07:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 12:07:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 12:07:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 12:07:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 12:07:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 12:07:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 12:07:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8984, 
2023-03-06 12:08:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.8641, Acc_2: 0.8568, F1-score_1: 0.8293, F1-score_2: 0.8212
2023-03-06 12:08:11 - __main__ - INFO - Epoch [21/100]
2023-03-06 12:08:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:08:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:08:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 12:08:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 12:08:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 12:08:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 12:08:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:09:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 12:09:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 12:09:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 12:09:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 12:09:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-06 12:09:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8601, Acc_2: 0.8565, F1-score_1: 0.8194, F1-score_2: 0.8200
2023-03-06 12:09:52 - __main__ - INFO - Epoch [22/100]
2023-03-06 12:09:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 12:10:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:10:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 12:10:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 12:10:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:10:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 12:10:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 12:10:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9219, 
2023-03-06 12:10:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 12:11:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 12:11:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 12:11:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-06 12:11:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0005, Acc_1: 0.8548, Acc_2: 0.8522, F1-score_1: 0.8185, F1-score_2: 0.8063
2023-03-06 12:11:34 - __main__ - INFO - Epoch [23/100]
2023-03-06 12:11:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:11:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 12:11:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0011, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 12:12:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 12:12:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 12:12:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 12:12:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0019, Loss_2: 0.0009, Acc_1: 0.8203, Acc_2: 0.8594, 
2023-03-06 12:12:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 12:12:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 12:12:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 12:12:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-06 12:12:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 12:13:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0027, Acc_1: 0.8251, Acc_2: 0.8225, F1-score_1: 0.7816, F1-score_2: 0.7735
2023-03-06 12:13:15 - __main__ - INFO - Epoch [24/100]
2023-03-06 12:13:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-06 12:13:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-06 12:13:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0010, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-06 12:13:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 12:13:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0011, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 12:13:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0016, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-06 12:14:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 12:14:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-06 12:14:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0014, Loss_2: 0.0017, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 12:14:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 12:14:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0012, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-06 12:14:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 12:14:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0028, Loss_2: 0.0017, Acc_1: 0.8319, Acc_2: 0.8327, F1-score_1: 0.7900, F1-score_2: 0.7869
2023-03-06 12:14:56 - __main__ - INFO - Epoch [25/100]
2023-03-06 12:15:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:15:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 12:15:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 12:15:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:15:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:15:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8984, 
2023-03-06 12:15:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 12:15:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 12:15:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-06 12:16:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8516, 
2023-03-06 12:16:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8906, 
2023-03-06 12:16:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 12:16:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0008, Acc_1: 0.8293, Acc_2: 0.8320, F1-score_1: 0.7806, F1-score_2: 0.7928
2023-03-06 12:16:38 - __main__ - INFO - Epoch [26/100]
2023-03-06 12:16:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:16:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-06 12:16:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:17:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 12:17:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 12:17:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 12:17:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8672, 
2023-03-06 12:17:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 12:17:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0017, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 12:17:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 12:17:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0011, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 12:18:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:18:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0016, Acc_1: 0.8290, Acc_2: 0.8339, F1-score_1: 0.7877, F1-score_2: 0.7887
2023-03-06 12:18:19 - __main__ - INFO - Epoch [27/100]
2023-03-06 12:18:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 12:18:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 12:18:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 12:18:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-06 12:18:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 12:19:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-06 12:19:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 12:19:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 12:19:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 12:19:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 12:19:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 12:19:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 12:20:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0015, Acc_1: 0.8308, Acc_2: 0.8361, F1-score_1: 0.7909, F1-score_2: 0.7879
2023-03-06 12:20:01 - __main__ - INFO - Epoch [28/100]
2023-03-06 12:20:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 12:20:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 12:20:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 12:20:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 12:20:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 12:20:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 12:20:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 12:20:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 12:21:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 12:21:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-06 12:21:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 12:21:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 12:21:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0016, Acc_1: 0.8454, Acc_2: 0.8410, F1-score_1: 0.8028, F1-score_2: 0.8030
2023-03-06 12:21:42 - __main__ - INFO - Epoch [29/100]
2023-03-06 12:21:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:21:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 12:22:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 12:22:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-06 12:22:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 12:22:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 12:22:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 12:22:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0016, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 12:22:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 12:22:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:22:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 12:23:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 12:23:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0012, Acc_1: 0.8395, Acc_2: 0.8431, F1-score_1: 0.7990, F1-score_2: 0.8012
2023-03-06 12:23:23 - __main__ - INFO - Epoch [30/100]
2023-03-06 12:23:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 12:23:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:23:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:23:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 12:23:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 12:24:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 12:24:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 12:24:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 12:24:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 12:24:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 12:24:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 12:24:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 12:25:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0014, Acc_1: 0.8415, Acc_2: 0.8325, F1-score_1: 0.7946, F1-score_2: 0.7855
2023-03-06 12:25:05 - __main__ - INFO - Epoch [31/100]
2023-03-06 12:25:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 12:25:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 12:25:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:25:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 12:25:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:25:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 12:25:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:26:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-06 12:26:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 12:26:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 12:26:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 12:26:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 12:26:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8465, Acc_2: 0.8349, F1-score_1: 0.8035, F1-score_2: 0.7889
2023-03-06 12:26:48 - __main__ - INFO - Epoch [32/100]
2023-03-06 12:26:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 12:27:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 12:27:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-06 12:27:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 12:27:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-06 12:27:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 12:27:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 12:27:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:27:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 12:27:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 12:28:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-06 12:28:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 12:28:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0012, Acc_1: 0.8405, Acc_2: 0.8310, F1-score_1: 0.7950, F1-score_2: 0.7860
2023-03-06 12:28:30 - __main__ - INFO - Epoch [33/100]
2023-03-06 12:28:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 12:28:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 12:28:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 12:28:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 12:29:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 12:29:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 12:29:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 12:29:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:29:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:29:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 12:29:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9297, 
2023-03-06 12:29:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:30:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0011, Acc_1: 0.8375, Acc_2: 0.8366, F1-score_1: 0.7981, F1-score_2: 0.7946
2023-03-06 12:30:11 - __main__ - INFO - Epoch [34/100]
2023-03-06 12:30:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 12:30:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 12:30:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:30:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 12:30:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 12:30:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 12:30:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 12:31:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 12:31:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 12:31:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 12:31:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 12:31:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 12:31:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0009, Acc_1: 0.8424, Acc_2: 0.8429, F1-score_1: 0.7984, F1-score_2: 0.8015
2023-03-06 12:31:52 - __main__ - INFO - Epoch [35/100]
2023-03-06 12:31:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 12:32:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 12:32:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 12:32:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:32:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 12:32:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 12:32:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 12:32:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 12:32:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 12:33:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 12:33:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:33:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-06 12:33:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0010, Acc_1: 0.8388, Acc_2: 0.8361, F1-score_1: 0.7952, F1-score_2: 0.7904
2023-03-06 12:33:34 - __main__ - INFO - Epoch [36/100]
2023-03-06 12:33:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 12:33:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 12:33:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-06 12:34:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 12:34:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:34:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:34:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-06 12:34:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:34:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 12:34:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 12:34:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-06 12:34:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-06 12:35:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8470, Acc_2: 0.8400, F1-score_1: 0.8080, F1-score_2: 0.7944
2023-03-06 12:35:15 - __main__ - INFO - Epoch [37/100]
2023-03-06 12:35:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 12:35:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:35:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 12:35:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:35:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 12:35:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 12:36:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 12:36:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 12:36:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 12:36:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:36:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 12:36:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 12:36:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.8431, Acc_2: 0.8388, F1-score_1: 0.8027, F1-score_2: 0.7955
2023-03-06 12:36:57 - __main__ - INFO - Epoch [38/100]
2023-03-06 12:37:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-06 12:37:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 12:37:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:37:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 12:37:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 12:37:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 12:37:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 12:37:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:37:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 12:38:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:38:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 12:38:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 12:38:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8378, Acc_2: 0.8477, F1-score_1: 0.7940, F1-score_2: 0.8054
2023-03-06 12:38:39 - __main__ - INFO - Epoch [39/100]
2023-03-06 12:38:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 12:38:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 12:38:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 12:39:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:39:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 12:39:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 12:39:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 12:39:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 12:39:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 12:39:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:39:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 12:40:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 12:40:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0006, Acc_1: 0.8405, Acc_2: 0.8444, F1-score_1: 0.8032, F1-score_2: 0.8012
2023-03-06 12:40:20 - __main__ - INFO - Epoch [40/100]
2023-03-06 12:40:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 12:40:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 12:40:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 12:40:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 12:40:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 12:41:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 12:41:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 12:41:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 12:41:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 12:41:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 12:41:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 12:41:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-06 12:42:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8424, Acc_2: 0.8424, F1-score_1: 0.7985, F1-score_2: 0.7984
2023-03-06 12:42:01 - __main__ - INFO - Epoch [41/100]
2023-03-06 12:42:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 12:42:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 12:42:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 12:42:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 12:42:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 12:42:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 12:42:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 12:42:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-06 12:43:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 12:43:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 12:43:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:43:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-06 12:43:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0007, Acc_1: 0.8419, Acc_2: 0.8463, F1-score_1: 0.7984, F1-score_2: 0.8058
2023-03-06 12:43:43 - __main__ - INFO - Epoch [42/100]
2023-03-06 12:43:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:43:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:44:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 12:44:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 12:44:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-06 12:44:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 12:44:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 12:44:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 12:44:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 12:44:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 12:44:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:45:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-06 12:45:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.8454, Acc_2: 0.8427, F1-score_1: 0.8042, F1-score_2: 0.8011
2023-03-06 12:45:24 - __main__ - INFO - Epoch [43/100]
2023-03-06 12:45:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 12:45:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 12:45:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 12:45:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 12:45:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 12:46:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 12:46:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 12:46:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 12:46:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 12:46:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 12:46:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 12:46:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-06 12:47:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0017, Acc_1: 0.8466, Acc_2: 0.8388, F1-score_1: 0.8057, F1-score_2: 0.7950
2023-03-06 12:47:06 - __main__ - INFO - Epoch [44/100]
2023-03-06 12:47:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:47:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 12:47:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 12:47:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 12:47:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 12:47:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9297, 
2023-03-06 12:47:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 12:48:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 12:48:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 12:48:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 12:48:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 12:48:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:48:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8421, Acc_2: 0.8426, F1-score_1: 0.8015, F1-score_2: 0.7994
2023-03-06 12:48:47 - __main__ - INFO - Epoch [45/100]
2023-03-06 12:48:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 12:49:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 12:49:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 12:49:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0029, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-06 12:49:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:49:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 12:49:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 12:49:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 12:49:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-06 12:49:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 12:50:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 12:50:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 12:50:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0020, Acc_1: 0.8488, Acc_2: 0.8454, F1-score_1: 0.8092, F1-score_2: 0.8052
2023-03-06 12:50:29 - __main__ - INFO - Epoch [46/100]
2023-03-06 12:50:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 12:50:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 12:50:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 12:50:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-06 12:51:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 12:51:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 12:51:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 12:51:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 12:51:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 12:51:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 12:51:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 12:51:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 12:52:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0010, Acc_1: 0.8342, Acc_2: 0.8298, F1-score_1: 0.7896, F1-score_2: 0.7868
2023-03-06 12:52:11 - __main__ - INFO - Epoch [47/100]
2023-03-06 12:52:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 12:52:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 12:52:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:52:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:52:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 12:52:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 12:52:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 12:53:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:53:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 12:53:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:53:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:53:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 12:53:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0013, Acc_1: 0.8319, Acc_2: 0.8392, F1-score_1: 0.7955, F1-score_2: 0.8019
2023-03-06 12:53:52 - __main__ - INFO - Epoch [48/100]
2023-03-06 12:53:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:54:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 12:54:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-06 12:54:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 12:54:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 12:54:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 12:54:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 12:54:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:54:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-06 12:55:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 12:55:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:55:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:55:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0012, Acc_1: 0.8393, Acc_2: 0.8381, F1-score_1: 0.7979, F1-score_2: 0.7977
2023-03-06 12:55:33 - __main__ - INFO - Epoch [49/100]
2023-03-06 12:55:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 12:55:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 12:55:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 12:56:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:56:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 12:56:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 12:56:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 12:56:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 12:56:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 12:56:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0013, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 12:56:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 12:56:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:57:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.8342, Acc_2: 0.8336, F1-score_1: 0.7910, F1-score_2: 0.7916
2023-03-06 12:57:15 - __main__ - INFO - Epoch [50/100]
2023-03-06 12:57:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:57:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:57:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 12:57:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 12:57:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 12:57:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 12:58:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0041, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 12:58:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 12:58:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 12:58:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 12:58:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 12:58:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 12:58:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0011, Acc_1: 0.8314, Acc_2: 0.8421, F1-score_1: 0.7880, F1-score_2: 0.8038
2023-03-06 12:58:56 - __main__ - INFO - Epoch [51/100]
2023-03-06 12:59:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 12:59:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 12:59:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-06 12:59:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-06 12:59:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 12:59:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 12:59:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 12:59:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0038, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-06 12:59:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 13:00:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 13:00:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:00:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 13:00:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0017, Acc_1: 0.8353, Acc_2: 0.8166, F1-score_1: 0.7857, F1-score_2: 0.7684
2023-03-06 13:00:38 - __main__ - INFO - Epoch [52/100]
2023-03-06 13:00:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 13:00:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0014, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 13:00:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 13:01:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 13:01:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:01:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 13:01:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:01:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:01:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 13:01:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:01:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 13:01:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-06 13:02:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0022, Acc_1: 0.8252, Acc_2: 0.8166, F1-score_1: 0.7810, F1-score_2: 0.7769
2023-03-06 13:02:19 - __main__ - INFO - Epoch [53/100]
2023-03-06 13:02:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-06 13:02:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:02:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:02:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0019, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 13:02:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-06 13:03:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 13:03:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:03:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 13:03:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:03:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0014, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 13:03:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:03:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-06 13:04:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0043, Acc_1: 0.8305, Acc_2: 0.8162, F1-score_1: 0.7867, F1-score_2: 0.7753
2023-03-06 13:04:00 - __main__ - INFO - Epoch [54/100]
2023-03-06 13:04:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 13:04:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 13:04:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 13:04:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:04:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 13:04:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:04:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8750, 
2023-03-06 13:04:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 13:05:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:05:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:05:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 13:05:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 13:05:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0025, Acc_1: 0.8295, Acc_2: 0.8263, F1-score_1: 0.7829, F1-score_2: 0.7824
2023-03-06 13:05:42 - __main__ - INFO - Epoch [55/100]
2023-03-06 13:05:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 13:05:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:06:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 13:06:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 13:06:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0015, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-06 13:06:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 13:06:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:06:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 13:06:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:06:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:06:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 13:07:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0027, Loss_2: 0.0008, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-06 13:07:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0043, Acc_1: 0.8235, Acc_2: 0.8208, F1-score_1: 0.7792, F1-score_2: 0.7755
2023-03-06 13:07:23 - __main__ - INFO - Epoch [56/100]
2023-03-06 13:07:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 13:07:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 13:07:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 13:07:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:07:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-06 13:08:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 13:08:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 13:08:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 13:08:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 13:08:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:08:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 13:08:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-06 13:09:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0034, Acc_1: 0.8364, Acc_2: 0.8266, F1-score_1: 0.7922, F1-score_2: 0.7797
2023-03-06 13:09:05 - __main__ - INFO - Epoch [57/100]
2023-03-06 13:09:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 13:09:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 13:09:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 13:09:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 13:09:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 13:09:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 13:09:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 13:10:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 13:10:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 13:10:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:10:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 13:10:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0029, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 13:10:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0032, Acc_1: 0.8213, Acc_2: 0.8376, F1-score_1: 0.7774, F1-score_2: 0.7957
2023-03-06 13:10:47 - __main__ - INFO - Epoch [58/100]
2023-03-06 13:10:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 13:10:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 13:11:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 13:11:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-06 13:11:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:11:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:11:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-06 13:11:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:11:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 13:11:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 13:12:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 13:12:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 13:12:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0010, Acc_1: 0.8295, Acc_2: 0.8402, F1-score_1: 0.7844, F1-score_2: 0.7976
2023-03-06 13:12:28 - __main__ - INFO - Epoch [59/100]
2023-03-06 13:12:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 13:12:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 13:12:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:12:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:13:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:13:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:13:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 13:13:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 13:13:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 13:13:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:13:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 13:13:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:14:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0017, Acc_1: 0.8217, Acc_2: 0.8341, F1-score_1: 0.7790, F1-score_2: 0.7870
2023-03-06 13:14:10 - __main__ - INFO - Epoch [60/100]
2023-03-06 13:14:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 13:14:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0013, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 13:14:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-06 13:14:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 13:14:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 13:14:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:14:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:15:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:15:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 13:15:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 13:15:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:15:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 13:15:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.8346, Acc_2: 0.8366, F1-score_1: 0.7896, F1-score_2: 0.7897
2023-03-06 13:15:51 - __main__ - INFO - Epoch [61/100]
2023-03-06 13:15:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:16:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 13:16:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 13:16:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:16:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 13:16:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 13:16:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:16:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:16:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 13:17:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:17:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 13:17:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 13:17:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0010, Acc_1: 0.8230, Acc_2: 0.8329, F1-score_1: 0.7790, F1-score_2: 0.7877
2023-03-06 13:17:33 - __main__ - INFO - Epoch [62/100]
2023-03-06 13:17:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 13:17:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 13:17:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-06 13:18:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 13:18:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 13:18:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 13:18:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:18:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:18:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 13:18:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:18:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 13:18:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 13:19:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0005, Acc_1: 0.8268, Acc_2: 0.8336, F1-score_1: 0.7835, F1-score_2: 0.7880
2023-03-06 13:19:15 - __main__ - INFO - Epoch [63/100]
2023-03-06 13:19:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:19:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 13:19:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 13:19:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 13:19:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 13:19:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:20:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 13:20:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:20:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:20:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:20:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 13:20:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 13:20:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.8232, Acc_2: 0.8375, F1-score_1: 0.7802, F1-score_2: 0.7932
2023-03-06 13:20:56 - __main__ - INFO - Epoch [64/100]
2023-03-06 13:21:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 13:21:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 13:21:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 13:21:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:21:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 13:21:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 13:21:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:21:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:21:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 13:22:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:22:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:22:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 13:22:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.8257, Acc_2: 0.8291, F1-score_1: 0.7773, F1-score_2: 0.7848
2023-03-06 13:22:38 - __main__ - INFO - Epoch [65/100]
2023-03-06 13:22:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 13:22:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 13:22:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:23:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 13:23:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 13:23:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 13:23:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 13:23:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 13:23:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:23:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 13:23:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 13:23:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 13:24:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8375, Acc_2: 0.8290, F1-score_1: 0.7934, F1-score_2: 0.7813
2023-03-06 13:24:19 - __main__ - INFO - Epoch [66/100]
2023-03-06 13:24:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:24:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:24:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:24:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:24:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 13:25:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 13:25:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:25:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:25:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:25:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:25:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 13:25:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:26:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0015, Acc_1: 0.8203, Acc_2: 0.8383, F1-score_1: 0.7727, F1-score_2: 0.7933
2023-03-06 13:26:01 - __main__ - INFO - Epoch [67/100]
2023-03-06 13:26:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:26:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 13:26:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:26:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:26:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:26:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:26:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 13:26:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:27:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:27:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:27:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:27:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 13:27:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.8319, Acc_2: 0.8375, F1-score_1: 0.7856, F1-score_2: 0.7945
2023-03-06 13:27:43 - __main__ - INFO - Epoch [68/100]
2023-03-06 13:27:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:27:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 13:28:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:28:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 13:28:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:28:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:28:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 13:28:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:28:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 13:28:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 13:28:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:29:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 13:29:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0018, Acc_1: 0.8383, Acc_2: 0.8264, F1-score_1: 0.7957, F1-score_2: 0.7791
2023-03-06 13:29:25 - __main__ - INFO - Epoch [69/100]
2023-03-06 13:29:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 13:29:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 13:29:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 13:29:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:29:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 13:30:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:30:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 13:30:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:30:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:30:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:30:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:30:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 13:31:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.8337, Acc_2: 0.8366, F1-score_1: 0.7916, F1-score_2: 0.7908
2023-03-06 13:31:06 - __main__ - INFO - Epoch [70/100]
2023-03-06 13:31:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:31:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:31:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 13:31:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:31:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 13:31:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:31:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 13:32:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 13:32:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 13:32:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:32:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 13:32:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:32:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0011, Loss_2: 0.0015, Acc_1: 0.8305, Acc_2: 0.8410, F1-score_1: 0.7854, F1-score_2: 0.7976
2023-03-06 13:32:48 - __main__ - INFO - Epoch [71/100]
2023-03-06 13:32:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:33:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 13:33:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:33:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:33:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 13:33:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 13:33:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:33:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 13:33:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 13:33:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 13:34:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 13:34:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 13:34:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0017, Acc_1: 0.8342, Acc_2: 0.8383, F1-score_1: 0.7895, F1-score_2: 0.7973
2023-03-06 13:34:30 - __main__ - INFO - Epoch [72/100]
2023-03-06 13:34:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 13:34:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 13:34:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:34:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:35:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 13:35:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:35:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 13:35:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 13:35:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 13:35:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 13:35:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 13:35:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 13:36:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0026, Acc_1: 0.8307, Acc_2: 0.8123, F1-score_1: 0.7839, F1-score_2: 0.7670
2023-03-06 13:36:12 - __main__ - INFO - Epoch [73/100]
2023-03-06 13:36:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 13:36:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-06 13:36:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 13:36:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 13:36:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 13:36:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 13:37:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 13:37:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:37:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 13:37:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 13:37:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9141, 
2023-03-06 13:37:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 13:37:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0013, Acc_1: 0.8286, Acc_2: 0.8302, F1-score_1: 0.7758, F1-score_2: 0.7870
2023-03-06 13:37:53 - __main__ - INFO - Epoch [74/100]
2023-03-06 13:37:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:38:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:38:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 13:38:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:38:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 13:38:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 13:38:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:38:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 13:38:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 13:39:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:39:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:39:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:39:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8364, Acc_2: 0.8249, F1-score_1: 0.7937, F1-score_2: 0.7776
2023-03-06 13:39:35 - __main__ - INFO - Epoch [75/100]
2023-03-06 13:39:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 13:39:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 13:39:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:40:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 13:40:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 13:40:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 13:40:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:40:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 13:40:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:40:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 13:40:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:40:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 13:41:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0033, Acc_1: 0.8409, Acc_2: 0.8268, F1-score_1: 0.7977, F1-score_2: 0.7882
2023-03-06 13:41:17 - __main__ - INFO - Epoch [76/100]
2023-03-06 13:41:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:41:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 13:41:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 13:41:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 13:41:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 13:41:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:42:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:42:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:42:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 13:42:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:42:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:42:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 13:42:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0014, Acc_1: 0.8375, Acc_2: 0.8246, F1-score_1: 0.7937, F1-score_2: 0.7762
2023-03-06 13:42:58 - __main__ - INFO - Epoch [77/100]
2023-03-06 13:43:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 13:43:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:43:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 13:43:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 13:43:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-06 13:43:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 13:43:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 13:43:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 13:44:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 13:44:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:44:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:44:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:44:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0008, Acc_1: 0.8358, Acc_2: 0.8387, F1-score_1: 0.7925, F1-score_2: 0.7966
2023-03-06 13:44:40 - __main__ - INFO - Epoch [78/100]
2023-03-06 13:44:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 13:44:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 13:44:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 13:45:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0020, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 13:45:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 13:45:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:45:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 13:45:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:45:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:45:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 13:45:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-06 13:46:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:46:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0014, Acc_1: 0.8380, Acc_2: 0.8339, F1-score_1: 0.7934, F1-score_2: 0.7926
2023-03-06 13:46:21 - __main__ - INFO - Epoch [79/100]
2023-03-06 13:46:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 13:46:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0014, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:46:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:46:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 13:46:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:47:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:47:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 13:47:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 13:47:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 13:47:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:47:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:47:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 13:48:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0013, Acc_1: 0.8302, Acc_2: 0.8347, F1-score_1: 0.7878, F1-score_2: 0.7927
2023-03-06 13:48:03 - __main__ - INFO - Epoch [80/100]
2023-03-06 13:48:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:48:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:48:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 13:48:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:48:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 13:48:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 13:48:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 13:48:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:49:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-06 13:49:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-06 13:49:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:49:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:49:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0009, Acc_1: 0.8319, Acc_2: 0.8346, F1-score_1: 0.7860, F1-score_2: 0.7944
2023-03-06 13:49:45 - __main__ - INFO - Epoch [81/100]
2023-03-06 13:49:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0026, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 13:49:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 13:50:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 13:50:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 13:50:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:50:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:50:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 13:50:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:50:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:50:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-06 13:51:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:51:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:51:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0001, Acc_1: 0.8349, Acc_2: 0.8307, F1-score_1: 0.7912, F1-score_2: 0.7866
2023-03-06 13:51:26 - __main__ - INFO - Epoch [82/100]
2023-03-06 13:51:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:51:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 13:51:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:51:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 13:52:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:52:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 13:52:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 13:52:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:52:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:52:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 13:52:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:52:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0014, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 13:53:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0008, Acc_1: 0.8132, Acc_2: 0.8271, F1-score_1: 0.7652, F1-score_2: 0.7814
2023-03-06 13:53:08 - __main__ - INFO - Epoch [83/100]
2023-03-06 13:53:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 13:53:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 13:53:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 13:53:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 13:53:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:53:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:53:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 13:54:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:54:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:54:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 13:54:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 13:54:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 13:54:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0014, Acc_1: 0.8235, Acc_2: 0.8217, F1-score_1: 0.7766, F1-score_2: 0.7833
2023-03-06 13:54:50 - __main__ - INFO - Epoch [84/100]
2023-03-06 13:54:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 13:55:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:55:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:55:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 13:55:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 13:55:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 13:55:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 13:55:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:55:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:55:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 13:56:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 13:56:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:56:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0007, Acc_1: 0.8319, Acc_2: 0.8302, F1-score_1: 0.7849, F1-score_2: 0.7904
2023-03-06 13:56:31 - __main__ - INFO - Epoch [85/100]
2023-03-06 13:56:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:56:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:56:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:56:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:57:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 13:57:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 13:57:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0035, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:57:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 13:57:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:57:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:57:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:57:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 13:58:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0007, Acc_1: 0.8307, Acc_2: 0.8281, F1-score_1: 0.7855, F1-score_2: 0.7854
2023-03-06 13:58:13 - __main__ - INFO - Epoch [86/100]
2023-03-06 13:58:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 13:58:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:58:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 13:58:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 13:58:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:58:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 13:59:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 13:59:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 13:59:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 13:59:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 13:59:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 13:59:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 13:59:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0007, Acc_1: 0.8354, Acc_2: 0.8325, F1-score_1: 0.7901, F1-score_2: 0.7910
2023-03-06 13:59:55 - __main__ - INFO - Epoch [87/100]
2023-03-06 14:00:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:00:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:00:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 14:00:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:00:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-06 14:00:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:00:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-06 14:00:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 14:00:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:01:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:01:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 14:01:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:01:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0034, Loss_2: 0.0008, Acc_1: 0.8297, Acc_2: 0.8293, F1-score_1: 0.7819, F1-score_2: 0.7869
2023-03-06 14:01:37 - __main__ - INFO - Epoch [88/100]
2023-03-06 14:01:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 14:01:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 14:01:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 14:02:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:02:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:02:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 14:02:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:02:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:02:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:02:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:02:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 14:02:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:03:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0016, Acc_1: 0.8293, Acc_2: 0.8259, F1-score_1: 0.7797, F1-score_2: 0.7843
2023-03-06 14:03:18 - __main__ - INFO - Epoch [89/100]
2023-03-06 14:03:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:03:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:03:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:03:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:03:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:03:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 14:04:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:04:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:04:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 14:04:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:04:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:04:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-06 14:05:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0009, Acc_1: 0.8361, Acc_2: 0.8290, F1-score_1: 0.7902, F1-score_2: 0.7864
2023-03-06 14:05:00 - __main__ - INFO - Epoch [90/100]
2023-03-06 14:05:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 14:05:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:05:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:05:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 14:05:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 14:05:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 14:05:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:05:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:06:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:06:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 14:06:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:06:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:06:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0011, Acc_1: 0.8361, Acc_2: 0.8293, F1-score_1: 0.7897, F1-score_2: 0.7862
2023-03-06 14:06:41 - __main__ - INFO - Epoch [91/100]
2023-03-06 14:06:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:06:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 14:07:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:07:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:07:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 14:07:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 14:07:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:07:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 14:07:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:07:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 14:07:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:08:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 14:08:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0010, Acc_1: 0.8358, Acc_2: 0.8261, F1-score_1: 0.7892, F1-score_2: 0.7835
2023-03-06 14:08:23 - __main__ - INFO - Epoch [92/100]
2023-03-06 14:08:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:08:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 14:08:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 14:08:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 14:08:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 14:09:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 14:09:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:09:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:09:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 14:09:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 14:09:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 14:09:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 14:10:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0010, Acc_1: 0.8331, Acc_2: 0.8242, F1-score_1: 0.7863, F1-score_2: 0.7796
2023-03-06 14:10:05 - __main__ - INFO - Epoch [93/100]
2023-03-06 14:10:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:10:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 14:10:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 14:10:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:10:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:10:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:10:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 14:10:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:11:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 14:11:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 14:11:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:11:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:11:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0007, Acc_1: 0.8368, Acc_2: 0.8259, F1-score_1: 0.7927, F1-score_2: 0.7837
2023-03-06 14:11:46 - __main__ - INFO - Epoch [94/100]
2023-03-06 14:11:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 14:11:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:12:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 14:12:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 14:12:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 14:12:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:12:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 14:12:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 14:12:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:12:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 14:13:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 14:13:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:13:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0006, Acc_1: 0.8373, Acc_2: 0.8274, F1-score_1: 0.7931, F1-score_2: 0.7854
2023-03-06 14:13:28 - __main__ - INFO - Epoch [95/100]
2023-03-06 14:13:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 14:13:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 14:13:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:13:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:14:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 14:14:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 14:14:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:14:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:14:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 14:14:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:14:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:14:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 14:15:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0006, Acc_1: 0.8373, Acc_2: 0.8271, F1-score_1: 0.7922, F1-score_2: 0.7852
2023-03-06 14:15:10 - __main__ - INFO - Epoch [96/100]
2023-03-06 14:15:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:15:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:15:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 14:15:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:15:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 14:15:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 14:15:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:16:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 14:16:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:16:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:16:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 14:16:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 14:16:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0006, Acc_1: 0.8381, Acc_2: 0.8263, F1-score_1: 0.7936, F1-score_2: 0.7844
2023-03-06 14:16:51 - __main__ - INFO - Epoch [97/100]
2023-03-06 14:16:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 14:17:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 14:17:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:17:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 14:17:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 14:17:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 14:17:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:17:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:17:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 14:18:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 14:18:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 14:18:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 14:18:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0007, Acc_1: 0.8376, Acc_2: 0.8273, F1-score_1: 0.7929, F1-score_2: 0.7859
2023-03-06 14:18:33 - __main__ - INFO - Epoch [98/100]
2023-03-06 14:18:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:18:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 14:18:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 14:19:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:19:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 14:19:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:19:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:19:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 14:19:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:19:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:19:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:19:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:20:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8286, F1-score_1: 0.7909, F1-score_2: 0.7875
2023-03-06 14:20:15 - __main__ - INFO - Epoch [99/100]
2023-03-06 14:20:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:20:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:20:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 14:20:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 14:20:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:20:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:21:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:21:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:21:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 14:21:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:21:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:21:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:21:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0007, Acc_1: 0.8356, Acc_2: 0.8290, F1-score_1: 0.7903, F1-score_2: 0.7880
2023-03-06 14:21:58 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 14:21:58 - utils._noise - DEBUG - 6, 7
2023-03-06 14:21:58 - utils._noise - DEBUG - 13997
2023-03-06 14:21:58 - utils._noise - INFO - Actual noise 0.20
2023-03-06 14:21:58 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-06 14:21:59 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-06 14:22:00 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 14:22:00 - __main__ - INFO - Loading dataset...
2023-03-06 14:22:00 - __main__ - INFO - Building model...
2023-03-06 14:22:01 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 14:22:01 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 14:22:01 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-06 14:22:01 - __main__ - INFO - Start train & evaluate
2023-03-06 14:22:01 - __main__ - INFO - Epoch [0/100]
2023-03-06 14:22:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0163, Loss_2: 0.0152, Acc_1: 0.1172, Acc_2: 0.1406, 
2023-03-06 14:22:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0132, Loss_2: 0.0129, Acc_1: 0.3828, Acc_2: 0.4453, 
2023-03-06 14:22:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0120, Loss_2: 0.0119, Acc_1: 0.4922, Acc_2: 0.4766, 
2023-03-06 14:22:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0108, Loss_2: 0.0107, Acc_1: 0.5547, Acc_2: 0.5312, 
2023-03-06 14:22:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0096, Loss_2: 0.0097, Acc_1: 0.6484, Acc_2: 0.6562, 
2023-03-06 14:22:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0104, Loss_2: 0.0104, Acc_1: 0.5938, Acc_2: 0.6016, 
2023-03-06 14:22:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0103, Loss_2: 0.0105, Acc_1: 0.5938, Acc_2: 0.5938, 
2023-03-06 14:22:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0093, Loss_2: 0.0094, Acc_1: 0.6328, Acc_2: 0.6172, 
2023-03-06 14:23:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0071, Loss_2: 0.0071, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-06 14:23:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0093, Loss_2: 0.0094, Acc_1: 0.6719, Acc_2: 0.6641, 
2023-03-06 14:23:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0087, Loss_2: 0.0090, Acc_1: 0.7188, Acc_2: 0.7109, 
2023-03-06 14:23:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0104, Loss_2: 0.0101, Acc_1: 0.6250, Acc_2: 0.5938, 
2023-03-06 14:23:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0057, Acc_1: 0.8585, Acc_2: 0.8544, F1-score_1: 0.7995, F1-score_2: 0.7940
2023-03-06 14:23:42 - __main__ - INFO - Epoch [1/100]
2023-03-06 14:23:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0077, Loss_2: 0.0080, Acc_1: 0.7188, Acc_2: 0.7266, 
2023-03-06 14:23:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0078, Loss_2: 0.0077, Acc_1: 0.6875, Acc_2: 0.7109, 
2023-03-06 14:24:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0063, Loss_2: 0.0061, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-06 14:24:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0079, Loss_2: 0.0078, Acc_1: 0.6562, Acc_2: 0.6562, 
2023-03-06 14:24:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0086, Loss_2: 0.0084, Acc_1: 0.6719, Acc_2: 0.6797, 
2023-03-06 14:24:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0070, Loss_2: 0.0069, Acc_1: 0.7500, Acc_2: 0.7500, 
2023-03-06 14:24:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0066, Loss_2: 0.0066, Acc_1: 0.7422, Acc_2: 0.7422, 
2023-03-06 14:24:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0085, Loss_2: 0.0087, Acc_1: 0.6797, Acc_2: 0.6875, 
2023-03-06 14:24:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0074, Loss_2: 0.0077, Acc_1: 0.7031, Acc_2: 0.7109, 
2023-03-06 14:24:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0077, Loss_2: 0.0076, Acc_1: 0.6797, Acc_2: 0.6875, 
2023-03-06 14:24:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0067, Loss_2: 0.0064, Acc_1: 0.7344, Acc_2: 0.7578, 
2023-03-06 14:25:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0076, Loss_2: 0.0074, Acc_1: 0.7578, Acc_2: 0.7422, 
2023-03-06 14:25:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0047, Loss_2: 0.0046, Acc_1: 0.8755, Acc_2: 0.8735, F1-score_1: 0.8397, F1-score_2: 0.8367
2023-03-06 14:25:24 - __main__ - INFO - Epoch [2/100]
2023-03-06 14:25:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0055, Loss_2: 0.0057, Acc_1: 0.7734, Acc_2: 0.7500, 
2023-03-06 14:25:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0044, Loss_2: 0.0041, Acc_1: 0.7578, Acc_2: 0.7969, 
2023-03-06 14:25:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0054, Loss_2: 0.0053, Acc_1: 0.7500, Acc_2: 0.7344, 
2023-03-06 14:25:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0055, Loss_2: 0.0057, Acc_1: 0.7656, Acc_2: 0.7500, 
2023-03-06 14:25:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0048, Loss_2: 0.0051, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-06 14:26:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0067, Loss_2: 0.0063, Acc_1: 0.7344, Acc_2: 0.7344, 
2023-03-06 14:26:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0039, Loss_2: 0.0042, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-06 14:26:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0047, Loss_2: 0.0045, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-06 14:26:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0056, Loss_2: 0.0059, Acc_1: 0.7500, Acc_2: 0.7500, 
2023-03-06 14:26:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0048, Loss_2: 0.0053, Acc_1: 0.7891, Acc_2: 0.7734, 
2023-03-06 14:26:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0052, Loss_2: 0.0057, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-06 14:26:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0038, Loss_2: 0.0039, Acc_1: 0.7734, Acc_2: 0.8047, 
2023-03-06 14:27:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0034, Loss_2: 0.0033, Acc_1: 0.8755, Acc_2: 0.8704, F1-score_1: 0.8297, F1-score_2: 0.8221
2023-03-06 14:27:05 - __main__ - INFO - Epoch [3/100]
2023-03-06 14:27:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0027, Loss_2: 0.0031, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-06 14:27:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0030, Loss_2: 0.0034, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-06 14:27:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0028, Loss_2: 0.0030, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 14:27:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0040, Loss_2: 0.0038, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-06 14:27:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0027, Loss_2: 0.0025, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 14:27:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0031, Loss_2: 0.0033, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-06 14:27:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0039, Loss_2: 0.0036, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-06 14:28:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0031, Loss_2: 0.0028, Acc_1: 0.8125, Acc_2: 0.8438, 
2023-03-06 14:28:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0049, Loss_2: 0.0045, Acc_1: 0.7500, Acc_2: 0.7500, 
2023-03-06 14:28:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0035, Loss_2: 0.0037, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-06 14:28:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0037, Loss_2: 0.0031, Acc_1: 0.8047, Acc_2: 0.8359, 
2023-03-06 14:28:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0020, Loss_2: 0.0017, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 14:28:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0028, Loss_2: 0.0030, Acc_1: 0.8578, Acc_2: 0.8565, F1-score_1: 0.8191, F1-score_2: 0.8164
2023-03-06 14:28:47 - __main__ - INFO - Epoch [4/100]
2023-03-06 14:28:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 14:29:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0030, Loss_2: 0.0030, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 14:29:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0016, Loss_2: 0.0018, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 14:29:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0017, Loss_2: 0.0019, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 14:29:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0012, Loss_2: 0.0013, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:29:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0016, Loss_2: 0.0015, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 14:29:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0012, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:29:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0014, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8984, 
2023-03-06 14:29:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0015, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 14:29:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-06 14:30:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0016, Loss_2: 0.0016, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 14:30:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0015, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-06 14:30:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0021, Acc_1: 0.8621, Acc_2: 0.8629, F1-score_1: 0.8231, F1-score_2: 0.8227
2023-03-06 14:30:29 - __main__ - INFO - Epoch [5/100]
2023-03-06 14:30:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 14:30:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 14:30:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:30:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 14:31:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 14:31:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 14:31:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.9375, 
2023-03-06 14:31:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 14:31:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-06 14:31:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0011, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 14:31:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 14:31:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 14:32:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0014, Acc_1: 0.8570, Acc_2: 0.8560, F1-score_1: 0.8169, F1-score_2: 0.8175
2023-03-06 14:32:10 - __main__ - INFO - Epoch [6/100]
2023-03-06 14:32:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 14:32:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-06 14:32:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-06 14:32:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 14:32:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 14:32:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-06 14:32:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 14:33:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 14:33:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-06 14:33:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 14:33:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0014, Loss_2: 0.0020, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-06 14:33:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 14:33:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0014, Acc_1: 0.8616, Acc_2: 0.8536, F1-score_1: 0.8251, F1-score_2: 0.8133
2023-03-06 14:33:52 - __main__ - INFO - Epoch [7/100]
2023-03-06 14:33:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 14:34:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-06 14:34:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:34:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 14:34:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 14:34:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9531, 
2023-03-06 14:34:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 14:34:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:34:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 14:35:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:35:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 14:35:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 14:35:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.8606, Acc_2: 0.8607, F1-score_1: 0.8254, F1-score_2: 0.8234
2023-03-06 14:35:34 - __main__ - INFO - Epoch [8/100]
2023-03-06 14:35:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9688, Acc_2: 0.9531, 
2023-03-06 14:35:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 14:35:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 14:36:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 14:36:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 14:36:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-06 14:36:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 14:36:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 14:36:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 14:36:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 14:36:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:36:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 14:37:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8590, Acc_2: 0.8578, F1-score_1: 0.8230, F1-score_2: 0.8216
2023-03-06 14:37:15 - __main__ - INFO - Epoch [9/100]
2023-03-06 14:37:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:37:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:37:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-06 14:37:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:37:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 14:37:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:38:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:38:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 14:38:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:38:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:38:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 14:38:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 14:38:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8626, Acc_2: 0.8633, F1-score_1: 0.8279, F1-score_2: 0.8260
2023-03-06 14:38:57 - __main__ - INFO - Epoch [10/100]
2023-03-06 14:39:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 14:39:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 14:39:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 14:39:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 14:39:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 14:39:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 14:39:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9688, Acc_2: 0.9688, 
2023-03-06 14:39:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 14:39:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 14:40:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:40:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:40:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 14:40:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8626, Acc_2: 0.8636, F1-score_1: 0.8274, F1-score_2: 0.8281
2023-03-06 14:40:39 - __main__ - INFO - Epoch [11/100]
2023-03-06 14:40:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:40:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:40:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 14:41:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 14:41:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:41:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 14:41:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:41:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 14:41:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 14:41:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 14:41:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:42:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9766, Acc_2: 0.9609, 
2023-03-06 14:42:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8641, Acc_2: 0.8614, F1-score_1: 0.8326, F1-score_2: 0.8247
2023-03-06 14:42:20 - __main__ - INFO - Epoch [12/100]
2023-03-06 14:42:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-06 14:42:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 14:42:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 14:42:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-06 14:42:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:43:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 14:43:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 14:43:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 14:43:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 14:43:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 14:43:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:43:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 14:44:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8651, Acc_2: 0.8631, F1-score_1: 0.8288, F1-score_2: 0.8250
2023-03-06 14:44:02 - __main__ - INFO - Epoch [13/100]
2023-03-06 14:44:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 14:44:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 14:44:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:44:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:44:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:44:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:44:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-06 14:44:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 14:45:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 14:45:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 14:45:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:45:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 14:45:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8648, Acc_2: 0.8611, F1-score_1: 0.8321, F1-score_2: 0.8247
2023-03-06 14:45:44 - __main__ - INFO - Epoch [14/100]
2023-03-06 14:45:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 14:45:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 14:46:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 14:46:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 14:46:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 14:46:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 14:46:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 14:46:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 14:46:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 14:46:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:47:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 14:47:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 14:47:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8643, Acc_2: 0.8633, F1-score_1: 0.8306, F1-score_2: 0.8252
2023-03-06 14:47:25 - __main__ - INFO - Epoch [15/100]
2023-03-06 14:47:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-06 14:47:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-06 14:47:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 14:47:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 14:47:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 14:48:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 14:48:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:48:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-06 14:48:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 14:48:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 14:48:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:48:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:49:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8667, Acc_2: 0.8621, F1-score_1: 0.8330, F1-score_2: 0.8253
2023-03-06 14:49:07 - __main__ - INFO - Epoch [16/100]
2023-03-06 14:49:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 14:49:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:49:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9453, 
2023-03-06 14:49:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:49:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 14:49:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 14:49:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 14:50:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 14:50:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 14:50:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 14:50:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:50:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 14:50:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8616, Acc_2: 0.8628, F1-score_1: 0.8251, F1-score_2: 0.8245
2023-03-06 14:50:49 - __main__ - INFO - Epoch [17/100]
2023-03-06 14:50:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 14:51:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 14:51:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 14:51:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:51:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 14:51:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 14:51:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:51:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 14:51:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 14:51:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:52:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:52:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 14:52:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8587, Acc_2: 0.8628, F1-score_1: 0.8245, F1-score_2: 0.8277
2023-03-06 14:52:30 - __main__ - INFO - Epoch [18/100]
2023-03-06 14:52:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 14:52:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 14:52:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 14:52:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:53:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 14:53:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:53:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0015, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:53:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 14:53:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 14:53:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 14:53:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 14:53:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 14:54:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8651, Acc_2: 0.8533, F1-score_1: 0.8314, F1-score_2: 0.8203
2023-03-06 14:54:12 - __main__ - INFO - Epoch [19/100]
2023-03-06 14:54:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9688, Acc_2: 0.9609, 
2023-03-06 14:54:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:54:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 14:54:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 14:54:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 14:54:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:55:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:55:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 14:55:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 14:55:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 14:55:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 14:55:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 14:55:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8631, Acc_2: 0.8618, F1-score_1: 0.8271, F1-score_2: 0.8210
2023-03-06 14:55:54 - __main__ - INFO - Epoch [20/100]
2023-03-06 14:55:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 14:56:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 14:56:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-06 14:56:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 14:56:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 14:56:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 14:56:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-06 14:56:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 14:56:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 14:57:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 14:57:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 14:57:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 14:57:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8575, Acc_2: 0.8618, F1-score_1: 0.8240, F1-score_2: 0.8237
2023-03-06 14:57:35 - __main__ - INFO - Epoch [21/100]
2023-03-06 14:57:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 14:57:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:57:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 14:58:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:58:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 14:58:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:58:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 14:58:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 14:58:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 14:58:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 14:58:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 14:58:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:59:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8565, Acc_2: 0.8585, F1-score_1: 0.8193, F1-score_2: 0.8231
2023-03-06 14:59:17 - __main__ - INFO - Epoch [22/100]
2023-03-06 14:59:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 14:59:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 14:59:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 14:59:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 14:59:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-06 14:59:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 15:00:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-06 15:00:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-06 15:00:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 15:00:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:00:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:00:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 15:00:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8580, Acc_2: 0.8585, F1-score_1: 0.8221, F1-score_2: 0.8207
2023-03-06 15:00:58 - __main__ - INFO - Epoch [23/100]
2023-03-06 15:01:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 15:01:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 15:01:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:01:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 15:01:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 15:01:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 15:01:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 15:01:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 15:02:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 15:02:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 15:02:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 15:02:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:02:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8419, Acc_2: 0.8471, F1-score_1: 0.8057, F1-score_2: 0.8096
2023-03-06 15:02:40 - __main__ - INFO - Epoch [24/100]
2023-03-06 15:02:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:02:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:02:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 15:03:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 15:03:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-06 15:03:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 15:03:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 15:03:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:03:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-06 15:03:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0015, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:03:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:04:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 15:04:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8522, Acc_2: 0.8645, F1-score_1: 0.8114, F1-score_2: 0.8240
2023-03-06 15:04:21 - __main__ - INFO - Epoch [25/100]
2023-03-06 15:04:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9453, 
2023-03-06 15:04:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9297, 
2023-03-06 15:04:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 15:04:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-06 15:04:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 15:05:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0019, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 15:05:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 15:05:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0015, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 15:05:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-06 15:05:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 15:05:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 15:05:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 15:06:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8417, Acc_2: 0.8415, F1-score_1: 0.7912, F1-score_2: 0.7980
2023-03-06 15:06:03 - __main__ - INFO - Epoch [26/100]
2023-03-06 15:06:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 15:06:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-06 15:06:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0016, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 15:06:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0032, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 15:06:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.9141, 
2023-03-06 15:06:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 15:06:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 15:06:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0012, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-06 15:07:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0010, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 15:07:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0014, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 15:07:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0010, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 15:07:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0023, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8359, 
2023-03-06 15:07:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0039, Loss_2: 0.0022, Acc_1: 0.8229, Acc_2: 0.8268, F1-score_1: 0.7802, F1-score_2: 0.7856
2023-03-06 15:07:45 - __main__ - INFO - Epoch [27/100]
2023-03-06 15:07:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0025, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:07:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:08:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 15:08:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-06 15:08:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-06 15:08:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-06 15:08:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0013, Loss_2: 0.0011, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 15:08:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:08:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 15:08:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0020, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 15:09:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 15:09:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8828, 
2023-03-06 15:09:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0011, Acc_1: 0.8203, Acc_2: 0.8173, F1-score_1: 0.7728, F1-score_2: 0.7727
2023-03-06 15:09:26 - __main__ - INFO - Epoch [28/100]
2023-03-06 15:09:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 15:09:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 15:09:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0011, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 15:09:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 15:10:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:10:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 15:10:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 15:10:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 15:10:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 15:10:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0027, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:10:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 15:10:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 15:11:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0021, Acc_1: 0.8324, Acc_2: 0.8327, F1-score_1: 0.7880, F1-score_2: 0.7932
2023-03-06 15:11:08 - __main__ - INFO - Epoch [29/100]
2023-03-06 15:11:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 15:11:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 15:11:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 15:11:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0010, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 15:11:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 15:11:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 15:11:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-06 15:12:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 15:12:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:12:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:12:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-06 15:12:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 15:12:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8351, Acc_2: 0.8319, F1-score_1: 0.7970, F1-score_2: 0.7897
2023-03-06 15:12:49 - __main__ - INFO - Epoch [30/100]
2023-03-06 15:12:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 15:13:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-06 15:13:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 15:13:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:13:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:13:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 15:13:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-06 15:13:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 15:13:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:13:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 15:14:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 15:14:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 15:14:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8504, Acc_2: 0.8429, F1-score_1: 0.8116, F1-score_2: 0.7968
2023-03-06 15:14:31 - __main__ - INFO - Epoch [31/100]
2023-03-06 15:14:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 15:14:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-06 15:14:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 15:14:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 15:15:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 15:15:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 15:15:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 15:15:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 15:15:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 15:15:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 15:15:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 15:15:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 15:16:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0028, Loss_2: 0.0004, Acc_1: 0.8398, Acc_2: 0.8431, F1-score_1: 0.8048, F1-score_2: 0.8008
2023-03-06 15:16:13 - __main__ - INFO - Epoch [32/100]
2023-03-06 15:16:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 15:16:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 15:16:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 15:16:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 15:16:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 15:16:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 15:17:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 15:17:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-06 15:17:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 15:17:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 15:17:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 15:17:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 15:17:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8404, Acc_2: 0.8410, F1-score_1: 0.7984, F1-score_2: 0.7983
2023-03-06 15:17:54 - __main__ - INFO - Epoch [33/100]
2023-03-06 15:18:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 15:18:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:18:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 15:18:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 15:18:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:18:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 15:18:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:18:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 15:18:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 15:19:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-06 15:19:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 15:19:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 15:19:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0005, Acc_1: 0.8404, Acc_2: 0.8414, F1-score_1: 0.7975, F1-score_2: 0.7985
2023-03-06 15:19:36 - __main__ - INFO - Epoch [34/100]
2023-03-06 15:19:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 15:19:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 15:19:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:20:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 15:20:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 15:20:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 15:20:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:20:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 15:20:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-06 15:20:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:20:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 15:20:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 15:21:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0003, Acc_1: 0.8429, Acc_2: 0.8398, F1-score_1: 0.8075, F1-score_2: 0.7968
2023-03-06 15:21:18 - __main__ - INFO - Epoch [35/100]
2023-03-06 15:21:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:21:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 15:21:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 15:21:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 15:21:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 15:21:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 15:22:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 15:22:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:22:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 15:22:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9453, 
2023-03-06 15:22:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 15:22:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 15:23:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8339, Acc_2: 0.8303, F1-score_1: 0.7903, F1-score_2: 0.7895
2023-03-06 15:23:00 - __main__ - INFO - Epoch [36/100]
2023-03-06 15:23:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 15:23:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 15:23:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:23:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 15:23:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 15:23:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 15:23:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-06 15:23:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 15:24:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 15:24:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 15:24:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 15:24:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 15:24:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8410, Acc_2: 0.8373, F1-score_1: 0.8013, F1-score_2: 0.7968
2023-03-06 15:24:41 - __main__ - INFO - Epoch [37/100]
2023-03-06 15:24:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:24:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 15:25:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:25:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 15:25:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 15:25:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-06 15:25:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:25:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 15:25:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 15:25:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 15:25:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9297, 
2023-03-06 15:26:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 15:26:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8422, Acc_2: 0.8370, F1-score_1: 0.8052, F1-score_2: 0.7949
2023-03-06 15:26:23 - __main__ - INFO - Epoch [38/100]
2023-03-06 15:26:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 15:26:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:26:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 15:26:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-06 15:26:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:27:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 15:27:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 15:27:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 15:27:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-06 15:27:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:27:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:27:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 15:28:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0009, Acc_1: 0.8422, Acc_2: 0.8443, F1-score_1: 0.8058, F1-score_2: 0.8022
2023-03-06 15:28:04 - __main__ - INFO - Epoch [39/100]
2023-03-06 15:28:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:28:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-06 15:28:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 15:28:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 15:28:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 15:28:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 15:28:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 15:28:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 15:29:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:29:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 15:29:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 15:29:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 15:29:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8477, Acc_2: 0.8307, F1-score_1: 0.8083, F1-score_2: 0.7878
2023-03-06 15:29:46 - __main__ - INFO - Epoch [40/100]
2023-03-06 15:29:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 15:29:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 15:30:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 15:30:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:30:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:30:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 15:30:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 15:30:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 15:30:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 15:30:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:31:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:31:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-06 15:31:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0009, Acc_1: 0.8344, Acc_2: 0.8364, F1-score_1: 0.7897, F1-score_2: 0.7908
2023-03-06 15:31:27 - __main__ - INFO - Epoch [41/100]
2023-03-06 15:31:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-06 15:31:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 15:31:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:31:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 15:32:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 15:32:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:32:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 15:32:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 15:32:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 15:32:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 15:32:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 15:32:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:33:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0008, Acc_1: 0.8456, Acc_2: 0.8285, F1-score_1: 0.8086, F1-score_2: 0.7953
2023-03-06 15:33:09 - __main__ - INFO - Epoch [42/100]
2023-03-06 15:33:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:33:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 15:33:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 15:33:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 15:33:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 15:33:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 15:33:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 15:34:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 15:34:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-06 15:34:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 15:34:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 15:34:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-06 15:34:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0004, Acc_1: 0.8392, Acc_2: 0.8446, F1-score_1: 0.8101, F1-score_2: 0.8066
2023-03-06 15:34:51 - __main__ - INFO - Epoch [43/100]
2023-03-06 15:34:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 15:35:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:35:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:35:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:35:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:35:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 15:35:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:35:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:35:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 15:36:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:36:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:36:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 15:36:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0001, Acc_1: 0.8310, Acc_2: 0.8329, F1-score_1: 0.7972, F1-score_2: 0.7870
2023-03-06 15:36:32 - __main__ - INFO - Epoch [44/100]
2023-03-06 15:36:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 15:36:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 15:36:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:36:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 15:37:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 15:37:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 15:37:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 15:37:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-06 15:37:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 15:37:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0011, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-06 15:37:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-06 15:37:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 15:38:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0004, Acc_1: 0.8451, Acc_2: 0.8390, F1-score_1: 0.8085, F1-score_2: 0.7896
2023-03-06 15:38:14 - __main__ - INFO - Epoch [45/100]
2023-03-06 15:38:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:38:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 15:38:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 15:38:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 15:38:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 15:38:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 15:39:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 15:39:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:39:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 15:39:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 15:39:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 15:39:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 15:39:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0010, Acc_1: 0.8341, Acc_2: 0.8240, F1-score_1: 0.7935, F1-score_2: 0.7812
2023-03-06 15:39:55 - __main__ - INFO - Epoch [46/100]
2023-03-06 15:40:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-06 15:40:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 15:40:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 15:40:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 15:40:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:40:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 15:40:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:40:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 15:40:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:41:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:41:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:41:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 15:41:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0034, Acc_1: 0.8271, Acc_2: 0.8390, F1-score_1: 0.7972, F1-score_2: 0.8032
2023-03-06 15:41:37 - __main__ - INFO - Epoch [47/100]
2023-03-06 15:41:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 15:41:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 15:41:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:42:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 15:42:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 15:42:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:42:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 15:42:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 15:42:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 15:42:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 15:42:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 15:42:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 15:43:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0011, Acc_1: 0.8407, Acc_2: 0.8283, F1-score_1: 0.8045, F1-score_2: 0.7885
2023-03-06 15:43:19 - __main__ - INFO - Epoch [48/100]
2023-03-06 15:43:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 15:43:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 15:43:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 15:43:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 15:43:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 15:43:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 15:44:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 15:44:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 15:44:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 15:44:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 15:44:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 15:44:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 15:45:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0031, Acc_1: 0.8142, Acc_2: 0.8339, F1-score_1: 0.7704, F1-score_2: 0.7935
2023-03-06 15:45:00 - __main__ - INFO - Epoch [49/100]
2023-03-06 15:45:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 15:45:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:45:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 15:45:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 15:45:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 15:45:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 15:45:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:45:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 15:46:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:46:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 15:46:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 15:46:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:46:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.8439, Acc_2: 0.8378, F1-score_1: 0.8030, F1-score_2: 0.7977
2023-03-06 15:46:42 - __main__ - INFO - Epoch [50/100]
2023-03-06 15:46:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 15:46:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 15:47:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 15:47:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 15:47:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:47:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-06 15:47:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 15:47:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 15:47:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 15:47:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 15:47:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 15:48:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 15:48:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8397, Acc_2: 0.8407, F1-score_1: 0.7994, F1-score_2: 0.7941
2023-03-06 15:48:23 - __main__ - INFO - Epoch [51/100]
2023-03-06 15:48:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:48:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 15:48:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 15:48:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-06 15:48:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:49:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 15:49:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 15:49:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:49:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 15:49:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 15:49:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 15:49:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 15:50:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0011, Loss_2: 0.0008, Acc_1: 0.8370, Acc_2: 0.8439, F1-score_1: 0.7902, F1-score_2: 0.8065
2023-03-06 15:50:05 - __main__ - INFO - Epoch [52/100]
2023-03-06 15:50:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 15:50:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 15:50:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 15:50:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:50:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 15:50:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 15:50:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:51:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 15:51:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:51:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 15:51:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 15:51:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 15:51:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0023, Acc_1: 0.8393, Acc_2: 0.8261, F1-score_1: 0.8014, F1-score_2: 0.7892
2023-03-06 15:51:47 - __main__ - INFO - Epoch [53/100]
2023-03-06 15:51:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:51:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 15:52:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 15:52:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 15:52:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 15:52:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-06 15:52:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:52:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 15:52:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 15:52:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 15:53:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-06 15:53:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 15:53:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0044, Acc_1: 0.8324, Acc_2: 0.8354, F1-score_1: 0.7873, F1-score_2: 0.7910
2023-03-06 15:53:28 - __main__ - INFO - Epoch [54/100]
2023-03-06 15:53:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 15:53:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 15:53:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 15:53:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:54:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 15:54:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-06 15:54:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 15:54:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 15:54:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 15:54:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 15:54:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 15:54:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 15:55:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.8249, Acc_2: 0.8300, F1-score_1: 0.7798, F1-score_2: 0.7924
2023-03-06 15:55:10 - __main__ - INFO - Epoch [55/100]
2023-03-06 15:55:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 15:55:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 15:55:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 15:55:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 15:55:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 15:55:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 15:55:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 15:56:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 15:56:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 15:56:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 15:56:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 15:56:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 15:56:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0038, Acc_1: 0.8325, Acc_2: 0.8246, F1-score_1: 0.7837, F1-score_2: 0.7897
2023-03-06 15:56:52 - __main__ - INFO - Epoch [56/100]
2023-03-06 15:56:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 15:57:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 15:57:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 15:57:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 15:57:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 15:57:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 15:57:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 15:57:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 15:57:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 15:58:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 15:58:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:58:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-06 15:58:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0019, Acc_1: 0.8346, Acc_2: 0.8347, F1-score_1: 0.7891, F1-score_2: 0.7894
2023-03-06 15:58:33 - __main__ - INFO - Epoch [57/100]
2023-03-06 15:58:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0024, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-06 15:58:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 15:58:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-06 15:59:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 15:59:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 15:59:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 15:59:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 15:59:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-06 15:59:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 15:59:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 15:59:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 15:59:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 16:00:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0003, Acc_1: 0.8393, Acc_2: 0.8198, F1-score_1: 0.7980, F1-score_2: 0.7632
2023-03-06 16:00:15 - __main__ - INFO - Epoch [58/100]
2023-03-06 16:00:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 16:00:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 16:00:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:00:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 16:00:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:00:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:01:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 16:01:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 16:01:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 16:01:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 16:01:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:01:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 16:01:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0023, Loss_2: 0.0025, Acc_1: 0.8342, Acc_2: 0.8263, F1-score_1: 0.7970, F1-score_2: 0.7804
2023-03-06 16:01:57 - __main__ - INFO - Epoch [59/100]
2023-03-06 16:02:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 16:02:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 16:02:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:02:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 16:02:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 16:02:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-06 16:02:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:02:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:02:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:03:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 16:03:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 16:03:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 16:03:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8310, Acc_2: 0.8398, F1-score_1: 0.7916, F1-score_2: 0.7936
2023-03-06 16:03:38 - __main__ - INFO - Epoch [60/100]
2023-03-06 16:03:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 16:03:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:03:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 16:04:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 16:04:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 16:04:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:04:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 16:04:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 16:04:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 16:04:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 16:04:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:05:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:05:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0022, Acc_1: 0.8339, Acc_2: 0.8247, F1-score_1: 0.7996, F1-score_2: 0.7872
2023-03-06 16:05:20 - __main__ - INFO - Epoch [61/100]
2023-03-06 16:05:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 16:05:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:05:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 16:05:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:05:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 16:06:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 16:06:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:06:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 16:06:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 16:06:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 16:06:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:06:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:07:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8281, Acc_2: 0.8419, F1-score_1: 0.7823, F1-score_2: 0.7995
2023-03-06 16:07:01 - __main__ - INFO - Epoch [62/100]
2023-03-06 16:07:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 16:07:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-06 16:07:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 16:07:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 16:07:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 16:07:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 16:07:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 16:07:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 16:08:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-06 16:08:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 16:08:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 16:08:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 16:08:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8341, Acc_2: 0.8358, F1-score_1: 0.7895, F1-score_2: 0.7910
2023-03-06 16:08:43 - __main__ - INFO - Epoch [63/100]
2023-03-06 16:08:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:08:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 16:09:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:09:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:09:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:09:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:09:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 16:09:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 16:09:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 16:09:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 16:09:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:10:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:10:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0013, Acc_1: 0.8331, Acc_2: 0.8392, F1-score_1: 0.7892, F1-score_2: 0.7954
2023-03-06 16:10:25 - __main__ - INFO - Epoch [64/100]
2023-03-06 16:10:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 16:10:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 16:10:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 16:10:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 16:10:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:11:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 16:11:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 16:11:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:11:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 16:11:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 16:11:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 16:11:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:12:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8381, Acc_2: 0.8359, F1-score_1: 0.7945, F1-score_2: 0.7930
2023-03-06 16:12:06 - __main__ - INFO - Epoch [65/100]
2023-03-06 16:12:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 16:12:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 16:12:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 16:12:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:12:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:12:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 16:12:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 16:13:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 16:13:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 16:13:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 16:13:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 16:13:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 16:13:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0021, Acc_1: 0.8370, Acc_2: 0.8331, F1-score_1: 0.7932, F1-score_2: 0.7898
2023-03-06 16:13:48 - __main__ - INFO - Epoch [66/100]
2023-03-06 16:13:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:14:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:14:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:14:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:14:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9375, 
2023-03-06 16:14:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:14:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 16:14:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:14:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 16:14:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:15:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:15:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 16:15:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0004, Acc_1: 0.8169, Acc_2: 0.8368, F1-score_1: 0.7692, F1-score_2: 0.7885
2023-03-06 16:15:30 - __main__ - INFO - Epoch [67/100]
2023-03-06 16:15:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:15:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 16:15:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 16:15:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-06 16:16:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:16:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 16:16:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:16:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:16:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:16:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:16:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 16:16:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 16:17:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.8331, Acc_2: 0.8315, F1-score_1: 0.7830, F1-score_2: 0.7877
2023-03-06 16:17:11 - __main__ - INFO - Epoch [68/100]
2023-03-06 16:17:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 16:17:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:17:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:17:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:17:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 16:17:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:17:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 16:18:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:18:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 16:18:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 16:18:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 16:18:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:18:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0009, Acc_1: 0.8347, Acc_2: 0.8366, F1-score_1: 0.7942, F1-score_2: 0.7907
2023-03-06 16:18:53 - __main__ - INFO - Epoch [69/100]
2023-03-06 16:18:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 16:19:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 16:19:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:19:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 16:19:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 16:19:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-06 16:19:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:19:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 16:19:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:20:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 16:20:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 16:20:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:20:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0004, Acc_1: 0.8363, Acc_2: 0.8314, F1-score_1: 0.7920, F1-score_2: 0.7877
2023-03-06 16:20:35 - __main__ - INFO - Epoch [70/100]
2023-03-06 16:20:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 16:20:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 16:20:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:21:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:21:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:21:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 16:21:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9609, 
2023-03-06 16:21:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 16:21:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 16:21:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:21:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:21:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 16:22:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0020, Acc_1: 0.8329, Acc_2: 0.8353, F1-score_1: 0.7903, F1-score_2: 0.7879
2023-03-06 16:22:17 - __main__ - INFO - Epoch [71/100]
2023-03-06 16:22:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:22:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:22:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 16:22:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 16:22:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 16:22:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 16:23:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 16:23:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 16:23:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 16:23:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:23:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 16:23:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 16:23:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.8334, Acc_2: 0.8264, F1-score_1: 0.7894, F1-score_2: 0.7814
2023-03-06 16:23:58 - __main__ - INFO - Epoch [72/100]
2023-03-06 16:24:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 16:24:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 16:24:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:24:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:24:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:24:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 16:24:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 16:24:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0026, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 16:25:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:25:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:25:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 16:25:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 16:25:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0011, Loss_2: 0.0016, Acc_1: 0.8361, Acc_2: 0.8302, F1-score_1: 0.7921, F1-score_2: 0.7881
2023-03-06 16:25:40 - __main__ - INFO - Epoch [73/100]
2023-03-06 16:25:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 16:25:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:25:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 16:26:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:26:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 16:26:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-06 16:26:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:26:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:26:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 16:26:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 16:26:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 16:27:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 16:27:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0035, Acc_1: 0.8164, Acc_2: 0.8188, F1-score_1: 0.7660, F1-score_2: 0.7751
2023-03-06 16:27:21 - __main__ - INFO - Epoch [74/100]
2023-03-06 16:27:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:27:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 16:27:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:27:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:27:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 16:28:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0022, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:28:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 16:28:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-06 16:28:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-06 16:28:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 16:28:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:28:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0017, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-06 16:29:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0005, Acc_1: 0.8346, Acc_2: 0.8225, F1-score_1: 0.7935, F1-score_2: 0.7711
2023-03-06 16:29:03 - __main__ - INFO - Epoch [75/100]
2023-03-06 16:29:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 16:29:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 16:29:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-06 16:29:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 16:29:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 16:29:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:29:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:29:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 16:30:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 16:30:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 16:30:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 16:30:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 16:30:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0004, Acc_1: 0.8303, Acc_2: 0.8324, F1-score_1: 0.7857, F1-score_2: 0.7881
2023-03-06 16:30:45 - __main__ - INFO - Epoch [76/100]
2023-03-06 16:30:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 16:30:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 16:31:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 16:31:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 16:31:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-06 16:31:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:31:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 16:31:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:31:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 16:31:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:32:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 16:32:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:32:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0016, Acc_1: 0.8314, Acc_2: 0.8324, F1-score_1: 0.7820, F1-score_2: 0.7906
2023-03-06 16:32:26 - __main__ - INFO - Epoch [77/100]
2023-03-06 16:32:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:32:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:32:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 16:32:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 16:33:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:33:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 16:33:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:33:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0012, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 16:33:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 16:33:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:33:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 16:33:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 16:34:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0054, Loss_2: 0.0027, Acc_1: 0.8139, Acc_2: 0.8244, F1-score_1: 0.7796, F1-score_2: 0.7873
2023-03-06 16:34:08 - __main__ - INFO - Epoch [78/100]
2023-03-06 16:34:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:34:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:34:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 16:34:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 16:34:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 16:34:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:34:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 16:35:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:35:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 16:35:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 16:35:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 16:35:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 16:35:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0007, Acc_1: 0.8295, Acc_2: 0.8257, F1-score_1: 0.7831, F1-score_2: 0.7839
2023-03-06 16:35:49 - __main__ - INFO - Epoch [79/100]
2023-03-06 16:35:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 16:36:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:36:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 16:36:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 16:36:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:36:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 16:36:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-06 16:36:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 16:36:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 16:36:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:37:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0014, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 16:37:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 16:37:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0046, Loss_2: 0.0017, Acc_1: 0.8234, Acc_2: 0.8322, F1-score_1: 0.7825, F1-score_2: 0.7907
2023-03-06 16:37:31 - __main__ - INFO - Epoch [80/100]
2023-03-06 16:37:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:37:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 16:37:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:37:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:38:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 16:38:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:38:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 16:38:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:38:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 16:38:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 16:38:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:38:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:39:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0037, Loss_2: 0.0024, Acc_1: 0.8290, Acc_2: 0.8337, F1-score_1: 0.7846, F1-score_2: 0.7871
2023-03-06 16:39:12 - __main__ - INFO - Epoch [81/100]
2023-03-06 16:39:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 16:39:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 16:39:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:39:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 16:39:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:39:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 16:40:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:40:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:40:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:40:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 16:40:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 16:40:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 16:40:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0023, Loss_2: 0.0025, Acc_1: 0.8310, Acc_2: 0.8144, F1-score_1: 0.7887, F1-score_2: 0.7657
2023-03-06 16:40:54 - __main__ - INFO - Epoch [82/100]
2023-03-06 16:41:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:41:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 16:41:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 16:41:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-06 16:41:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:41:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 16:41:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:41:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 16:41:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 16:42:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:42:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 16:42:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:42:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0045, Acc_1: 0.8259, Acc_2: 0.8174, F1-score_1: 0.7855, F1-score_2: 0.7837
2023-03-06 16:42:36 - __main__ - INFO - Epoch [83/100]
2023-03-06 16:42:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 16:42:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:42:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:43:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 16:43:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 16:43:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 16:43:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 16:43:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 16:43:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 16:43:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 16:43:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 16:43:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 16:44:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0042, Loss_2: 0.0007, Acc_1: 0.8256, Acc_2: 0.8327, F1-score_1: 0.7816, F1-score_2: 0.7888
2023-03-06 16:44:18 - __main__ - INFO - Epoch [84/100]
2023-03-06 16:44:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 16:44:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 16:44:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:44:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:44:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:44:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:45:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:45:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 16:45:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:45:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:45:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 16:45:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 16:45:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0051, Loss_2: 0.0005, Acc_1: 0.8254, Acc_2: 0.8346, F1-score_1: 0.7806, F1-score_2: 0.7917
2023-03-06 16:45:59 - __main__ - INFO - Epoch [85/100]
2023-03-06 16:46:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 16:46:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 16:46:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 16:46:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 16:46:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 16:46:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 16:46:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:46:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 16:47:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:47:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:47:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:47:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 16:47:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0016, Acc_1: 0.8261, Acc_2: 0.8283, F1-score_1: 0.7798, F1-score_2: 0.7886
2023-03-06 16:47:41 - __main__ - INFO - Epoch [86/100]
2023-03-06 16:47:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:47:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 16:48:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 16:48:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 16:48:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 16:48:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:48:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:48:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 16:48:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 16:48:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:48:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:49:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 16:49:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0040, Loss_2: 0.0045, Acc_1: 0.8225, Acc_2: 0.7994, F1-score_1: 0.7691, F1-score_2: 0.7505
2023-03-06 16:49:22 - __main__ - INFO - Epoch [87/100]
2023-03-06 16:49:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:49:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 16:49:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:49:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:49:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:50:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:50:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 16:50:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 16:50:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 16:50:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 16:50:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 16:50:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:51:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0007, Acc_1: 0.8239, Acc_2: 0.8325, F1-score_1: 0.7799, F1-score_2: 0.7890
2023-03-06 16:51:04 - __main__ - INFO - Epoch [88/100]
2023-03-06 16:51:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:51:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:51:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:51:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 16:51:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 16:51:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:51:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:51:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:52:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:52:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 16:52:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 16:52:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:52:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0007, Acc_1: 0.8276, Acc_2: 0.8351, F1-score_1: 0.7832, F1-score_2: 0.7899
2023-03-06 16:52:46 - __main__ - INFO - Epoch [89/100]
2023-03-06 16:52:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 16:52:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 16:53:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 16:53:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-06 16:53:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:53:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:53:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:53:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:53:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:53:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 16:54:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 16:54:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 16:54:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0010, Acc_1: 0.8203, Acc_2: 0.8332, F1-score_1: 0.7710, F1-score_2: 0.7914
2023-03-06 16:54:28 - __main__ - INFO - Epoch [90/100]
2023-03-06 16:54:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 16:54:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 16:54:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 16:54:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 16:55:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 16:55:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 16:55:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 16:55:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:55:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 16:55:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 16:55:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 16:55:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:56:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0009, Acc_1: 0.8288, Acc_2: 0.8302, F1-score_1: 0.7823, F1-score_2: 0.7914
2023-03-06 16:56:09 - __main__ - INFO - Epoch [91/100]
2023-03-06 16:56:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 16:56:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:56:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:56:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 16:56:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 16:56:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 16:56:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 16:57:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:57:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 16:57:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 16:57:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 16:57:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 16:57:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0006, Acc_1: 0.8298, Acc_2: 0.8339, F1-score_1: 0.7872, F1-score_2: 0.7924
2023-03-06 16:57:51 - __main__ - INFO - Epoch [92/100]
2023-03-06 16:57:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 16:58:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:58:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 16:58:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 16:58:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 16:58:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 16:58:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:58:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-06 16:58:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 16:59:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:59:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 16:59:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 16:59:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0005, Acc_1: 0.8259, Acc_2: 0.8342, F1-score_1: 0.7822, F1-score_2: 0.7913
2023-03-06 16:59:33 - __main__ - INFO - Epoch [93/100]
2023-03-06 16:59:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:59:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 16:59:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 16:59:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:00:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:00:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:00:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 17:00:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 17:00:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:00:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 17:00:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 17:00:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 17:01:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0012, Acc_1: 0.8137, Acc_2: 0.8346, F1-score_1: 0.7695, F1-score_2: 0.7933
2023-03-06 17:01:14 - __main__ - INFO - Epoch [94/100]
2023-03-06 17:01:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-06 17:01:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 17:01:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 17:01:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:01:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 17:01:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:02:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:02:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 17:02:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 17:02:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 17:02:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:02:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 17:02:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0005, Acc_1: 0.8229, Acc_2: 0.8324, F1-score_1: 0.7796, F1-score_2: 0.7898
2023-03-06 17:02:55 - __main__ - INFO - Epoch [95/100]
2023-03-06 17:03:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:03:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 17:03:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 17:03:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 17:03:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 17:03:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 17:03:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 17:03:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:03:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:04:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 17:04:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 17:04:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 17:04:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0006, Acc_1: 0.8259, Acc_2: 0.8332, F1-score_1: 0.7827, F1-score_2: 0.7903
2023-03-06 17:04:37 - __main__ - INFO - Epoch [96/100]
2023-03-06 17:04:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 17:04:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-06 17:04:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:05:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 17:05:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 17:05:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 17:05:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 17:05:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 17:05:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:05:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 17:05:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 17:05:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 17:06:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0003, Acc_1: 0.8244, Acc_2: 0.8331, F1-score_1: 0.7780, F1-score_2: 0.7902
2023-03-06 17:06:19 - __main__ - INFO - Epoch [97/100]
2023-03-06 17:06:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 17:06:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:06:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:06:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:06:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:07:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 17:07:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 17:07:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:07:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 17:07:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:07:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 17:07:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 17:08:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0004, Acc_1: 0.8264, Acc_2: 0.8347, F1-score_1: 0.7807, F1-score_2: 0.7921
2023-03-06 17:08:01 - __main__ - INFO - Epoch [98/100]
2023-03-06 17:08:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:08:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:08:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 17:08:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 17:08:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-06 17:08:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 17:08:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 17:08:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 17:09:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 17:09:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 17:09:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 17:09:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:09:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0047, Loss_2: 0.0003, Acc_1: 0.8234, Acc_2: 0.8310, F1-score_1: 0.7780, F1-score_2: 0.7866
2023-03-06 17:09:42 - __main__ - INFO - Epoch [99/100]
2023-03-06 17:09:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 17:09:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 17:10:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 17:10:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 17:10:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 17:10:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:10:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 17:10:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 17:10:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 17:10:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 17:10:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 17:11:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 17:11:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0046, Loss_2: 0.0004, Acc_1: 0.8234, Acc_2: 0.8325, F1-score_1: 0.7779, F1-score_2: 0.7891
2023-03-06 17:11:26 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 17:11:26 - utils._noise - DEBUG - 6, 7
2023-03-06 17:11:26 - utils._noise - DEBUG - 13997
2023-03-06 17:11:26 - utils._noise - INFO - Actual noise 0.20
2023-03-06 17:11:26 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-06 17:11:26 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-06 17:11:28 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 17:11:28 - __main__ - INFO - Loading dataset...
2023-03-06 17:11:28 - __main__ - INFO - Building model...
2023-03-06 17:11:28 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 17:11:28 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 17:11:28 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-06 17:11:28 - __main__ - INFO - Start train & evaluate
2023-03-06 17:11:28 - __main__ - INFO - Epoch [0/100]
2023-03-06 17:11:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0154, Loss_2: 0.0159, Acc_1: 0.1328, Acc_2: 0.0547, 
2023-03-06 17:11:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0127, Loss_2: 0.0130, Acc_1: 0.4766, Acc_2: 0.4375, 
2023-03-06 17:11:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0119, Loss_2: 0.0118, Acc_1: 0.5469, Acc_2: 0.4844, 
2023-03-06 17:11:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0099, Loss_2: 0.0096, Acc_1: 0.6016, Acc_2: 0.6562, 
2023-03-06 17:12:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0093, Loss_2: 0.0094, Acc_1: 0.6797, Acc_2: 0.6250, 
2023-03-06 17:12:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0110, Loss_2: 0.0111, Acc_1: 0.6328, Acc_2: 0.6250, 
2023-03-06 17:12:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0103, Loss_2: 0.0103, Acc_1: 0.6016, Acc_2: 0.6172, 
2023-03-06 17:12:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0086, Loss_2: 0.0088, Acc_1: 0.6641, Acc_2: 0.6562, 
2023-03-06 17:12:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0105, Loss_2: 0.0108, Acc_1: 0.6250, Acc_2: 0.6172, 
2023-03-06 17:12:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0103, Loss_2: 0.0100, Acc_1: 0.5938, Acc_2: 0.6328, 
2023-03-06 17:12:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0094, Loss_2: 0.0094, Acc_1: 0.6953, Acc_2: 0.6797, 
2023-03-06 17:12:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0073, Loss_2: 0.0071, Acc_1: 0.7500, Acc_2: 0.7734, 
2023-03-06 17:13:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0057, Acc_1: 0.8687, Acc_2: 0.8645, F1-score_1: 0.8274, F1-score_2: 0.8229
2023-03-06 17:13:10 - __main__ - INFO - Epoch [1/100]
2023-03-06 17:13:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0073, Loss_2: 0.0073, Acc_1: 0.7578, Acc_2: 0.7344, 
2023-03-06 17:13:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0067, Loss_2: 0.0068, Acc_1: 0.6953, Acc_2: 0.7109, 
2023-03-06 17:13:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0073, Loss_2: 0.0074, Acc_1: 0.7344, Acc_2: 0.7031, 
2023-03-06 17:13:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0077, Loss_2: 0.0076, Acc_1: 0.7266, Acc_2: 0.7422, 
2023-03-06 17:13:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0081, Loss_2: 0.0082, Acc_1: 0.7109, Acc_2: 0.7188, 
2023-03-06 17:13:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0085, Loss_2: 0.0085, Acc_1: 0.7109, Acc_2: 0.7109, 
2023-03-06 17:13:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0059, Loss_2: 0.0058, Acc_1: 0.7734, Acc_2: 0.7969, 
2023-03-06 17:14:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0098, Loss_2: 0.0097, Acc_1: 0.6250, Acc_2: 0.5781, 
2023-03-06 17:14:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0070, Loss_2: 0.0066, Acc_1: 0.7422, Acc_2: 0.7656, 
2023-03-06 17:14:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0083, Loss_2: 0.0086, Acc_1: 0.6875, Acc_2: 0.6797, 
2023-03-06 17:14:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0070, Loss_2: 0.0073, Acc_1: 0.7500, Acc_2: 0.7266, 
2023-03-06 17:14:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0067, Loss_2: 0.0069, Acc_1: 0.7422, Acc_2: 0.7422, 
2023-03-06 17:14:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0045, Acc_1: 0.8798, Acc_2: 0.8786, F1-score_1: 0.8355, F1-score_2: 0.8352
2023-03-06 17:14:52 - __main__ - INFO - Epoch [2/100]
2023-03-06 17:14:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0055, Loss_2: 0.0059, Acc_1: 0.7344, Acc_2: 0.7422, 
2023-03-06 17:15:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0051, Loss_2: 0.0048, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-06 17:15:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0050, Loss_2: 0.0052, Acc_1: 0.7656, Acc_2: 0.7500, 
2023-03-06 17:15:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0057, Loss_2: 0.0056, Acc_1: 0.7500, Acc_2: 0.7266, 
2023-03-06 17:15:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0042, Loss_2: 0.0043, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-06 17:15:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0051, Loss_2: 0.0052, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-06 17:15:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0040, Loss_2: 0.0044, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-06 17:15:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0060, Loss_2: 0.0059, Acc_1: 0.7109, Acc_2: 0.7266, 
2023-03-06 17:15:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0048, Loss_2: 0.0047, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-06 17:16:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0059, Loss_2: 0.0061, Acc_1: 0.7344, Acc_2: 0.7031, 
2023-03-06 17:16:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0043, Loss_2: 0.0041, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 17:16:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0068, Loss_2: 0.0070, Acc_1: 0.7031, Acc_2: 0.7109, 
2023-03-06 17:16:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0036, Acc_1: 0.8735, Acc_2: 0.8764, F1-score_1: 0.8351, F1-score_2: 0.8420
2023-03-06 17:16:33 - __main__ - INFO - Epoch [3/100]
2023-03-06 17:16:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0028, Loss_2: 0.0030, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 17:16:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0039, Loss_2: 0.0037, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 17:16:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0028, Loss_2: 0.0026, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-06 17:17:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0034, Loss_2: 0.0033, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-06 17:17:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0034, Loss_2: 0.0030, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-06 17:17:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0032, Loss_2: 0.0032, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 17:17:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0024, Loss_2: 0.0023, Acc_1: 0.8047, Acc_2: 0.8438, 
2023-03-06 17:17:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0043, Loss_2: 0.0044, Acc_1: 0.7578, Acc_2: 0.7734, 
2023-03-06 17:17:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0025, Loss_2: 0.0023, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 17:17:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0043, Loss_2: 0.0039, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-06 17:17:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0033, Loss_2: 0.0032, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 17:17:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0037, Loss_2: 0.0040, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-06 17:18:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0031, Acc_1: 0.8405, Acc_2: 0.8460, F1-score_1: 0.8015, F1-score_2: 0.8082
2023-03-06 17:18:15 - __main__ - INFO - Epoch [4/100]
2023-03-06 17:18:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 17:18:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0016, Loss_2: 0.0020, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-06 17:18:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0023, Loss_2: 0.0026, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-06 17:18:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0022, Loss_2: 0.0023, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-06 17:18:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0018, Loss_2: 0.0023, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-06 17:18:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 17:19:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0016, Loss_2: 0.0014, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:19:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0016, Loss_2: 0.0013, Acc_1: 0.8359, Acc_2: 0.8750, 
2023-03-06 17:19:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0016, Loss_2: 0.0021, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-06 17:19:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0014, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 17:19:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0030, Loss_2: 0.0026, Acc_1: 0.7969, Acc_2: 0.8516, 
2023-03-06 17:19:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0016, Loss_2: 0.0018, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 17:19:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0026, Acc_1: 0.8488, Acc_2: 0.8519, F1-score_1: 0.8141, F1-score_2: 0.8169
2023-03-06 17:19:57 - __main__ - INFO - Epoch [5/100]
2023-03-06 17:20:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 17:20:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0013, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-06 17:20:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0015, Loss_2: 0.0013, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 17:20:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.9219, 
2023-03-06 17:20:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-06 17:20:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.9297, 
2023-03-06 17:20:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0012, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 17:20:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0012, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 17:20:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 17:21:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-06 17:21:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.9062, 
2023-03-06 17:21:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 17:21:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0020, Acc_1: 0.8568, Acc_2: 0.8539, F1-score_1: 0.8157, F1-score_2: 0.8102
2023-03-06 17:21:38 - __main__ - INFO - Epoch [6/100]
2023-03-06 17:21:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 17:21:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 17:21:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:22:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 17:22:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 17:22:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 17:22:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 17:22:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 17:22:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 17:22:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 17:22:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 17:23:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 17:23:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0016, Acc_1: 0.8538, Acc_2: 0.8629, F1-score_1: 0.8115, F1-score_2: 0.8218
2023-03-06 17:23:20 - __main__ - INFO - Epoch [7/100]
2023-03-06 17:23:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 17:23:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 17:23:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 17:23:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 17:23:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 17:24:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-06 17:24:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 17:24:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 17:24:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:24:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 17:24:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:24:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 17:25:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0010, Acc_1: 0.8658, Acc_2: 0.8646, F1-score_1: 0.8275, F1-score_2: 0.8233
2023-03-06 17:25:01 - __main__ - INFO - Epoch [8/100]
2023-03-06 17:25:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:25:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 17:25:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 17:25:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 17:25:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 17:25:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 17:25:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:25:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 17:26:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9609, 
2023-03-06 17:26:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 17:26:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 17:26:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 17:26:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.8650, Acc_2: 0.8609, F1-score_1: 0.8256, F1-score_2: 0.8200
2023-03-06 17:26:43 - __main__ - INFO - Epoch [9/100]
2023-03-06 17:26:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 17:26:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 17:27:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 17:27:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 17:27:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9688, Acc_2: 0.9766, 
2023-03-06 17:27:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 17:27:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 17:27:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 17:27:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 17:27:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:27:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 17:28:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 17:28:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8646, Acc_2: 0.8626, F1-score_1: 0.8240, F1-score_2: 0.8232
2023-03-06 17:28:25 - __main__ - INFO - Epoch [10/100]
2023-03-06 17:28:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 17:28:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 17:28:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 17:28:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 17:28:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 17:29:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 17:29:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 17:29:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 17:29:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 17:29:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9531, 
2023-03-06 17:29:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 17:29:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 17:30:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0013, Acc_1: 0.8660, Acc_2: 0.8616, F1-score_1: 0.8253, F1-score_2: 0.8219
2023-03-06 17:30:06 - __main__ - INFO - Epoch [11/100]
2023-03-06 17:30:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 17:30:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 17:30:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:30:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 17:30:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 17:30:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:30:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:31:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 17:31:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 17:31:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 17:31:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 17:31:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 17:31:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8629, Acc_2: 0.8635, F1-score_1: 0.8228, F1-score_2: 0.8246
2023-03-06 17:31:48 - __main__ - INFO - Epoch [12/100]
2023-03-06 17:31:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 17:32:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:32:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:32:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 17:32:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 17:32:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 17:32:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 17:32:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:32:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 17:32:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 17:33:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-06 17:33:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 17:33:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8626, Acc_2: 0.8655, F1-score_1: 0.8243, F1-score_2: 0.8275
2023-03-06 17:33:29 - __main__ - INFO - Epoch [13/100]
2023-03-06 17:33:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 17:33:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 17:33:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 17:33:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-06 17:34:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:34:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 17:34:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:34:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 17:34:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-06 17:34:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 17:34:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 17:34:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:35:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8648, Acc_2: 0.8629, F1-score_1: 0.8254, F1-score_2: 0.8251
2023-03-06 17:35:11 - __main__ - INFO - Epoch [14/100]
2023-03-06 17:35:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 17:35:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 17:35:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 17:35:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 17:35:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 17:35:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:35:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 17:36:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:36:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-06 17:36:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 17:36:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 17:36:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 17:36:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.8640, Acc_2: 0.8655, F1-score_1: 0.8266, F1-score_2: 0.8270
2023-03-06 17:36:52 - __main__ - INFO - Epoch [15/100]
2023-03-06 17:36:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 17:37:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 17:37:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 17:37:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 17:37:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 17:37:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:37:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 17:37:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 17:37:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 17:38:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 17:38:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9688, 
2023-03-06 17:38:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:38:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.8638, Acc_2: 0.8623, F1-score_1: 0.8260, F1-score_2: 0.8245
2023-03-06 17:38:34 - __main__ - INFO - Epoch [16/100]
2023-03-06 17:38:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 17:38:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:38:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 17:39:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 17:39:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:39:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 17:39:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 17:39:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-06 17:39:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 17:39:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:39:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 17:39:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 17:40:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8628, Acc_2: 0.8635, F1-score_1: 0.8232, F1-score_2: 0.8268
2023-03-06 17:40:15 - __main__ - INFO - Epoch [17/100]
2023-03-06 17:40:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:40:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 17:40:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 17:40:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 17:40:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-06 17:40:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 17:41:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 17:41:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 17:41:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 17:41:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:41:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 17:41:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 17:41:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8567, Acc_2: 0.8675, F1-score_1: 0.8204, F1-score_2: 0.8304
2023-03-06 17:41:57 - __main__ - INFO - Epoch [18/100]
2023-03-06 17:42:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:42:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 17:42:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9297, 
2023-03-06 17:42:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 17:42:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 17:42:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 17:42:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 17:42:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 17:42:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:43:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 17:43:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 17:43:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 17:43:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8595, Acc_2: 0.8645, F1-score_1: 0.8216, F1-score_2: 0.8272
2023-03-06 17:43:38 - __main__ - INFO - Epoch [19/100]
2023-03-06 17:43:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 17:43:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:43:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 17:44:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-06 17:44:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:44:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 17:44:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 17:44:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:44:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 17:44:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 17:44:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 17:45:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 17:45:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8595, Acc_2: 0.8629, F1-score_1: 0.8201, F1-score_2: 0.8272
2023-03-06 17:45:20 - __main__ - INFO - Epoch [20/100]
2023-03-06 17:45:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 17:45:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 17:45:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:45:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 17:45:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 17:46:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 17:46:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:46:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:46:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 17:46:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 17:46:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:46:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 17:47:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8505, Acc_2: 0.8626, F1-score_1: 0.8086, F1-score_2: 0.8271
2023-03-06 17:47:02 - __main__ - INFO - Epoch [21/100]
2023-03-06 17:47:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 17:47:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 17:47:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 17:47:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:47:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 17:47:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 17:47:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 17:47:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 17:48:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:48:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 17:48:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:48:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9453, 
2023-03-06 17:48:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8575, Acc_2: 0.8451, F1-score_1: 0.8194, F1-score_2: 0.8058
2023-03-06 17:48:43 - __main__ - INFO - Epoch [22/100]
2023-03-06 17:48:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 17:48:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 17:49:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-06 17:49:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 17:49:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 17:49:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 17:49:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 17:49:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:49:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 17:49:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 17:49:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 17:50:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 17:50:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0009, Acc_1: 0.8553, Acc_2: 0.8421, F1-score_1: 0.8108, F1-score_2: 0.7960
2023-03-06 17:50:25 - __main__ - INFO - Epoch [23/100]
2023-03-06 17:50:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9219, 
2023-03-06 17:50:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 17:50:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 17:50:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 17:50:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 17:51:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 17:51:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-06 17:51:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 17:51:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 17:51:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:51:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 17:51:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 17:52:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0004, Acc_1: 0.8555, Acc_2: 0.8538, F1-score_1: 0.8166, F1-score_2: 0.8114
2023-03-06 17:52:06 - __main__ - INFO - Epoch [24/100]
2023-03-06 17:52:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 17:52:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 17:52:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 17:52:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 17:52:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 17:52:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:52:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 17:53:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 17:53:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 17:53:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 17:53:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 17:53:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 17:53:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0013, Acc_1: 0.8565, Acc_2: 0.8543, F1-score_1: 0.8192, F1-score_2: 0.8181
2023-03-06 17:53:48 - __main__ - INFO - Epoch [25/100]
2023-03-06 17:53:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 17:54:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-06 17:54:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 17:54:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 17:54:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 17:54:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 17:54:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9453, Acc_2: 0.9062, 
2023-03-06 17:54:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 17:54:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 17:54:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 17:55:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 17:55:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 17:55:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0011, Loss_2: 0.0020, Acc_1: 0.8441, Acc_2: 0.8387, F1-score_1: 0.8016, F1-score_2: 0.7949
2023-03-06 17:55:30 - __main__ - INFO - Epoch [26/100]
2023-03-06 17:55:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 17:55:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 17:55:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-06 17:55:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 17:56:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 17:56:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-06 17:56:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 17:56:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 17:56:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 17:56:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 17:56:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 17:56:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0026, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 17:57:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0047, Loss_2: 0.0019, Acc_1: 0.8424, Acc_2: 0.8264, F1-score_1: 0.8045, F1-score_2: 0.7786
2023-03-06 17:57:12 - __main__ - INFO - Epoch [27/100]
2023-03-06 17:57:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-06 17:57:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 17:57:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 17:57:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 17:57:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-06 17:57:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 17:57:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-06 17:58:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-06 17:58:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 17:58:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0018, Loss_2: 0.0009, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 17:58:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 17:58:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0023, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-06 17:58:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0015, Acc_1: 0.8183, Acc_2: 0.8305, F1-score_1: 0.7664, F1-score_2: 0.7890
2023-03-06 17:58:53 - __main__ - INFO - Epoch [28/100]
2023-03-06 17:58:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 17:59:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0016, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 17:59:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0009, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 17:59:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 17:59:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0014, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8906, 
2023-03-06 17:59:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 17:59:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 17:59:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-06 17:59:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 18:00:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.9141, 
2023-03-06 18:00:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 18:00:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 18:00:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0011, Loss_2: 0.0033, Acc_1: 0.8353, Acc_2: 0.8290, F1-score_1: 0.7827, F1-score_2: 0.7921
2023-03-06 18:00:35 - __main__ - INFO - Epoch [29/100]
2023-03-06 18:00:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-06 18:00:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 18:00:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 18:01:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 18:01:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0016, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-06 18:01:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-06 18:01:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0011, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 18:01:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8594, 
2023-03-06 18:01:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 18:01:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0016, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 18:01:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-06 18:01:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:02:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0011, Acc_1: 0.8196, Acc_2: 0.8271, F1-score_1: 0.7726, F1-score_2: 0.7811
2023-03-06 18:02:16 - __main__ - INFO - Epoch [30/100]
2023-03-06 18:02:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 18:02:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 18:02:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 18:02:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 18:02:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:02:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0011, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:03:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-06 18:03:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 18:03:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 18:03:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 18:03:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 18:03:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 18:03:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0011, Acc_1: 0.8397, Acc_2: 0.8351, F1-score_1: 0.7998, F1-score_2: 0.7947
2023-03-06 18:03:58 - __main__ - INFO - Epoch [31/100]
2023-03-06 18:04:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:04:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 18:04:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 18:04:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 18:04:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-06 18:04:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 18:04:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 18:04:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-06 18:05:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 18:05:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 18:05:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:05:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 18:05:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0025, Acc_1: 0.8254, Acc_2: 0.8347, F1-score_1: 0.7786, F1-score_2: 0.7978
2023-03-06 18:05:40 - __main__ - INFO - Epoch [32/100]
2023-03-06 18:05:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 18:05:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 18:05:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 18:06:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:06:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 18:06:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 18:06:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 18:06:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:06:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:06:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 18:06:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 18:07:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:07:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0028, Loss_2: 0.0021, Acc_1: 0.8404, Acc_2: 0.8337, F1-score_1: 0.7961, F1-score_2: 0.7952
2023-03-06 18:07:21 - __main__ - INFO - Epoch [33/100]
2023-03-06 18:07:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 18:07:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 18:07:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 18:07:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.9062, 
2023-03-06 18:07:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 18:08:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:08:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 18:08:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 18:08:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 18:08:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:08:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 18:08:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:09:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0011, Acc_1: 0.8412, Acc_2: 0.8314, F1-score_1: 0.8037, F1-score_2: 0.7936
2023-03-06 18:09:03 - __main__ - INFO - Epoch [34/100]
2023-03-06 18:09:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 18:09:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 18:09:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:09:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 18:09:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 18:09:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 18:09:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 18:09:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:10:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 18:10:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:10:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:10:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-06 18:10:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0011, Loss_2: 0.0014, Acc_1: 0.8297, Acc_2: 0.8431, F1-score_1: 0.7860, F1-score_2: 0.8042
2023-03-06 18:10:44 - __main__ - INFO - Epoch [35/100]
2023-03-06 18:10:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 18:10:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:11:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 18:11:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 18:11:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 18:11:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:11:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 18:11:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 18:11:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:11:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 18:12:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 18:12:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-06 18:12:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0012, Acc_1: 0.8319, Acc_2: 0.8432, F1-score_1: 0.7845, F1-score_2: 0.8063
2023-03-06 18:12:26 - __main__ - INFO - Epoch [36/100]
2023-03-06 18:12:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-06 18:12:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 18:12:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:12:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 18:13:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 18:13:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 18:13:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 18:13:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 18:13:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:13:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 18:13:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:13:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 18:14:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0006, Acc_1: 0.8398, Acc_2: 0.8473, F1-score_1: 0.7991, F1-score_2: 0.8110
2023-03-06 18:14:07 - __main__ - INFO - Epoch [37/100]
2023-03-06 18:14:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 18:14:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:14:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 18:14:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-06 18:14:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 18:14:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:14:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 18:15:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 18:15:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 18:15:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 18:15:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:15:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 18:15:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0010, Acc_1: 0.8376, Acc_2: 0.8422, F1-score_1: 0.7964, F1-score_2: 0.8014
2023-03-06 18:15:49 - __main__ - INFO - Epoch [38/100]
2023-03-06 18:15:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 18:16:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:16:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:16:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 18:16:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-06 18:16:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 18:16:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 18:16:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 18:16:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-06 18:16:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 18:17:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 18:17:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:17:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0017, Acc_1: 0.8421, Acc_2: 0.8468, F1-score_1: 0.8036, F1-score_2: 0.8078
2023-03-06 18:17:31 - __main__ - INFO - Epoch [39/100]
2023-03-06 18:17:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 18:17:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:17:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 18:17:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 18:18:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 18:18:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9531, 
2023-03-06 18:18:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 18:18:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 18:18:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 18:18:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:18:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 18:18:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:19:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0014, Acc_1: 0.8380, Acc_2: 0.8454, F1-score_1: 0.7955, F1-score_2: 0.8086
2023-03-06 18:19:12 - __main__ - INFO - Epoch [40/100]
2023-03-06 18:19:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-06 18:19:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 18:19:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:19:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 18:19:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 18:19:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:20:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 18:20:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 18:20:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 18:20:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 18:20:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:20:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 18:20:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0012, Acc_1: 0.8312, Acc_2: 0.8356, F1-score_1: 0.7906, F1-score_2: 0.7919
2023-03-06 18:20:54 - __main__ - INFO - Epoch [41/100]
2023-03-06 18:20:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:21:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 18:21:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 18:21:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:21:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 18:21:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:21:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-06 18:21:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 18:21:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 18:22:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:22:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 18:22:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:22:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8393, Acc_2: 0.8448, F1-score_1: 0.8019, F1-score_2: 0.8044
2023-03-06 18:22:36 - __main__ - INFO - Epoch [42/100]
2023-03-06 18:22:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 18:22:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-06 18:22:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 18:23:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 18:23:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 18:23:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-06 18:23:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 18:23:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 18:23:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:23:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 18:23:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 18:23:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 18:24:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.8427, Acc_2: 0.8443, F1-score_1: 0.8047, F1-score_2: 0.8033
2023-03-06 18:24:17 - __main__ - INFO - Epoch [43/100]
2023-03-06 18:24:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 18:24:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 18:24:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 18:24:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:24:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 18:24:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:25:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 18:25:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:25:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 18:25:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 18:25:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 18:25:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 18:25:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0016, Acc_1: 0.8368, Acc_2: 0.8373, F1-score_1: 0.7948, F1-score_2: 0.7949
2023-03-06 18:25:59 - __main__ - INFO - Epoch [44/100]
2023-03-06 18:26:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:26:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 18:26:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-06 18:26:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 18:26:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 18:26:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 18:26:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 18:26:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:27:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 18:27:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 18:27:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 18:27:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 18:27:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0028, Acc_1: 0.8398, Acc_2: 0.8254, F1-score_1: 0.7980, F1-score_2: 0.7837
2023-03-06 18:27:41 - __main__ - INFO - Epoch [45/100]
2023-03-06 18:27:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:27:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 18:28:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:28:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-06 18:28:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:28:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-06 18:28:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 18:28:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 18:28:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 18:28:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 18:28:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 18:29:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 18:29:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0011, Loss_2: 0.0009, Acc_1: 0.8405, Acc_2: 0.8434, F1-score_1: 0.7975, F1-score_2: 0.8040
2023-03-06 18:29:23 - __main__ - INFO - Epoch [46/100]
2023-03-06 18:29:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:29:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:29:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:29:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 18:29:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:30:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 18:30:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 18:30:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 18:30:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:30:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:30:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 18:30:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 18:31:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0015, Acc_1: 0.8339, Acc_2: 0.8288, F1-score_1: 0.7882, F1-score_2: 0.7879
2023-03-06 18:31:04 - __main__ - INFO - Epoch [47/100]
2023-03-06 18:31:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 18:31:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 18:31:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:31:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:31:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 18:31:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 18:31:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 18:31:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 18:32:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 18:32:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 18:32:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 18:32:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:32:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.8319, Acc_2: 0.8385, F1-score_1: 0.7849, F1-score_2: 0.8002
2023-03-06 18:32:46 - __main__ - INFO - Epoch [48/100]
2023-03-06 18:32:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 18:32:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 18:33:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:33:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:33:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 18:33:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 18:33:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 18:33:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-06 18:33:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 18:33:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:34:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 18:34:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 18:34:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0025, Acc_1: 0.8222, Acc_2: 0.8261, F1-score_1: 0.7768, F1-score_2: 0.7766
2023-03-06 18:34:27 - __main__ - INFO - Epoch [49/100]
2023-03-06 18:34:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 18:34:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 18:34:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-06 18:34:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 18:35:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 18:35:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 18:35:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 18:35:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 18:35:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 18:35:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 18:35:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0016, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.9219, 
2023-03-06 18:35:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 18:36:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0012, Acc_1: 0.8324, Acc_2: 0.8342, F1-score_1: 0.7860, F1-score_2: 0.7959
2023-03-06 18:36:09 - __main__ - INFO - Epoch [50/100]
2023-03-06 18:36:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-06 18:36:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 18:36:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 18:36:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 18:36:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:36:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 18:36:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:37:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:37:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8672, 
2023-03-06 18:37:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:37:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:37:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 18:37:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0010, Acc_1: 0.8327, Acc_2: 0.8308, F1-score_1: 0.7923, F1-score_2: 0.7903
2023-03-06 18:37:51 - __main__ - INFO - Epoch [51/100]
2023-03-06 18:37:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0009, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 18:38:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 18:38:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:38:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 18:38:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:38:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:38:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 18:38:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 18:38:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 18:39:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-06 18:39:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 18:39:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 18:39:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0019, Acc_1: 0.8181, Acc_2: 0.8263, F1-score_1: 0.7716, F1-score_2: 0.7839
2023-03-06 18:39:32 - __main__ - INFO - Epoch [52/100]
2023-03-06 18:39:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:39:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:39:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:39:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:40:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-06 18:40:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 18:40:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 18:40:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 18:40:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0013, Loss_2: 0.0015, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-06 18:40:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 18:40:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 18:40:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:41:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0041, Loss_2: 0.0013, Acc_1: 0.8127, Acc_2: 0.8336, F1-score_1: 0.7638, F1-score_2: 0.7928
2023-03-06 18:41:14 - __main__ - INFO - Epoch [53/100]
2023-03-06 18:41:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 18:41:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 18:41:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 18:41:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 18:41:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 18:41:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-06 18:42:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 18:42:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0021, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 18:42:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 18:42:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 18:42:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:42:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 18:42:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0024, Acc_1: 0.8297, Acc_2: 0.8398, F1-score_1: 0.7726, F1-score_2: 0.8038
2023-03-06 18:42:56 - __main__ - INFO - Epoch [54/100]
2023-03-06 18:43:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 18:43:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:43:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 18:43:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 18:43:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-06 18:43:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:43:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 18:43:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 18:43:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 18:44:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 18:44:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:44:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 18:44:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0024, Acc_1: 0.8359, Acc_2: 0.8371, F1-score_1: 0.7899, F1-score_2: 0.7964
2023-03-06 18:44:37 - __main__ - INFO - Epoch [55/100]
2023-03-06 18:44:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 18:44:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-06 18:44:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:45:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:45:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 18:45:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 18:45:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:45:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 18:45:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 18:45:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:45:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:45:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 18:46:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0026, Acc_1: 0.8286, Acc_2: 0.8337, F1-score_1: 0.7794, F1-score_2: 0.7931
2023-03-06 18:46:19 - __main__ - INFO - Epoch [56/100]
2023-03-06 18:46:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 18:46:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 18:46:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 18:46:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:46:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 18:47:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:47:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 18:47:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 18:47:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 18:47:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 18:47:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:47:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 18:48:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0046, Loss_2: 0.0006, Acc_1: 0.8178, Acc_2: 0.8404, F1-score_1: 0.7676, F1-score_2: 0.8035
2023-03-06 18:48:01 - __main__ - INFO - Epoch [57/100]
2023-03-06 18:48:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-06 18:48:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:48:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 18:48:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:48:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 18:48:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 18:48:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:48:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 18:49:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:49:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 18:49:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 18:49:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 18:49:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0014, Acc_1: 0.8178, Acc_2: 0.8332, F1-score_1: 0.7727, F1-score_2: 0.7962
2023-03-06 18:49:42 - __main__ - INFO - Epoch [58/100]
2023-03-06 18:49:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 18:49:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-06 18:50:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 18:50:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 18:50:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 18:50:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 18:50:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 18:50:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 18:50:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 18:50:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:50:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 18:51:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 18:51:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0034, Loss_2: 0.0021, Acc_1: 0.8305, Acc_2: 0.8273, F1-score_1: 0.7865, F1-score_2: 0.7888
2023-03-06 18:51:24 - __main__ - INFO - Epoch [59/100]
2023-03-06 18:51:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 18:51:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:51:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 18:51:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 18:51:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 18:52:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 18:52:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 18:52:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 18:52:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:52:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:52:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 18:52:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:53:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0013, Acc_1: 0.8397, Acc_2: 0.8293, F1-score_1: 0.7949, F1-score_2: 0.7868
2023-03-06 18:53:06 - __main__ - INFO - Epoch [60/100]
2023-03-06 18:53:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 18:53:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-06 18:53:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0009, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 18:53:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 18:53:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 18:53:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 18:53:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 18:54:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 18:54:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 18:54:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0011, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 18:54:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 18:54:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 18:54:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0047, Loss_2: 0.0008, Acc_1: 0.8331, Acc_2: 0.8378, F1-score_1: 0.7893, F1-score_2: 0.7968
2023-03-06 18:54:48 - __main__ - INFO - Epoch [61/100]
2023-03-06 18:54:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 18:55:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 18:55:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-06 18:55:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 18:55:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 18:55:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:55:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 18:55:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 18:55:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:55:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 18:56:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 18:56:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:56:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0058, Acc_1: 0.8409, Acc_2: 0.8037, F1-score_1: 0.7972, F1-score_2: 0.7617
2023-03-06 18:56:29 - __main__ - INFO - Epoch [62/100]
2023-03-06 18:56:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-06 18:56:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 18:56:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 18:56:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 18:57:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 18:57:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:57:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-06 18:57:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:57:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 18:57:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 18:57:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 18:57:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 18:58:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0042, Loss_2: 0.0027, Acc_1: 0.8347, Acc_2: 0.8251, F1-score_1: 0.7891, F1-score_2: 0.7842
2023-03-06 18:58:11 - __main__ - INFO - Epoch [63/100]
2023-03-06 18:58:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 18:58:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 18:58:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 18:58:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 18:58:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 18:58:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 18:58:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 18:59:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 18:59:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 18:59:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 18:59:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 18:59:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 18:59:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0054, Loss_2: 0.0007, Acc_1: 0.8341, Acc_2: 0.8215, F1-score_1: 0.7930, F1-score_2: 0.7762
2023-03-06 18:59:52 - __main__ - INFO - Epoch [64/100]
2023-03-06 18:59:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 19:00:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:00:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 19:00:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 19:00:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 19:00:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:00:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 19:00:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 19:00:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:01:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:01:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:01:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 19:01:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0010, Acc_1: 0.8366, Acc_2: 0.8239, F1-score_1: 0.7927, F1-score_2: 0.7803
2023-03-06 19:01:34 - __main__ - INFO - Epoch [65/100]
2023-03-06 19:01:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 19:01:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 19:01:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 19:02:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 19:02:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:02:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 19:02:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-06 19:02:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 19:02:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:02:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 19:02:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 19:02:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 19:03:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0010, Acc_1: 0.8293, Acc_2: 0.8281, F1-score_1: 0.7880, F1-score_2: 0.7856
2023-03-06 19:03:16 - __main__ - INFO - Epoch [66/100]
2023-03-06 19:03:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 19:03:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:03:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:03:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 19:03:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 19:03:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 19:04:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:04:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0013, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 19:04:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:04:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 19:04:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 19:04:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:04:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0044, Loss_2: 0.0043, Acc_1: 0.8319, Acc_2: 0.8334, F1-score_1: 0.7896, F1-score_2: 0.7904
2023-03-06 19:04:57 - __main__ - INFO - Epoch [67/100]
2023-03-06 19:05:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:05:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-06 19:05:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 19:05:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:05:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:05:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 19:05:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 19:05:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 19:05:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:06:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 19:06:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 19:06:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 19:06:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0013, Acc_1: 0.8329, Acc_2: 0.8342, F1-score_1: 0.7867, F1-score_2: 0.7914
2023-03-06 19:06:39 - __main__ - INFO - Epoch [68/100]
2023-03-06 19:06:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 19:06:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:06:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 19:07:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 19:07:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9688, Acc_2: 0.9688, 
2023-03-06 19:07:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 19:07:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 19:07:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 19:07:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 19:07:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 19:07:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 19:08:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 19:08:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0058, Loss_2: 0.0044, Acc_1: 0.8259, Acc_2: 0.8300, F1-score_1: 0.7835, F1-score_2: 0.7870
2023-03-06 19:08:21 - __main__ - INFO - Epoch [69/100]
2023-03-06 19:08:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:08:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 19:08:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:08:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 19:08:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:09:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:09:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 19:09:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:09:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:09:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 19:09:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 19:09:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 19:10:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0038, Acc_1: 0.8370, Acc_2: 0.8307, F1-score_1: 0.7932, F1-score_2: 0.7885
2023-03-06 19:10:02 - __main__ - INFO - Epoch [70/100]
2023-03-06 19:10:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:10:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0009, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 19:10:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:10:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 19:10:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 19:10:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 19:10:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 19:10:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 19:11:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:11:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:11:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 19:11:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 19:11:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0035, Acc_1: 0.8247, Acc_2: 0.8307, F1-score_1: 0.7800, F1-score_2: 0.7876
2023-03-06 19:11:44 - __main__ - INFO - Epoch [71/100]
2023-03-06 19:11:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 19:11:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 19:12:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.9141, 
2023-03-06 19:12:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 19:12:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:12:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:12:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 19:12:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:12:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:12:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 19:13:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 19:13:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 19:13:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0025, Acc_1: 0.8280, Acc_2: 0.8190, F1-score_1: 0.7839, F1-score_2: 0.7830
2023-03-06 19:13:25 - __main__ - INFO - Epoch [72/100]
2023-03-06 19:13:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 19:13:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 19:13:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:13:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 19:13:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:14:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 19:14:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 19:14:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:14:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-06 19:14:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:14:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:14:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 19:15:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0016, Acc_1: 0.8266, Acc_2: 0.8344, F1-score_1: 0.7822, F1-score_2: 0.7920
2023-03-06 19:15:07 - __main__ - INFO - Epoch [73/100]
2023-03-06 19:15:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 19:15:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 19:15:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:15:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-06 19:15:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-06 19:15:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 19:15:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 19:16:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 19:16:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 19:16:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 19:16:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:16:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 19:16:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0068, Loss_2: 0.0025, Acc_1: 0.8263, Acc_2: 0.8327, F1-score_1: 0.7779, F1-score_2: 0.7906
2023-03-06 19:16:49 - __main__ - INFO - Epoch [74/100]
2023-03-06 19:16:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 19:17:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 19:17:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0018, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 19:17:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 19:17:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 19:17:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 19:17:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 19:17:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 19:17:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-06 19:17:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:18:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 19:18:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-06 19:18:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0049, Loss_2: 0.0010, Acc_1: 0.8303, Acc_2: 0.8341, F1-score_1: 0.7810, F1-score_2: 0.7899
2023-03-06 19:18:30 - __main__ - INFO - Epoch [75/100]
2023-03-06 19:18:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:18:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 19:18:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 19:18:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 19:19:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:19:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 19:19:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 19:19:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 19:19:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-06 19:19:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-06 19:19:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 19:19:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:20:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0061, Loss_2: 0.0016, Acc_1: 0.8173, Acc_2: 0.8283, F1-score_1: 0.7684, F1-score_2: 0.7834
2023-03-06 19:20:12 - __main__ - INFO - Epoch [76/100]
2023-03-06 19:20:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:20:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:20:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 19:20:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0016, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.9062, 
2023-03-06 19:20:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 19:20:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0076, Loss_2: 0.0053, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-06 19:21:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 19:21:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:21:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 19:21:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0037, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 19:21:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 19:21:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:21:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0046, Loss_2: 0.0037, Acc_1: 0.8283, Acc_2: 0.8317, F1-score_1: 0.7813, F1-score_2: 0.7868
2023-03-06 19:21:53 - __main__ - INFO - Epoch [77/100]
2023-03-06 19:21:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 19:22:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:22:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:22:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 19:22:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 19:22:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 19:22:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:22:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 19:22:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 19:23:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 19:23:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:23:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 19:23:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0081, Loss_2: 0.0012, Acc_1: 0.8198, Acc_2: 0.8341, F1-score_1: 0.7738, F1-score_2: 0.7913
2023-03-06 19:23:35 - __main__ - INFO - Epoch [78/100]
2023-03-06 19:23:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 19:23:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 19:23:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:24:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 19:24:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:24:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 19:24:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 19:24:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 19:24:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 19:24:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:24:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:24:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:25:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0015, Acc_1: 0.8193, Acc_2: 0.8286, F1-score_1: 0.7742, F1-score_2: 0.7797
2023-03-06 19:25:17 - __main__ - INFO - Epoch [79/100]
2023-03-06 19:25:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:25:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:25:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 19:25:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:25:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 19:25:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 19:26:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:26:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 19:26:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:26:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 19:26:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:26:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 19:26:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0052, Loss_2: 0.0036, Acc_1: 0.8298, Acc_2: 0.8298, F1-score_1: 0.7841, F1-score_2: 0.7820
2023-03-06 19:26:58 - __main__ - INFO - Epoch [80/100]
2023-03-06 19:27:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:27:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 19:27:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:27:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:27:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:27:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 19:27:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:27:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-06 19:28:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:28:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 19:28:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:28:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 19:28:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0069, Loss_2: 0.0032, Acc_1: 0.8302, Acc_2: 0.8293, F1-score_1: 0.7880, F1-score_2: 0.7840
2023-03-06 19:28:40 - __main__ - INFO - Epoch [81/100]
2023-03-06 19:28:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:28:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0047, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:29:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 19:29:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:29:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:29:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 19:29:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 19:29:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:29:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:29:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 19:29:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:30:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 19:30:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0062, Loss_2: 0.0052, Acc_1: 0.8235, Acc_2: 0.8190, F1-score_1: 0.7808, F1-score_2: 0.7750
2023-03-06 19:30:22 - __main__ - INFO - Epoch [82/100]
2023-03-06 19:30:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:30:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:30:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 19:30:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:30:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:31:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:31:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 19:31:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 19:31:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:31:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:31:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 19:31:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:32:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0090, Loss_2: 0.0062, Acc_1: 0.8278, Acc_2: 0.8256, F1-score_1: 0.7801, F1-score_2: 0.7861
2023-03-06 19:32:03 - __main__ - INFO - Epoch [83/100]
2023-03-06 19:32:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 19:32:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:32:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:32:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:32:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 19:32:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-06 19:32:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 19:32:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:33:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:33:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:33:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 19:33:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 19:33:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0051, Loss_2: 0.0034, Acc_1: 0.8286, Acc_2: 0.8234, F1-score_1: 0.7874, F1-score_2: 0.7718
2023-03-06 19:33:45 - __main__ - INFO - Epoch [84/100]
2023-03-06 19:33:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 19:33:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:34:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:34:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:34:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:34:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 19:34:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:34:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:34:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:34:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 19:35:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:35:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 19:35:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0059, Loss_2: 0.0036, Acc_1: 0.8268, Acc_2: 0.8344, F1-score_1: 0.7852, F1-score_2: 0.7920
2023-03-06 19:35:27 - __main__ - INFO - Epoch [85/100]
2023-03-06 19:35:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 19:35:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:35:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:35:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 19:36:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:36:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-06 19:36:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 19:36:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:36:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 19:36:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 19:36:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 19:36:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:37:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0070, Loss_2: 0.0032, Acc_1: 0.8286, Acc_2: 0.8332, F1-score_1: 0.7873, F1-score_2: 0.7893
2023-03-06 19:37:08 - __main__ - INFO - Epoch [86/100]
2023-03-06 19:37:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:37:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:37:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 19:37:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:37:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:37:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 19:37:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 19:38:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:38:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:38:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 19:38:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:38:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 19:38:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0047, Loss_2: 0.0047, Acc_1: 0.8300, Acc_2: 0.8331, F1-score_1: 0.7891, F1-score_2: 0.7925
2023-03-06 19:38:50 - __main__ - INFO - Epoch [87/100]
2023-03-06 19:38:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:39:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 19:39:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:39:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:39:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 19:39:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:39:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:39:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:39:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:39:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 19:40:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 19:40:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 19:40:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0049, Loss_2: 0.0037, Acc_1: 0.8305, Acc_2: 0.8383, F1-score_1: 0.7891, F1-score_2: 0.7978
2023-03-06 19:40:31 - __main__ - INFO - Epoch [88/100]
2023-03-06 19:40:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 19:40:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:40:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 19:40:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:41:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:41:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 19:41:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-06 19:41:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 19:41:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 19:41:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 19:41:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:41:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:42:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0046, Loss_2: 0.0041, Acc_1: 0.8288, Acc_2: 0.8380, F1-score_1: 0.7884, F1-score_2: 0.7985
2023-03-06 19:42:13 - __main__ - INFO - Epoch [89/100]
2023-03-06 19:42:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:42:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:42:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 19:42:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 19:42:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:42:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 19:43:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:43:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:43:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 19:43:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 19:43:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:43:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 19:43:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0039, Loss_2: 0.0058, Acc_1: 0.8271, Acc_2: 0.8347, F1-score_1: 0.7825, F1-score_2: 0.7949
2023-03-06 19:43:55 - __main__ - INFO - Epoch [90/100]
2023-03-06 19:44:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:44:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:44:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:44:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:44:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 19:44:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:44:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:44:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:44:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:45:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:45:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:45:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:45:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0047, Loss_2: 0.0044, Acc_1: 0.8308, Acc_2: 0.8359, F1-score_1: 0.7892, F1-score_2: 0.7960
2023-03-06 19:45:36 - __main__ - INFO - Epoch [91/100]
2023-03-06 19:45:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:45:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:45:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:46:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:46:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:46:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:46:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 19:46:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:46:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:46:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:46:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:46:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 19:47:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0047, Loss_2: 0.0034, Acc_1: 0.8305, Acc_2: 0.8347, F1-score_1: 0.7893, F1-score_2: 0.7947
2023-03-06 19:47:18 - __main__ - INFO - Epoch [92/100]
2023-03-06 19:47:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:47:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:47:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:47:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:47:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:47:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:48:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:48:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 19:48:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:48:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:48:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 19:48:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 19:49:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0048, Loss_2: 0.0037, Acc_1: 0.8305, Acc_2: 0.8347, F1-score_1: 0.7922, F1-score_2: 0.7944
2023-03-06 19:49:00 - __main__ - INFO - Epoch [93/100]
2023-03-06 19:49:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:49:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 19:49:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:49:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:49:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 19:49:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:49:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 19:49:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:50:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 19:50:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:50:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:50:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:50:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0051, Loss_2: 0.0035, Acc_1: 0.8302, Acc_2: 0.8320, F1-score_1: 0.7880, F1-score_2: 0.7900
2023-03-06 19:50:41 - __main__ - INFO - Epoch [94/100]
2023-03-06 19:50:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:50:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 19:51:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:51:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:51:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 19:51:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:51:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 19:51:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 19:51:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:51:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:51:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 19:52:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 19:52:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0054, Loss_2: 0.0033, Acc_1: 0.8300, Acc_2: 0.8370, F1-score_1: 0.7894, F1-score_2: 0.7969
2023-03-06 19:52:23 - __main__ - INFO - Epoch [95/100]
2023-03-06 19:52:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:52:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:52:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:52:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:52:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 19:53:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 19:53:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 19:53:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:53:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:53:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:53:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 19:53:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 19:54:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0053, Loss_2: 0.0039, Acc_1: 0.8317, Acc_2: 0.8385, F1-score_1: 0.7902, F1-score_2: 0.7995
2023-03-06 19:54:05 - __main__ - INFO - Epoch [96/100]
2023-03-06 19:54:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 19:54:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:54:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 19:54:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:54:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 19:54:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 19:54:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:55:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:55:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 19:55:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 19:55:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:55:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:55:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0062, Loss_2: 0.0034, Acc_1: 0.8325, Acc_2: 0.8381, F1-score_1: 0.7915, F1-score_2: 0.7995
2023-03-06 19:55:46 - __main__ - INFO - Epoch [97/100]
2023-03-06 19:55:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:55:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:56:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:56:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:56:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 19:56:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:56:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:56:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:56:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 19:56:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 19:57:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:57:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:57:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0042, Loss_2: 0.0043, Acc_1: 0.8314, Acc_2: 0.8378, F1-score_1: 0.7898, F1-score_2: 0.8000
2023-03-06 19:57:28 - __main__ - INFO - Epoch [98/100]
2023-03-06 19:57:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 19:57:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:57:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 19:57:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 19:58:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 19:58:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:58:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 19:58:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 19:58:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:58:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 19:58:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:58:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 19:59:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0042, Loss_2: 0.0044, Acc_1: 0.8308, Acc_2: 0.8375, F1-score_1: 0.7891, F1-score_2: 0.7988
2023-03-06 19:59:10 - __main__ - INFO - Epoch [99/100]
2023-03-06 19:59:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 19:59:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 19:59:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 19:59:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 19:59:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 19:59:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 19:59:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 20:00:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 20:00:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 20:00:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 20:00:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 20:00:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 20:00:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0043, Acc_1: 0.8310, Acc_2: 0.8383, F1-score_1: 0.7893, F1-score_2: 0.7999
2023-03-06 20:00:53 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 20:00:53 - utils._noise - DEBUG - 6, 7
2023-03-06 20:00:53 - utils._noise - DEBUG - 13997
2023-03-06 20:00:53 - utils._noise - INFO - Actual noise 0.20
2023-03-06 20:00:53 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-06 20:00:53 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-06 20:00:55 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-06 20:00:55 - __main__ - INFO - Loading dataset...
2023-03-06 20:00:55 - __main__ - INFO - Building model...
2023-03-06 20:00:55 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 20:00:55 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-06 20:00:55 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-06 20:00:55 - __main__ - INFO - Start train & evaluate
2023-03-06 20:00:55 - __main__ - INFO - Epoch [0/100]
2023-03-06 20:01:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0155, Loss_2: 0.0154, Acc_1: 0.1641, Acc_2: 0.0859, 
2023-03-06 20:01:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0131, Loss_2: 0.0131, Acc_1: 0.3594, Acc_2: 0.3984, 
2023-03-06 20:01:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0116, Loss_2: 0.0115, Acc_1: 0.5234, Acc_2: 0.5391, 
2023-03-06 20:01:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0104, Loss_2: 0.0106, Acc_1: 0.5469, Acc_2: 0.5469, 
2023-03-06 20:01:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0104, Loss_2: 0.0103, Acc_1: 0.5938, Acc_2: 0.5781, 
2023-03-06 20:01:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0100, Loss_2: 0.0101, Acc_1: 0.6719, Acc_2: 0.6562, 
2023-03-06 20:01:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0089, Loss_2: 0.0087, Acc_1: 0.7031, Acc_2: 0.6797, 
2023-03-06 20:01:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0082, Loss_2: 0.0084, Acc_1: 0.7266, Acc_2: 0.7109, 
2023-03-06 20:01:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0092, Loss_2: 0.0090, Acc_1: 0.6094, Acc_2: 0.6328, 
2023-03-06 20:02:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0086, Loss_2: 0.0084, Acc_1: 0.6875, Acc_2: 0.7109, 
2023-03-06 20:02:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0096, Loss_2: 0.0096, Acc_1: 0.6797, Acc_2: 0.6875, 
2023-03-06 20:02:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0086, Loss_2: 0.0084, Acc_1: 0.7031, Acc_2: 0.7031, 
2023-03-06 20:02:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0057, Acc_1: 0.8531, Acc_2: 0.8594, F1-score_1: 0.7916, F1-score_2: 0.8011
2023-03-06 20:02:37 - __main__ - INFO - Epoch [1/100]
2023-03-06 20:02:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0080, Loss_2: 0.0079, Acc_1: 0.7031, Acc_2: 0.6953, 
2023-03-06 20:02:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0074, Loss_2: 0.0073, Acc_1: 0.7031, Acc_2: 0.6641, 
2023-03-06 20:02:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0069, Loss_2: 0.0069, Acc_1: 0.7109, Acc_2: 0.7266, 
2023-03-06 20:03:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0083, Loss_2: 0.0082, Acc_1: 0.6641, Acc_2: 0.6875, 
2023-03-06 20:03:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0074, Loss_2: 0.0068, Acc_1: 0.7109, Acc_2: 0.7422, 
2023-03-06 20:03:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0058, Loss_2: 0.0053, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-06 20:03:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0073, Loss_2: 0.0077, Acc_1: 0.7188, Acc_2: 0.7031, 
2023-03-06 20:03:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0064, Loss_2: 0.0063, Acc_1: 0.7656, Acc_2: 0.8047, 
2023-03-06 20:03:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0076, Loss_2: 0.0074, Acc_1: 0.7344, Acc_2: 0.7500, 
2023-03-06 20:03:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0076, Loss_2: 0.0077, Acc_1: 0.6719, Acc_2: 0.6953, 
2023-03-06 20:03:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0076, Loss_2: 0.0075, Acc_1: 0.7422, Acc_2: 0.7266, 
2023-03-06 20:03:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0081, Loss_2: 0.0081, Acc_1: 0.6875, Acc_2: 0.6953, 
2023-03-06 20:04:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0044, Acc_1: 0.8723, Acc_2: 0.8742, F1-score_1: 0.8229, F1-score_2: 0.8257
2023-03-06 20:04:19 - __main__ - INFO - Epoch [2/100]
2023-03-06 20:04:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0050, Loss_2: 0.0050, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-06 20:04:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0038, Loss_2: 0.0038, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-06 20:04:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0056, Loss_2: 0.0059, Acc_1: 0.7500, Acc_2: 0.7422, 
2023-03-06 20:04:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0061, Loss_2: 0.0055, Acc_1: 0.7500, Acc_2: 0.7500, 
2023-03-06 20:04:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0043, Loss_2: 0.0039, Acc_1: 0.7969, Acc_2: 0.8281, 
2023-03-06 20:05:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0074, Loss_2: 0.0069, Acc_1: 0.7031, Acc_2: 0.6875, 
2023-03-06 20:05:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0052, Loss_2: 0.0051, Acc_1: 0.7656, Acc_2: 0.7891, 
2023-03-06 20:05:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0049, Loss_2: 0.0052, Acc_1: 0.7500, Acc_2: 0.7734, 
2023-03-06 20:05:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0052, Loss_2: 0.0053, Acc_1: 0.7344, Acc_2: 0.7266, 
2023-03-06 20:05:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0056, Loss_2: 0.0053, Acc_1: 0.7578, Acc_2: 0.7734, 
2023-03-06 20:05:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0058, Loss_2: 0.0059, Acc_1: 0.7578, Acc_2: 0.7266, 
2023-03-06 20:05:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0058, Loss_2: 0.0057, Acc_1: 0.7578, Acc_2: 0.7344, 
2023-03-06 20:06:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0031, Acc_1: 0.8767, Acc_2: 0.8719, F1-score_1: 0.8259, F1-score_2: 0.8193
2023-03-06 20:06:00 - __main__ - INFO - Epoch [3/100]
2023-03-06 20:06:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0023, Loss_2: 0.0023, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 20:06:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0033, Loss_2: 0.0028, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 20:06:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0030, Loss_2: 0.0031, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-06 20:06:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0026, Loss_2: 0.0026, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 20:06:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0033, Loss_2: 0.0029, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-06 20:06:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0039, Loss_2: 0.0039, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-06 20:06:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0024, Loss_2: 0.0024, Acc_1: 0.8438, Acc_2: 0.8828, 
2023-03-06 20:06:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0040, Loss_2: 0.0042, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-06 20:07:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0031, Loss_2: 0.0027, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 20:07:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0049, Loss_2: 0.0047, Acc_1: 0.7500, Acc_2: 0.7656, 
2023-03-06 20:07:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0029, Loss_2: 0.0031, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-06 20:07:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0036, Loss_2: 0.0034, Acc_1: 0.7812, Acc_2: 0.8359, 
2023-03-06 20:07:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0028, Acc_1: 0.8575, Acc_2: 0.8565, F1-score_1: 0.8129, F1-score_2: 0.8119
2023-03-06 20:07:42 - __main__ - INFO - Epoch [4/100]
2023-03-06 20:07:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0017, Loss_2: 0.0015, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 20:07:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0015, Loss_2: 0.0013, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 20:08:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0011, Loss_2: 0.0012, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 20:08:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0014, Loss_2: 0.0013, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-06 20:08:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 20:08:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0013, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 20:08:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0016, Loss_2: 0.0015, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 20:08:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0025, Loss_2: 0.0030, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-06 20:08:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0021, Loss_2: 0.0017, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 20:08:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0017, Loss_2: 0.0025, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 20:08:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0013, Loss_2: 0.0015, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 20:09:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0013, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 20:09:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0020, Acc_1: 0.8565, Acc_2: 0.8611, F1-score_1: 0.8089, F1-score_2: 0.8187
2023-03-06 20:09:24 - __main__ - INFO - Epoch [5/100]
2023-03-06 20:09:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0011, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-06 20:09:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0013, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-06 20:09:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 20:09:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0010, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-06 20:09:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 20:10:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 20:10:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.9297, 
2023-03-06 20:10:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 20:10:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 20:10:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 20:10:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 20:10:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 20:11:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0017, Acc_1: 0.8635, Acc_2: 0.8577, F1-score_1: 0.8177, F1-score_2: 0.8140
2023-03-06 20:11:05 - __main__ - INFO - Epoch [6/100]
2023-03-06 20:11:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-06 20:11:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 20:11:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 20:11:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 20:11:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 20:11:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 20:11:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:12:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 20:12:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 20:12:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 20:12:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 20:12:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 20:12:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0013, Acc_1: 0.8578, Acc_2: 0.8599, F1-score_1: 0.8163, F1-score_2: 0.8171
2023-03-06 20:12:47 - __main__ - INFO - Epoch [7/100]
2023-03-06 20:12:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-06 20:13:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 20:13:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 20:13:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 20:13:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-06 20:13:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 20:13:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-06 20:13:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 20:13:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 20:13:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 20:14:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9609, 
2023-03-06 20:14:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 20:14:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.8623, Acc_2: 0.8618, F1-score_1: 0.8189, F1-score_2: 0.8191
2023-03-06 20:14:29 - __main__ - INFO - Epoch [8/100]
2023-03-06 20:14:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 20:14:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 20:14:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 20:14:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 20:15:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 20:15:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 20:15:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 20:15:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 20:15:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 20:15:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 20:15:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 20:15:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 20:16:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8636, Acc_2: 0.8636, F1-score_1: 0.8235, F1-score_2: 0.8230
2023-03-06 20:16:11 - __main__ - INFO - Epoch [9/100]
2023-03-06 20:16:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-06 20:16:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 20:16:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 20:16:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 20:16:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 20:16:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 20:16:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 20:17:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 20:17:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 20:17:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 20:17:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9375, 
2023-03-06 20:17:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 20:17:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8650, Acc_2: 0.8668, F1-score_1: 0.8236, F1-score_2: 0.8285
2023-03-06 20:17:52 - __main__ - INFO - Epoch [10/100]
2023-03-06 20:17:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 20:18:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 20:18:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 20:18:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 20:18:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 20:18:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-06 20:18:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 20:18:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 20:18:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 20:19:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 20:19:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 20:19:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 20:19:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8546, Acc_2: 0.8567, F1-score_1: 0.8174, F1-score_2: 0.8189
2023-03-06 20:19:34 - __main__ - INFO - Epoch [11/100]
2023-03-06 20:19:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 20:19:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-06 20:19:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 20:20:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 20:20:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-06 20:20:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 20:20:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 20:20:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 20:20:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 20:20:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 20:20:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 20:20:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-06 20:21:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8653, Acc_2: 0.8612, F1-score_1: 0.8260, F1-score_2: 0.8209
2023-03-06 20:21:15 - __main__ - INFO - Epoch [12/100]
2023-03-06 20:21:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 20:21:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 20:21:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 20:21:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:21:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 20:21:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 20:22:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 20:22:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-06 20:22:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 20:22:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 20:22:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 20:22:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 20:22:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8645, Acc_2: 0.8638, F1-score_1: 0.8254, F1-score_2: 0.8215
2023-03-06 20:22:57 - __main__ - INFO - Epoch [13/100]
2023-03-06 20:23:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 20:23:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9453, 
2023-03-06 20:23:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 20:23:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 20:23:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 20:23:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 20:23:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 20:23:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 20:23:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 20:24:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 20:24:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 20:24:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 20:24:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8657, Acc_2: 0.8650, F1-score_1: 0.8277, F1-score_2: 0.8239
2023-03-06 20:24:39 - __main__ - INFO - Epoch [14/100]
2023-03-06 20:24:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 20:24:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 20:24:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 20:25:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 20:25:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 20:25:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 20:25:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 20:25:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 20:25:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 20:25:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 20:25:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 20:26:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 20:26:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8633, Acc_2: 0.8592, F1-score_1: 0.8229, F1-score_2: 0.8191
2023-03-06 20:26:20 - __main__ - INFO - Epoch [15/100]
2023-03-06 20:26:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 20:26:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 20:26:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 20:26:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 20:26:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-06 20:27:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:27:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 20:27:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 20:27:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 20:27:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 20:27:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 20:27:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 20:28:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8623, Acc_2: 0.8589, F1-score_1: 0.8234, F1-score_2: 0.8168
2023-03-06 20:28:02 - __main__ - INFO - Epoch [16/100]
2023-03-06 20:28:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 20:28:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 20:28:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 20:28:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 20:28:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 20:28:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 20:28:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 20:28:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:29:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 20:29:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 20:29:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 20:29:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 20:29:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8631, Acc_2: 0.8602, F1-score_1: 0.8238, F1-score_2: 0.8246
2023-03-06 20:29:44 - __main__ - INFO - Epoch [17/100]
2023-03-06 20:29:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-06 20:29:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 20:30:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 20:30:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 20:30:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 20:30:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-06 20:30:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 20:30:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 20:30:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 20:30:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 20:31:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 20:31:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-06 20:31:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8621, F1-score_1: 0.8311, F1-score_2: 0.8238
2023-03-06 20:31:25 - __main__ - INFO - Epoch [18/100]
2023-03-06 20:31:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-06 20:31:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 20:31:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 20:31:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 20:31:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 20:32:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 20:32:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 20:32:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 20:32:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 20:32:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 20:32:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 20:32:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 20:33:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8663, Acc_2: 0.8641, F1-score_1: 0.8295, F1-score_2: 0.8257
2023-03-06 20:33:07 - __main__ - INFO - Epoch [19/100]
2023-03-06 20:33:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 20:33:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 20:33:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 20:33:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 20:33:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 20:33:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 20:33:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 20:34:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 20:34:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 20:34:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 20:34:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 20:34:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 20:34:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8674, Acc_2: 0.8589, F1-score_1: 0.8316, F1-score_2: 0.8226
2023-03-06 20:34:49 - __main__ - INFO - Epoch [20/100]
2023-03-06 20:34:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 20:35:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-06 20:35:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 20:35:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 20:35:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 20:35:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 20:35:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:35:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 20:35:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 20:35:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 20:36:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 20:36:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 20:36:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8663, Acc_2: 0.8563, F1-score_1: 0.8306, F1-score_2: 0.8178
2023-03-06 20:36:30 - __main__ - INFO - Epoch [21/100]
2023-03-06 20:36:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 20:36:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 20:36:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 20:36:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-06 20:37:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:37:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 20:37:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-06 20:37:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 20:37:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 20:37:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 20:37:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 20:37:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 20:38:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8660, Acc_2: 0.8618, F1-score_1: 0.8293, F1-score_2: 0.8212
2023-03-06 20:38:12 - __main__ - INFO - Epoch [22/100]
2023-03-06 20:38:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9141, 
2023-03-06 20:38:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 20:38:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 20:38:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 20:38:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 20:38:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 20:39:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 20:39:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-06 20:39:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 20:39:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 20:39:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 20:39:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-06 20:39:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8662, Acc_2: 0.8599, F1-score_1: 0.8288, F1-score_2: 0.8230
2023-03-06 20:39:53 - __main__ - INFO - Epoch [23/100]
2023-03-06 20:39:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 20:40:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 20:40:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 20:40:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 20:40:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 20:40:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 20:40:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 20:40:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 20:40:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 20:41:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 20:41:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 20:41:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-06 20:41:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.8587, Acc_2: 0.8378, F1-score_1: 0.8196, F1-score_2: 0.7944
2023-03-06 20:41:35 - __main__ - INFO - Epoch [24/100]
2023-03-06 20:41:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 20:41:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 20:41:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 20:42:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 20:42:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 20:42:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 20:42:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-06 20:42:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 20:42:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 20:42:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-06 20:42:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-06 20:42:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9453, 
2023-03-06 20:43:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8538, Acc_2: 0.8283, F1-score_1: 0.8037, F1-score_2: 0.7812
2023-03-06 20:43:17 - __main__ - INFO - Epoch [25/100]
2023-03-06 20:43:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 20:43:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 20:43:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 20:43:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 20:43:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 20:43:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-06 20:44:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-06 20:44:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 20:44:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 20:44:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 20:44:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 20:44:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:44:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0008, Acc_1: 0.8460, Acc_2: 0.8320, F1-score_1: 0.8125, F1-score_2: 0.7991
2023-03-06 20:44:59 - __main__ - INFO - Epoch [26/100]
2023-03-06 20:45:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-06 20:45:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 20:45:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-06 20:45:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-06 20:45:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 20:45:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8906, 
2023-03-06 20:45:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-06 20:45:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-06 20:46:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 20:46:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 20:46:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 20:46:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 20:46:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0023, Acc_1: 0.8359, Acc_2: 0.8257, F1-score_1: 0.7930, F1-score_2: 0.7790
2023-03-06 20:46:40 - __main__ - INFO - Epoch [27/100]
2023-03-06 20:46:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 20:46:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-06 20:47:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 20:47:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-06 20:47:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9453, 
2023-03-06 20:47:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 20:47:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:47:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0016, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-06 20:47:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0017, Loss_2: 0.0008, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 20:47:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 20:47:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0012, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-06 20:48:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0017, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8594, 
2023-03-06 20:48:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0024, Acc_1: 0.8305, Acc_2: 0.8142, F1-score_1: 0.7853, F1-score_2: 0.7708
2023-03-06 20:48:22 - __main__ - INFO - Epoch [28/100]
2023-03-06 20:48:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0009, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 20:48:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:48:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9141, 
2023-03-06 20:48:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0020, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-06 20:48:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-06 20:49:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8906, 
2023-03-06 20:49:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 20:49:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 20:49:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 20:49:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 20:49:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:49:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:50:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0007, Acc_1: 0.8332, Acc_2: 0.8368, F1-score_1: 0.7877, F1-score_2: 0.7884
2023-03-06 20:50:04 - __main__ - INFO - Epoch [29/100]
2023-03-06 20:50:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 20:50:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-06 20:50:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 20:50:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 20:50:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 20:50:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0022, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 20:50:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0014, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 20:50:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 20:51:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 20:51:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-06 20:51:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 20:51:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 20:51:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0017, Acc_1: 0.8417, Acc_2: 0.8417, F1-score_1: 0.8006, F1-score_2: 0.7984
2023-03-06 20:51:46 - __main__ - INFO - Epoch [30/100]
2023-03-06 20:51:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 20:51:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 20:52:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 20:52:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-06 20:52:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 20:52:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-06 20:52:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-06 20:52:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 20:52:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 20:52:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 20:53:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-06 20:53:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 20:53:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0042, Loss_2: 0.0017, Acc_1: 0.8407, Acc_2: 0.8370, F1-score_1: 0.7957, F1-score_2: 0.7926
2023-03-06 20:53:27 - __main__ - INFO - Epoch [31/100]
2023-03-06 20:53:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 20:53:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 20:53:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 20:53:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 20:54:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:54:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 20:54:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 20:54:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 20:54:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 20:54:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9375, 
2023-03-06 20:54:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 20:54:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 20:55:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0040, Loss_2: 0.0024, Acc_1: 0.8368, Acc_2: 0.8337, F1-score_1: 0.7948, F1-score_2: 0.7898
2023-03-06 20:55:09 - __main__ - INFO - Epoch [32/100]
2023-03-06 20:55:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 20:55:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-06 20:55:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 20:55:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 20:55:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-06 20:55:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 20:55:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 20:56:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 20:56:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 20:56:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 20:56:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 20:56:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:56:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0014, Acc_1: 0.8409, Acc_2: 0.8259, F1-score_1: 0.8023, F1-score_2: 0.7883
2023-03-06 20:56:51 - __main__ - INFO - Epoch [33/100]
2023-03-06 20:56:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 20:57:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-06 20:57:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-06 20:57:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 20:57:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 20:57:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:57:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 20:57:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 20:57:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-06 20:58:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 20:58:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-06 20:58:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 20:58:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0017, Acc_1: 0.8488, Acc_2: 0.8354, F1-score_1: 0.8077, F1-score_2: 0.7895
2023-03-06 20:58:32 - __main__ - INFO - Epoch [34/100]
2023-03-06 20:58:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 20:58:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 20:58:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 20:58:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 20:59:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 20:59:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 20:59:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 20:59:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 20:59:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 20:59:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 20:59:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 20:59:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 21:00:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0011, Acc_1: 0.8458, Acc_2: 0.8414, F1-score_1: 0.8063, F1-score_2: 0.7972
2023-03-06 21:00:14 - __main__ - INFO - Epoch [35/100]
2023-03-06 21:00:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 21:00:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 21:00:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-06 21:00:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 21:00:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:00:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 21:01:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 21:01:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 21:01:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:01:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-06 21:01:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 21:01:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:01:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0011, Acc_1: 0.8456, Acc_2: 0.8415, F1-score_1: 0.8007, F1-score_2: 0.8007
2023-03-06 21:01:56 - __main__ - INFO - Epoch [36/100]
2023-03-06 21:02:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 21:02:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 21:02:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 21:02:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:02:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 21:02:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 21:02:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:02:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 21:02:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 21:03:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:03:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 21:03:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 21:03:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0009, Acc_1: 0.8424, Acc_2: 0.8410, F1-score_1: 0.8030, F1-score_2: 0.7995
2023-03-06 21:03:37 - __main__ - INFO - Epoch [37/100]
2023-03-06 21:03:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 21:03:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:03:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:04:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 21:04:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:04:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 21:04:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 21:04:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 21:04:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8828, 
2023-03-06 21:04:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 21:04:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 21:04:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 21:05:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0013, Acc_1: 0.8470, Acc_2: 0.8446, F1-score_1: 0.8059, F1-score_2: 0.8041
2023-03-06 21:05:19 - __main__ - INFO - Epoch [38/100]
2023-03-06 21:05:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 21:05:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:05:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0010, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 21:05:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 21:05:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:06:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 21:06:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 21:06:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 21:06:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 21:06:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 21:06:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 21:06:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 21:07:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0010, Acc_1: 0.8342, Acc_2: 0.8298, F1-score_1: 0.7901, F1-score_2: 0.7834
2023-03-06 21:07:01 - __main__ - INFO - Epoch [39/100]
2023-03-06 21:07:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-06 21:07:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 21:07:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:07:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 21:07:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:07:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-06 21:07:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 21:07:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-06 21:08:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 21:08:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 21:08:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:08:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:08:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0011, Acc_1: 0.8331, Acc_2: 0.8286, F1-score_1: 0.7852, F1-score_2: 0.7834
2023-03-06 21:08:42 - __main__ - INFO - Epoch [40/100]
2023-03-06 21:08:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:08:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:09:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 21:09:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 21:09:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:09:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:09:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9297, 
2023-03-06 21:09:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 21:09:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 21:09:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 21:09:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:10:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:10:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0008, Acc_1: 0.8414, Acc_2: 0.8390, F1-score_1: 0.8007, F1-score_2: 0.7993
2023-03-06 21:10:24 - __main__ - INFO - Epoch [41/100]
2023-03-06 21:10:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 21:10:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 21:10:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 21:10:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 21:10:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:11:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-06 21:11:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 21:11:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 21:11:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:11:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 21:11:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 21:11:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 21:12:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0013, Acc_1: 0.8407, Acc_2: 0.8458, F1-score_1: 0.7937, F1-score_2: 0.8033
2023-03-06 21:12:06 - __main__ - INFO - Epoch [42/100]
2023-03-06 21:12:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:12:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:12:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 21:12:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 21:12:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 21:12:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-06 21:12:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:13:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:13:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0018, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 21:13:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 21:13:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-06 21:13:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:13:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0014, Acc_1: 0.8404, Acc_2: 0.8252, F1-score_1: 0.7961, F1-score_2: 0.7744
2023-03-06 21:13:48 - __main__ - INFO - Epoch [43/100]
2023-03-06 21:13:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 21:14:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 21:14:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:14:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-06 21:14:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 21:14:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 21:14:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 21:14:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 21:14:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:14:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 21:15:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:15:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 21:15:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0006, Loss_2: 0.0019, Acc_1: 0.8308, Acc_2: 0.8351, F1-score_1: 0.7957, F1-score_2: 0.7909
2023-03-06 21:15:29 - __main__ - INFO - Epoch [44/100]
2023-03-06 21:15:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 21:15:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:15:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-06 21:15:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:16:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 21:16:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-06 21:16:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8516, 
2023-03-06 21:16:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 21:16:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 21:16:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 21:16:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 21:16:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 21:17:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0028, Loss_2: 0.0010, Acc_1: 0.8414, Acc_2: 0.8280, F1-score_1: 0.8009, F1-score_2: 0.7719
2023-03-06 21:17:11 - __main__ - INFO - Epoch [45/100]
2023-03-06 21:17:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-06 21:17:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 21:17:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 21:17:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:17:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 21:17:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 21:17:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-06 21:18:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:18:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 21:18:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:18:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 21:18:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 21:18:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0004, Acc_1: 0.8334, Acc_2: 0.8376, F1-score_1: 0.7881, F1-score_2: 0.7942
2023-03-06 21:18:53 - __main__ - INFO - Epoch [46/100]
2023-03-06 21:18:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 21:19:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:19:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 21:19:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 21:19:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 21:19:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 21:19:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:19:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 21:19:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0027, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 21:20:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 21:20:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 21:20:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:20:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0004, Acc_1: 0.8400, Acc_2: 0.8341, F1-score_1: 0.7980, F1-score_2: 0.7885
2023-03-06 21:20:34 - __main__ - INFO - Epoch [47/100]
2023-03-06 21:20:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:20:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:20:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:21:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:21:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:21:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 21:21:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:21:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 21:21:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-06 21:21:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-06 21:21:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:21:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-06 21:22:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0005, Acc_1: 0.8198, Acc_2: 0.8410, F1-score_1: 0.7707, F1-score_2: 0.7962
2023-03-06 21:22:16 - __main__ - INFO - Epoch [48/100]
2023-03-06 21:22:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-06 21:22:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:22:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 21:22:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:22:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:22:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:23:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:23:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 21:23:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 21:23:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 21:23:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 21:23:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-06 21:23:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0020, Acc_1: 0.8351, Acc_2: 0.8298, F1-score_1: 0.7897, F1-score_2: 0.7825
2023-03-06 21:23:58 - __main__ - INFO - Epoch [49/100]
2023-03-06 21:24:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 21:24:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:24:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 21:24:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-06 21:24:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0022, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:24:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:24:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 21:24:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-06 21:25:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:25:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 21:25:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 21:25:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-06 21:25:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0016, Acc_1: 0.8361, Acc_2: 0.8302, F1-score_1: 0.7919, F1-score_2: 0.7929
2023-03-06 21:25:39 - __main__ - INFO - Epoch [50/100]
2023-03-06 21:25:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-06 21:25:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 21:25:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 21:26:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:26:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:26:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:26:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-06 21:26:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:26:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:26:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:26:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 21:27:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 21:27:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0009, Acc_1: 0.8302, Acc_2: 0.8280, F1-score_1: 0.7847, F1-score_2: 0.7912
2023-03-06 21:27:21 - __main__ - INFO - Epoch [51/100]
2023-03-06 21:27:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:27:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:27:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 21:27:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 21:27:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:28:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:28:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:28:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 21:28:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 21:28:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 21:28:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:28:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-06 21:29:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0006, Acc_1: 0.8337, Acc_2: 0.8376, F1-score_1: 0.7948, F1-score_2: 0.7942
2023-03-06 21:29:03 - __main__ - INFO - Epoch [52/100]
2023-03-06 21:29:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 21:29:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 21:29:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:29:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:29:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:29:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 21:29:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:29:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 21:30:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 21:30:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-06 21:30:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:30:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 21:30:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8390, Acc_2: 0.8334, F1-score_1: 0.7925, F1-score_2: 0.7889
2023-03-06 21:30:44 - __main__ - INFO - Epoch [53/100]
2023-03-06 21:30:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 21:30:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 21:31:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 21:31:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:31:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:31:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:31:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:31:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:31:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-06 21:31:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:32:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:32:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 21:32:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0010, Loss_2: 0.0002, Acc_1: 0.8393, Acc_2: 0.8387, F1-score_1: 0.7968, F1-score_2: 0.7943
2023-03-06 21:32:26 - __main__ - INFO - Epoch [54/100]
2023-03-06 21:32:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:32:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 21:32:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 21:32:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.9062, 
2023-03-06 21:33:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-06 21:33:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0018, Loss_2: 0.0009, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-06 21:33:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 21:33:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:33:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 21:33:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-06 21:33:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 21:33:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 21:34:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0005, Acc_1: 0.8381, Acc_2: 0.8400, F1-score_1: 0.7943, F1-score_2: 0.7956
2023-03-06 21:34:08 - __main__ - INFO - Epoch [55/100]
2023-03-06 21:34:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:34:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:34:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 21:34:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 21:34:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 21:34:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:34:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:35:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:35:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:35:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-06 21:35:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:35:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 21:35:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8373, Acc_2: 0.8353, F1-score_1: 0.7921, F1-score_2: 0.7928
2023-03-06 21:35:49 - __main__ - INFO - Epoch [56/100]
2023-03-06 21:35:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 21:36:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 21:36:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 21:36:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:36:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 21:36:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 21:36:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:36:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-06 21:36:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 21:36:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 21:37:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:37:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 21:37:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0016, Acc_1: 0.8349, Acc_2: 0.8398, F1-score_1: 0.7921, F1-score_2: 0.7981
2023-03-06 21:37:31 - __main__ - INFO - Epoch [57/100]
2023-03-06 21:37:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:37:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 21:37:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 21:37:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:38:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:38:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9453, 
2023-03-06 21:38:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:38:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:38:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 21:38:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:38:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:38:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 21:39:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0015, Acc_1: 0.8329, Acc_2: 0.8398, F1-score_1: 0.7879, F1-score_2: 0.7980
2023-03-06 21:39:13 - __main__ - INFO - Epoch [58/100]
2023-03-06 21:39:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 21:39:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 21:39:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 21:39:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:39:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 21:39:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 21:40:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:40:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:40:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 21:40:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:40:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 21:40:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 21:40:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0013, Acc_1: 0.8298, Acc_2: 0.8302, F1-score_1: 0.7821, F1-score_2: 0.7817
2023-03-06 21:40:54 - __main__ - INFO - Epoch [59/100]
2023-03-06 21:41:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 21:41:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:41:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 21:41:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:41:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:41:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0018, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 21:41:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:41:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-06 21:41:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:42:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-06 21:42:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 21:42:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 21:42:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0011, Acc_1: 0.8091, Acc_2: 0.8229, F1-score_1: 0.7688, F1-score_2: 0.7761
2023-03-06 21:42:36 - __main__ - INFO - Epoch [60/100]
2023-03-06 21:42:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 21:42:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 21:42:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:43:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0016, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:43:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:43:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9609, 
2023-03-06 21:43:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 21:43:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 21:43:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 21:43:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-06 21:43:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0023, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 21:43:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:44:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0020, Acc_1: 0.8349, Acc_2: 0.8227, F1-score_1: 0.7936, F1-score_2: 0.7705
2023-03-06 21:44:17 - __main__ - INFO - Epoch [61/100]
2023-03-06 21:44:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:44:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9453, 
2023-03-06 21:44:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-06 21:44:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-06 21:44:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 21:44:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 21:45:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-06 21:45:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:45:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-06 21:45:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:45:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-06 21:45:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 21:45:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0005, Loss_2: 0.0038, Acc_1: 0.8368, Acc_2: 0.8271, F1-score_1: 0.7917, F1-score_2: 0.7847
2023-03-06 21:45:59 - __main__ - INFO - Epoch [62/100]
2023-03-06 21:46:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-06 21:46:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-06 21:46:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 21:46:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-06 21:46:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-06 21:46:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:46:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:46:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-06 21:47:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-06 21:47:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-06 21:47:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 21:47:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 21:47:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0023, Acc_1: 0.8327, Acc_2: 0.8310, F1-score_1: 0.7869, F1-score_2: 0.7808
2023-03-06 21:47:41 - __main__ - INFO - Epoch [63/100]
2023-03-06 21:47:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 21:47:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-06 21:48:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 21:48:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 21:48:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 21:48:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:48:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 21:48:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-06 21:48:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 21:48:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 21:48:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:49:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:49:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0038, Loss_2: 0.0021, Acc_1: 0.8273, Acc_2: 0.8130, F1-score_1: 0.7831, F1-score_2: 0.7694
2023-03-06 21:49:23 - __main__ - INFO - Epoch [64/100]
2023-03-06 21:49:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 21:49:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 21:49:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:49:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:49:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-06 21:50:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-06 21:50:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:50:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 21:50:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:50:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 21:50:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:50:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 21:51:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0012, Acc_1: 0.8314, Acc_2: 0.8144, F1-score_1: 0.7888, F1-score_2: 0.7639
2023-03-06 21:51:04 - __main__ - INFO - Epoch [65/100]
2023-03-06 21:51:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 21:51:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 21:51:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:51:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:51:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 21:51:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 21:51:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0018, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-06 21:51:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:52:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 21:52:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0014, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 21:52:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 21:52:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 21:52:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0019, Acc_1: 0.8364, Acc_2: 0.8174, F1-score_1: 0.7928, F1-score_2: 0.7723
2023-03-06 21:52:46 - __main__ - INFO - Epoch [66/100]
2023-03-06 21:52:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 21:52:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 21:53:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 21:53:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:53:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-06 21:53:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:53:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:53:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 21:53:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-06 21:53:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:54:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-06 21:54:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:54:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0012, Acc_1: 0.8324, Acc_2: 0.8332, F1-score_1: 0.7902, F1-score_2: 0.7867
2023-03-06 21:54:27 - __main__ - INFO - Epoch [67/100]
2023-03-06 21:54:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-06 21:54:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-06 21:54:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-06 21:54:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 21:55:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-06 21:55:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:55:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:55:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 21:55:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 21:55:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-06 21:55:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 21:55:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-06 21:56:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0036, Loss_2: 0.0019, Acc_1: 0.8387, Acc_2: 0.8314, F1-score_1: 0.8005, F1-score_2: 0.7881
2023-03-06 21:56:09 - __main__ - INFO - Epoch [68/100]
2023-03-06 21:56:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:56:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 21:56:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-06 21:56:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 21:56:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-06 21:56:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:56:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 21:57:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-06 21:57:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 21:57:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:57:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:57:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 21:57:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0010, Acc_1: 0.8320, Acc_2: 0.8354, F1-score_1: 0.7871, F1-score_2: 0.7932
2023-03-06 21:57:50 - __main__ - INFO - Epoch [69/100]
2023-03-06 21:57:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 21:58:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 21:58:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-06 21:58:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 21:58:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 21:58:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-06 21:58:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-06 21:58:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:58:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-06 21:58:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 21:59:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:59:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-06 21:59:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0027, Acc_1: 0.8281, Acc_2: 0.8186, F1-score_1: 0.7853, F1-score_2: 0.7694
2023-03-06 21:59:32 - __main__ - INFO - Epoch [70/100]
2023-03-06 21:59:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-06 21:59:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 21:59:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-06 21:59:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9453, 
2023-03-06 22:00:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-06 22:00:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-06 22:00:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-06 22:00:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-06 22:00:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0042, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-06 22:00:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 22:00:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 22:00:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-06 22:01:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0046, Acc_1: 0.8215, Acc_2: 0.8249, F1-score_1: 0.7759, F1-score_2: 0.7775
2023-03-06 22:01:14 - __main__ - INFO - Epoch [71/100]
2023-03-06 22:01:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 22:01:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-06 22:01:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-06 22:01:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-06 22:01:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 22:01:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 22:02:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 22:02:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-06 22:02:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-06 22:02:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-06 22:02:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-06 22:02:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 22:02:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0028, Acc_1: 0.8373, Acc_2: 0.8266, F1-score_1: 0.7940, F1-score_2: 0.7807
2023-03-06 22:02:56 - __main__ - INFO - Epoch [72/100]
2023-03-06 22:03:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-06 22:03:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-06 22:03:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 22:03:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0015, Loss_2: 0.0026, Acc_1: 0.7656, Acc_2: 0.7969, 
2023-03-06 22:03:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-06 22:03:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-06 22:03:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-06 22:03:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-06 22:03:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 22:04:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0027, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-06 22:04:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-06 22:04:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8594, 
2023-03-06 22:04:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0029, Acc_1: 0.8235, Acc_2: 0.8246, F1-score_1: 0.7772, F1-score_2: 0.7787
2023-03-06 22:04:38 - __main__ - INFO - Epoch [73/100]
2023-03-06 22:04:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-06 22:04:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-06 22:04:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-06 22:05:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-06 22:05:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-06 22:05:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-06 22:05:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 08:48:05 - utils._utils - DEBUG - [Args] (seed: 1), (model1: None), (model2: None), (noise_rate: 0.2)
2023-03-07 08:48:07 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 08:48:08 - utils._noise - DEBUG - 6, 7
2023-03-07 08:48:08 - utils._noise - DEBUG - 13997
2023-03-07 08:48:08 - utils._noise - INFO - Actual noise 0.20
2023-03-07 08:48:08 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-07 08:48:08 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-07 08:48:10 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 08:48:10 - __main__ - INFO - Loading dataset...
2023-03-07 08:48:10 - __main__ - INFO - Building model...
2023-03-07 08:48:13 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-07 08:48:15 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-07 08:48:15 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-07 08:48:15 - __main__ - INFO - Start train & evaluate
2023-03-07 08:48:15 - __main__ - INFO - Epoch [0/100]
2023-03-07 08:48:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0164, Loss_2: 0.0152, Acc_1: 0.1641, Acc_2: 0.0625, 
2023-03-07 08:48:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0125, Loss_2: 0.0139, Acc_1: 0.5156, Acc_2: 0.3125, 
2023-03-07 08:48:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0108, Loss_2: 0.0141, Acc_1: 0.5938, Acc_2: 0.2812, 
2023-03-07 08:48:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0109, Loss_2: 0.0136, Acc_1: 0.5938, Acc_2: 0.3203, 
2023-03-07 08:48:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0087, Loss_2: 0.0144, Acc_1: 0.6875, Acc_2: 0.3125, 
2023-03-07 08:48:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0105, Loss_2: 0.0132, Acc_1: 0.5781, Acc_2: 0.3828, 
2023-03-07 08:49:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0088, Loss_2: 0.0112, Acc_1: 0.7109, Acc_2: 0.5625, 
2023-03-07 08:49:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0081, Loss_2: 0.0140, Acc_1: 0.7266, Acc_2: 0.2891, 
2023-03-07 08:49:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0117, Loss_2: 0.0143, Acc_1: 0.5938, Acc_2: 0.2734, 
2023-03-07 08:49:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0091, Loss_2: 0.0144, Acc_1: 0.6328, Acc_2: 0.2500, 
2023-03-07 08:49:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0082, Loss_2: 0.0134, Acc_1: 0.7031, Acc_2: 0.3984, 
2023-03-07 08:49:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0090, Loss_2: 0.0140, Acc_1: 0.6953, Acc_2: 0.2891, 
2023-03-07 08:49:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0061, Loss_2: 0.0129, Acc_1: 0.8490, Acc_2: 0.3872, F1-score_1: 0.7952, F1-score_2: 0.2183
2023-03-07 08:49:52 - __main__ - INFO - Epoch [1/100]
2023-03-07 08:49:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0071, Loss_2: 0.0132, Acc_1: 0.7422, Acc_2: 0.4141, 
2023-03-07 08:50:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0062, Loss_2: 0.0128, Acc_1: 0.7812, Acc_2: 0.4766, 
2023-03-07 08:50:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0063, Loss_2: 0.0133, Acc_1: 0.7422, Acc_2: 0.3828, 
2023-03-07 08:50:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0071, Loss_2: 0.0126, Acc_1: 0.7812, Acc_2: 0.4453, 
2023-03-07 08:50:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0077, Loss_2: 0.0134, Acc_1: 0.7109, Acc_2: 0.3516, 
2023-03-07 08:50:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0068, Loss_2: 0.0118, Acc_1: 0.7656, Acc_2: 0.4297, 
2023-03-07 08:50:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0081, Loss_2: 0.0126, Acc_1: 0.7109, Acc_2: 0.4297, 
2023-03-07 08:50:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0070, Loss_2: 0.0109, Acc_1: 0.7422, Acc_2: 0.5469, 
2023-03-07 08:50:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0077, Loss_2: 0.0121, Acc_1: 0.7500, Acc_2: 0.4688, 
2023-03-07 08:50:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0072, Loss_2: 0.0122, Acc_1: 0.7266, Acc_2: 0.4141, 
2023-03-07 08:51:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0075, Loss_2: 0.0110, Acc_1: 0.7344, Acc_2: 0.5156, 
2023-03-07 08:51:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0080, Loss_2: 0.0118, Acc_1: 0.6875, Acc_2: 0.4688, 
2023-03-07 08:51:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0049, Loss_2: 0.0098, Acc_1: 0.8731, Acc_2: 0.5844, F1-score_1: 0.8285, F1-score_2: 0.3646
2023-03-07 08:51:29 - __main__ - INFO - Epoch [2/100]
2023-03-07 08:51:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0048, Loss_2: 0.0115, Acc_1: 0.8125, Acc_2: 0.4766, 
2023-03-07 08:51:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0057, Loss_2: 0.0114, Acc_1: 0.7734, Acc_2: 0.5078, 
2023-03-07 08:51:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0042, Loss_2: 0.0105, Acc_1: 0.8203, Acc_2: 0.5469, 
2023-03-07 08:51:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0049, Loss_2: 0.0101, Acc_1: 0.7969, Acc_2: 0.5312, 
2023-03-07 08:52:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0059, Loss_2: 0.0121, Acc_1: 0.7812, Acc_2: 0.4219, 
2023-03-07 08:52:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0052, Loss_2: 0.0107, Acc_1: 0.7891, Acc_2: 0.5391, 
2023-03-07 08:52:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0044, Loss_2: 0.0084, Acc_1: 0.8516, Acc_2: 0.6172, 
2023-03-07 08:52:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0065, Loss_2: 0.0117, Acc_1: 0.7031, Acc_2: 0.4844, 
2023-03-07 08:52:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0066, Loss_2: 0.0115, Acc_1: 0.7266, Acc_2: 0.4766, 
2023-03-07 08:52:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0060, Loss_2: 0.0104, Acc_1: 0.7344, Acc_2: 0.5312, 
2023-03-07 08:52:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0070, Loss_2: 0.0114, Acc_1: 0.7188, Acc_2: 0.5078, 
2023-03-07 08:52:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0068, Loss_2: 0.0095, Acc_1: 0.7188, Acc_2: 0.6172, 
2023-03-07 08:53:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0081, Acc_1: 0.8511, Acc_2: 0.6839, F1-score_1: 0.8015, F1-score_2: 0.5531
2023-03-07 08:53:06 - __main__ - INFO - Epoch [3/100]
2023-03-07 08:53:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0051, Loss_2: 0.0104, Acc_1: 0.7812, Acc_2: 0.5469, 
2023-03-07 08:53:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0028, Loss_2: 0.0084, Acc_1: 0.8594, Acc_2: 0.5938, 
2023-03-07 08:53:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0040, Loss_2: 0.0093, Acc_1: 0.8281, Acc_2: 0.6016, 
2023-03-07 08:53:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0025, Loss_2: 0.0075, Acc_1: 0.8359, Acc_2: 0.6719, 
2023-03-07 08:53:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0030, Loss_2: 0.0087, Acc_1: 0.8438, Acc_2: 0.6016, 
2023-03-07 08:53:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0020, Loss_2: 0.0071, Acc_1: 0.8594, Acc_2: 0.6797, 
2023-03-07 08:53:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0031, Loss_2: 0.0079, Acc_1: 0.8438, Acc_2: 0.6172, 
2023-03-07 08:53:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0044, Loss_2: 0.0089, Acc_1: 0.7969, Acc_2: 0.5703, 
2023-03-07 08:54:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0036, Loss_2: 0.0081, Acc_1: 0.8516, Acc_2: 0.6406, 
2023-03-07 08:54:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0064, Loss_2: 0.0110, Acc_1: 0.7109, Acc_2: 0.5547, 
2023-03-07 08:54:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0048, Loss_2: 0.0115, Acc_1: 0.7812, Acc_2: 0.5078, 
2023-03-07 08:54:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0039, Loss_2: 0.0088, Acc_1: 0.8203, Acc_2: 0.6094, 
2023-03-07 08:54:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0088, Acc_1: 0.8682, Acc_2: 0.6466, F1-score_1: 0.8284, F1-score_2: 0.5900
2023-03-07 08:54:43 - __main__ - INFO - Epoch [4/100]
2023-03-07 08:54:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0030, Loss_2: 0.0098, Acc_1: 0.8750, Acc_2: 0.5234, 
2023-03-07 08:54:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0017, Loss_2: 0.0071, Acc_1: 0.8828, Acc_2: 0.6406, 
2023-03-07 08:55:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0015, Loss_2: 0.0058, Acc_1: 0.9062, Acc_2: 0.7344, 
2023-03-07 08:55:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0017, Loss_2: 0.0067, Acc_1: 0.8906, Acc_2: 0.6484, 
2023-03-07 08:55:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0022, Loss_2: 0.0068, Acc_1: 0.8125, Acc_2: 0.6953, 
2023-03-07 08:55:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0024, Loss_2: 0.0075, Acc_1: 0.8359, Acc_2: 0.6094, 
2023-03-07 08:55:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0014, Loss_2: 0.0055, Acc_1: 0.8828, Acc_2: 0.7266, 
2023-03-07 08:55:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0016, Loss_2: 0.0054, Acc_1: 0.8750, Acc_2: 0.7266, 
2023-03-07 08:55:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0018, Loss_2: 0.0063, Acc_1: 0.8906, Acc_2: 0.7422, 
2023-03-07 08:55:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0017, Loss_2: 0.0066, Acc_1: 0.8672, Acc_2: 0.6328, 
2023-03-07 08:55:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0026, Loss_2: 0.0059, Acc_1: 0.8594, Acc_2: 0.7422, 
2023-03-07 08:56:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0038, Loss_2: 0.0070, Acc_1: 0.7969, Acc_2: 0.7109, 
2023-03-07 08:56:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0044, Acc_1: 0.8670, Acc_2: 0.7802, F1-score_1: 0.8254, F1-score_2: 0.7073
2023-03-07 08:56:20 - __main__ - INFO - Epoch [5/100]
2023-03-07 08:56:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0033, Acc_1: 0.9375, Acc_2: 0.8203, 
2023-03-07 08:56:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0045, Acc_1: 0.9062, Acc_2: 0.7500, 
2023-03-07 08:56:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0012, Loss_2: 0.0049, Acc_1: 0.8516, Acc_2: 0.7188, 
2023-03-07 08:56:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0016, Loss_2: 0.0071, Acc_1: 0.8594, Acc_2: 0.6719, 
2023-03-07 08:56:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0056, Acc_1: 0.9062, Acc_2: 0.7109, 
2023-03-07 08:57:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0024, Loss_2: 0.0066, Acc_1: 0.8516, Acc_2: 0.6953, 
2023-03-07 08:57:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0020, Loss_2: 0.0063, Acc_1: 0.8516, Acc_2: 0.6953, 
2023-03-07 08:57:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0013, Loss_2: 0.0062, Acc_1: 0.9062, Acc_2: 0.7031, 
2023-03-07 08:57:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0026, Loss_2: 0.0066, Acc_1: 0.8203, Acc_2: 0.6797, 
2023-03-07 08:57:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0041, Acc_1: 0.9062, Acc_2: 0.7578, 
2023-03-07 08:57:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0019, Loss_2: 0.0045, Acc_1: 0.8516, Acc_2: 0.7578, 
2023-03-07 08:57:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0014, Loss_2: 0.0054, Acc_1: 0.8594, Acc_2: 0.7422, 
2023-03-07 08:57:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0043, Acc_1: 0.8631, Acc_2: 0.7819, F1-score_1: 0.8231, F1-score_2: 0.7222
2023-03-07 08:57:57 - __main__ - INFO - Epoch [6/100]
2023-03-07 08:58:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0034, Acc_1: 0.8906, Acc_2: 0.7891, 
2023-03-07 08:58:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0029, Acc_1: 0.9219, Acc_2: 0.8125, 
2023-03-07 08:58:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0009, Loss_2: 0.0036, Acc_1: 0.8750, Acc_2: 0.7969, 
2023-03-07 08:58:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0022, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 08:58:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0012, Loss_2: 0.0038, Acc_1: 0.8906, Acc_2: 0.7656, 
2023-03-07 08:58:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0013, Loss_2: 0.0058, Acc_1: 0.8594, Acc_2: 0.6797, 
2023-03-07 08:58:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0014, Loss_2: 0.0030, Acc_1: 0.8984, Acc_2: 0.7734, 
2023-03-07 08:58:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0036, Acc_1: 0.9141, Acc_2: 0.7734, 
2023-03-07 08:58:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0011, Loss_2: 0.0041, Acc_1: 0.8750, Acc_2: 0.7734, 
2023-03-07 08:59:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0031, Acc_1: 0.8906, Acc_2: 0.7734, 
2023-03-07 08:59:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0034, Acc_1: 0.8906, Acc_2: 0.7891, 
2023-03-07 08:59:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0033, Acc_1: 0.8984, Acc_2: 0.7734, 
2023-03-07 08:59:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0040, Acc_1: 0.8636, Acc_2: 0.7777, F1-score_1: 0.8226, F1-score_2: 0.7122
2023-03-07 08:59:34 - __main__ - INFO - Epoch [7/100]
2023-03-07 08:59:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0028, Acc_1: 0.8828, Acc_2: 0.7969, 
2023-03-07 08:59:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0023, Acc_1: 0.8828, Acc_2: 0.8125, 
2023-03-07 08:59:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0030, Acc_1: 0.8672, Acc_2: 0.7578, 
2023-03-07 09:00:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0024, Acc_1: 0.8984, Acc_2: 0.8125, 
2023-03-07 09:00:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0029, Acc_1: 0.8516, Acc_2: 0.7656, 
2023-03-07 09:00:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0019, Acc_1: 0.9375, Acc_2: 0.8359, 
2023-03-07 09:00:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0038, Acc_1: 0.8906, Acc_2: 0.7422, 
2023-03-07 09:00:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0021, Acc_1: 0.9297, Acc_2: 0.8438, 
2023-03-07 09:00:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0014, Loss_2: 0.0031, Acc_1: 0.8516, Acc_2: 0.7891, 
2023-03-07 09:00:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0026, Acc_1: 0.9062, Acc_2: 0.7969, 
2023-03-07 09:00:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0041, Acc_1: 0.8594, Acc_2: 0.7188, 
2023-03-07 09:00:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0031, Acc_1: 0.8594, Acc_2: 0.7578, 
2023-03-07 09:01:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0037, Acc_1: 0.8714, Acc_2: 0.7852, F1-score_1: 0.8286, F1-score_2: 0.7270
2023-03-07 09:01:11 - __main__ - INFO - Epoch [8/100]
2023-03-07 09:01:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0018, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 09:01:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 09:01:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0022, Acc_1: 0.8594, Acc_2: 0.7578, 
2023-03-07 09:01:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0023, Acc_1: 0.8594, Acc_2: 0.7812, 
2023-03-07 09:01:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0017, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-07 09:01:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0019, Acc_1: 0.8516, Acc_2: 0.7656, 
2023-03-07 09:01:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0025, Acc_1: 0.9531, Acc_2: 0.8281, 
2023-03-07 09:02:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0026, Acc_1: 0.8750, Acc_2: 0.7500, 
2023-03-07 09:02:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 09:02:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 09:02:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0011, Acc_1: 0.8984, Acc_2: 0.8281, 
2023-03-07 09:02:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-07 09:02:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0023, Loss_2: 0.0035, Acc_1: 0.8580, Acc_2: 0.7863, F1-score_1: 0.8113, F1-score_2: 0.7209
2023-03-07 09:02:49 - __main__ - INFO - Epoch [9/100]
2023-03-07 09:02:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8516, Acc_2: 0.7891, 
2023-03-07 09:03:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 09:03:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0012, Acc_1: 0.8438, Acc_2: 0.7969, 
2023-03-07 09:03:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0017, Acc_1: 0.8750, Acc_2: 0.7812, 
2023-03-07 09:03:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0012, Acc_1: 0.8906, Acc_2: 0.8281, 
2023-03-07 09:03:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0031, Acc_1: 0.8906, Acc_2: 0.7891, 
2023-03-07 09:03:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0050, Acc_1: 0.8359, Acc_2: 0.7031, 
2023-03-07 09:03:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0020, Acc_1: 0.9219, Acc_2: 0.8203, 
2023-03-07 09:03:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8750, Acc_2: 0.8047, 
2023-03-07 09:03:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0027, Acc_1: 0.8750, Acc_2: 0.7891, 
2023-03-07 09:04:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9453, Acc_2: 0.8828, 
2023-03-07 09:04:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0013, Loss_2: 0.0016, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 09:04:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0042, Acc_1: 0.8597, Acc_2: 0.7612, F1-score_1: 0.8144, F1-score_2: 0.6993
2023-03-07 09:04:26 - __main__ - INFO - Epoch [10/100]
2023-03-07 09:04:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0022, Acc_1: 0.8359, Acc_2: 0.7578, 
2023-03-07 09:04:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.8281, Acc_2: 0.7812, 
2023-03-07 09:04:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0016, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 09:04:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 09:04:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-07 09:05:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 09:05:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.9219, Acc_2: 0.8516, 
2023-03-07 09:05:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 09:05:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 09:05:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-07 09:05:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 09:05:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.9453, Acc_2: 0.8516, 
2023-03-07 09:06:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0051, Acc_1: 0.8709, Acc_2: 0.7649, F1-score_1: 0.8343, F1-score_2: 0.7083
2023-03-07 09:06:03 - __main__ - INFO - Epoch [11/100]
2023-03-07 09:06:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 09:06:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 09:06:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 09:06:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 09:06:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 09:06:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 09:06:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 09:06:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 09:07:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 09:07:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 09:07:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 09:07:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-07 09:07:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0048, Acc_1: 0.8721, Acc_2: 0.7733, F1-score_1: 0.8347, F1-score_2: 0.7156
2023-03-07 09:07:40 - __main__ - INFO - Epoch [12/100]
2023-03-07 09:07:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 09:07:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-07 09:08:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 09:08:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-07 09:08:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 09:08:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-07 09:08:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 09:08:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8047, 
2023-03-07 09:08:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 09:08:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 09:08:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.7969, 
2023-03-07 09:09:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8125, 
2023-03-07 09:09:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0060, Acc_1: 0.8743, Acc_2: 0.7425, F1-score_1: 0.8353, F1-score_2: 0.6931
2023-03-07 09:09:18 - __main__ - INFO - Epoch [13/100]
2023-03-07 09:09:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 09:09:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-07 09:09:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.7969, 
2023-03-07 09:09:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 09:09:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 09:09:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9609, Acc_2: 0.9453, 
2023-03-07 09:10:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 09:10:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 09:10:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-07 09:10:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 09:10:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-07 09:10:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 09:10:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0049, Acc_1: 0.8701, Acc_2: 0.7877, F1-score_1: 0.8338, F1-score_2: 0.7241
2023-03-07 09:10:55 - __main__ - INFO - Epoch [14/100]
2023-03-07 09:11:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 09:11:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 09:11:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 09:11:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 09:11:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 09:11:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-07 09:11:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 09:11:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 09:11:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 09:12:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 09:12:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-07 09:12:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 09:12:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0047, Acc_1: 0.8689, Acc_2: 0.7733, F1-score_1: 0.8307, F1-score_2: 0.7132
2023-03-07 09:12:32 - __main__ - INFO - Epoch [15/100]
2023-03-07 09:12:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 09:12:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 09:12:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 09:12:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 09:13:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-07 09:13:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-07 09:13:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-07 09:13:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-07 09:13:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 09:13:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-07 09:13:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9141, 
2023-03-07 09:13:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 09:14:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0032, Acc_1: 0.8680, Acc_2: 0.7823, F1-score_1: 0.8291, F1-score_2: 0.7236
2023-03-07 09:14:09 - __main__ - INFO - Epoch [16/100]
2023-03-07 09:14:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 09:14:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 09:14:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 09:14:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 09:14:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 09:14:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 09:14:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 09:15:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 09:15:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8203, 
2023-03-07 09:15:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 09:15:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 09:15:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 09:15:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0047, Acc_1: 0.8699, Acc_2: 0.7792, F1-score_1: 0.8309, F1-score_2: 0.7172
2023-03-07 09:15:47 - __main__ - INFO - Epoch [17/100]
2023-03-07 09:15:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 09:15:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 09:16:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 09:16:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 09:16:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 09:16:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 09:16:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 09:16:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 09:16:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-07 09:16:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 09:17:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 09:17:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 09:17:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0031, Acc_1: 0.8711, Acc_2: 0.7950, F1-score_1: 0.8310, F1-score_2: 0.7330
2023-03-07 09:17:24 - __main__ - INFO - Epoch [18/100]
2023-03-07 09:17:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 09:17:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 09:17:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 09:17:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 09:17:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 09:18:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 09:18:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 09:18:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 09:18:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 09:18:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9531, Acc_2: 0.9141, 
2023-03-07 09:18:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 09:18:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0022, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-07 09:19:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0031, Acc_1: 0.8704, Acc_2: 0.7903, F1-score_1: 0.8279, F1-score_2: 0.7218
2023-03-07 09:19:01 - __main__ - INFO - Epoch [19/100]
2023-03-07 09:19:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-07 09:19:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 09:19:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 09:19:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.7969, 
2023-03-07 09:19:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 09:19:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 09:19:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 09:19:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 09:20:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 09:20:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-07 09:20:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 09:20:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 09:20:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0037, Acc_1: 0.8685, Acc_2: 0.7914, F1-score_1: 0.8272, F1-score_2: 0.7215
2023-03-07 09:20:38 - __main__ - INFO - Epoch [20/100]
2023-03-07 09:20:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 09:20:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 09:20:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 09:21:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 09:21:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-07 09:21:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 09:21:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 09:21:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 09:21:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 09:21:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 09:21:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 09:21:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 09:22:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0037, Acc_1: 0.8696, Acc_2: 0.7882, F1-score_1: 0.8217, F1-score_2: 0.7208
2023-03-07 09:22:16 - __main__ - INFO - Epoch [21/100]
2023-03-07 09:22:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 09:22:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-07 09:22:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 09:22:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 09:22:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 09:22:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 09:23:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 09:23:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 09:23:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8281, 
2023-03-07 09:23:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 09:23:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 09:23:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 09:23:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0041, Acc_1: 0.8645, Acc_2: 0.7857, F1-score_1: 0.8262, F1-score_2: 0.7235
2023-03-07 09:23:53 - __main__ - INFO - Epoch [22/100]
2023-03-07 09:23:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-07 09:24:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 09:24:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 09:24:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 09:24:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 09:24:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 09:24:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 09:24:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 09:24:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 09:25:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 09:25:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 09:25:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 09:25:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0036, Loss_2: 0.0044, Acc_1: 0.8663, Acc_2: 0.7687, F1-score_1: 0.8246, F1-score_2: 0.7096
2023-03-07 09:25:30 - __main__ - INFO - Epoch [23/100]
2023-03-07 09:25:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-07 09:25:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 09:25:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 09:25:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-07 09:26:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 09:26:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 09:26:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 09:26:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-07 09:26:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-07 09:26:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0011, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 09:26:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 09:26:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 09:27:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0059, Acc_1: 0.8658, Acc_2: 0.7908, F1-score_1: 0.8255, F1-score_2: 0.7262
2023-03-07 09:27:08 - __main__ - INFO - Epoch [24/100]
2023-03-07 09:27:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 09:27:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 09:27:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 09:27:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 09:27:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 09:27:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 09:27:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0011, Loss_2: 0.0026, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-07 09:28:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 09:28:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 09:28:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 09:28:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 09:28:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 09:28:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0065, Acc_1: 0.8633, Acc_2: 0.7896, F1-score_1: 0.8255, F1-score_2: 0.7209
2023-03-07 09:28:45 - __main__ - INFO - Epoch [25/100]
2023-03-07 09:28:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 09:28:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 09:29:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 09:29:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 09:29:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 09:29:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 09:29:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 09:29:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 09:29:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 09:29:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.7812, 
2023-03-07 09:29:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 09:30:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 09:30:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0048, Acc_1: 0.8607, Acc_2: 0.7728, F1-score_1: 0.8240, F1-score_2: 0.7165
2023-03-07 09:30:22 - __main__ - INFO - Epoch [26/100]
2023-03-07 09:30:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9688, Acc_2: 0.9688, 
2023-03-07 09:30:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 09:30:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 09:30:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 09:30:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 09:31:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 09:31:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 09:31:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 09:31:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:31:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-07 09:31:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 09:31:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 09:32:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0043, Acc_1: 0.8675, Acc_2: 0.7772, F1-score_1: 0.8309, F1-score_2: 0.7161
2023-03-07 09:32:00 - __main__ - INFO - Epoch [27/100]
2023-03-07 09:32:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 09:32:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 09:32:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 09:32:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 09:32:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 09:32:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 09:32:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 09:32:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0028, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 09:33:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 09:33:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 09:33:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 09:33:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 09:33:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0037, Acc_1: 0.8629, Acc_2: 0.7911, F1-score_1: 0.8251, F1-score_2: 0.7326
2023-03-07 09:33:37 - __main__ - INFO - Epoch [28/100]
2023-03-07 09:33:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 09:33:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 09:33:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 09:34:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0010, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 09:34:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 09:34:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 09:34:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 09:34:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0014, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 09:34:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 09:34:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8438, 
2023-03-07 09:34:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 09:34:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:35:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0042, Acc_1: 0.8541, Acc_2: 0.7901, F1-score_1: 0.8164, F1-score_2: 0.7263
2023-03-07 09:35:14 - __main__ - INFO - Epoch [29/100]
2023-03-07 09:35:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 09:35:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-07 09:35:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-07 09:35:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 09:35:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 09:35:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 09:36:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0013, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8828, 
2023-03-07 09:36:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 09:36:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9453, 
2023-03-07 09:36:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 09:36:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-07 09:36:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-07 09:36:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0055, Acc_1: 0.8492, Acc_2: 0.7835, F1-score_1: 0.8097, F1-score_2: 0.7234
2023-03-07 09:36:52 - __main__ - INFO - Epoch [30/100]
2023-03-07 09:36:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 09:37:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 09:37:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 09:37:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 09:37:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 09:37:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:37:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8750, 
2023-03-07 09:37:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 09:37:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-07 09:37:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 09:38:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 09:38:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 09:38:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0037, Loss_2: 0.0051, Acc_1: 0.8504, Acc_2: 0.7858, F1-score_1: 0.8084, F1-score_2: 0.7268
2023-03-07 09:38:29 - __main__ - INFO - Epoch [31/100]
2023-03-07 09:38:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0013, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-07 09:38:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 09:38:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 09:38:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 09:39:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 09:39:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 09:39:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 09:39:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 09:39:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 09:39:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 09:39:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8672, 
2023-03-07 09:39:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 09:40:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0053, Acc_1: 0.8412, Acc_2: 0.7877, F1-score_1: 0.7907, F1-score_2: 0.7302
2023-03-07 09:40:06 - __main__ - INFO - Epoch [32/100]
2023-03-07 09:40:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 09:40:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-07 09:40:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 09:40:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 09:40:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 09:40:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 09:40:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 09:41:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:41:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 09:41:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 09:41:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 09:41:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 09:41:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0049, Acc_1: 0.8509, Acc_2: 0.7826, F1-score_1: 0.8175, F1-score_2: 0.7209
2023-03-07 09:41:43 - __main__ - INFO - Epoch [33/100]
2023-03-07 09:41:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 09:41:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 09:42:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 09:42:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 09:42:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 09:42:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 09:42:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 09:42:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 09:42:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 09:42:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 09:42:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 09:43:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 09:43:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0042, Loss_2: 0.0050, Acc_1: 0.8443, Acc_2: 0.7943, F1-score_1: 0.8076, F1-score_2: 0.7305
2023-03-07 09:43:21 - __main__ - INFO - Epoch [34/100]
2023-03-07 09:43:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 09:43:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 09:43:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 09:43:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 09:43:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 09:44:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 09:44:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 09:44:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 09:44:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 09:44:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-07 09:44:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 09:44:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 09:44:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0047, Acc_1: 0.8329, Acc_2: 0.7789, F1-score_1: 0.7892, F1-score_2: 0.7129
2023-03-07 09:44:58 - __main__ - INFO - Epoch [35/100]
2023-03-07 09:45:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 09:45:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 09:45:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 09:45:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 09:45:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 09:45:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0012, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 09:45:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 09:45:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 09:45:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 09:46:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8438, 
2023-03-07 09:46:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:46:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 09:46:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0038, Loss_2: 0.0044, Acc_1: 0.8473, Acc_2: 0.8040, F1-score_1: 0.8094, F1-score_2: 0.7405
2023-03-07 09:46:35 - __main__ - INFO - Epoch [36/100]
2023-03-07 09:46:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 09:46:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 09:46:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:47:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 09:47:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 09:47:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 09:47:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 09:47:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 09:47:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 09:47:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 09:47:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 09:47:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 09:48:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0051, Acc_1: 0.8519, Acc_2: 0.7889, F1-score_1: 0.8124, F1-score_2: 0.7312
2023-03-07 09:48:13 - __main__ - INFO - Epoch [37/100]
2023-03-07 09:48:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 09:48:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-07 09:48:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-07 09:48:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 09:48:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 09:48:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 09:48:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:49:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 09:49:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 09:49:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:49:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 09:49:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 09:49:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0041, Loss_2: 0.0042, Acc_1: 0.8509, Acc_2: 0.7923, F1-score_1: 0.8064, F1-score_2: 0.7325
2023-03-07 09:49:50 - __main__ - INFO - Epoch [38/100]
2023-03-07 09:49:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:50:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 09:50:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 09:50:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-07 09:50:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 09:50:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 09:50:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 09:50:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 09:50:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 09:50:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 09:51:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 09:51:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 09:51:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0038, Loss_2: 0.0062, Acc_1: 0.8514, Acc_2: 0.7446, F1-score_1: 0.8123, F1-score_2: 0.6920
2023-03-07 09:51:27 - __main__ - INFO - Epoch [39/100]
2023-03-07 09:51:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 09:51:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:51:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 09:51:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 09:52:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:52:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 09:52:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 09:52:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 09:52:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 09:52:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0017, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-07 09:52:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 09:52:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:53:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0048, Loss_2: 0.0069, Acc_1: 0.8397, Acc_2: 0.7750, F1-score_1: 0.8017, F1-score_2: 0.7203
2023-03-07 09:53:04 - __main__ - INFO - Epoch [40/100]
2023-03-07 09:53:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 09:53:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 09:53:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 09:53:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 09:53:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 09:53:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 09:53:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 09:53:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:54:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 09:54:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 09:54:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 09:54:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 09:54:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0053, Acc_1: 0.8504, Acc_2: 0.7877, F1-score_1: 0.8089, F1-score_2: 0.7268
2023-03-07 09:54:42 - __main__ - INFO - Epoch [41/100]
2023-03-07 09:54:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 09:54:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 09:55:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 09:55:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 09:55:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 09:55:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:55:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 09:55:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 09:55:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 09:55:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 09:55:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 09:56:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 09:56:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0050, Loss_2: 0.0047, Acc_1: 0.8507, Acc_2: 0.7896, F1-score_1: 0.8081, F1-score_2: 0.7276
2023-03-07 09:56:19 - __main__ - INFO - Epoch [42/100]
2023-03-07 09:56:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 09:56:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:56:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 09:56:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 09:56:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 09:56:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 09:57:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 09:57:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 09:57:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 09:57:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 09:57:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 09:57:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 09:57:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0061, Loss_2: 0.0047, Acc_1: 0.8517, Acc_2: 0.7933, F1-score_1: 0.8138, F1-score_2: 0.7301
2023-03-07 09:57:56 - __main__ - INFO - Epoch [43/100]
2023-03-07 09:58:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 09:58:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 09:58:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 09:58:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 09:58:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 09:58:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 09:58:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 09:58:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 09:58:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 09:59:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 09:59:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 09:59:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 09:59:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0049, Acc_1: 0.8511, Acc_2: 0.7882, F1-score_1: 0.8073, F1-score_2: 0.7277
2023-03-07 09:59:33 - __main__ - INFO - Epoch [44/100]
2023-03-07 09:59:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 09:59:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 09:59:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:00:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:00:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 10:00:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 10:00:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 10:00:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 10:00:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 10:00:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 10:00:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 10:00:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:01:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0047, Loss_2: 0.0049, Acc_1: 0.8529, Acc_2: 0.7889, F1-score_1: 0.8145, F1-score_2: 0.7285
2023-03-07 10:01:11 - __main__ - INFO - Epoch [45/100]
2023-03-07 10:01:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 10:01:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 10:01:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:01:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:01:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 10:01:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 10:01:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:02:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:02:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 10:02:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 10:02:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 10:02:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 10:02:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0059, Loss_2: 0.0037, Acc_1: 0.8526, Acc_2: 0.7965, F1-score_1: 0.8129, F1-score_2: 0.7349
2023-03-07 10:02:48 - __main__ - INFO - Epoch [46/100]
2023-03-07 10:02:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:03:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:03:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:03:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:03:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 10:03:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 10:03:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 10:03:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:03:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 10:03:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 10:04:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:04:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:04:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0056, Loss_2: 0.0042, Acc_1: 0.8536, Acc_2: 0.7965, F1-score_1: 0.8148, F1-score_2: 0.7346
2023-03-07 10:04:25 - __main__ - INFO - Epoch [47/100]
2023-03-07 10:04:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 10:04:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 10:04:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 10:04:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 10:04:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 10:05:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 10:05:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 10:05:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 10:05:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 10:05:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:05:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 10:05:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 10:06:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0072, Loss_2: 0.0045, Acc_1: 0.8443, Acc_2: 0.7952, F1-score_1: 0.8060, F1-score_2: 0.7343
2023-03-07 10:06:03 - __main__ - INFO - Epoch [48/100]
2023-03-07 10:06:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 10:06:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 10:06:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:06:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:06:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-07 10:06:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:06:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 10:06:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9453, 
2023-03-07 10:07:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:07:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:07:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 10:07:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 10:07:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0054, Loss_2: 0.0047, Acc_1: 0.8490, Acc_2: 0.7845, F1-score_1: 0.8110, F1-score_2: 0.7252
2023-03-07 10:07:40 - __main__ - INFO - Epoch [49/100]
2023-03-07 10:07:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 10:07:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:07:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 10:08:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-07 10:08:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 10:08:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:08:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 10:08:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 10:08:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 10:08:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 10:08:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 10:09:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 10:09:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0050, Loss_2: 0.0054, Acc_1: 0.8415, Acc_2: 0.7889, F1-score_1: 0.7981, F1-score_2: 0.7236
2023-03-07 10:09:17 - __main__ - INFO - Epoch [50/100]
2023-03-07 10:09:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 10:09:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 10:09:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-07 10:09:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 10:09:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 10:09:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 10:10:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 10:10:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:10:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:10:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 10:10:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:10:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 10:10:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0087, Loss_2: 0.0056, Acc_1: 0.8380, Acc_2: 0.7784, F1-score_1: 0.7951, F1-score_2: 0.7106
2023-03-07 10:10:55 - __main__ - INFO - Epoch [51/100]
2023-03-07 10:11:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 10:11:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 10:11:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 10:11:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 10:11:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 10:11:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-07 10:11:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 10:11:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 10:11:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 10:12:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:12:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 10:12:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-07 10:12:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0071, Loss_2: 0.0057, Acc_1: 0.8378, Acc_2: 0.7736, F1-score_1: 0.7957, F1-score_2: 0.7114
2023-03-07 10:12:32 - __main__ - INFO - Epoch [52/100]
2023-03-07 10:12:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:12:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 10:12:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-07 10:12:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 10:13:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 10:13:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 10:13:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-07 10:13:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:13:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 10:13:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:13:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-07 10:13:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0014, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-07 10:14:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0068, Loss_2: 0.0048, Acc_1: 0.8465, Acc_2: 0.7753, F1-score_1: 0.8067, F1-score_2: 0.7136
2023-03-07 10:14:09 - __main__ - INFO - Epoch [53/100]
2023-03-07 10:14:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 10:14:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:14:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 10:14:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 10:14:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 10:14:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 10:14:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 10:15:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 10:15:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 10:15:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 10:15:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 10:15:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:15:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0065, Loss_2: 0.0045, Acc_1: 0.8359, Acc_2: 0.7748, F1-score_1: 0.7939, F1-score_2: 0.7126
2023-03-07 10:15:47 - __main__ - INFO - Epoch [54/100]
2023-03-07 10:15:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 10:15:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 10:16:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 10:16:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 10:16:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:16:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:16:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 10:16:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:16:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0019, Loss_2: 0.0009, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-07 10:16:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 10:17:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:17:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 10:17:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0055, Loss_2: 0.0060, Acc_1: 0.8485, Acc_2: 0.7711, F1-score_1: 0.8090, F1-score_2: 0.7087
2023-03-07 10:17:24 - __main__ - INFO - Epoch [55/100]
2023-03-07 10:17:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:17:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 10:17:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:17:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 10:17:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:18:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:18:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:18:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:18:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9219, 
2023-03-07 10:18:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:18:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 10:18:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 10:19:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0063, Loss_2: 0.0054, Acc_1: 0.8434, Acc_2: 0.7666, F1-score_1: 0.8024, F1-score_2: 0.7053
2023-03-07 10:19:01 - __main__ - INFO - Epoch [56/100]
2023-03-07 10:19:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 10:19:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 10:19:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 10:19:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 10:19:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:19:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 10:19:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 10:19:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:20:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:20:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 10:20:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 10:20:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 10:20:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0066, Loss_2: 0.0060, Acc_1: 0.8412, Acc_2: 0.7860, F1-score_1: 0.7949, F1-score_2: 0.7231
2023-03-07 10:20:39 - __main__ - INFO - Epoch [57/100]
2023-03-07 10:20:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:20:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:20:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 10:21:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 10:21:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:21:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 10:21:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:21:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 10:21:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 10:21:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:21:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:21:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-07 10:22:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0059, Loss_2: 0.0052, Acc_1: 0.8436, Acc_2: 0.7846, F1-score_1: 0.8011, F1-score_2: 0.7212
2023-03-07 10:22:16 - __main__ - INFO - Epoch [58/100]
2023-03-07 10:22:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:22:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:22:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 10:22:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:22:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 10:22:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 10:23:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 10:23:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 10:23:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 10:23:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:23:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 10:23:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 10:23:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0063, Loss_2: 0.0059, Acc_1: 0.8454, Acc_2: 0.7877, F1-score_1: 0.8023, F1-score_2: 0.7245
2023-03-07 10:23:53 - __main__ - INFO - Epoch [59/100]
2023-03-07 10:23:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 10:24:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 10:24:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 10:24:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 10:24:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:24:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 10:24:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 10:24:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0019, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-07 10:24:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:25:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:25:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 10:25:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 10:25:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0064, Loss_2: 0.0066, Acc_1: 0.8375, Acc_2: 0.7707, F1-score_1: 0.7888, F1-score_2: 0.7094
2023-03-07 10:25:30 - __main__ - INFO - Epoch [60/100]
2023-03-07 10:25:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 10:25:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:25:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:25:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 10:26:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 10:26:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:26:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 10:26:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:26:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 10:26:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 10:26:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 10:26:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 10:27:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0083, Loss_2: 0.0057, Acc_1: 0.8400, Acc_2: 0.7824, F1-score_1: 0.7985, F1-score_2: 0.7151
2023-03-07 10:27:08 - __main__ - INFO - Epoch [61/100]
2023-03-07 10:27:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-07 10:27:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 10:27:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:27:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:27:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 10:27:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 10:27:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:28:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 10:28:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 10:28:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 10:28:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 10:28:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 10:28:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0119, Loss_2: 0.0053, Acc_1: 0.8334, Acc_2: 0.7855, F1-score_1: 0.7947, F1-score_2: 0.7241
2023-03-07 10:28:45 - __main__ - INFO - Epoch [62/100]
2023-03-07 10:28:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 10:28:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:29:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:29:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:29:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:29:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:29:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0011, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-07 10:29:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:29:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 10:29:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 10:29:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:30:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 10:30:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0075, Loss_2: 0.0043, Acc_1: 0.8449, Acc_2: 0.7916, F1-score_1: 0.8060, F1-score_2: 0.7253
2023-03-07 10:30:22 - __main__ - INFO - Epoch [63/100]
2023-03-07 10:30:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 10:30:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0011, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-07 10:30:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 10:30:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:30:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 10:31:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0012, Loss_2: 0.0011, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-07 10:31:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:31:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 10:31:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:31:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:31:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 10:31:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 10:32:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0046, Acc_1: 0.8312, Acc_2: 0.7767, F1-score_1: 0.7875, F1-score_2: 0.7157
2023-03-07 10:32:00 - __main__ - INFO - Epoch [64/100]
2023-03-07 10:32:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:32:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 10:32:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:32:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 10:32:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 10:32:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 10:32:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:32:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:33:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 10:33:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 10:33:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 10:33:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 10:33:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0114, Loss_2: 0.0042, Acc_1: 0.8417, Acc_2: 0.7812, F1-score_1: 0.8006, F1-score_2: 0.7158
2023-03-07 10:33:37 - __main__ - INFO - Epoch [65/100]
2023-03-07 10:33:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:33:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 10:33:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:34:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:34:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 10:34:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 10:34:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 10:34:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:34:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 10:34:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 10:34:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:34:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 10:35:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0035, Acc_1: 0.8473, Acc_2: 0.7887, F1-score_1: 0.8045, F1-score_2: 0.7260
2023-03-07 10:35:14 - __main__ - INFO - Epoch [66/100]
2023-03-07 10:35:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 10:35:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:35:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:35:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 10:35:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:35:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 10:36:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:36:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 10:36:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 10:36:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 10:36:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:36:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 10:36:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0122, Loss_2: 0.0041, Acc_1: 0.8237, Acc_2: 0.7904, F1-score_1: 0.7743, F1-score_2: 0.7299
2023-03-07 10:36:51 - __main__ - INFO - Epoch [67/100]
2023-03-07 10:36:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 10:37:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:37:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:37:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:37:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 10:37:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 10:37:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:37:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 10:37:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:37:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0010, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-07 10:38:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:38:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:38:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0124, Loss_2: 0.0046, Acc_1: 0.8325, Acc_2: 0.7852, F1-score_1: 0.7947, F1-score_2: 0.7233
2023-03-07 10:38:29 - __main__ - INFO - Epoch [68/100]
2023-03-07 10:38:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 10:38:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 10:38:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 10:38:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:39:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:39:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 10:39:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 10:39:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 10:39:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 10:39:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:39:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:39:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:40:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0111, Loss_2: 0.0046, Acc_1: 0.8393, Acc_2: 0.7897, F1-score_1: 0.7998, F1-score_2: 0.7279
2023-03-07 10:40:06 - __main__ - INFO - Epoch [69/100]
2023-03-07 10:40:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:40:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 10:40:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 10:40:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 10:40:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:40:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 10:40:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 10:41:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 10:41:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0011, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:41:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:41:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 10:41:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:41:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0144, Loss_2: 0.0049, Acc_1: 0.8246, Acc_2: 0.7801, F1-score_1: 0.7894, F1-score_2: 0.7180
2023-03-07 10:41:43 - __main__ - INFO - Epoch [70/100]
2023-03-07 10:41:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:41:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 10:42:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 10:42:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 10:42:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:42:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8594, 
2023-03-07 10:42:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 10:42:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 10:42:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 10:42:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 10:42:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:43:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 10:43:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0114, Loss_2: 0.0052, Acc_1: 0.8376, Acc_2: 0.7891, F1-score_1: 0.7935, F1-score_2: 0.7256
2023-03-07 10:43:21 - __main__ - INFO - Epoch [71/100]
2023-03-07 10:43:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:43:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 10:43:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 10:43:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 10:43:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 10:44:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 10:44:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 10:44:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 10:44:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:44:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 10:44:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 10:44:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 10:44:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0062, Acc_1: 0.8274, Acc_2: 0.7745, F1-score_1: 0.7798, F1-score_2: 0.7150
2023-03-07 10:44:58 - __main__ - INFO - Epoch [72/100]
2023-03-07 10:45:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 10:45:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 10:45:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 10:45:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 10:45:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 10:45:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 10:45:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:45:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:45:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 10:46:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 10:46:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:46:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 10:46:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0100, Loss_2: 0.0049, Acc_1: 0.8404, Acc_2: 0.7860, F1-score_1: 0.7931, F1-score_2: 0.7219
2023-03-07 10:46:35 - __main__ - INFO - Epoch [73/100]
2023-03-07 10:46:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 10:46:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 10:46:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:47:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:47:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-07 10:47:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:47:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:47:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:47:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:47:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 10:47:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 10:47:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 10:48:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0103, Loss_2: 0.0047, Acc_1: 0.8446, Acc_2: 0.7953, F1-score_1: 0.8040, F1-score_2: 0.7295
2023-03-07 10:48:13 - __main__ - INFO - Epoch [74/100]
2023-03-07 10:48:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:48:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 10:48:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 10:48:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:48:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:48:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:49:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-07 10:49:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:49:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 10:49:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:49:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:49:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 10:49:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0114, Loss_2: 0.0047, Acc_1: 0.8281, Acc_2: 0.7845, F1-score_1: 0.7833, F1-score_2: 0.7211
2023-03-07 10:49:50 - __main__ - INFO - Epoch [75/100]
2023-03-07 10:49:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 10:50:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:50:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:50:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 10:50:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:50:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 10:50:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:50:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 10:50:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:50:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 10:51:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-07 10:51:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 10:51:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0054, Acc_1: 0.8470, Acc_2: 0.7716, F1-score_1: 0.8035, F1-score_2: 0.7140
2023-03-07 10:51:28 - __main__ - INFO - Epoch [76/100]
2023-03-07 10:51:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 10:51:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:51:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 10:51:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 10:52:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 10:52:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-07 10:52:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 10:52:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 10:52:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 10:52:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:52:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:52:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 10:53:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0148, Loss_2: 0.0049, Acc_1: 0.8363, Acc_2: 0.7891, F1-score_1: 0.7974, F1-score_2: 0.7286
2023-03-07 10:53:05 - __main__ - INFO - Epoch [77/100]
2023-03-07 10:53:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 10:53:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 10:53:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 10:53:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 10:53:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:53:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:53:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 10:53:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:54:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 10:54:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 10:54:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:54:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 10:54:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0133, Loss_2: 0.0050, Acc_1: 0.8363, Acc_2: 0.7925, F1-score_1: 0.7901, F1-score_2: 0.7342
2023-03-07 10:54:42 - __main__ - INFO - Epoch [78/100]
2023-03-07 10:54:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-07 10:54:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 10:55:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 10:55:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:55:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 10:55:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 10:55:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 10:55:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:55:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 10:55:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:55:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 10:56:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 10:56:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0145, Loss_2: 0.0043, Acc_1: 0.8344, Acc_2: 0.7933, F1-score_1: 0.7861, F1-score_2: 0.7324
2023-03-07 10:56:20 - __main__ - INFO - Epoch [79/100]
2023-03-07 10:56:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 10:56:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 10:56:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:56:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 10:56:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 10:57:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 10:57:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 10:57:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:57:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 10:57:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 10:57:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 10:57:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 10:57:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0156, Loss_2: 0.0043, Acc_1: 0.8314, Acc_2: 0.7892, F1-score_1: 0.7910, F1-score_2: 0.7291
2023-03-07 10:57:57 - __main__ - INFO - Epoch [80/100]
2023-03-07 10:58:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 10:58:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 10:58:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 10:58:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 10:58:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 10:58:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-07 10:58:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 10:58:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 10:58:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 10:59:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 10:59:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 10:59:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 10:59:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0132, Loss_2: 0.0049, Acc_1: 0.8385, Acc_2: 0.7904, F1-score_1: 0.7956, F1-score_2: 0.7287
2023-03-07 10:59:34 - __main__ - INFO - Epoch [81/100]
2023-03-07 10:59:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 10:59:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 10:59:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 11:00:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 11:00:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 11:00:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 11:00:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 11:00:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 11:00:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 11:00:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-07 11:00:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 11:00:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 11:01:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0123, Loss_2: 0.0044, Acc_1: 0.8446, Acc_2: 0.7935, F1-score_1: 0.8063, F1-score_2: 0.7308
2023-03-07 11:01:11 - __main__ - INFO - Epoch [82/100]
2023-03-07 11:01:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 11:01:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:01:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 11:01:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 11:01:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 11:01:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 11:01:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 11:02:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 11:02:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 11:02:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 11:02:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:02:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 11:02:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0131, Loss_2: 0.0043, Acc_1: 0.8485, Acc_2: 0.7938, F1-score_1: 0.8111, F1-score_2: 0.7313
2023-03-07 11:02:49 - __main__ - INFO - Epoch [83/100]
2023-03-07 11:02:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 11:03:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 11:03:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 11:03:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 11:03:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 11:03:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:03:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 11:03:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 11:03:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 11:03:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 11:04:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 11:04:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 11:04:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0122, Loss_2: 0.0048, Acc_1: 0.8473, Acc_2: 0.7918, F1-score_1: 0.8074, F1-score_2: 0.7311
2023-03-07 11:04:26 - __main__ - INFO - Epoch [84/100]
2023-03-07 11:04:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 11:04:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 11:04:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:04:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 11:04:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 11:05:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:05:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 11:05:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 11:05:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 11:05:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 11:05:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 11:05:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:06:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0121, Loss_2: 0.0048, Acc_1: 0.8487, Acc_2: 0.7933, F1-score_1: 0.8098, F1-score_2: 0.7323
2023-03-07 11:06:03 - __main__ - INFO - Epoch [85/100]
2023-03-07 11:06:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 11:06:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:06:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 11:06:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 11:06:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 11:06:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 11:06:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-07 11:06:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:07:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 11:07:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 11:07:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 11:07:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 11:07:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0112, Loss_2: 0.0051, Acc_1: 0.8438, Acc_2: 0.7880, F1-score_1: 0.8028, F1-score_2: 0.7274
2023-03-07 11:07:41 - __main__ - INFO - Epoch [86/100]
2023-03-07 11:07:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 11:07:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 11:08:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9609, 
2023-03-07 11:08:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 11:08:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 11:08:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 11:08:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 11:08:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 11:08:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 11:08:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 11:08:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0095, Loss_2: 0.0054, Acc_1: 0.7578, Acc_2: 0.7578, 
2023-03-07 11:09:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 11:09:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0131, Loss_2: 0.0071, Acc_1: 0.8351, Acc_2: 0.7658, F1-score_1: 0.7967, F1-score_2: 0.7051
2023-03-07 11:09:18 - __main__ - INFO - Epoch [87/100]
2023-03-07 11:09:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 11:09:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 11:09:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 11:09:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:09:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-07 11:09:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 11:10:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 11:10:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0023, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-07 11:10:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:10:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-07 11:10:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 11:10:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 11:10:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0124, Loss_2: 0.0055, Acc_1: 0.8356, Acc_2: 0.7753, F1-score_1: 0.7859, F1-score_2: 0.7145
2023-03-07 11:10:55 - __main__ - INFO - Epoch [88/100]
2023-03-07 11:11:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 11:11:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 11:11:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 11:11:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 11:11:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 11:11:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 11:11:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 11:11:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 11:11:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 11:12:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 11:12:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 11:12:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 11:12:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0049, Acc_1: 0.8446, Acc_2: 0.7818, F1-score_1: 0.7997, F1-score_2: 0.7206
2023-03-07 11:12:32 - __main__ - INFO - Epoch [89/100]
2023-03-07 11:12:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 11:12:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 11:12:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 11:12:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 11:13:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 11:13:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:13:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:13:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 11:13:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 11:13:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 11:13:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:13:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 11:14:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0113, Loss_2: 0.0045, Acc_1: 0.8444, Acc_2: 0.7806, F1-score_1: 0.8013, F1-score_2: 0.7203
2023-03-07 11:14:10 - __main__ - INFO - Epoch [90/100]
2023-03-07 11:14:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 11:14:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:14:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 11:14:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 11:14:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 11:14:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 11:14:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 11:15:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 11:15:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 11:15:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:15:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 11:15:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-07 11:15:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0044, Acc_1: 0.8252, Acc_2: 0.7772, F1-score_1: 0.7795, F1-score_2: 0.7152
2023-03-07 11:15:47 - __main__ - INFO - Epoch [91/100]
2023-03-07 11:15:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 11:16:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 11:16:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 11:16:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 11:16:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:16:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:16:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:16:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 11:16:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 11:16:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 11:17:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:17:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 11:17:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0135, Loss_2: 0.0052, Acc_1: 0.8347, Acc_2: 0.7731, F1-score_1: 0.7846, F1-score_2: 0.7131
2023-03-07 11:17:25 - __main__ - INFO - Epoch [92/100]
2023-03-07 11:17:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:17:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 11:17:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 11:17:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 11:17:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 11:18:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 11:18:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 11:18:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-07 11:18:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 11:18:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 11:18:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 11:18:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 11:19:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0050, Acc_1: 0.8371, Acc_2: 0.7760, F1-score_1: 0.7899, F1-score_2: 0.7132
2023-03-07 11:19:02 - __main__ - INFO - Epoch [93/100]
2023-03-07 11:19:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 11:19:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 11:19:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 11:19:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-07 11:19:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 11:19:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 11:19:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 11:19:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 11:20:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 11:20:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 11:20:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 11:20:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 11:20:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0115, Loss_2: 0.0053, Acc_1: 0.8376, Acc_2: 0.7733, F1-score_1: 0.7932, F1-score_2: 0.7085
2023-03-07 11:20:39 - __main__ - INFO - Epoch [94/100]
2023-03-07 11:20:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:20:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 11:20:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:21:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 11:21:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 11:21:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 11:21:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:21:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:21:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 11:21:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-07 11:21:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 11:21:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:22:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0113, Loss_2: 0.0050, Acc_1: 0.8421, Acc_2: 0.7787, F1-score_1: 0.7988, F1-score_2: 0.7140
2023-03-07 11:22:16 - __main__ - INFO - Epoch [95/100]
2023-03-07 11:22:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 11:22:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 11:22:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 11:22:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 11:22:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 11:22:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:23:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 11:23:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 11:23:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 11:23:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 11:23:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 11:23:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:23:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0110, Loss_2: 0.0050, Acc_1: 0.8409, Acc_2: 0.7756, F1-score_1: 0.7963, F1-score_2: 0.7120
2023-03-07 11:23:54 - __main__ - INFO - Epoch [96/100]
2023-03-07 11:23:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 11:24:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 11:24:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 11:24:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0060, Loss_2: 0.0019, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-07 11:24:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 11:24:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 11:24:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 11:24:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 11:24:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 11:25:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 11:25:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 11:25:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 11:25:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0116, Loss_2: 0.0052, Acc_1: 0.8414, Acc_2: 0.7741, F1-score_1: 0.7981, F1-score_2: 0.7106
2023-03-07 11:25:31 - __main__ - INFO - Epoch [97/100]
2023-03-07 11:25:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 11:25:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 11:25:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 11:25:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 11:26:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 11:26:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 11:26:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 11:26:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 11:26:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 11:26:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 11:26:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 11:26:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:27:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0116, Loss_2: 0.0051, Acc_1: 0.8415, Acc_2: 0.7772, F1-score_1: 0.7983, F1-score_2: 0.7135
2023-03-07 11:27:08 - __main__ - INFO - Epoch [98/100]
2023-03-07 11:27:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:27:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 11:27:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 11:27:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 11:27:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 11:27:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 11:27:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 11:28:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 11:28:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-07 11:28:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 11:28:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 11:28:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 11:28:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0115, Loss_2: 0.0052, Acc_1: 0.8419, Acc_2: 0.7772, F1-score_1: 0.7993, F1-score_2: 0.7124
2023-03-07 11:28:46 - __main__ - INFO - Epoch [99/100]
2023-03-07 11:28:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 11:28:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 11:29:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 11:29:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 11:29:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 11:29:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 11:29:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 11:29:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 11:29:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 11:29:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 11:30:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 11:30:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 11:30:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0113, Loss_2: 0.0052, Acc_1: 0.8424, Acc_2: 0.7775, F1-score_1: 0.7999, F1-score_2: 0.7134
2023-03-07 11:30:25 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 11:30:25 - utils._noise - DEBUG - 6, 7
2023-03-07 11:30:25 - utils._noise - DEBUG - 13997
2023-03-07 11:30:25 - utils._noise - INFO - Actual noise 0.20
2023-03-07 11:30:25 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-07 11:30:25 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-07 11:30:27 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 11:30:27 - __main__ - INFO - Loading dataset...
2023-03-07 11:30:27 - __main__ - INFO - Building model...
2023-03-07 11:30:27 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-07 11:30:28 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-07 11:30:28 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-07 11:30:28 - __main__ - INFO - Start train & evaluate
2023-03-07 11:30:28 - __main__ - INFO - Epoch [0/100]
2023-03-07 11:30:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0154, Loss_2: 0.0152, Acc_1: 0.1328, Acc_2: 0.1875, 
2023-03-07 11:30:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0131, Loss_2: 0.0145, Acc_1: 0.4453, Acc_2: 0.1953, 
2023-03-07 11:30:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0113, Loss_2: 0.0143, Acc_1: 0.5859, Acc_2: 0.2891, 
2023-03-07 11:30:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0103, Loss_2: 0.0131, Acc_1: 0.6016, Acc_2: 0.3750, 
2023-03-07 11:31:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0097, Loss_2: 0.0134, Acc_1: 0.6406, Acc_2: 0.3203, 
2023-03-07 11:31:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0106, Loss_2: 0.0135, Acc_1: 0.5547, Acc_2: 0.3750, 
2023-03-07 11:31:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0080, Loss_2: 0.0135, Acc_1: 0.7188, Acc_2: 0.3359, 
2023-03-07 11:31:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0097, Loss_2: 0.0137, Acc_1: 0.6719, Acc_2: 0.3750, 
2023-03-07 11:31:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0099, Loss_2: 0.0136, Acc_1: 0.6641, Acc_2: 0.3359, 
2023-03-07 11:31:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0081, Loss_2: 0.0121, Acc_1: 0.7500, Acc_2: 0.3984, 
2023-03-07 11:31:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0100, Loss_2: 0.0126, Acc_1: 0.6484, Acc_2: 0.3906, 
2023-03-07 11:31:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0083, Loss_2: 0.0162, Acc_1: 0.7109, Acc_2: 0.2969, 
2023-03-07 11:32:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0058, Loss_2: 0.0133, Acc_1: 0.8499, Acc_2: 0.4431, F1-score_1: 0.7945, F1-score_2: 0.2401
2023-03-07 11:32:05 - __main__ - INFO - Epoch [1/100]
2023-03-07 11:32:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0082, Loss_2: 0.0147, Acc_1: 0.7344, Acc_2: 0.3438, 
2023-03-07 11:32:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0086, Loss_2: 0.0135, Acc_1: 0.6953, Acc_2: 0.4141, 
2023-03-07 11:32:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0075, Loss_2: 0.0123, Acc_1: 0.7422, Acc_2: 0.4609, 
2023-03-07 11:32:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0075, Loss_2: 0.0127, Acc_1: 0.7422, Acc_2: 0.4219, 
2023-03-07 11:32:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0066, Loss_2: 0.0115, Acc_1: 0.7734, Acc_2: 0.5234, 
2023-03-07 11:32:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0070, Loss_2: 0.0117, Acc_1: 0.7812, Acc_2: 0.4531, 
2023-03-07 11:32:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0071, Loss_2: 0.0134, Acc_1: 0.7578, Acc_2: 0.3906, 
2023-03-07 11:32:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0068, Loss_2: 0.0115, Acc_1: 0.7500, Acc_2: 0.5000, 
2023-03-07 11:33:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0082, Loss_2: 0.0129, Acc_1: 0.6953, Acc_2: 0.4297, 
2023-03-07 11:33:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0068, Loss_2: 0.0105, Acc_1: 0.7422, Acc_2: 0.5625, 
2023-03-07 11:33:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0063, Loss_2: 0.0100, Acc_1: 0.7891, Acc_2: 0.5625, 
2023-03-07 11:33:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0088, Loss_2: 0.0126, Acc_1: 0.6797, Acc_2: 0.4141, 
2023-03-07 11:33:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0054, Loss_2: 0.0103, Acc_1: 0.8704, Acc_2: 0.5591, F1-score_1: 0.8351, F1-score_2: 0.4337
2023-03-07 11:33:42 - __main__ - INFO - Epoch [2/100]
2023-03-07 11:33:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0061, Loss_2: 0.0126, Acc_1: 0.7422, Acc_2: 0.3906, 
2023-03-07 11:33:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0054, Loss_2: 0.0101, Acc_1: 0.7812, Acc_2: 0.5703, 
2023-03-07 11:34:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0047, Loss_2: 0.0098, Acc_1: 0.8281, Acc_2: 0.5625, 
2023-03-07 11:34:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0055, Loss_2: 0.0100, Acc_1: 0.7578, Acc_2: 0.5234, 
2023-03-07 11:34:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0062, Loss_2: 0.0104, Acc_1: 0.7656, Acc_2: 0.5391, 
2023-03-07 11:34:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0075, Loss_2: 0.0116, Acc_1: 0.6484, Acc_2: 0.4531, 
2023-03-07 11:34:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0057, Loss_2: 0.0101, Acc_1: 0.7578, Acc_2: 0.5859, 
2023-03-07 11:34:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0055, Loss_2: 0.0090, Acc_1: 0.7969, Acc_2: 0.6016, 
2023-03-07 11:34:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0077, Loss_2: 0.0112, Acc_1: 0.6953, Acc_2: 0.5234, 
2023-03-07 11:34:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0074, Loss_2: 0.0112, Acc_1: 0.7344, Acc_2: 0.5156, 
2023-03-07 11:34:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0058, Loss_2: 0.0098, Acc_1: 0.7578, Acc_2: 0.5312, 
2023-03-07 11:35:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0044, Loss_2: 0.0084, Acc_1: 0.8281, Acc_2: 0.6719, 
2023-03-07 11:35:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0041, Loss_2: 0.0072, Acc_1: 0.8828, Acc_2: 0.7359, F1-score_1: 0.8428, F1-score_2: 0.6510
2023-03-07 11:35:20 - __main__ - INFO - Epoch [3/100]
2023-03-07 11:35:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0028, Loss_2: 0.0072, Acc_1: 0.8828, Acc_2: 0.6641, 
2023-03-07 11:35:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0038, Loss_2: 0.0128, Acc_1: 0.8516, Acc_2: 0.4062, 
2023-03-07 11:35:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0045, Loss_2: 0.0104, Acc_1: 0.8203, Acc_2: 0.5469, 
2023-03-07 11:35:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0033, Loss_2: 0.0104, Acc_1: 0.8281, Acc_2: 0.5547, 
2023-03-07 11:35:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0038, Loss_2: 0.0092, Acc_1: 0.8203, Acc_2: 0.6016, 
2023-03-07 11:36:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0032, Loss_2: 0.0090, Acc_1: 0.8750, Acc_2: 0.5703, 
2023-03-07 11:36:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0040, Loss_2: 0.0102, Acc_1: 0.8047, Acc_2: 0.5312, 
2023-03-07 11:36:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0050, Loss_2: 0.0103, Acc_1: 0.7578, Acc_2: 0.5625, 
2023-03-07 11:36:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0034, Loss_2: 0.0083, Acc_1: 0.8438, Acc_2: 0.6250, 
2023-03-07 11:36:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0040, Loss_2: 0.0079, Acc_1: 0.8125, Acc_2: 0.6562, 
2023-03-07 11:36:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0032, Loss_2: 0.0076, Acc_1: 0.8750, Acc_2: 0.5938, 
2023-03-07 11:36:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0047, Loss_2: 0.0089, Acc_1: 0.7891, Acc_2: 0.6484, 
2023-03-07 11:36:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0042, Loss_2: 0.0067, Acc_1: 0.8731, Acc_2: 0.7232, F1-score_1: 0.8332, F1-score_2: 0.6361
2023-03-07 11:36:57 - __main__ - INFO - Epoch [4/100]
2023-03-07 11:37:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0021, Loss_2: 0.0078, Acc_1: 0.8750, Acc_2: 0.6406, 
2023-03-07 11:37:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0020, Loss_2: 0.0075, Acc_1: 0.8672, Acc_2: 0.6641, 
2023-03-07 11:37:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0032, Loss_2: 0.0087, Acc_1: 0.7969, Acc_2: 0.6094, 
2023-03-07 11:37:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0028, Loss_2: 0.0087, Acc_1: 0.8594, Acc_2: 0.6016, 
2023-03-07 11:37:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0036, Loss_2: 0.0080, Acc_1: 0.8125, Acc_2: 0.6250, 
2023-03-07 11:37:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0027, Loss_2: 0.0083, Acc_1: 0.8125, Acc_2: 0.6484, 
2023-03-07 11:37:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0016, Loss_2: 0.0052, Acc_1: 0.8906, Acc_2: 0.7656, 
2023-03-07 11:37:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0025, Loss_2: 0.0066, Acc_1: 0.8594, Acc_2: 0.7031, 
2023-03-07 11:37:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0024, Loss_2: 0.0068, Acc_1: 0.8516, Acc_2: 0.6719, 
2023-03-07 11:38:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0024, Loss_2: 0.0056, Acc_1: 0.8594, Acc_2: 0.7109, 
2023-03-07 11:38:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0034, Loss_2: 0.0077, Acc_1: 0.8125, Acc_2: 0.6797, 
2023-03-07 11:38:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0023, Loss_2: 0.0070, Acc_1: 0.8516, Acc_2: 0.6719, 
2023-03-07 11:38:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0036, Loss_2: 0.0061, Acc_1: 0.8497, Acc_2: 0.7437, F1-score_1: 0.8077, F1-score_2: 0.6782
2023-03-07 11:38:34 - __main__ - INFO - Epoch [5/100]
2023-03-07 11:38:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0054, Acc_1: 0.8438, Acc_2: 0.7500, 
2023-03-07 11:38:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0012, Loss_2: 0.0042, Acc_1: 0.8984, Acc_2: 0.8125, 
2023-03-07 11:38:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0044, Acc_1: 0.9531, Acc_2: 0.7656, 
2023-03-07 11:39:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0011, Loss_2: 0.0048, Acc_1: 0.9062, Acc_2: 0.7656, 
2023-03-07 11:39:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0037, Acc_1: 0.9141, Acc_2: 0.7891, 
2023-03-07 11:39:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0015, Loss_2: 0.0047, Acc_1: 0.8984, Acc_2: 0.7578, 
2023-03-07 11:39:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0038, Acc_1: 0.8672, Acc_2: 0.7969, 
2023-03-07 11:39:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0023, Loss_2: 0.0079, Acc_1: 0.8359, Acc_2: 0.6875, 
2023-03-07 11:39:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0043, Acc_1: 0.9297, Acc_2: 0.7734, 
2023-03-07 11:39:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0010, Loss_2: 0.0046, Acc_1: 0.8828, Acc_2: 0.7578, 
2023-03-07 11:39:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0045, Acc_1: 0.9219, Acc_2: 0.7266, 
2023-03-07 11:39:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0024, Loss_2: 0.0064, Acc_1: 0.8516, Acc_2: 0.6797, 
2023-03-07 11:40:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0041, Acc_1: 0.8672, Acc_2: 0.7863, F1-score_1: 0.8235, F1-score_2: 0.7209
2023-03-07 11:40:12 - __main__ - INFO - Epoch [6/100]
2023-03-07 11:40:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0009, Loss_2: 0.0028, Acc_1: 0.8594, Acc_2: 0.8047, 
2023-03-07 11:40:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0041, Acc_1: 0.9297, Acc_2: 0.7812, 
2023-03-07 11:40:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0016, Loss_2: 0.0040, Acc_1: 0.8594, Acc_2: 0.7578, 
2023-03-07 11:40:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0011, Loss_2: 0.0058, Acc_1: 0.9062, Acc_2: 0.7344, 
2023-03-07 11:40:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0011, Loss_2: 0.0035, Acc_1: 0.9297, Acc_2: 0.7734, 
2023-03-07 11:40:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0033, Loss_2: 0.0075, Acc_1: 0.8438, Acc_2: 0.6328, 
2023-03-07 11:40:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0014, Loss_2: 0.0048, Acc_1: 0.8906, Acc_2: 0.7422, 
2023-03-07 11:41:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0039, Acc_1: 0.9219, Acc_2: 0.7500, 
2023-03-07 11:41:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0018, Loss_2: 0.0065, Acc_1: 0.8516, Acc_2: 0.6719, 
2023-03-07 11:41:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0034, Acc_1: 0.9375, Acc_2: 0.8281, 
2023-03-07 11:41:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0010, Loss_2: 0.0043, Acc_1: 0.9062, Acc_2: 0.7500, 
2023-03-07 11:41:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0019, Loss_2: 0.0043, Acc_1: 0.8672, Acc_2: 0.7500, 
2023-03-07 11:41:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0042, Acc_1: 0.8653, Acc_2: 0.7714, F1-score_1: 0.8172, F1-score_2: 0.7063
2023-03-07 11:41:49 - __main__ - INFO - Epoch [7/100]
2023-03-07 11:41:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0020, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-07 11:42:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0025, Acc_1: 0.9141, Acc_2: 0.8281, 
2023-03-07 11:42:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0024, Acc_1: 0.9219, Acc_2: 0.8281, 
2023-03-07 11:42:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0022, Loss_2: 0.0035, Acc_1: 0.8359, Acc_2: 0.7891, 
2023-03-07 11:42:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0035, Acc_1: 0.9297, Acc_2: 0.8203, 
2023-03-07 11:42:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0013, Loss_2: 0.0031, Acc_1: 0.8203, Acc_2: 0.7656, 
2023-03-07 11:42:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0019, Acc_1: 0.8828, Acc_2: 0.8125, 
2023-03-07 11:42:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0020, Acc_1: 0.9062, Acc_2: 0.8125, 
2023-03-07 11:42:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0027, Acc_1: 0.8906, Acc_2: 0.7812, 
2023-03-07 11:42:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0025, Acc_1: 0.8750, Acc_2: 0.7891, 
2023-03-07 11:43:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0037, Acc_1: 0.8672, Acc_2: 0.7344, 
2023-03-07 11:43:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0036, Acc_1: 0.9141, Acc_2: 0.7500, 
2023-03-07 11:43:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0045, Acc_1: 0.8687, Acc_2: 0.7789, F1-score_1: 0.8300, F1-score_2: 0.7147
2023-03-07 11:43:27 - __main__ - INFO - Epoch [8/100]
2023-03-07 11:43:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0022, Acc_1: 0.8750, Acc_2: 0.7891, 
2023-03-07 11:43:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0013, Acc_1: 0.9062, Acc_2: 0.8438, 
2023-03-07 11:43:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 11:43:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-07 11:44:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0012, Acc_1: 0.8828, Acc_2: 0.8203, 
2023-03-07 11:44:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0012, Loss_2: 0.0021, Acc_1: 0.8750, Acc_2: 0.7656, 
2023-03-07 11:44:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0022, Acc_1: 0.9062, Acc_2: 0.7969, 
2023-03-07 11:44:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0017, Acc_1: 0.8906, Acc_2: 0.8047, 
2023-03-07 11:44:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 11:44:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0018, Acc_1: 0.8984, Acc_2: 0.8281, 
2023-03-07 11:44:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.9219, Acc_2: 0.8359, 
2023-03-07 11:44:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0018, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 11:45:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0039, Acc_1: 0.8657, Acc_2: 0.7894, F1-score_1: 0.8265, F1-score_2: 0.7223
2023-03-07 11:45:04 - __main__ - INFO - Epoch [9/100]
2023-03-07 11:45:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8047, 
2023-03-07 11:45:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 11:45:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 11:45:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 11:45:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 11:45:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8047, 
2023-03-07 11:45:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8828, Acc_2: 0.7891, 
2023-03-07 11:45:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 11:46:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.8828, 
2023-03-07 11:46:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8281, 
2023-03-07 11:46:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0017, Acc_1: 0.8906, Acc_2: 0.8203, 
2023-03-07 11:46:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8203, 
2023-03-07 11:46:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0033, Acc_1: 0.8743, Acc_2: 0.7936, F1-score_1: 0.8338, F1-score_2: 0.7271
2023-03-07 11:46:42 - __main__ - INFO - Epoch [10/100]
2023-03-07 11:46:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0014, Loss_2: 0.0026, Acc_1: 0.8359, Acc_2: 0.7578, 
2023-03-07 11:46:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.8828, 
2023-03-07 11:47:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-07 11:47:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.8672, 
2023-03-07 11:47:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-07 11:47:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-07 11:47:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 11:47:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 11:47:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-07 11:47:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 11:47:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 11:48:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8281, 
2023-03-07 11:48:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0054, Acc_1: 0.8725, Acc_2: 0.7537, F1-score_1: 0.8331, F1-score_2: 0.6948
2023-03-07 11:48:19 - __main__ - INFO - Epoch [11/100]
2023-03-07 11:48:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0018, Acc_1: 0.8984, Acc_2: 0.8203, 
2023-03-07 11:48:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 11:48:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.8750, 
2023-03-07 11:48:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 11:48:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-07 11:48:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 11:49:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 11:49:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-07 11:49:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 11:49:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8438, Acc_2: 0.7891, 
2023-03-07 11:49:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0013, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-07 11:49:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.8750, Acc_2: 0.8047, 
2023-03-07 11:49:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0047, Acc_1: 0.8709, Acc_2: 0.7685, F1-score_1: 0.8292, F1-score_2: 0.7016
2023-03-07 11:49:56 - __main__ - INFO - Epoch [12/100]
2023-03-07 11:50:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8438, 
2023-03-07 11:50:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 11:50:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8203, 
2023-03-07 11:50:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 11:50:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-07 11:50:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0011, Acc_1: 0.8828, Acc_2: 0.7891, 
2023-03-07 11:50:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 11:50:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 11:50:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-07 11:51:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 11:51:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-07 11:51:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 11:51:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0040, Acc_1: 0.8736, Acc_2: 0.7889, F1-score_1: 0.8333, F1-score_2: 0.7238
2023-03-07 11:51:34 - __main__ - INFO - Epoch [13/100]
2023-03-07 11:51:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-07 11:51:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 11:51:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 11:52:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 11:52:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 11:52:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 11:52:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 11:52:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 11:52:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 11:52:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-07 11:52:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-07 11:52:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-07 11:53:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0050, Acc_1: 0.8684, Acc_2: 0.7918, F1-score_1: 0.8315, F1-score_2: 0.7283
2023-03-07 11:53:11 - __main__ - INFO - Epoch [14/100]
2023-03-07 11:53:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 11:53:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 11:53:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-07 11:53:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0013, Acc_1: 0.8750, Acc_2: 0.8047, 
2023-03-07 11:53:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 11:53:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 11:53:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 11:54:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 11:54:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 11:54:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 11:54:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 11:54:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 11:54:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0032, Acc_1: 0.8742, Acc_2: 0.7850, F1-score_1: 0.8347, F1-score_2: 0.7147
2023-03-07 11:54:52 - __main__ - INFO - Epoch [15/100]
2023-03-07 11:54:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9062, 
2023-03-07 11:55:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 11:55:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 11:55:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-07 11:55:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-07 11:55:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 11:55:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 11:55:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 11:55:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-07 11:55:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-07 11:56:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 11:56:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-07 11:56:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0046, Acc_1: 0.8750, Acc_2: 0.7935, F1-score_1: 0.8342, F1-score_2: 0.7267
2023-03-07 11:56:29 - __main__ - INFO - Epoch [16/100]
2023-03-07 11:56:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 11:56:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8047, 
2023-03-07 11:56:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 11:56:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 11:57:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-07 11:57:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 11:57:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 11:57:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 11:57:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 11:57:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 11:57:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 11:57:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 11:58:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0038, Acc_1: 0.8753, Acc_2: 0.7862, F1-score_1: 0.8350, F1-score_2: 0.7165
2023-03-07 11:58:06 - __main__ - INFO - Epoch [17/100]
2023-03-07 11:58:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 11:58:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:58:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-07 11:58:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 11:58:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 11:58:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 11:58:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 11:59:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 11:59:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-07 11:59:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-07 11:59:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 11:59:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 11:59:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0056, Acc_1: 0.8736, Acc_2: 0.7892, F1-score_1: 0.8347, F1-score_2: 0.7241
2023-03-07 11:59:44 - __main__ - INFO - Epoch [18/100]
2023-03-07 11:59:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 11:59:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 12:00:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9141, 
2023-03-07 12:00:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-07 12:00:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 12:00:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 12:00:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 12:00:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-07 12:00:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 12:00:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-07 12:00:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-07 12:01:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 12:01:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0060, Acc_1: 0.8635, Acc_2: 0.7763, F1-score_1: 0.8259, F1-score_2: 0.7066
2023-03-07 12:01:21 - __main__ - INFO - Epoch [19/100]
2023-03-07 12:01:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 12:01:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 12:01:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 12:01:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 12:01:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-07 12:02:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 12:02:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 12:02:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 12:02:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 12:02:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 12:02:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-07 12:02:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 12:02:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0067, Acc_1: 0.8725, Acc_2: 0.8023, F1-score_1: 0.8335, F1-score_2: 0.7311
2023-03-07 12:02:59 - __main__ - INFO - Epoch [20/100]
2023-03-07 12:03:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-07 12:03:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 12:03:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 12:03:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 12:03:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:03:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 12:03:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 12:03:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 12:03:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 12:04:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-07 12:04:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 12:04:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 12:04:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0037, Acc_1: 0.8735, Acc_2: 0.7855, F1-score_1: 0.8365, F1-score_2: 0.7229
2023-03-07 12:04:36 - __main__ - INFO - Epoch [21/100]
2023-03-07 12:04:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 12:04:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 12:04:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:05:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 12:05:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8203, 
2023-03-07 12:05:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 12:05:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 12:05:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 12:05:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 12:05:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 12:05:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 12:05:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:06:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0052, Acc_1: 0.8736, Acc_2: 0.7921, F1-score_1: 0.8330, F1-score_2: 0.7263
2023-03-07 12:06:14 - __main__ - INFO - Epoch [22/100]
2023-03-07 12:06:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 12:06:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 12:06:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 12:06:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 12:06:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 12:06:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 12:07:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0023, Acc_1: 0.8281, Acc_2: 0.7734, 
2023-03-07 12:07:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 12:07:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 12:07:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 12:07:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 12:07:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 12:07:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0047, Acc_1: 0.8755, Acc_2: 0.8010, F1-score_1: 0.8358, F1-score_2: 0.7303
2023-03-07 12:07:51 - __main__ - INFO - Epoch [23/100]
2023-03-07 12:07:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 12:08:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 12:08:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 12:08:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 12:08:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 12:08:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8281, 
2023-03-07 12:08:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-07 12:08:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 12:08:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-07 12:08:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 12:09:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-07 12:09:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 12:09:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0047, Acc_1: 0.8714, Acc_2: 0.7921, F1-score_1: 0.8307, F1-score_2: 0.7260
2023-03-07 12:09:28 - __main__ - INFO - Epoch [24/100]
2023-03-07 12:09:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 12:09:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 12:09:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.7812, 
2023-03-07 12:09:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 12:10:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 12:10:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-07 12:10:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 12:10:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 12:10:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 12:10:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 12:10:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 12:10:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 12:11:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0054, Acc_1: 0.8519, Acc_2: 0.7916, F1-score_1: 0.8105, F1-score_2: 0.7251
2023-03-07 12:11:05 - __main__ - INFO - Epoch [25/100]
2023-03-07 12:11:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 12:11:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8047, 
2023-03-07 12:11:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 12:11:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 12:11:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 12:11:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 12:11:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 12:11:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 12:12:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 12:12:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.8281, Acc_2: 0.7891, 
2023-03-07 12:12:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 12:12:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:12:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0036, Acc_1: 0.8522, Acc_2: 0.8030, F1-score_1: 0.8088, F1-score_2: 0.7385
2023-03-07 12:12:43 - __main__ - INFO - Epoch [26/100]
2023-03-07 12:12:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-07 12:12:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 12:13:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 12:13:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:13:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8047, Acc_2: 0.7812, 
2023-03-07 12:13:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 12:13:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 12:13:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:13:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:13:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0017, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 12:13:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:14:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-07 12:14:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0044, Acc_1: 0.8602, Acc_2: 0.7867, F1-score_1: 0.8239, F1-score_2: 0.7218
2023-03-07 12:14:20 - __main__ - INFO - Epoch [27/100]
2023-03-07 12:14:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 12:14:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 12:14:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 12:14:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 12:14:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 12:15:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 12:15:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:15:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 12:15:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 12:15:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 12:15:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 12:15:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 12:15:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0043, Acc_1: 0.8563, Acc_2: 0.7989, F1-score_1: 0.8164, F1-score_2: 0.7324
2023-03-07 12:15:57 - __main__ - INFO - Epoch [28/100]
2023-03-07 12:16:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 12:16:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-07 12:16:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 12:16:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-07 12:16:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 12:16:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 12:16:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 12:16:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 12:16:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:17:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 12:17:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 12:17:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-07 12:17:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0057, Acc_1: 0.8488, Acc_2: 0.7843, F1-score_1: 0.8035, F1-score_2: 0.7187
2023-03-07 12:17:34 - __main__ - INFO - Epoch [29/100]
2023-03-07 12:17:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 12:17:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 12:17:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0012, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 12:18:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 12:18:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 12:18:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-07 12:18:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 12:18:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 12:18:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0012, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-07 12:18:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 12:18:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 12:18:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.9453, Acc_2: 0.9062, 
2023-03-07 12:19:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0041, Loss_2: 0.0053, Acc_1: 0.8424, Acc_2: 0.7638, F1-score_1: 0.7924, F1-score_2: 0.6925
2023-03-07 12:19:12 - __main__ - INFO - Epoch [30/100]
2023-03-07 12:19:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:19:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 12:19:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-07 12:19:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 12:19:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 12:19:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 12:19:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 12:20:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 12:20:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 12:20:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 12:20:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 12:20:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 12:20:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0055, Acc_1: 0.8487, Acc_2: 0.7928, F1-score_1: 0.8002, F1-score_2: 0.7167
2023-03-07 12:20:49 - __main__ - INFO - Epoch [31/100]
2023-03-07 12:20:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-07 12:21:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 12:21:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 12:21:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-07 12:21:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 12:21:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 12:21:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 12:21:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 12:21:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 12:21:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-07 12:22:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 12:22:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 12:22:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0048, Acc_1: 0.8556, Acc_2: 0.7938, F1-score_1: 0.8128, F1-score_2: 0.7259
2023-03-07 12:22:26 - __main__ - INFO - Epoch [32/100]
2023-03-07 12:22:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 12:22:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-07 12:22:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:22:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 12:22:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 12:23:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:23:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 12:23:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 12:23:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 12:23:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-07 12:23:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 12:23:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:24:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0040, Loss_2: 0.0049, Acc_1: 0.8517, Acc_2: 0.7935, F1-score_1: 0.8139, F1-score_2: 0.7239
2023-03-07 12:24:04 - __main__ - INFO - Epoch [33/100]
2023-03-07 12:24:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 12:24:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 12:24:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:24:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 12:24:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 12:24:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 12:24:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-07 12:24:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 12:25:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 12:25:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:25:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:25:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 12:25:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0061, Acc_1: 0.8451, Acc_2: 0.7923, F1-score_1: 0.8028, F1-score_2: 0.7206
2023-03-07 12:25:41 - __main__ - INFO - Epoch [34/100]
2023-03-07 12:25:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 12:25:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 12:26:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 12:26:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 12:26:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 12:26:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 12:26:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 12:26:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 12:26:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 12:26:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-07 12:26:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:27:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 12:27:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0058, Loss_2: 0.0055, Acc_1: 0.8458, Acc_2: 0.7855, F1-score_1: 0.8049, F1-score_2: 0.7197
2023-03-07 12:27:18 - __main__ - INFO - Epoch [35/100]
2023-03-07 12:27:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 12:27:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 12:27:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 12:27:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 12:27:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 12:27:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 12:28:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:28:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 12:28:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 12:28:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0012, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 12:28:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 12:28:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 12:28:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0070, Loss_2: 0.0059, Acc_1: 0.8380, Acc_2: 0.7826, F1-score_1: 0.8035, F1-score_2: 0.7168
2023-03-07 12:28:55 - __main__ - INFO - Epoch [36/100]
2023-03-07 12:29:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 12:29:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:29:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 12:29:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 12:29:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:29:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0043, Loss_2: 0.0021, Acc_1: 0.7578, Acc_2: 0.7734, 
2023-03-07 12:29:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 12:29:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-07 12:29:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 12:30:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 12:30:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:30:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 12:30:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0046, Loss_2: 0.0041, Acc_1: 0.8388, Acc_2: 0.7935, F1-score_1: 0.7888, F1-score_2: 0.7232
2023-03-07 12:30:32 - __main__ - INFO - Epoch [37/100]
2023-03-07 12:30:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 12:30:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 12:30:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 12:30:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:31:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:31:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 12:31:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 12:31:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-07 12:31:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 12:31:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-07 12:31:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:31:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-07 12:32:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0044, Acc_1: 0.8454, Acc_2: 0.7967, F1-score_1: 0.8090, F1-score_2: 0.7326
2023-03-07 12:32:10 - __main__ - INFO - Epoch [38/100]
2023-03-07 12:32:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 12:32:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 12:32:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0017, Loss_2: 0.0025, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-07 12:32:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 12:32:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 12:32:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 12:32:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 12:33:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:33:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 12:33:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:33:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 12:33:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 12:33:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0056, Loss_2: 0.0033, Acc_1: 0.8337, Acc_2: 0.7936, F1-score_1: 0.7889, F1-score_2: 0.7215
2023-03-07 12:33:47 - __main__ - INFO - Epoch [39/100]
2023-03-07 12:33:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 12:33:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 12:34:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 12:34:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 12:34:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0016, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-07 12:34:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 12:34:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 12:34:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9688, Acc_2: 0.9609, 
2023-03-07 12:34:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 12:34:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 12:35:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 12:35:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 12:35:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0053, Loss_2: 0.0050, Acc_1: 0.8387, Acc_2: 0.7996, F1-score_1: 0.7997, F1-score_2: 0.7243
2023-03-07 12:35:24 - __main__ - INFO - Epoch [40/100]
2023-03-07 12:35:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 12:35:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 12:35:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 12:35:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:35:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 12:36:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 12:36:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 12:36:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 12:36:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:36:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:36:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 12:36:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0016, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 12:37:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0056, Loss_2: 0.0045, Acc_1: 0.8398, Acc_2: 0.7753, F1-score_1: 0.8029, F1-score_2: 0.7059
2023-03-07 12:37:02 - __main__ - INFO - Epoch [41/100]
2023-03-07 12:37:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 12:37:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 12:37:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 12:37:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 12:37:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:37:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 12:37:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 12:37:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 12:38:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 12:38:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-07 12:38:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 12:38:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 12:38:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0046, Loss_2: 0.0045, Acc_1: 0.8398, Acc_2: 0.7970, F1-score_1: 0.7934, F1-score_2: 0.7330
2023-03-07 12:38:39 - __main__ - INFO - Epoch [42/100]
2023-03-07 12:38:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:38:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 12:38:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 12:39:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 12:39:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:39:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 12:39:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 12:39:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:39:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 12:39:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 12:39:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 12:39:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 12:40:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0061, Loss_2: 0.0040, Acc_1: 0.8358, Acc_2: 0.7998, F1-score_1: 0.7949, F1-score_2: 0.7368
2023-03-07 12:40:16 - __main__ - INFO - Epoch [43/100]
2023-03-07 12:40:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 12:40:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 12:40:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 12:40:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 12:40:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 12:40:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 12:41:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 12:41:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 12:41:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 12:41:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:41:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 12:41:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 12:41:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0051, Loss_2: 0.0036, Acc_1: 0.8422, Acc_2: 0.8026, F1-score_1: 0.8004, F1-score_2: 0.7335
2023-03-07 12:41:54 - __main__ - INFO - Epoch [44/100]
2023-03-07 12:41:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-07 12:42:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9297, 
2023-03-07 12:42:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 12:42:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 12:42:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8984, 
2023-03-07 12:42:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 12:42:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 12:42:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 12:42:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 12:43:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 12:43:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 12:43:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 12:43:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0049, Loss_2: 0.0048, Acc_1: 0.8499, Acc_2: 0.8015, F1-score_1: 0.8092, F1-score_2: 0.7371
2023-03-07 12:43:31 - __main__ - INFO - Epoch [45/100]
2023-03-07 12:43:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0011, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-07 12:43:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 12:43:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:43:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:44:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 12:44:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 12:44:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 12:44:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 12:44:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 12:44:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:44:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 12:44:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 12:45:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0060, Loss_2: 0.0044, Acc_1: 0.8444, Acc_2: 0.7981, F1-score_1: 0.8063, F1-score_2: 0.7347
2023-03-07 12:45:08 - __main__ - INFO - Epoch [46/100]
2023-03-07 12:45:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 12:45:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 12:45:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:45:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 12:45:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 12:45:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 12:45:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 12:46:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 12:46:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 12:46:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 12:46:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-07 12:46:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 12:46:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0055, Loss_2: 0.0048, Acc_1: 0.8412, Acc_2: 0.7848, F1-score_1: 0.8022, F1-score_2: 0.7153
2023-03-07 12:46:45 - __main__ - INFO - Epoch [47/100]
2023-03-07 12:46:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 12:46:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 12:47:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0011, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-07 12:47:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-07 12:47:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 12:47:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-07 12:47:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 12:47:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 12:47:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0013, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 12:47:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 12:48:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0014, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8359, 
2023-03-07 12:48:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 12:48:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0044, Loss_2: 0.0050, Acc_1: 0.8460, Acc_2: 0.7970, F1-score_1: 0.8124, F1-score_2: 0.7323
2023-03-07 12:48:23 - __main__ - INFO - Epoch [48/100]
2023-03-07 12:48:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9297, 
2023-03-07 12:48:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 12:48:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 12:48:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 12:48:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:49:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 12:49:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 12:49:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 12:49:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 12:49:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 12:49:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 12:49:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8516, 
2023-03-07 12:50:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0071, Loss_2: 0.0059, Acc_1: 0.8376, Acc_2: 0.7787, F1-score_1: 0.7989, F1-score_2: 0.7169
2023-03-07 12:50:00 - __main__ - INFO - Epoch [49/100]
2023-03-07 12:50:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 12:50:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 12:50:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 12:50:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0013, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 12:50:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 12:50:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-07 12:50:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-07 12:50:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-07 12:51:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-07 12:51:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 12:51:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 12:51:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:51:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0046, Acc_1: 0.8358, Acc_2: 0.7716, F1-score_1: 0.7910, F1-score_2: 0.7063
2023-03-07 12:51:37 - __main__ - INFO - Epoch [50/100]
2023-03-07 12:51:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9219, 
2023-03-07 12:51:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 12:51:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-07 12:52:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 12:52:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-07 12:52:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 12:52:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 12:52:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 12:52:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 12:52:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 12:52:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 12:52:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 12:53:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0074, Loss_2: 0.0046, Acc_1: 0.8485, Acc_2: 0.7984, F1-score_1: 0.8065, F1-score_2: 0.7287
2023-03-07 12:53:15 - __main__ - INFO - Epoch [51/100]
2023-03-07 12:53:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 12:53:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 12:53:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 12:53:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-07 12:53:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 12:53:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 12:54:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 12:54:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:54:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 12:54:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 12:54:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 12:54:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 12:54:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0063, Loss_2: 0.0062, Acc_1: 0.8324, Acc_2: 0.7758, F1-score_1: 0.7883, F1-score_2: 0.7126
2023-03-07 12:54:52 - __main__ - INFO - Epoch [52/100]
2023-03-07 12:54:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0014, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 12:55:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 12:55:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-07 12:55:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-07 12:55:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 12:55:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0012, Loss_2: 0.0011, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 12:55:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 12:55:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:55:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 12:55:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 12:56:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 12:56:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 12:56:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0089, Loss_2: 0.0057, Acc_1: 0.8354, Acc_2: 0.7994, F1-score_1: 0.7990, F1-score_2: 0.7248
2023-03-07 12:56:29 - __main__ - INFO - Epoch [53/100]
2023-03-07 12:56:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 12:56:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 12:56:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-07 12:56:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 12:57:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:57:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 12:57:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 12:57:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 12:57:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 12:57:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 12:57:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 12:57:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 12:58:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0080, Loss_2: 0.0051, Acc_1: 0.8434, Acc_2: 0.7994, F1-score_1: 0.8062, F1-score_2: 0.7316
2023-03-07 12:58:07 - __main__ - INFO - Epoch [54/100]
2023-03-07 12:58:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 12:58:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 12:58:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 12:58:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 12:58:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 12:58:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 12:58:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 12:59:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0011, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 12:59:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-07 12:59:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 12:59:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 12:59:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 12:59:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0072, Loss_2: 0.0054, Acc_1: 0.8456, Acc_2: 0.7996, F1-score_1: 0.8033, F1-score_2: 0.7295
2023-03-07 12:59:44 - __main__ - INFO - Epoch [55/100]
2023-03-07 12:59:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 12:59:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:00:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 13:00:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 13:00:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 13:00:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 13:00:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:00:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:00:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 13:00:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:00:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 13:01:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:01:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0092, Loss_2: 0.0059, Acc_1: 0.8349, Acc_2: 0.7869, F1-score_1: 0.7894, F1-score_2: 0.7233
2023-03-07 13:01:21 - __main__ - INFO - Epoch [56/100]
2023-03-07 13:01:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:01:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:01:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 13:01:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:01:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 13:02:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 13:02:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:02:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 13:02:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-07 13:02:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:02:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 13:02:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 13:02:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0070, Loss_2: 0.0058, Acc_1: 0.8404, Acc_2: 0.7906, F1-score_1: 0.7981, F1-score_2: 0.7215
2023-03-07 13:02:59 - __main__ - INFO - Epoch [57/100]
2023-03-07 13:03:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:03:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:03:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:03:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:03:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 13:03:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:03:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:03:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 13:03:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:04:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:04:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:04:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:04:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0074, Loss_2: 0.0059, Acc_1: 0.8443, Acc_2: 0.7926, F1-score_1: 0.8018, F1-score_2: 0.7254
2023-03-07 13:04:36 - __main__ - INFO - Epoch [58/100]
2023-03-07 13:04:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:04:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:04:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 13:05:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 13:05:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 13:05:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:05:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 13:05:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:05:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-07 13:05:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 13:05:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:05:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9688, Acc_2: 0.9688, 
2023-03-07 13:06:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0085, Loss_2: 0.0057, Acc_1: 0.8482, Acc_2: 0.7897, F1-score_1: 0.8056, F1-score_2: 0.7240
2023-03-07 13:06:13 - __main__ - INFO - Epoch [59/100]
2023-03-07 13:06:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:06:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 13:06:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 13:06:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 13:06:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:06:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 13:07:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 13:07:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:07:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:07:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:07:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 13:07:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 13:07:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0095, Loss_2: 0.0046, Acc_1: 0.8346, Acc_2: 0.7977, F1-score_1: 0.7958, F1-score_2: 0.7283
2023-03-07 13:07:50 - __main__ - INFO - Epoch [60/100]
2023-03-07 13:07:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 13:08:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:08:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-07 13:08:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 13:08:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:08:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 13:08:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 13:08:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 13:08:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 13:08:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:09:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 13:09:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 13:09:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0072, Loss_2: 0.0051, Acc_1: 0.8421, Acc_2: 0.7928, F1-score_1: 0.7946, F1-score_2: 0.7189
2023-03-07 13:09:28 - __main__ - INFO - Epoch [61/100]
2023-03-07 13:09:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:09:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 13:09:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:09:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 13:10:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 13:10:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 13:10:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 13:10:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 13:10:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 13:10:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 13:10:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 13:10:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:11:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0080, Loss_2: 0.0056, Acc_1: 0.8473, Acc_2: 0.7979, F1-score_1: 0.8085, F1-score_2: 0.7305
2023-03-07 13:11:05 - __main__ - INFO - Epoch [62/100]
2023-03-07 13:11:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 13:11:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 13:11:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:11:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 13:11:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:11:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:11:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:11:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:12:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 13:12:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 13:12:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:12:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-07 13:12:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0075, Loss_2: 0.0052, Acc_1: 0.8458, Acc_2: 0.7982, F1-score_1: 0.7959, F1-score_2: 0.7299
2023-03-07 13:12:42 - __main__ - INFO - Epoch [63/100]
2023-03-07 13:12:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-07 13:12:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 13:13:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:13:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 13:13:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:13:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 13:13:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 13:13:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 13:13:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 13:13:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 13:13:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-07 13:14:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:14:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0089, Loss_2: 0.0040, Acc_1: 0.8453, Acc_2: 0.7994, F1-score_1: 0.8087, F1-score_2: 0.7272
2023-03-07 13:14:19 - __main__ - INFO - Epoch [64/100]
2023-03-07 13:14:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 13:14:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-07 13:14:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 13:14:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 13:14:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 13:14:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:15:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:15:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 13:15:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 13:15:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 13:15:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:15:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 13:15:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0072, Loss_2: 0.0052, Acc_1: 0.8461, Acc_2: 0.7998, F1-score_1: 0.8054, F1-score_2: 0.7318
2023-03-07 13:15:57 - __main__ - INFO - Epoch [65/100]
2023-03-07 13:16:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 13:16:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 13:16:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 13:16:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 13:16:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 13:16:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 13:16:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:16:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:16:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-07 13:17:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 13:17:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:17:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:17:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0071, Loss_2: 0.0058, Acc_1: 0.8473, Acc_2: 0.7930, F1-score_1: 0.8042, F1-score_2: 0.7261
2023-03-07 13:17:34 - __main__ - INFO - Epoch [66/100]
2023-03-07 13:17:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 13:17:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-07 13:17:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 13:18:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 13:18:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:18:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 13:18:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 13:18:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-07 13:18:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 13:18:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 13:18:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 13:18:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 13:19:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0082, Loss_2: 0.0053, Acc_1: 0.8263, Acc_2: 0.7931, F1-score_1: 0.7845, F1-score_2: 0.7283
2023-03-07 13:19:11 - __main__ - INFO - Epoch [67/100]
2023-03-07 13:19:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 13:19:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:19:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:19:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:19:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:19:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-07 13:19:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:20:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 13:20:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 13:20:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-07 13:20:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-07 13:20:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:20:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0096, Loss_2: 0.0066, Acc_1: 0.8288, Acc_2: 0.7931, F1-score_1: 0.7885, F1-score_2: 0.7189
2023-03-07 13:20:49 - __main__ - INFO - Epoch [68/100]
2023-03-07 13:20:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 13:21:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:21:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 13:21:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-07 13:21:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-07 13:21:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 13:21:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:21:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 13:21:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-07 13:21:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 13:22:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 13:22:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:22:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0106, Loss_2: 0.0061, Acc_1: 0.8397, Acc_2: 0.7953, F1-score_1: 0.7978, F1-score_2: 0.7248
2023-03-07 13:22:26 - __main__ - INFO - Epoch [69/100]
2023-03-07 13:22:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 13:22:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 13:22:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:22:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 13:22:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 13:23:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:23:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-07 13:23:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 13:23:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 13:23:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:23:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 13:23:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:24:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0095, Loss_2: 0.0061, Acc_1: 0.8385, Acc_2: 0.7891, F1-score_1: 0.7970, F1-score_2: 0.7233
2023-03-07 13:24:04 - __main__ - INFO - Epoch [70/100]
2023-03-07 13:24:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 13:24:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 13:24:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 13:24:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 13:24:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:24:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:24:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-07 13:24:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 13:25:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:25:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 13:25:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 13:25:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 13:25:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0096, Loss_2: 0.0045, Acc_1: 0.8375, Acc_2: 0.7947, F1-score_1: 0.7958, F1-score_2: 0.7287
2023-03-07 13:25:41 - __main__ - INFO - Epoch [71/100]
2023-03-07 13:25:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 13:25:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 13:26:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 13:26:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:26:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 13:26:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:26:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0019, Loss_2: 0.0014, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-07 13:26:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 13:26:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 13:26:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 13:26:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 13:27:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 13:27:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0112, Loss_2: 0.0052, Acc_1: 0.8254, Acc_2: 0.7863, F1-score_1: 0.7881, F1-score_2: 0.7181
2023-03-07 13:27:19 - __main__ - INFO - Epoch [72/100]
2023-03-07 13:27:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 13:27:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 13:27:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:27:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 13:27:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 13:27:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:28:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 13:28:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 13:28:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 13:28:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 13:28:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:28:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 13:28:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0112, Loss_2: 0.0053, Acc_1: 0.8414, Acc_2: 0.7982, F1-score_1: 0.7989, F1-score_2: 0.7320
2023-03-07 13:28:56 - __main__ - INFO - Epoch [73/100]
2023-03-07 13:29:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 13:29:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 13:29:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 13:29:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 13:29:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 13:29:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 13:29:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 13:29:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 13:29:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:30:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0024, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 13:30:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 13:30:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:30:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0112, Loss_2: 0.0042, Acc_1: 0.8398, Acc_2: 0.7986, F1-score_1: 0.7933, F1-score_2: 0.7308
2023-03-07 13:30:33 - __main__ - INFO - Epoch [74/100]
2023-03-07 13:30:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 13:30:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 13:30:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:30:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:31:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:31:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 13:31:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 13:31:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 13:31:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 13:31:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0028, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 13:31:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 13:31:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 13:32:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0115, Loss_2: 0.0051, Acc_1: 0.8375, Acc_2: 0.7936, F1-score_1: 0.7926, F1-score_2: 0.7289
2023-03-07 13:32:11 - __main__ - INFO - Epoch [75/100]
2023-03-07 13:32:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-07 13:32:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 13:32:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 13:32:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 13:32:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 13:32:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 13:32:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 13:33:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 13:33:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 13:33:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:33:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 13:33:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8984, 
2023-03-07 13:33:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0108, Loss_2: 0.0037, Acc_1: 0.8392, Acc_2: 0.7957, F1-score_1: 0.7955, F1-score_2: 0.7251
2023-03-07 13:33:48 - __main__ - INFO - Epoch [76/100]
2023-03-07 13:33:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 13:34:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 13:34:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 13:34:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 13:34:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:34:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 13:34:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:34:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:34:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:34:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 13:35:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:35:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 13:35:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0108, Loss_2: 0.0045, Acc_1: 0.8378, Acc_2: 0.7918, F1-score_1: 0.7949, F1-score_2: 0.7171
2023-03-07 13:35:25 - __main__ - INFO - Epoch [77/100]
2023-03-07 13:35:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 13:35:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 13:35:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:35:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:35:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 13:36:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 13:36:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 13:36:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 13:36:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 13:36:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:36:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 13:36:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 13:37:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0048, Acc_1: 0.8381, Acc_2: 0.7942, F1-score_1: 0.7967, F1-score_2: 0.7253
2023-03-07 13:37:03 - __main__ - INFO - Epoch [78/100]
2023-03-07 13:37:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-07 13:37:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:37:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:37:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 13:37:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 13:37:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 13:37:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:37:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:38:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 13:38:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 13:38:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:38:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-07 13:38:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0115, Loss_2: 0.0044, Acc_1: 0.8320, Acc_2: 0.7852, F1-score_1: 0.7855, F1-score_2: 0.7146
2023-03-07 13:38:40 - __main__ - INFO - Epoch [79/100]
2023-03-07 13:38:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 13:38:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 13:38:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 13:39:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-07 13:39:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:39:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:39:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 13:39:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 13:39:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 13:39:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 13:39:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 13:40:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:40:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0146, Loss_2: 0.0056, Acc_1: 0.8378, Acc_2: 0.7833, F1-score_1: 0.7968, F1-score_2: 0.7190
2023-03-07 13:40:17 - __main__ - INFO - Epoch [80/100]
2023-03-07 13:40:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 13:40:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 13:40:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-07 13:40:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:40:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:40:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0458, Loss_2: 0.0198, Acc_1: 0.7344, Acc_2: 0.6406, 
2023-03-07 13:41:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0017, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 13:41:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 13:41:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0023, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 13:41:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0013, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 13:41:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 13:41:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0012, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-07 13:41:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0123, Loss_2: 0.0033, Acc_1: 0.8297, Acc_2: 0.7952, F1-score_1: 0.7780, F1-score_2: 0.7219
2023-03-07 13:41:54 - __main__ - INFO - Epoch [81/100]
2023-03-07 13:42:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 13:42:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 13:42:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:42:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:42:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 13:42:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-07 13:42:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 13:42:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 13:42:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:43:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 13:43:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 13:43:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 13:43:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0131, Loss_2: 0.0048, Acc_1: 0.8305, Acc_2: 0.7901, F1-score_1: 0.7826, F1-score_2: 0.7224
2023-03-07 13:43:32 - __main__ - INFO - Epoch [82/100]
2023-03-07 13:43:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:43:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 13:43:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:43:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:44:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 13:44:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 13:44:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:44:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 13:44:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 13:44:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 13:44:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 13:44:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:45:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0081, Loss_2: 0.0042, Acc_1: 0.8242, Acc_2: 0.7858, F1-score_1: 0.7705, F1-score_2: 0.7178
2023-03-07 13:45:09 - __main__ - INFO - Epoch [83/100]
2023-03-07 13:45:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:45:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:45:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:45:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 13:45:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 13:45:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 13:45:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 13:46:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:46:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 13:46:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:46:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:46:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 13:46:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0126, Loss_2: 0.0040, Acc_1: 0.8295, Acc_2: 0.7940, F1-score_1: 0.7815, F1-score_2: 0.7226
2023-03-07 13:46:46 - __main__ - INFO - Epoch [84/100]
2023-03-07 13:46:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 13:46:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 13:47:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0028, Loss_2: 0.0006, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-07 13:47:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 13:47:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 13:47:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 13:47:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 13:47:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 13:47:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 13:47:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 13:48:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 13:48:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 13:48:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0127, Loss_2: 0.0049, Acc_1: 0.8293, Acc_2: 0.7911, F1-score_1: 0.7843, F1-score_2: 0.7257
2023-03-07 13:48:24 - __main__ - INFO - Epoch [85/100]
2023-03-07 13:48:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 13:48:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 13:48:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 13:48:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:48:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 13:49:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-07 13:49:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 13:49:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 13:49:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 13:49:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 13:49:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 13:49:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:50:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0141, Loss_2: 0.0045, Acc_1: 0.8227, Acc_2: 0.7930, F1-score_1: 0.7741, F1-score_2: 0.7224
2023-03-07 13:50:01 - __main__ - INFO - Epoch [86/100]
2023-03-07 13:50:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 13:50:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 13:50:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:50:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 13:50:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:50:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:50:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-07 13:50:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 13:51:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:51:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:51:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:51:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 13:51:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0124, Loss_2: 0.0045, Acc_1: 0.8334, Acc_2: 0.7884, F1-score_1: 0.7890, F1-score_2: 0.7223
2023-03-07 13:51:38 - __main__ - INFO - Epoch [87/100]
2023-03-07 13:51:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 13:51:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 13:51:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:52:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:52:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:52:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:52:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 13:52:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 13:52:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:52:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 13:52:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 13:52:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:53:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0121, Loss_2: 0.0053, Acc_1: 0.8358, Acc_2: 0.7916, F1-score_1: 0.7928, F1-score_2: 0.7232
2023-03-07 13:53:16 - __main__ - INFO - Epoch [88/100]
2023-03-07 13:53:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 13:53:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 13:53:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 13:53:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 13:53:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 13:53:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 13:54:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 13:54:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:54:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:54:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0016, Loss_2: 0.0005, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-07 13:54:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:54:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 13:54:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0127, Loss_2: 0.0056, Acc_1: 0.8293, Acc_2: 0.7913, F1-score_1: 0.7805, F1-score_2: 0.7194
2023-03-07 13:54:53 - __main__ - INFO - Epoch [89/100]
2023-03-07 13:54:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 13:55:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:55:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 13:55:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 13:55:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:55:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:55:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:55:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 13:55:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:56:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 13:56:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 13:56:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:56:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0132, Loss_2: 0.0056, Acc_1: 0.8339, Acc_2: 0.7916, F1-score_1: 0.7897, F1-score_2: 0.7215
2023-03-07 13:56:31 - __main__ - INFO - Epoch [90/100]
2023-03-07 13:56:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:56:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 13:56:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 13:56:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:57:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 13:57:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 13:57:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 13:57:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 13:57:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 13:57:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-07 13:57:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 13:57:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 13:58:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0119, Loss_2: 0.0044, Acc_1: 0.8344, Acc_2: 0.7950, F1-score_1: 0.7916, F1-score_2: 0.7237
2023-03-07 13:58:08 - __main__ - INFO - Epoch [91/100]
2023-03-07 13:58:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 13:58:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 13:58:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:58:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 13:58:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:58:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:58:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 13:59:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 13:59:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 13:59:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 13:59:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 13:59:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 13:59:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0126, Loss_2: 0.0050, Acc_1: 0.8324, Acc_2: 0.7948, F1-score_1: 0.7891, F1-score_2: 0.7249
2023-03-07 13:59:45 - __main__ - INFO - Epoch [92/100]
2023-03-07 13:59:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 13:59:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 14:00:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 14:00:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 14:00:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 14:00:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 14:00:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 14:00:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 14:00:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 14:00:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 14:01:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 14:01:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 14:01:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0127, Loss_2: 0.0050, Acc_1: 0.8347, Acc_2: 0.7948, F1-score_1: 0.7913, F1-score_2: 0.7253
2023-03-07 14:01:23 - __main__ - INFO - Epoch [93/100]
2023-03-07 14:01:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 14:01:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 14:01:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 14:01:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 14:01:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 14:02:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 14:02:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 14:02:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 14:02:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 14:02:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 14:02:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 14:02:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 14:03:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0135, Loss_2: 0.0055, Acc_1: 0.8283, Acc_2: 0.7933, F1-score_1: 0.7870, F1-score_2: 0.7235
2023-03-07 14:03:00 - __main__ - INFO - Epoch [94/100]
2023-03-07 14:03:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 14:03:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 14:03:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 14:03:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 14:03:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 14:03:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 14:03:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 14:03:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 14:04:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 14:04:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 14:04:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 14:04:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 14:04:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0058, Acc_1: 0.8331, Acc_2: 0.7938, F1-score_1: 0.7907, F1-score_2: 0.7247
2023-03-07 14:04:38 - __main__ - INFO - Epoch [95/100]
2023-03-07 14:04:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 14:04:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 14:04:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 14:05:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 14:05:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 14:05:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 14:05:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 14:05:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 14:05:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 14:05:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 14:05:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 14:05:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 14:06:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0068, Acc_1: 0.8334, Acc_2: 0.7940, F1-score_1: 0.7910, F1-score_2: 0.7258
2023-03-07 14:06:15 - __main__ - INFO - Epoch [96/100]
2023-03-07 14:06:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 14:06:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 14:06:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 14:06:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 14:06:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 14:06:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 14:07:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 14:07:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 14:07:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 14:07:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 14:07:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 14:07:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 14:07:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0065, Acc_1: 0.8332, Acc_2: 0.7969, F1-score_1: 0.7906, F1-score_2: 0.7282
2023-03-07 14:07:52 - __main__ - INFO - Epoch [97/100]
2023-03-07 14:07:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 14:08:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 14:08:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 14:08:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 14:08:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 14:08:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 14:08:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 14:08:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 14:08:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 14:09:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 14:09:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 14:09:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 14:09:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0129, Loss_2: 0.0064, Acc_1: 0.8342, Acc_2: 0.7965, F1-score_1: 0.7918, F1-score_2: 0.7272
2023-03-07 14:09:29 - __main__ - INFO - Epoch [98/100]
2023-03-07 14:09:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 14:09:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 14:09:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 14:09:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 14:10:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 14:10:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 14:10:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 14:10:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 14:10:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 14:10:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 14:10:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 14:10:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 14:11:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0063, Acc_1: 0.8337, Acc_2: 0.7967, F1-score_1: 0.7914, F1-score_2: 0.7269
2023-03-07 14:11:07 - __main__ - INFO - Epoch [99/100]
2023-03-07 14:11:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 14:11:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 14:11:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 14:11:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 14:11:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 14:11:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 14:11:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 14:12:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 14:12:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 14:12:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 14:12:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 14:12:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 14:12:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0129, Loss_2: 0.0063, Acc_1: 0.8337, Acc_2: 0.7960, F1-score_1: 0.7915, F1-score_2: 0.7261
2023-03-07 14:12:46 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 14:12:46 - utils._noise - DEBUG - 6, 7
2023-03-07 14:12:46 - utils._noise - DEBUG - 13997
2023-03-07 14:12:46 - utils._noise - INFO - Actual noise 0.20
2023-03-07 14:12:46 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-07 14:12:47 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-07 14:12:48 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 14:12:48 - __main__ - INFO - Loading dataset...
2023-03-07 14:12:48 - __main__ - INFO - Building model...
2023-03-07 14:12:49 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-07 14:12:49 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-07 14:12:49 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-07 14:12:49 - __main__ - INFO - Start train & evaluate
2023-03-07 14:12:49 - __main__ - INFO - Epoch [0/100]
2023-03-07 14:12:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0160, Loss_2: 0.0152, Acc_1: 0.1719, Acc_2: 0.1875, 
2023-03-07 14:13:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0127, Loss_2: 0.0141, Acc_1: 0.4844, Acc_2: 0.2344, 
2023-03-07 14:13:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0121, Loss_2: 0.0143, Acc_1: 0.4766, Acc_2: 0.2891, 
2023-03-07 14:13:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0093, Loss_2: 0.0129, Acc_1: 0.6562, Acc_2: 0.3750, 
2023-03-07 14:13:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0095, Loss_2: 0.0128, Acc_1: 0.6094, Acc_2: 0.3750, 
2023-03-07 14:13:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0092, Loss_2: 0.0146, Acc_1: 0.6484, Acc_2: 0.2656, 
2023-03-07 14:13:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0094, Loss_2: 0.0141, Acc_1: 0.6328, Acc_2: 0.3203, 
2023-03-07 14:13:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0096, Loss_2: 0.0136, Acc_1: 0.6562, Acc_2: 0.3281, 
2023-03-07 14:13:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0088, Loss_2: 0.0134, Acc_1: 0.6953, Acc_2: 0.4609, 
2023-03-07 14:13:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0095, Loss_2: 0.0134, Acc_1: 0.6641, Acc_2: 0.3516, 
2023-03-07 14:14:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0093, Loss_2: 0.0156, Acc_1: 0.6641, Acc_2: 0.2031, 
2023-03-07 14:14:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0091, Loss_2: 0.0139, Acc_1: 0.6797, Acc_2: 0.2344, 
2023-03-07 14:14:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0134, Acc_1: 0.8555, Acc_2: 0.3167, F1-score_1: 0.7880, F1-score_2: 0.1395
2023-03-07 14:14:26 - __main__ - INFO - Epoch [1/100]
2023-03-07 14:14:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0073, Loss_2: 0.0141, Acc_1: 0.7656, Acc_2: 0.2969, 
2023-03-07 14:14:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0071, Loss_2: 0.0136, Acc_1: 0.7578, Acc_2: 0.3672, 
2023-03-07 14:14:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0067, Loss_2: 0.0129, Acc_1: 0.7500, Acc_2: 0.4688, 
2023-03-07 14:14:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0068, Loss_2: 0.0129, Acc_1: 0.7578, Acc_2: 0.3984, 
2023-03-07 14:14:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0085, Loss_2: 0.0120, Acc_1: 0.6719, Acc_2: 0.5000, 
2023-03-07 14:15:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0091, Loss_2: 0.0167, Acc_1: 0.6406, Acc_2: 0.2578, 
2023-03-07 14:15:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0078, Loss_2: 0.0134, Acc_1: 0.7109, Acc_2: 0.3281, 
2023-03-07 14:15:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0078, Loss_2: 0.0134, Acc_1: 0.7188, Acc_2: 0.3906, 
2023-03-07 14:15:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0070, Loss_2: 0.0136, Acc_1: 0.7422, Acc_2: 0.3203, 
2023-03-07 14:15:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0076, Loss_2: 0.0130, Acc_1: 0.7344, Acc_2: 0.3750, 
2023-03-07 14:15:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0066, Loss_2: 0.0129, Acc_1: 0.7500, Acc_2: 0.4375, 
2023-03-07 14:15:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0075, Loss_2: 0.0115, Acc_1: 0.7266, Acc_2: 0.4922, 
2023-03-07 14:16:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0048, Loss_2: 0.0106, Acc_1: 0.8757, Acc_2: 0.5216, F1-score_1: 0.8260, F1-score_2: 0.3728
2023-03-07 14:16:03 - __main__ - INFO - Epoch [2/100]
2023-03-07 14:16:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0053, Loss_2: 0.0122, Acc_1: 0.7578, Acc_2: 0.4453, 
2023-03-07 14:16:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0071, Loss_2: 0.0121, Acc_1: 0.7188, Acc_2: 0.4922, 
2023-03-07 14:16:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0057, Loss_2: 0.0117, Acc_1: 0.7656, Acc_2: 0.4844, 
2023-03-07 14:16:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0055, Loss_2: 0.0120, Acc_1: 0.7891, Acc_2: 0.4609, 
2023-03-07 14:16:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0051, Loss_2: 0.0112, Acc_1: 0.7734, Acc_2: 0.5156, 
2023-03-07 14:16:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0061, Loss_2: 0.0126, Acc_1: 0.7109, Acc_2: 0.4062, 
2023-03-07 14:16:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0071, Loss_2: 0.0113, Acc_1: 0.7578, Acc_2: 0.4688, 
2023-03-07 14:16:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0052, Loss_2: 0.0108, Acc_1: 0.7734, Acc_2: 0.4766, 
2023-03-07 14:17:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0040, Loss_2: 0.0096, Acc_1: 0.8594, Acc_2: 0.6016, 
2023-03-07 14:17:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0043, Loss_2: 0.0089, Acc_1: 0.8047, Acc_2: 0.6172, 
2023-03-07 14:17:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0063, Loss_2: 0.0092, Acc_1: 0.7422, Acc_2: 0.5859, 
2023-03-07 14:17:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0046, Loss_2: 0.0089, Acc_1: 0.8359, Acc_2: 0.6016, 
2023-03-07 14:17:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0044, Loss_2: 0.0075, Acc_1: 0.8820, Acc_2: 0.6970, F1-score_1: 0.8449, F1-score_2: 0.5644
2023-03-07 14:17:41 - __main__ - INFO - Epoch [3/100]
2023-03-07 14:17:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0039, Loss_2: 0.0089, Acc_1: 0.7969, Acc_2: 0.5703, 
2023-03-07 14:17:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0031, Loss_2: 0.0084, Acc_1: 0.8438, Acc_2: 0.6406, 
2023-03-07 14:18:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0033, Loss_2: 0.0077, Acc_1: 0.8281, Acc_2: 0.6562, 
2023-03-07 14:18:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0038, Loss_2: 0.0085, Acc_1: 0.8516, Acc_2: 0.5859, 
2023-03-07 14:18:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0033, Loss_2: 0.0079, Acc_1: 0.8281, Acc_2: 0.6562, 
2023-03-07 14:18:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0036, Loss_2: 0.0077, Acc_1: 0.8125, Acc_2: 0.6484, 
2023-03-07 14:18:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0046, Loss_2: 0.0085, Acc_1: 0.8047, Acc_2: 0.6953, 
2023-03-07 14:18:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0028, Loss_2: 0.0071, Acc_1: 0.8359, Acc_2: 0.6719, 
2023-03-07 14:18:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0050, Loss_2: 0.0079, Acc_1: 0.7344, Acc_2: 0.6172, 
2023-03-07 14:18:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0044, Loss_2: 0.0080, Acc_1: 0.7969, Acc_2: 0.6641, 
2023-03-07 14:18:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0050, Loss_2: 0.0081, Acc_1: 0.7812, Acc_2: 0.6641, 
2023-03-07 14:19:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0041, Loss_2: 0.0066, Acc_1: 0.8203, Acc_2: 0.7266, 
2023-03-07 14:19:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0036, Loss_2: 0.0054, Acc_1: 0.8699, Acc_2: 0.7658, F1-score_1: 0.8218, F1-score_2: 0.6858
2023-03-07 14:19:18 - __main__ - INFO - Epoch [4/100]
2023-03-07 14:19:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0013, Loss_2: 0.0058, Acc_1: 0.9375, Acc_2: 0.7266, 
2023-03-07 14:19:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0016, Loss_2: 0.0051, Acc_1: 0.8828, Acc_2: 0.7656, 
2023-03-07 14:19:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0022, Loss_2: 0.0069, Acc_1: 0.8594, Acc_2: 0.6953, 
2023-03-07 14:19:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0023, Loss_2: 0.0055, Acc_1: 0.8359, Acc_2: 0.7109, 
2023-03-07 14:19:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0015, Loss_2: 0.0046, Acc_1: 0.8672, Acc_2: 0.7656, 
2023-03-07 14:19:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0022, Loss_2: 0.0082, Acc_1: 0.8750, Acc_2: 0.6172, 
2023-03-07 14:20:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0017, Loss_2: 0.0053, Acc_1: 0.8594, Acc_2: 0.7578, 
2023-03-07 14:20:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0027, Loss_2: 0.0055, Acc_1: 0.8438, Acc_2: 0.7109, 
2023-03-07 14:20:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0023, Loss_2: 0.0057, Acc_1: 0.8359, Acc_2: 0.7656, 
2023-03-07 14:20:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0020, Loss_2: 0.0060, Acc_1: 0.8594, Acc_2: 0.7500, 
2023-03-07 14:20:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0037, Loss_2: 0.0070, Acc_1: 0.7891, Acc_2: 0.6875, 
2023-03-07 14:20:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0030, Loss_2: 0.0061, Acc_1: 0.8359, Acc_2: 0.7109, 
2023-03-07 14:20:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0043, Acc_1: 0.8641, Acc_2: 0.7957, F1-score_1: 0.8225, F1-score_2: 0.7301
2023-03-07 14:20:55 - __main__ - INFO - Epoch [5/100]
2023-03-07 14:21:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0013, Loss_2: 0.0043, Acc_1: 0.8750, Acc_2: 0.7578, 
2023-03-07 14:21:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0009, Loss_2: 0.0039, Acc_1: 0.8906, Acc_2: 0.7891, 
2023-03-07 14:21:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0015, Loss_2: 0.0047, Acc_1: 0.8594, Acc_2: 0.7266, 
2023-03-07 14:21:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0033, Acc_1: 0.9297, Acc_2: 0.8125, 
2023-03-07 14:21:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0015, Loss_2: 0.0053, Acc_1: 0.8516, Acc_2: 0.7188, 
2023-03-07 14:21:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0010, Loss_2: 0.0044, Acc_1: 0.8906, Acc_2: 0.7422, 
2023-03-07 14:21:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0012, Loss_2: 0.0038, Acc_1: 0.8906, Acc_2: 0.7891, 
2023-03-07 14:21:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0042, Acc_1: 0.9375, Acc_2: 0.7656, 
2023-03-07 14:21:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0021, Loss_2: 0.0051, Acc_1: 0.8594, Acc_2: 0.7109, 
2023-03-07 14:22:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0030, Acc_1: 0.9219, Acc_2: 0.7891, 
2023-03-07 14:22:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0015, Loss_2: 0.0035, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-07 14:22:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0015, Loss_2: 0.0030, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-07 14:22:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0045, Acc_1: 0.8691, Acc_2: 0.7897, F1-score_1: 0.8228, F1-score_2: 0.7222
2023-03-07 14:22:33 - __main__ - INFO - Epoch [6/100]
2023-03-07 14:22:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0013, Loss_2: 0.0026, Acc_1: 0.9219, Acc_2: 0.8125, 
2023-03-07 14:22:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0029, Acc_1: 0.9141, Acc_2: 0.8281, 
2023-03-07 14:22:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0013, Acc_1: 0.9375, Acc_2: 0.8672, 
2023-03-07 14:22:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0016, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 14:23:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0013, Loss_2: 0.0041, Acc_1: 0.8438, Acc_2: 0.7812, 
2023-03-07 14:23:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0013, Loss_2: 0.0034, Acc_1: 0.8672, Acc_2: 0.7656, 
2023-03-07 14:23:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0038, Acc_1: 0.8828, Acc_2: 0.7422, 
2023-03-07 14:23:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0027, Acc_1: 0.8906, Acc_2: 0.7891, 
2023-03-07 14:23:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0015, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 14:23:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0017, Acc_1: 0.9141, Acc_2: 0.8281, 
2023-03-07 14:23:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0013, Loss_2: 0.0024, Acc_1: 0.8672, Acc_2: 0.7969, 
2023-03-07 14:23:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0015, Loss_2: 0.0034, Acc_1: 0.8438, Acc_2: 0.7734, 
2023-03-07 14:24:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0046, Acc_1: 0.8680, Acc_2: 0.7884, F1-score_1: 0.8254, F1-score_2: 0.7174
2023-03-07 14:24:10 - __main__ - INFO - Epoch [7/100]
2023-03-07 14:24:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0014, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 14:24:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0021, Acc_1: 0.8828, Acc_2: 0.8203, 
2023-03-07 14:24:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0019, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 14:24:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0014, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 14:24:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.9219, Acc_2: 0.8203, 
2023-03-07 14:24:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0022, Acc_1: 0.9062, Acc_2: 0.8047, 
2023-03-07 14:24:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 14:25:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0024, Acc_1: 0.8984, Acc_2: 0.8125, 
2023-03-07 14:25:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0017, Acc_1: 0.9219, Acc_2: 0.8359, 
2023-03-07 14:25:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0010, Loss_2: 0.0021, Acc_1: 0.8594, Acc_2: 0.8047, 
2023-03-07 14:25:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0033, Acc_1: 0.8672, Acc_2: 0.7266, 
2023-03-07 14:25:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-07 14:25:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0035, Acc_1: 0.8670, Acc_2: 0.7845, F1-score_1: 0.8298, F1-score_2: 0.7234
2023-03-07 14:25:47 - __main__ - INFO - Epoch [8/100]
2023-03-07 14:25:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 14:26:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0022, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 14:26:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 14:26:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 14:26:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 14:26:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 14:26:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 14:26:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0021, Acc_1: 0.8984, Acc_2: 0.7656, 
2023-03-07 14:26:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 14:26:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0012, Acc_1: 0.8359, Acc_2: 0.7891, 
2023-03-07 14:27:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 14:27:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 14:27:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0040, Acc_1: 0.8725, Acc_2: 0.7974, F1-score_1: 0.8346, F1-score_2: 0.7269
2023-03-07 14:27:25 - __main__ - INFO - Epoch [9/100]
2023-03-07 14:27:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 14:27:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 14:27:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 14:27:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-07 14:27:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 14:28:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-07 14:28:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9453, Acc_2: 0.8359, 
2023-03-07 14:28:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8438, 
2023-03-07 14:28:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 14:28:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8594, Acc_2: 0.7969, 
2023-03-07 14:28:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 14:28:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 14:29:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0036, Acc_1: 0.8738, Acc_2: 0.8117, F1-score_1: 0.8372, F1-score_2: 0.7462
2023-03-07 14:29:02 - __main__ - INFO - Epoch [10/100]
2023-03-07 14:29:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 14:29:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 14:29:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 14:29:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 14:29:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 14:29:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-07 14:29:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 14:29:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 14:30:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 14:30:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 14:30:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 14:30:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 14:30:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0060, Acc_1: 0.8725, Acc_2: 0.7930, F1-score_1: 0.8345, F1-score_2: 0.7297
2023-03-07 14:30:40 - __main__ - INFO - Epoch [11/100]
2023-03-07 14:30:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 14:30:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 14:30:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8047, 
2023-03-07 14:31:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-07 14:31:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 14:31:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.7969, 
2023-03-07 14:31:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 14:31:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 14:31:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 14:31:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 14:31:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 14:32:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-07 14:32:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0040, Acc_1: 0.8718, Acc_2: 0.8018, F1-score_1: 0.8344, F1-score_2: 0.7372
2023-03-07 14:32:17 - __main__ - INFO - Epoch [12/100]
2023-03-07 14:32:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 14:32:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 14:32:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 14:32:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 14:32:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 14:32:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 14:33:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-07 14:33:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 14:33:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 14:33:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 14:33:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-07 14:33:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 14:33:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0054, Acc_1: 0.8716, Acc_2: 0.7976, F1-score_1: 0.8340, F1-score_2: 0.7297
2023-03-07 14:33:55 - __main__ - INFO - Epoch [13/100]
2023-03-07 14:34:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 14:34:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-07 14:34:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 14:34:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 14:34:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8438, 
2023-03-07 14:34:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 14:34:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-07 14:34:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 14:34:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 14:35:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 14:35:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 14:35:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 14:35:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0044, Acc_1: 0.8657, Acc_2: 0.7823, F1-score_1: 0.8286, F1-score_2: 0.7175
2023-03-07 14:35:32 - __main__ - INFO - Epoch [14/100]
2023-03-07 14:35:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 14:35:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 14:35:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 14:35:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 14:36:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 14:36:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 14:36:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 14:36:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 14:36:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 14:36:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 14:36:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 14:36:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 14:37:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0060, Acc_1: 0.8730, Acc_2: 0.7936, F1-score_1: 0.8342, F1-score_2: 0.7302
2023-03-07 14:37:09 - __main__ - INFO - Epoch [15/100]
2023-03-07 14:37:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 14:37:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 14:37:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 14:37:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 14:37:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 14:37:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 14:37:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 14:38:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 14:38:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 14:38:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 14:38:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 14:38:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 14:38:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0054, Acc_1: 0.8713, Acc_2: 0.8035, F1-score_1: 0.8318, F1-score_2: 0.7364
2023-03-07 14:38:47 - __main__ - INFO - Epoch [16/100]
2023-03-07 14:38:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 14:38:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 14:39:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-07 14:39:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 14:39:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 14:39:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 14:39:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 14:39:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 14:39:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-07 14:39:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 14:40:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 14:40:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 14:40:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0050, Acc_1: 0.8736, Acc_2: 0.7916, F1-score_1: 0.8344, F1-score_2: 0.7290
2023-03-07 14:40:24 - __main__ - INFO - Epoch [17/100]
2023-03-07 14:40:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-07 14:40:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 14:40:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 14:40:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 14:40:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 14:41:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 14:41:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 14:41:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-07 14:41:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 14:41:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 14:41:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 14:41:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 14:42:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0023, Loss_2: 0.0063, Acc_1: 0.8702, Acc_2: 0.7913, F1-score_1: 0.8323, F1-score_2: 0.7261
2023-03-07 14:42:02 - __main__ - INFO - Epoch [18/100]
2023-03-07 14:42:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-07 14:42:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 14:42:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 14:42:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 14:42:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 14:42:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-07 14:42:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 14:42:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 14:43:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 14:43:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 14:43:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 14:43:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 14:43:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0056, Acc_1: 0.8718, Acc_2: 0.7695, F1-score_1: 0.8333, F1-score_2: 0.7094
2023-03-07 14:43:39 - __main__ - INFO - Epoch [19/100]
2023-03-07 14:43:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 14:43:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 14:43:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-07 14:44:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 14:44:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 14:44:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 14:44:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 14:44:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 14:44:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 14:44:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 14:44:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 14:44:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 14:45:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0047, Acc_1: 0.8689, Acc_2: 0.7969, F1-score_1: 0.8279, F1-score_2: 0.7253
2023-03-07 14:45:16 - __main__ - INFO - Epoch [20/100]
2023-03-07 14:45:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 14:45:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 14:45:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 14:45:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 14:45:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-07 14:45:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 14:46:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 14:46:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 14:46:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 14:46:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 14:46:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 14:46:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-07 14:46:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0075, Acc_1: 0.8708, Acc_2: 0.7874, F1-score_1: 0.8345, F1-score_2: 0.7230
2023-03-07 14:46:54 - __main__ - INFO - Epoch [21/100]
2023-03-07 14:46:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-07 14:47:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 14:47:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 14:47:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 14:47:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 14:47:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 14:47:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 14:47:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-07 14:47:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-07 14:48:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 14:48:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 14:48:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 14:48:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0036, Loss_2: 0.0066, Acc_1: 0.8635, Acc_2: 0.8015, F1-score_1: 0.8311, F1-score_2: 0.7347
2023-03-07 14:48:31 - __main__ - INFO - Epoch [22/100]
2023-03-07 14:48:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 14:48:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 14:48:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 14:48:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 14:49:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 14:49:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 14:49:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-07 14:49:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 14:49:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 14:49:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 14:49:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 14:49:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 14:50:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0061, Acc_1: 0.8726, Acc_2: 0.8049, F1-score_1: 0.8346, F1-score_2: 0.7399
2023-03-07 14:50:08 - __main__ - INFO - Epoch [23/100]
2023-03-07 14:50:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 14:50:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 14:50:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 14:50:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 14:50:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 14:50:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 14:50:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 14:51:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 14:51:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 14:51:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 14:51:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 14:51:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 14:51:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0037, Loss_2: 0.0077, Acc_1: 0.8633, Acc_2: 0.8018, F1-score_1: 0.8276, F1-score_2: 0.7322
2023-03-07 14:51:46 - __main__ - INFO - Epoch [24/100]
2023-03-07 14:51:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 14:51:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-07 14:52:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 14:52:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 14:52:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 14:52:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 14:52:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 14:52:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 14:52:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-07 14:52:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 14:53:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 14:53:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 14:53:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0078, Acc_1: 0.8674, Acc_2: 0.8074, F1-score_1: 0.8308, F1-score_2: 0.7447
2023-03-07 14:53:23 - __main__ - INFO - Epoch [25/100]
2023-03-07 14:53:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 14:53:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-07 14:53:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 14:53:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 14:53:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 14:54:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-07 14:54:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 14:54:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 14:54:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 14:54:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 14:54:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 14:54:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 14:55:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0061, Acc_1: 0.8640, Acc_2: 0.7858, F1-score_1: 0.8190, F1-score_2: 0.7191
2023-03-07 14:55:01 - __main__ - INFO - Epoch [26/100]
2023-03-07 14:55:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 14:55:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 14:55:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 14:55:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 14:55:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 14:55:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 14:55:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 14:55:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 14:56:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 14:56:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 14:56:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9453, Acc_2: 0.9062, 
2023-03-07 14:56:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 14:56:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0069, Acc_1: 0.8631, Acc_2: 0.7911, F1-score_1: 0.8240, F1-score_2: 0.7228
2023-03-07 14:56:38 - __main__ - INFO - Epoch [27/100]
2023-03-07 14:56:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 14:56:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-07 14:56:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 14:57:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 14:57:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 14:57:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-07 14:57:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 14:57:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 14:57:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 14:57:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 14:57:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 14:57:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 14:58:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0085, Acc_1: 0.8611, Acc_2: 0.8043, F1-score_1: 0.8199, F1-score_2: 0.7370
2023-03-07 14:58:15 - __main__ - INFO - Epoch [28/100]
2023-03-07 14:58:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 14:58:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 14:58:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0014, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 14:58:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 14:58:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 14:58:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 14:59:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 14:59:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 14:59:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 14:59:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 14:59:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 14:59:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 14:59:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0068, Acc_1: 0.8585, Acc_2: 0.7848, F1-score_1: 0.8143, F1-score_2: 0.7213
2023-03-07 14:59:53 - __main__ - INFO - Epoch [29/100]
2023-03-07 14:59:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 15:00:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-07 15:00:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 15:00:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:00:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:00:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 15:00:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0023, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 15:00:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 15:00:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:01:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:01:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 15:01:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:01:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0037, Loss_2: 0.0066, Acc_1: 0.8477, Acc_2: 0.7947, F1-score_1: 0.7992, F1-score_2: 0.7325
2023-03-07 15:01:30 - __main__ - INFO - Epoch [30/100]
2023-03-07 15:01:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 15:01:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 15:01:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:01:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:02:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 15:02:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-07 15:02:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-07 15:02:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 15:02:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 15:02:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 15:02:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 15:02:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-07 15:03:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0058, Acc_1: 0.8502, Acc_2: 0.7923, F1-score_1: 0.8084, F1-score_2: 0.7270
2023-03-07 15:03:08 - __main__ - INFO - Epoch [31/100]
2023-03-07 15:03:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0014, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 15:03:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 15:03:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 15:03:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 15:03:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:03:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.7812, Acc_2: 0.8203, 
2023-03-07 15:03:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 15:04:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 15:04:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0016, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8828, 
2023-03-07 15:04:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:04:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0014, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 15:04:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 15:04:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0057, Acc_1: 0.8429, Acc_2: 0.8020, F1-score_1: 0.8035, F1-score_2: 0.7366
2023-03-07 15:04:46 - __main__ - INFO - Epoch [32/100]
2023-03-07 15:04:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:04:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:05:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 15:05:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 15:05:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-07 15:05:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 15:05:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 15:05:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8672, 
2023-03-07 15:05:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8906, 
2023-03-07 15:05:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 15:06:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-07 15:06:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:06:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0049, Acc_1: 0.8381, Acc_2: 0.7999, F1-score_1: 0.7937, F1-score_2: 0.7340
2023-03-07 15:06:23 - __main__ - INFO - Epoch [33/100]
2023-03-07 15:06:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 15:06:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 15:06:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 15:06:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9219, 
2023-03-07 15:06:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 15:07:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 15:07:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8672, 
2023-03-07 15:07:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 15:07:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 15:07:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 15:07:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:07:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-07 15:08:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0045, Acc_1: 0.8463, Acc_2: 0.8047, F1-score_1: 0.7955, F1-score_2: 0.7267
2023-03-07 15:08:00 - __main__ - INFO - Epoch [34/100]
2023-03-07 15:08:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 15:08:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 15:08:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 15:08:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 15:08:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-07 15:08:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 15:08:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-07 15:08:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:09:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 15:09:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0024, Loss_2: 0.0010, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-07 15:09:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:09:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 15:09:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0055, Loss_2: 0.0056, Acc_1: 0.8407, Acc_2: 0.8057, F1-score_1: 0.8035, F1-score_2: 0.7410
2023-03-07 15:09:38 - __main__ - INFO - Epoch [35/100]
2023-03-07 15:09:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8672, 
2023-03-07 15:09:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 15:09:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 15:10:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 15:10:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0011, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-07 15:10:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 15:10:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:10:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 15:10:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:10:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 15:10:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:10:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 15:11:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0049, Acc_1: 0.8390, Acc_2: 0.8038, F1-score_1: 0.7969, F1-score_2: 0.7314
2023-03-07 15:11:15 - __main__ - INFO - Epoch [36/100]
2023-03-07 15:11:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:11:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-07 15:11:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-07 15:11:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 15:11:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 15:11:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:12:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 15:12:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 15:12:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 15:12:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:12:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-07 15:12:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 15:12:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0043, Acc_1: 0.8480, Acc_2: 0.8026, F1-score_1: 0.8064, F1-score_2: 0.7338
2023-03-07 15:12:53 - __main__ - INFO - Epoch [37/100]
2023-03-07 15:12:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-07 15:13:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 15:13:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:13:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 15:13:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 15:13:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 15:13:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-07 15:13:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8359, 
2023-03-07 15:13:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:14:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 15:14:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:14:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 15:14:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0036, Loss_2: 0.0058, Acc_1: 0.8346, Acc_2: 0.8050, F1-score_1: 0.7907, F1-score_2: 0.7363
2023-03-07 15:14:31 - __main__ - INFO - Epoch [38/100]
2023-03-07 15:14:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 15:14:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 15:14:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 15:14:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 15:15:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 15:15:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:15:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-07 15:15:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 15:15:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:15:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 15:15:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:15:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0019, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 15:16:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0044, Loss_2: 0.0056, Acc_1: 0.8404, Acc_2: 0.8023, F1-score_1: 0.8002, F1-score_2: 0.7312
2023-03-07 15:16:08 - __main__ - INFO - Epoch [39/100]
2023-03-07 15:16:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 15:16:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 15:16:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:16:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:16:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:16:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:16:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 15:17:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 15:17:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:17:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:17:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 15:17:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 15:17:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0048, Acc_1: 0.8431, Acc_2: 0.7996, F1-score_1: 0.8048, F1-score_2: 0.7328
2023-03-07 15:17:45 - __main__ - INFO - Epoch [40/100]
2023-03-07 15:17:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-07 15:17:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 15:18:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 15:18:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 15:18:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:18:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 15:18:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 15:18:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 15:18:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0016, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-07 15:18:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 15:19:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:19:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 15:19:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0049, Loss_2: 0.0051, Acc_1: 0.8337, Acc_2: 0.8001, F1-score_1: 0.7944, F1-score_2: 0.7220
2023-03-07 15:19:23 - __main__ - INFO - Epoch [41/100]
2023-03-07 15:19:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:19:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 15:19:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:19:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 15:19:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:20:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:20:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 15:20:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 15:20:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 15:20:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 15:20:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 15:20:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:21:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0042, Loss_2: 0.0058, Acc_1: 0.8415, Acc_2: 0.7999, F1-score_1: 0.8007, F1-score_2: 0.7330
2023-03-07 15:21:01 - __main__ - INFO - Epoch [42/100]
2023-03-07 15:21:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 15:21:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 15:21:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 15:21:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:21:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:21:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 15:21:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 15:21:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:22:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 15:22:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 15:22:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:22:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 15:22:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0040, Loss_2: 0.0054, Acc_1: 0.8237, Acc_2: 0.7634, F1-score_1: 0.7787, F1-score_2: 0.6993
2023-03-07 15:22:38 - __main__ - INFO - Epoch [43/100]
2023-03-07 15:22:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-07 15:22:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 15:22:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-07 15:23:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 15:23:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:23:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 15:23:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8594, 
2023-03-07 15:23:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:23:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-07 15:23:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 15:23:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0010, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-07 15:23:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:24:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0047, Loss_2: 0.0051, Acc_1: 0.8373, Acc_2: 0.7882, F1-score_1: 0.7947, F1-score_2: 0.7236
2023-03-07 15:24:16 - __main__ - INFO - Epoch [44/100]
2023-03-07 15:24:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 15:24:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 15:24:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:24:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-07 15:24:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 15:24:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 15:25:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:25:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 15:25:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 15:25:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-07 15:25:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:25:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 15:25:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0059, Loss_2: 0.0052, Acc_1: 0.8432, Acc_2: 0.7940, F1-score_1: 0.7997, F1-score_2: 0.7307
2023-03-07 15:25:53 - __main__ - INFO - Epoch [45/100]
2023-03-07 15:25:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 15:26:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 15:26:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:26:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 15:26:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 15:26:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 15:26:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 15:26:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 15:26:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:27:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:27:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:27:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0026, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 15:27:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0036, Loss_2: 0.0048, Acc_1: 0.8534, Acc_2: 0.7999, F1-score_1: 0.8124, F1-score_2: 0.7348
2023-03-07 15:27:31 - __main__ - INFO - Epoch [46/100]
2023-03-07 15:27:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 15:27:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 15:27:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 15:27:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:28:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 15:28:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 15:28:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 15:28:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-07 15:28:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 15:28:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 15:28:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 15:28:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 15:29:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0042, Loss_2: 0.0046, Acc_1: 0.8465, Acc_2: 0.8067, F1-score_1: 0.8004, F1-score_2: 0.7391
2023-03-07 15:29:08 - __main__ - INFO - Epoch [47/100]
2023-03-07 15:29:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 15:29:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:29:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 15:29:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-07 15:29:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 15:29:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 15:29:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 15:30:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 15:30:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 15:30:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:30:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8516, 
2023-03-07 15:30:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-07 15:30:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0046, Loss_2: 0.0060, Acc_1: 0.8436, Acc_2: 0.7877, F1-score_1: 0.7970, F1-score_2: 0.7203
2023-03-07 15:30:46 - __main__ - INFO - Epoch [48/100]
2023-03-07 15:30:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:30:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:31:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 15:31:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 15:31:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 15:31:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 15:31:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-07 15:31:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 15:31:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:31:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 15:32:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 15:32:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 15:32:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0060, Loss_2: 0.0053, Acc_1: 0.8422, Acc_2: 0.8008, F1-score_1: 0.7985, F1-score_2: 0.7308
2023-03-07 15:32:23 - __main__ - INFO - Epoch [49/100]
2023-03-07 15:32:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 15:32:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 15:32:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:32:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-07 15:32:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 15:33:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:33:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-07 15:33:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 15:33:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:33:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 15:33:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 15:33:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-07 15:34:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0043, Acc_1: 0.8458, Acc_2: 0.8020, F1-score_1: 0.7995, F1-score_2: 0.7370
2023-03-07 15:34:01 - __main__ - INFO - Epoch [50/100]
2023-03-07 15:34:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 15:34:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:34:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:34:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:34:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:34:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-07 15:34:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:34:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0030, Loss_2: 0.0020, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-07 15:35:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-07 15:35:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 15:35:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:35:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 15:35:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0041, Loss_2: 0.0045, Acc_1: 0.8387, Acc_2: 0.7976, F1-score_1: 0.7938, F1-score_2: 0.7321
2023-03-07 15:35:38 - __main__ - INFO - Epoch [51/100]
2023-03-07 15:35:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 15:35:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 15:35:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-07 15:36:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 15:36:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:36:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 15:36:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 15:36:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0022, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:36:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 15:36:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9141, 
2023-03-07 15:36:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 15:36:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:37:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0049, Loss_2: 0.0060, Acc_1: 0.8417, Acc_2: 0.7938, F1-score_1: 0.7973, F1-score_2: 0.7268
2023-03-07 15:37:16 - __main__ - INFO - Epoch [52/100]
2023-03-07 15:37:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 15:37:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 15:37:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 15:37:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-07 15:37:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 15:37:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:38:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 15:38:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 15:38:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:38:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 15:38:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 15:38:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:38:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0064, Acc_1: 0.8446, Acc_2: 0.7965, F1-score_1: 0.8025, F1-score_2: 0.7300
2023-03-07 15:38:53 - __main__ - INFO - Epoch [53/100]
2023-03-07 15:38:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 15:39:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 15:39:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:39:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 15:39:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 15:39:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 15:39:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 15:39:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:39:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-07 15:40:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 15:40:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:40:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 15:40:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0048, Loss_2: 0.0060, Acc_1: 0.8453, Acc_2: 0.7965, F1-score_1: 0.8016, F1-score_2: 0.7272
2023-03-07 15:40:31 - __main__ - INFO - Epoch [54/100]
2023-03-07 15:40:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 15:40:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 15:40:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 15:40:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 15:41:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:41:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 15:41:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 15:41:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 15:41:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 15:41:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 15:41:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 15:41:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:42:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0050, Loss_2: 0.0058, Acc_1: 0.8483, Acc_2: 0.8011, F1-score_1: 0.8006, F1-score_2: 0.7294
2023-03-07 15:42:09 - __main__ - INFO - Epoch [55/100]
2023-03-07 15:42:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 15:42:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 15:42:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 15:42:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 15:42:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 15:42:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 15:42:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 15:43:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 15:43:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 15:43:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 15:43:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0012, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-07 15:43:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:43:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0062, Acc_1: 0.8254, Acc_2: 0.7950, F1-score_1: 0.7775, F1-score_2: 0.7257
2023-03-07 15:43:46 - __main__ - INFO - Epoch [56/100]
2023-03-07 15:43:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 15:43:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 15:44:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 15:44:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:44:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 15:44:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:44:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:44:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:44:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-07 15:44:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 15:45:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 15:45:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 15:45:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0047, Loss_2: 0.0052, Acc_1: 0.8454, Acc_2: 0.7972, F1-score_1: 0.8016, F1-score_2: 0.7281
2023-03-07 15:45:23 - __main__ - INFO - Epoch [57/100]
2023-03-07 15:45:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 15:45:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 15:45:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 15:45:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 15:45:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 15:46:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 15:46:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 15:46:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:46:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 15:46:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 15:46:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 15:46:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 15:47:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0058, Loss_2: 0.0066, Acc_1: 0.8246, Acc_2: 0.8021, F1-score_1: 0.7858, F1-score_2: 0.7339
2023-03-07 15:47:01 - __main__ - INFO - Epoch [58/100]
2023-03-07 15:47:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 15:47:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:47:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 15:47:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 15:47:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 15:47:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 15:47:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 15:47:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 15:48:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 15:48:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 15:48:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 15:48:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 15:48:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0042, Loss_2: 0.0056, Acc_1: 0.8407, Acc_2: 0.8026, F1-score_1: 0.7993, F1-score_2: 0.7326
2023-03-07 15:48:38 - __main__ - INFO - Epoch [59/100]
2023-03-07 15:48:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 15:48:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:48:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:49:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 15:49:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 15:49:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 15:49:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:49:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 15:49:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 15:49:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 15:49:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 15:49:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 15:50:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0053, Loss_2: 0.0057, Acc_1: 0.8368, Acc_2: 0.8006, F1-score_1: 0.7986, F1-score_2: 0.7303
2023-03-07 15:50:16 - __main__ - INFO - Epoch [60/100]
2023-03-07 15:50:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 15:50:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 15:50:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:50:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 15:50:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 15:50:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 15:51:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 15:51:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 15:51:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:51:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 15:51:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 15:51:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 15:51:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0059, Acc_1: 0.8387, Acc_2: 0.8025, F1-score_1: 0.7950, F1-score_2: 0.7324
2023-03-07 15:51:53 - __main__ - INFO - Epoch [61/100]
2023-03-07 15:51:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 15:52:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:52:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 15:52:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 15:52:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 15:52:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:52:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 15:52:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 15:52:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:53:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 15:53:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 15:53:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 15:53:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0046, Loss_2: 0.0068, Acc_1: 0.8456, Acc_2: 0.7908, F1-score_1: 0.8058, F1-score_2: 0.7240
2023-03-07 15:53:31 - __main__ - INFO - Epoch [62/100]
2023-03-07 15:53:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 15:53:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 15:53:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 15:53:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:54:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 15:54:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 15:54:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 15:54:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 15:54:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:54:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 15:54:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 15:54:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:55:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0065, Acc_1: 0.8449, Acc_2: 0.7993, F1-score_1: 0.8046, F1-score_2: 0.7310
2023-03-07 15:55:08 - __main__ - INFO - Epoch [63/100]
2023-03-07 15:55:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 15:55:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 15:55:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 15:55:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:55:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:55:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:55:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 15:56:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 15:56:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:56:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 15:56:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 15:56:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 15:56:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0073, Loss_2: 0.0068, Acc_1: 0.8320, Acc_2: 0.7829, F1-score_1: 0.7996, F1-score_2: 0.7163
2023-03-07 15:56:46 - __main__ - INFO - Epoch [64/100]
2023-03-07 15:56:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 15:56:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 15:57:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-07 15:57:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 15:57:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 15:57:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 15:57:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 15:57:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 15:57:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 15:57:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 15:58:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 15:58:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:58:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0053, Loss_2: 0.0054, Acc_1: 0.8395, Acc_2: 0.7923, F1-score_1: 0.7995, F1-score_2: 0.7242
2023-03-07 15:58:23 - __main__ - INFO - Epoch [65/100]
2023-03-07 15:58:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-07 15:58:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 15:58:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 15:58:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 15:58:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 15:59:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 15:59:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 15:59:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 15:59:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-07 15:59:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 15:59:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 15:59:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 16:00:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0054, Loss_2: 0.0066, Acc_1: 0.8410, Acc_2: 0.7930, F1-score_1: 0.7917, F1-score_2: 0.7259
2023-03-07 16:00:01 - __main__ - INFO - Epoch [66/100]
2023-03-07 16:00:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:00:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 16:00:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 16:00:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 16:00:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:00:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 16:00:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 16:00:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 16:01:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 16:01:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:01:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 16:01:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 16:01:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0044, Loss_2: 0.0039, Acc_1: 0.8291, Acc_2: 0.7979, F1-score_1: 0.7833, F1-score_2: 0.7333
2023-03-07 16:01:39 - __main__ - INFO - Epoch [67/100]
2023-03-07 16:01:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 16:01:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 16:01:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 16:02:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:02:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 16:02:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 16:02:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 16:02:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 16:02:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 16:02:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 16:02:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0082, Loss_2: 0.0036, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-07 16:02:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 16:03:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0062, Loss_2: 0.0053, Acc_1: 0.8224, Acc_2: 0.7930, F1-score_1: 0.7835, F1-score_2: 0.7251
2023-03-07 16:03:16 - __main__ - INFO - Epoch [68/100]
2023-03-07 16:03:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:03:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 16:03:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 16:03:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-07 16:03:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 16:03:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:04:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 16:04:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:04:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 16:04:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:04:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:04:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 16:04:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0064, Loss_2: 0.0058, Acc_1: 0.8280, Acc_2: 0.7884, F1-score_1: 0.7783, F1-score_2: 0.7259
2023-03-07 16:04:54 - __main__ - INFO - Epoch [69/100]
2023-03-07 16:04:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:05:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 16:05:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 16:05:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 16:05:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:05:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 16:05:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 16:05:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 16:05:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 16:06:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:06:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 16:06:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 16:06:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0050, Loss_2: 0.0053, Acc_1: 0.8393, Acc_2: 0.7916, F1-score_1: 0.7937, F1-score_2: 0.7261
2023-03-07 16:06:31 - __main__ - INFO - Epoch [70/100]
2023-03-07 16:06:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:06:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:06:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 16:06:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 16:07:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 16:07:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 16:07:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 16:07:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 16:07:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-07 16:07:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:07:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:07:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:08:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0061, Loss_2: 0.0055, Acc_1: 0.8417, Acc_2: 0.7901, F1-score_1: 0.7962, F1-score_2: 0.7236
2023-03-07 16:08:08 - __main__ - INFO - Epoch [71/100]
2023-03-07 16:08:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:08:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 16:08:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:08:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 16:08:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 16:08:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 16:08:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 16:09:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 16:09:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:09:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 16:09:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9375, 
2023-03-07 16:09:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 16:09:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0063, Loss_2: 0.0050, Acc_1: 0.8196, Acc_2: 0.7872, F1-score_1: 0.7767, F1-score_2: 0.7168
2023-03-07 16:09:46 - __main__ - INFO - Epoch [72/100]
2023-03-07 16:09:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:09:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 16:10:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:10:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:10:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 16:10:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 16:10:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:10:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 16:10:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 16:10:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:11:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:11:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:11:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0060, Loss_2: 0.0045, Acc_1: 0.8375, Acc_2: 0.7953, F1-score_1: 0.7921, F1-score_2: 0.7286
2023-03-07 16:11:23 - __main__ - INFO - Epoch [73/100]
2023-03-07 16:11:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:11:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:11:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 16:11:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 16:11:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:12:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:12:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 16:12:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-07 16:12:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:12:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:12:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 16:12:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 16:13:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0069, Loss_2: 0.0056, Acc_1: 0.8310, Acc_2: 0.7821, F1-score_1: 0.7857, F1-score_2: 0.7171
2023-03-07 16:13:01 - __main__ - INFO - Epoch [74/100]
2023-03-07 16:13:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 16:13:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-07 16:13:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 16:13:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:13:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9219, 
2023-03-07 16:13:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:13:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 16:13:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 16:14:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 16:14:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:14:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-07 16:14:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 16:14:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0072, Loss_2: 0.0060, Acc_1: 0.8339, Acc_2: 0.7894, F1-score_1: 0.7872, F1-score_2: 0.7262
2023-03-07 16:14:38 - __main__ - INFO - Epoch [75/100]
2023-03-07 16:14:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:14:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:14:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 16:15:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-07 16:15:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:15:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 16:15:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 16:15:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 16:15:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:15:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-07 16:15:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:15:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:16:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0075, Loss_2: 0.0060, Acc_1: 0.8395, Acc_2: 0.7950, F1-score_1: 0.7953, F1-score_2: 0.7263
2023-03-07 16:16:15 - __main__ - INFO - Epoch [76/100]
2023-03-07 16:16:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 16:16:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-07 16:16:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 16:16:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 16:16:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:16:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:17:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 16:17:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 16:17:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 16:17:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 16:17:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 16:17:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 16:17:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0062, Loss_2: 0.0059, Acc_1: 0.8388, Acc_2: 0.7914, F1-score_1: 0.7924, F1-score_2: 0.7239
2023-03-07 16:17:53 - __main__ - INFO - Epoch [77/100]
2023-03-07 16:17:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 16:18:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:18:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:18:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 16:18:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 16:18:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 16:18:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 16:18:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:18:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 16:19:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 16:19:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:19:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 16:19:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0074, Loss_2: 0.0069, Acc_1: 0.8376, Acc_2: 0.7899, F1-score_1: 0.7952, F1-score_2: 0.7267
2023-03-07 16:19:30 - __main__ - INFO - Epoch [78/100]
2023-03-07 16:19:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 16:19:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:19:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 16:19:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:20:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:20:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 16:20:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:20:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 16:20:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:20:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:20:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 16:20:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 16:21:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0072, Loss_2: 0.0074, Acc_1: 0.8370, Acc_2: 0.7953, F1-score_1: 0.7939, F1-score_2: 0.7312
2023-03-07 16:21:08 - __main__ - INFO - Epoch [79/100]
2023-03-07 16:21:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:21:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 16:21:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:21:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 16:21:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:21:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-07 16:21:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 16:22:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:22:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 16:22:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:22:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 16:22:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-07 16:22:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0084, Loss_2: 0.0087, Acc_1: 0.8308, Acc_2: 0.7865, F1-score_1: 0.7846, F1-score_2: 0.7216
2023-03-07 16:22:45 - __main__ - INFO - Epoch [80/100]
2023-03-07 16:22:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 16:22:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9141, 
2023-03-07 16:23:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 16:23:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:23:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 16:23:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 16:23:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 16:23:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 16:23:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:23:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:24:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 16:24:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:24:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0089, Loss_2: 0.0065, Acc_1: 0.8308, Acc_2: 0.7909, F1-score_1: 0.7921, F1-score_2: 0.7224
2023-03-07 16:24:23 - __main__ - INFO - Epoch [81/100]
2023-03-07 16:24:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 16:24:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 16:24:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:24:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 16:24:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:25:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:25:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 16:25:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 16:25:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:25:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 16:25:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 16:25:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 16:26:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0072, Loss_2: 0.0067, Acc_1: 0.8271, Acc_2: 0.7925, F1-score_1: 0.7852, F1-score_2: 0.7267
2023-03-07 16:26:00 - __main__ - INFO - Epoch [82/100]
2023-03-07 16:26:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 16:26:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 16:26:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:26:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 16:26:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 16:26:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:26:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:26:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 16:27:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 16:27:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 16:27:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:27:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 16:27:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0061, Acc_1: 0.8356, Acc_2: 0.7981, F1-score_1: 0.7932, F1-score_2: 0.7296
2023-03-07 16:27:37 - __main__ - INFO - Epoch [83/100]
2023-03-07 16:27:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:27:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 16:27:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 16:28:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 16:28:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:28:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 16:28:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:28:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 16:28:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:28:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:28:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 16:28:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:29:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0054, Loss_2: 0.0062, Acc_1: 0.8363, Acc_2: 0.8015, F1-score_1: 0.7903, F1-score_2: 0.7350
2023-03-07 16:29:15 - __main__ - INFO - Epoch [84/100]
2023-03-07 16:29:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 16:29:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 16:29:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:29:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 16:29:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 16:29:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 16:30:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:30:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:30:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 16:30:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 16:30:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:30:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:30:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0069, Loss_2: 0.0067, Acc_1: 0.8317, Acc_2: 0.7948, F1-score_1: 0.7891, F1-score_2: 0.7258
2023-03-07 16:30:52 - __main__ - INFO - Epoch [85/100]
2023-03-07 16:30:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 16:31:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:31:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 16:31:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:31:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-07 16:31:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:31:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:31:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:31:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:32:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 16:32:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 16:32:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:32:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0075, Loss_2: 0.0068, Acc_1: 0.8354, Acc_2: 0.7919, F1-score_1: 0.7851, F1-score_2: 0.7242
2023-03-07 16:32:30 - __main__ - INFO - Epoch [86/100]
2023-03-07 16:32:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 16:32:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:32:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 16:32:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:33:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 16:33:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:33:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:33:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 16:33:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 16:33:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 16:33:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:33:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 16:34:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0074, Loss_2: 0.0064, Acc_1: 0.8322, Acc_2: 0.7942, F1-score_1: 0.7845, F1-score_2: 0.7253
2023-03-07 16:34:07 - __main__ - INFO - Epoch [87/100]
2023-03-07 16:34:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 16:34:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 16:34:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 16:34:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 16:34:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 16:34:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 16:34:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:35:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 16:35:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 16:35:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-07 16:35:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:35:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 16:35:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0083, Loss_2: 0.0064, Acc_1: 0.8351, Acc_2: 0.7957, F1-score_1: 0.7896, F1-score_2: 0.7286
2023-03-07 16:35:44 - __main__ - INFO - Epoch [88/100]
2023-03-07 16:35:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 16:35:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:36:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:36:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 16:36:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:36:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:36:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 16:36:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:36:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 16:36:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:36:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 16:37:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 16:37:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0085, Loss_2: 0.0065, Acc_1: 0.8336, Acc_2: 0.7969, F1-score_1: 0.7891, F1-score_2: 0.7274
2023-03-07 16:37:22 - __main__ - INFO - Epoch [89/100]
2023-03-07 16:37:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 16:37:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:37:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-07 16:37:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:37:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:38:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:38:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 16:38:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 16:38:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:38:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 16:38:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 16:38:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:38:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0079, Loss_2: 0.0066, Acc_1: 0.8358, Acc_2: 0.7928, F1-score_1: 0.7921, F1-score_2: 0.7248
2023-03-07 16:38:59 - __main__ - INFO - Epoch [90/100]
2023-03-07 16:39:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 16:39:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 16:39:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 16:39:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:39:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 16:39:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:39:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 16:39:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 16:39:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:40:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:40:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:40:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:40:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0079, Loss_2: 0.0066, Acc_1: 0.8371, Acc_2: 0.7911, F1-score_1: 0.7916, F1-score_2: 0.7242
2023-03-07 16:40:36 - __main__ - INFO - Epoch [91/100]
2023-03-07 16:40:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 16:40:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 16:40:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 16:41:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 16:41:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 16:41:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-07 16:41:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:41:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 16:41:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:41:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:41:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:41:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:42:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0069, Loss_2: 0.0063, Acc_1: 0.8370, Acc_2: 0.7901, F1-score_1: 0.7919, F1-score_2: 0.7237
2023-03-07 16:42:13 - __main__ - INFO - Epoch [92/100]
2023-03-07 16:42:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:42:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 16:42:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 16:42:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:42:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 16:42:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-07 16:43:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 16:43:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 16:43:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 16:43:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 16:43:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 16:43:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-07 16:43:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0061, Loss_2: 0.0057, Acc_1: 0.8336, Acc_2: 0.7959, F1-score_1: 0.7896, F1-score_2: 0.7311
2023-03-07 16:43:51 - __main__ - INFO - Epoch [93/100]
2023-03-07 16:43:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:44:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:44:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 16:44:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:44:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 16:44:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:44:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:44:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:44:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:44:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:45:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:45:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 16:45:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0082, Loss_2: 0.0052, Acc_1: 0.8341, Acc_2: 0.7950, F1-score_1: 0.7892, F1-score_2: 0.7284
2023-03-07 16:45:28 - __main__ - INFO - Epoch [94/100]
2023-03-07 16:45:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:45:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:45:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:45:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 16:46:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 16:46:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:46:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 16:46:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:46:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 16:46:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 16:46:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 16:46:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 16:47:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0068, Loss_2: 0.0052, Acc_1: 0.8337, Acc_2: 0.7957, F1-score_1: 0.7876, F1-score_2: 0.7291
2023-03-07 16:47:06 - __main__ - INFO - Epoch [95/100]
2023-03-07 16:47:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 16:47:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:47:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 16:47:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 16:47:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 16:47:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 16:47:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 16:48:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:48:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:48:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:48:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 16:48:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 16:48:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0067, Loss_2: 0.0052, Acc_1: 0.8349, Acc_2: 0.7962, F1-score_1: 0.7896, F1-score_2: 0.7293
2023-03-07 16:48:43 - __main__ - INFO - Epoch [96/100]
2023-03-07 16:48:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 16:48:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 16:49:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:49:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 16:49:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 16:49:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 16:49:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:49:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 16:49:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:49:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:49:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 16:50:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 16:50:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0081, Loss_2: 0.0051, Acc_1: 0.8329, Acc_2: 0.7896, F1-score_1: 0.7870, F1-score_2: 0.7206
2023-03-07 16:50:21 - __main__ - INFO - Epoch [97/100]
2023-03-07 16:50:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:50:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:50:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:50:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-07 16:50:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:51:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 16:51:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 16:51:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 16:51:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:51:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 16:51:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 16:51:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 16:51:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0064, Loss_2: 0.0051, Acc_1: 0.8337, Acc_2: 0.7903, F1-score_1: 0.7881, F1-score_2: 0.7210
2023-03-07 16:51:58 - __main__ - INFO - Epoch [98/100]
2023-03-07 16:52:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9453, 
2023-03-07 16:52:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 16:52:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 16:52:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 16:52:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 16:52:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 16:52:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 16:52:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 16:52:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 16:53:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 16:53:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 16:53:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 16:53:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0080, Loss_2: 0.0053, Acc_1: 0.8339, Acc_2: 0.7897, F1-score_1: 0.7888, F1-score_2: 0.7214
2023-03-07 16:53:36 - __main__ - INFO - Epoch [99/100]
2023-03-07 16:53:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:53:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 16:53:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:54:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 16:54:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:54:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 16:54:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 16:54:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 16:54:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 16:54:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 16:54:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 16:54:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 16:55:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0080, Loss_2: 0.0053, Acc_1: 0.8325, Acc_2: 0.7897, F1-score_1: 0.7866, F1-score_2: 0.7209
2023-03-07 16:55:15 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 16:55:15 - utils._noise - DEBUG - 6, 7
2023-03-07 16:55:15 - utils._noise - DEBUG - 13997
2023-03-07 16:55:16 - utils._noise - INFO - Actual noise 0.20
2023-03-07 16:55:16 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-07 16:55:16 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-07 16:55:17 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 16:55:17 - __main__ - INFO - Loading dataset...
2023-03-07 16:55:17 - __main__ - INFO - Building model...
2023-03-07 16:55:17 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-07 16:55:18 - __main__ - INFO - <bound method Module.parameters of NewsNet(
  (embedding): Embedding(20000, 300)
  (avgpool): AdaptiveAvgPool1d(output_size=4800)
  (fc1): Linear(in_features=4800, out_features=1200, bias=True)
  (bn1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ac): Softsign()
  (fc2): Linear(in_features=1200, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=7, bias=True)
)>
2023-03-07 16:55:18 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-07 16:55:18 - __main__ - INFO - Start train & evaluate
2023-03-07 16:55:18 - __main__ - INFO - Epoch [0/100]
2023-03-07 16:55:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0161, Loss_2: 0.0153, Acc_1: 0.1250, Acc_2: 0.1797, 
2023-03-07 16:55:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0131, Loss_2: 0.0142, Acc_1: 0.3516, Acc_2: 0.2969, 
2023-03-07 16:55:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0109, Loss_2: 0.0130, Acc_1: 0.5625, Acc_2: 0.4062, 
2023-03-07 16:55:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0095, Loss_2: 0.0133, Acc_1: 0.6328, Acc_2: 0.3594, 
2023-03-07 16:55:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0093, Loss_2: 0.0136, Acc_1: 0.6484, Acc_2: 0.3516, 
2023-03-07 16:55:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0087, Loss_2: 0.0139, Acc_1: 0.6406, Acc_2: 0.3828, 
2023-03-07 16:55:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0095, Loss_2: 0.0130, Acc_1: 0.6797, Acc_2: 0.3594, 
2023-03-07 16:55:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0110, Loss_2: 0.0141, Acc_1: 0.5938, Acc_2: 0.3359, 
2023-03-07 16:55:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0094, Loss_2: 0.0126, Acc_1: 0.6641, Acc_2: 0.4375, 
2023-03-07 16:55:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0093, Loss_2: 0.0130, Acc_1: 0.6641, Acc_2: 0.3984, 
2023-03-07 16:55:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0101, Loss_2: 0.0138, Acc_1: 0.6562, Acc_2: 0.2969, 
2023-03-07 16:56:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0110, Loss_2: 0.0137, Acc_1: 0.6250, Acc_2: 0.3750, 
2023-03-07 16:56:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0056, Loss_2: 0.0121, Acc_1: 0.8514, Acc_2: 0.4648, F1-score_1: 0.7890, F1-score_2: 0.2842
2023-03-07 16:56:16 - __main__ - INFO - Epoch [1/100]
2023-03-07 16:56:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0081, Loss_2: 0.0114, Acc_1: 0.6797, Acc_2: 0.5391, 
2023-03-07 16:56:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0075, Loss_2: 0.0118, Acc_1: 0.7188, Acc_2: 0.4062, 
2023-03-07 16:56:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0085, Loss_2: 0.0114, Acc_1: 0.6797, Acc_2: 0.4922, 
2023-03-07 16:56:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0082, Loss_2: 0.0126, Acc_1: 0.7188, Acc_2: 0.4766, 
2023-03-07 16:56:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0087, Loss_2: 0.0119, Acc_1: 0.6875, Acc_2: 0.4062, 
2023-03-07 16:56:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0078, Loss_2: 0.0128, Acc_1: 0.6875, Acc_2: 0.3906, 
2023-03-07 16:56:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0063, Loss_2: 0.0113, Acc_1: 0.7734, Acc_2: 0.5000, 
2023-03-07 16:56:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0072, Loss_2: 0.0116, Acc_1: 0.7344, Acc_2: 0.4141, 
2023-03-07 16:56:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0066, Loss_2: 0.0113, Acc_1: 0.7344, Acc_2: 0.4844, 
2023-03-07 16:56:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0081, Loss_2: 0.0122, Acc_1: 0.7109, Acc_2: 0.5078, 
2023-03-07 16:56:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0064, Loss_2: 0.0127, Acc_1: 0.8047, Acc_2: 0.4219, 
2023-03-07 16:57:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0090, Loss_2: 0.0128, Acc_1: 0.6953, Acc_2: 0.3438, 
2023-03-07 16:57:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0049, Loss_2: 0.0122, Acc_1: 0.8740, Acc_2: 0.4604, F1-score_1: 0.8333, F1-score_2: 0.3054
2023-03-07 16:57:13 - __main__ - INFO - Epoch [2/100]
2023-03-07 16:57:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0055, Loss_2: 0.0103, Acc_1: 0.7812, Acc_2: 0.5234, 
2023-03-07 16:57:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0065, Loss_2: 0.0097, Acc_1: 0.7422, Acc_2: 0.5781, 
2023-03-07 16:57:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0052, Loss_2: 0.0096, Acc_1: 0.7656, Acc_2: 0.5547, 
2023-03-07 16:57:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0055, Loss_2: 0.0104, Acc_1: 0.7891, Acc_2: 0.4922, 
2023-03-07 16:57:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0057, Loss_2: 0.0117, Acc_1: 0.8125, Acc_2: 0.4375, 
2023-03-07 16:57:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0047, Loss_2: 0.0111, Acc_1: 0.7891, Acc_2: 0.4766, 
2023-03-07 16:57:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0064, Loss_2: 0.0102, Acc_1: 0.7812, Acc_2: 0.5312, 
2023-03-07 16:57:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0065, Loss_2: 0.0109, Acc_1: 0.7578, Acc_2: 0.5312, 
2023-03-07 16:57:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0053, Loss_2: 0.0113, Acc_1: 0.8203, Acc_2: 0.4453, 
2023-03-07 16:57:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0058, Loss_2: 0.0116, Acc_1: 0.7578, Acc_2: 0.4453, 
2023-03-07 16:57:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0053, Loss_2: 0.0109, Acc_1: 0.7734, Acc_2: 0.5234, 
2023-03-07 16:57:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0061, Loss_2: 0.0118, Acc_1: 0.7656, Acc_2: 0.4219, 
2023-03-07 16:58:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0126, Acc_1: 0.8760, Acc_2: 0.4453, F1-score_1: 0.8324, F1-score_2: 0.3195
2023-03-07 16:58:11 - __main__ - INFO - Epoch [3/100]
2023-03-07 16:58:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0043, Loss_2: 0.0101, Acc_1: 0.8125, Acc_2: 0.5312, 
2023-03-07 16:58:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0035, Loss_2: 0.0088, Acc_1: 0.8516, Acc_2: 0.5547, 
2023-03-07 16:58:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0038, Loss_2: 0.0100, Acc_1: 0.8281, Acc_2: 0.5469, 
2023-03-07 16:58:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0039, Loss_2: 0.0091, Acc_1: 0.8359, Acc_2: 0.5625, 
2023-03-07 16:58:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0043, Loss_2: 0.0092, Acc_1: 0.8047, Acc_2: 0.5547, 
2023-03-07 16:58:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0039, Loss_2: 0.0103, Acc_1: 0.8359, Acc_2: 0.4844, 
2023-03-07 16:58:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0040, Loss_2: 0.0091, Acc_1: 0.8047, Acc_2: 0.5859, 
2023-03-07 16:58:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0041, Loss_2: 0.0099, Acc_1: 0.7734, Acc_2: 0.5000, 
2023-03-07 16:58:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0049, Loss_2: 0.0119, Acc_1: 0.7422, Acc_2: 0.4609, 
2023-03-07 16:58:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0041, Loss_2: 0.0102, Acc_1: 0.8203, Acc_2: 0.4844, 
2023-03-07 16:58:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0041, Loss_2: 0.0099, Acc_1: 0.8125, Acc_2: 0.5625, 
2023-03-07 16:58:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0046, Loss_2: 0.0105, Acc_1: 0.7734, Acc_2: 0.4453, 
2023-03-07 16:59:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0140, Acc_1: 0.8650, Acc_2: 0.4377, F1-score_1: 0.8290, F1-score_2: 0.3472
2023-03-07 16:59:09 - __main__ - INFO - Epoch [4/100]
2023-03-07 16:59:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0020, Loss_2: 0.0076, Acc_1: 0.8984, Acc_2: 0.6641, 
2023-03-07 16:59:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0014, Loss_2: 0.0087, Acc_1: 0.9297, Acc_2: 0.6250, 
2023-03-07 16:59:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0018, Loss_2: 0.0072, Acc_1: 0.8828, Acc_2: 0.6406, 
2023-03-07 16:59:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0029, Loss_2: 0.0082, Acc_1: 0.8281, Acc_2: 0.6016, 
2023-03-07 16:59:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0037, Loss_2: 0.0092, Acc_1: 0.8047, Acc_2: 0.5547, 
2023-03-07 16:59:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0032, Loss_2: 0.0102, Acc_1: 0.8438, Acc_2: 0.5625, 
2023-03-07 16:59:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0027, Loss_2: 0.0090, Acc_1: 0.8750, Acc_2: 0.5938, 
2023-03-07 16:59:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0024, Loss_2: 0.0083, Acc_1: 0.8828, Acc_2: 0.6250, 
2023-03-07 16:59:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0033, Loss_2: 0.0095, Acc_1: 0.8281, Acc_2: 0.6016, 
2023-03-07 16:59:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0027, Loss_2: 0.0079, Acc_1: 0.8906, Acc_2: 0.6406, 
2023-03-07 16:59:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0023, Loss_2: 0.0089, Acc_1: 0.8828, Acc_2: 0.6172, 
2023-03-07 16:59:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0022, Loss_2: 0.0076, Acc_1: 0.8828, Acc_2: 0.6094, 
2023-03-07 17:00:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0155, Acc_1: 0.8636, Acc_2: 0.4212, F1-score_1: 0.8223, F1-score_2: 0.3302
2023-03-07 17:00:06 - __main__ - INFO - Epoch [5/100]
2023-03-07 17:00:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0014, Loss_2: 0.0069, Acc_1: 0.9219, Acc_2: 0.7188, 
2023-03-07 17:00:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0020, Loss_2: 0.0075, Acc_1: 0.8906, Acc_2: 0.6484, 
2023-03-07 17:00:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0009, Loss_2: 0.0068, Acc_1: 0.9375, Acc_2: 0.7031, 
2023-03-07 17:00:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0014, Loss_2: 0.0068, Acc_1: 0.9219, Acc_2: 0.6719, 
2023-03-07 17:00:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0015, Loss_2: 0.0071, Acc_1: 0.8984, Acc_2: 0.6484, 
2023-03-07 17:00:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0023, Loss_2: 0.0097, Acc_1: 0.8984, Acc_2: 0.5391, 
2023-03-07 17:00:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0086, Acc_1: 0.9219, Acc_2: 0.5547, 
2023-03-07 17:00:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0012, Loss_2: 0.0084, Acc_1: 0.8750, Acc_2: 0.6016, 
2023-03-07 17:00:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0016, Loss_2: 0.0078, Acc_1: 0.9141, Acc_2: 0.5391, 
2023-03-07 17:00:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0014, Loss_2: 0.0083, Acc_1: 0.9141, Acc_2: 0.5938, 
2023-03-07 17:00:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0021, Loss_2: 0.0084, Acc_1: 0.8750, Acc_2: 0.6328, 
2023-03-07 17:00:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0026, Loss_2: 0.0095, Acc_1: 0.8672, Acc_2: 0.5234, 
2023-03-07 17:01:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0158, Acc_1: 0.8482, Acc_2: 0.4198, F1-score_1: 0.8104, F1-score_2: 0.3270
2023-03-07 17:01:04 - __main__ - INFO - Epoch [6/100]
2023-03-07 17:01:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0063, Acc_1: 0.8984, Acc_2: 0.7109, 
2023-03-07 17:01:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0012, Loss_2: 0.0072, Acc_1: 0.9219, Acc_2: 0.7031, 
2023-03-07 17:01:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0013, Loss_2: 0.0071, Acc_1: 0.8906, Acc_2: 0.6797, 
2023-03-07 17:01:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0063, Acc_1: 0.9375, Acc_2: 0.7188, 
2023-03-07 17:01:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0011, Loss_2: 0.0081, Acc_1: 0.9141, Acc_2: 0.6016, 
2023-03-07 17:01:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0014, Loss_2: 0.0080, Acc_1: 0.8906, Acc_2: 0.5703, 
2023-03-07 17:01:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0017, Loss_2: 0.0073, Acc_1: 0.8828, Acc_2: 0.6484, 
2023-03-07 17:01:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0016, Loss_2: 0.0086, Acc_1: 0.9062, Acc_2: 0.5859, 
2023-03-07 17:01:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0012, Loss_2: 0.0085, Acc_1: 0.8906, Acc_2: 0.5938, 
2023-03-07 17:01:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0024, Loss_2: 0.0083, Acc_1: 0.8906, Acc_2: 0.5938, 
2023-03-07 17:01:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0088, Acc_1: 0.8828, Acc_2: 0.5703, 
2023-03-07 17:01:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0018, Loss_2: 0.0086, Acc_1: 0.8750, Acc_2: 0.5625, 
2023-03-07 17:02:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0048, Loss_2: 0.0177, Acc_1: 0.8434, Acc_2: 0.4078, F1-score_1: 0.8006, F1-score_2: 0.3148
2023-03-07 17:02:02 - __main__ - INFO - Epoch [7/100]
2023-03-07 17:02:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0066, Acc_1: 0.8750, Acc_2: 0.6406, 
2023-03-07 17:02:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0066, Acc_1: 0.9219, Acc_2: 0.6406, 
2023-03-07 17:02:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0062, Acc_1: 0.9219, Acc_2: 0.6953, 
2023-03-07 17:02:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0056, Acc_1: 0.9375, Acc_2: 0.6953, 
2023-03-07 17:02:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0013, Loss_2: 0.0075, Acc_1: 0.9062, Acc_2: 0.6172, 
2023-03-07 17:02:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0067, Acc_1: 0.9062, Acc_2: 0.6641, 
2023-03-07 17:02:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0015, Loss_2: 0.0060, Acc_1: 0.9062, Acc_2: 0.6875, 
2023-03-07 17:02:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0058, Acc_1: 0.9062, Acc_2: 0.7109, 
2023-03-07 17:02:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0064, Acc_1: 0.9609, Acc_2: 0.7031, 
2023-03-07 17:02:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0010, Loss_2: 0.0073, Acc_1: 0.9531, Acc_2: 0.6250, 
2023-03-07 17:02:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0077, Acc_1: 0.9219, Acc_2: 0.6094, 
2023-03-07 17:02:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0080, Acc_1: 0.9375, Acc_2: 0.6406, 
2023-03-07 17:03:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0051, Loss_2: 0.0179, Acc_1: 0.8480, Acc_2: 0.4200, F1-score_1: 0.8081, F1-score_2: 0.3255
2023-03-07 17:03:00 - __main__ - INFO - Epoch [8/100]
2023-03-07 17:03:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0050, Acc_1: 0.8906, Acc_2: 0.7031, 
2023-03-07 17:03:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0047, Acc_1: 0.8828, Acc_2: 0.7188, 
2023-03-07 17:03:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0067, Acc_1: 0.9531, Acc_2: 0.6797, 
2023-03-07 17:03:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0056, Acc_1: 0.9531, Acc_2: 0.7422, 
2023-03-07 17:03:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0055, Acc_1: 0.9375, Acc_2: 0.7266, 
2023-03-07 17:03:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0012, Loss_2: 0.0066, Acc_1: 0.8984, Acc_2: 0.6875, 
2023-03-07 17:03:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0069, Acc_1: 0.9219, Acc_2: 0.6406, 
2023-03-07 17:03:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0077, Acc_1: 0.8906, Acc_2: 0.5938, 
2023-03-07 17:03:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0069, Acc_1: 0.9062, Acc_2: 0.6250, 
2023-03-07 17:03:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0011, Loss_2: 0.0065, Acc_1: 0.9141, Acc_2: 0.6484, 
2023-03-07 17:03:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0069, Acc_1: 0.9297, Acc_2: 0.7109, 
2023-03-07 17:03:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0065, Acc_1: 0.8906, Acc_2: 0.6328, 
2023-03-07 17:03:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0054, Loss_2: 0.0201, Acc_1: 0.8511, Acc_2: 0.4127, F1-score_1: 0.8135, F1-score_2: 0.3106
2023-03-07 17:03:57 - __main__ - INFO - Epoch [9/100]
2023-03-07 17:04:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0049, Acc_1: 0.9531, Acc_2: 0.8125, 
2023-03-07 17:04:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0056, Acc_1: 0.9062, Acc_2: 0.7031, 
2023-03-07 17:04:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0014, Loss_2: 0.0045, Acc_1: 0.9141, Acc_2: 0.7578, 
2023-03-07 17:04:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0046, Acc_1: 0.9531, Acc_2: 0.7422, 
2023-03-07 17:04:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0058, Acc_1: 0.9219, Acc_2: 0.7500, 
2023-03-07 17:04:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0051, Acc_1: 0.8984, Acc_2: 0.6797, 
2023-03-07 17:04:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0017, Loss_2: 0.0053, Acc_1: 0.9219, Acc_2: 0.7188, 
2023-03-07 17:04:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0065, Acc_1: 0.9453, Acc_2: 0.6797, 
2023-03-07 17:04:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0072, Acc_1: 0.9062, Acc_2: 0.6641, 
2023-03-07 17:04:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0062, Acc_1: 0.9219, Acc_2: 0.7109, 
2023-03-07 17:04:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0058, Acc_1: 0.9219, Acc_2: 0.7109, 
2023-03-07 17:04:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0051, Acc_1: 0.9297, Acc_2: 0.7266, 
2023-03-07 17:04:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0048, Loss_2: 0.0211, Acc_1: 0.8528, Acc_2: 0.3945, F1-score_1: 0.8104, F1-score_2: 0.3108
2023-03-07 17:04:55 - __main__ - INFO - Epoch [10/100]
2023-03-07 17:05:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0035, Acc_1: 0.9609, Acc_2: 0.7891, 
2023-03-07 17:05:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0032, Acc_1: 0.8906, Acc_2: 0.7734, 
2023-03-07 17:05:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0037, Acc_1: 0.9453, Acc_2: 0.7734, 
2023-03-07 17:05:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0051, Acc_1: 0.8984, Acc_2: 0.7266, 
2023-03-07 17:05:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0053, Acc_1: 0.9375, Acc_2: 0.7188, 
2023-03-07 17:05:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0054, Acc_1: 0.9219, Acc_2: 0.7266, 
2023-03-07 17:05:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0043, Acc_1: 0.8984, Acc_2: 0.7422, 
2023-03-07 17:05:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0044, Acc_1: 0.9453, Acc_2: 0.7812, 
2023-03-07 17:05:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0013, Loss_2: 0.0054, Acc_1: 0.8906, Acc_2: 0.6875, 
2023-03-07 17:05:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0040, Acc_1: 0.8984, Acc_2: 0.7656, 
2023-03-07 17:05:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0046, Acc_1: 0.8984, Acc_2: 0.7031, 
2023-03-07 17:05:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0049, Acc_1: 0.9219, Acc_2: 0.6797, 
2023-03-07 17:05:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0061, Loss_2: 0.0248, Acc_1: 0.8494, Acc_2: 0.4098, F1-score_1: 0.8095, F1-score_2: 0.3270
2023-03-07 17:05:53 - __main__ - INFO - Epoch [11/100]
2023-03-07 17:05:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0039, Acc_1: 0.9297, Acc_2: 0.7656, 
2023-03-07 17:06:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0034, Acc_1: 0.9531, Acc_2: 0.8125, 
2023-03-07 17:06:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0038, Acc_1: 0.9141, Acc_2: 0.7188, 
2023-03-07 17:06:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0049, Acc_1: 0.9219, Acc_2: 0.7188, 
2023-03-07 17:06:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0042, Acc_1: 0.9453, Acc_2: 0.7500, 
2023-03-07 17:06:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0043, Acc_1: 0.9297, Acc_2: 0.7656, 
2023-03-07 17:06:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0048, Acc_1: 0.8828, Acc_2: 0.6797, 
2023-03-07 17:06:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0049, Acc_1: 0.9219, Acc_2: 0.6797, 
2023-03-07 17:06:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0042, Acc_1: 0.9375, Acc_2: 0.7344, 
2023-03-07 17:06:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0046, Acc_1: 0.9453, Acc_2: 0.7266, 
2023-03-07 17:06:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0039, Acc_1: 0.9531, Acc_2: 0.7656, 
2023-03-07 17:06:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0013, Loss_2: 0.0041, Acc_1: 0.8906, Acc_2: 0.7266, 
2023-03-07 17:06:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0066, Loss_2: 0.0227, Acc_1: 0.8497, Acc_2: 0.4103, F1-score_1: 0.8092, F1-score_2: 0.3352
2023-03-07 17:06:50 - __main__ - INFO - Epoch [12/100]
2023-03-07 17:06:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0036, Acc_1: 0.8828, Acc_2: 0.7422, 
2023-03-07 17:06:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0009, Loss_2: 0.0041, Acc_1: 0.9375, Acc_2: 0.7891, 
2023-03-07 17:07:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0029, Acc_1: 0.9219, Acc_2: 0.7812, 
2023-03-07 17:07:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0034, Acc_1: 0.8828, Acc_2: 0.7500, 
2023-03-07 17:07:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0036, Acc_1: 0.9531, Acc_2: 0.8281, 
2023-03-07 17:07:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0028, Acc_1: 0.9297, Acc_2: 0.7969, 
2023-03-07 17:07:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0029, Acc_1: 0.8984, Acc_2: 0.7422, 
2023-03-07 17:07:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0037, Acc_1: 0.8906, Acc_2: 0.7422, 
2023-03-07 17:07:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0042, Acc_1: 0.9297, Acc_2: 0.7500, 
2023-03-07 17:07:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0036, Acc_1: 0.9141, Acc_2: 0.7422, 
2023-03-07 17:07:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0032, Acc_1: 0.9297, Acc_2: 0.7969, 
2023-03-07 17:07:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0043, Acc_1: 0.9297, Acc_2: 0.7656, 
2023-03-07 17:07:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0072, Loss_2: 0.0251, Acc_1: 0.8528, Acc_2: 0.3876, F1-score_1: 0.8149, F1-score_2: 0.3115
2023-03-07 17:07:48 - __main__ - INFO - Epoch [13/100]
2023-03-07 17:07:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0027, Acc_1: 0.9219, Acc_2: 0.8047, 
2023-03-07 17:07:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0023, Acc_1: 0.9531, Acc_2: 0.8672, 
2023-03-07 17:08:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0025, Acc_1: 0.9609, Acc_2: 0.8438, 
2023-03-07 17:08:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0024, Acc_1: 0.9297, Acc_2: 0.8359, 
2023-03-07 17:08:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0022, Acc_1: 0.9609, Acc_2: 0.8203, 
2023-03-07 17:08:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0028, Acc_1: 0.9141, Acc_2: 0.8203, 
2023-03-07 17:08:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0035, Acc_1: 0.9219, Acc_2: 0.7656, 
2023-03-07 17:08:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0033, Acc_1: 0.9219, Acc_2: 0.7500, 
2023-03-07 17:08:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0027, Acc_1: 0.9375, Acc_2: 0.8047, 
2023-03-07 17:08:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0035, Acc_1: 0.9219, Acc_2: 0.7969, 
2023-03-07 17:08:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0044, Acc_1: 0.9375, Acc_2: 0.8359, 
2023-03-07 17:08:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0037, Acc_1: 0.9375, Acc_2: 0.7656, 
2023-03-07 17:08:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0067, Loss_2: 0.0294, Acc_1: 0.8432, Acc_2: 0.3949, F1-score_1: 0.8050, F1-score_2: 0.3252
2023-03-07 17:08:46 - __main__ - INFO - Epoch [14/100]
2023-03-07 17:08:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0015, Acc_1: 0.9219, Acc_2: 0.8438, 
2023-03-07 17:08:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0029, Acc_1: 0.9531, Acc_2: 0.7891, 
2023-03-07 17:08:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0032, Acc_1: 0.9141, Acc_2: 0.7891, 
2023-03-07 17:09:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0026, Acc_1: 0.8984, Acc_2: 0.7812, 
2023-03-07 17:09:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0019, Acc_1: 0.9453, Acc_2: 0.8438, 
2023-03-07 17:09:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0022, Acc_1: 0.9219, Acc_2: 0.8203, 
2023-03-07 17:09:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0022, Acc_1: 0.9453, Acc_2: 0.8594, 
2023-03-07 17:09:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0027, Acc_1: 0.9062, Acc_2: 0.7891, 
2023-03-07 17:09:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0016, Acc_1: 0.8984, Acc_2: 0.8203, 
2023-03-07 17:09:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0032, Acc_1: 0.8828, Acc_2: 0.7578, 
2023-03-07 17:09:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0036, Acc_1: 0.8906, Acc_2: 0.7812, 
2023-03-07 17:09:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0025, Acc_1: 0.9141, Acc_2: 0.8125, 
2023-03-07 17:09:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0068, Loss_2: 0.0287, Acc_1: 0.8526, Acc_2: 0.4017, F1-score_1: 0.8158, F1-score_2: 0.3182
2023-03-07 17:09:43 - __main__ - INFO - Epoch [15/100]
2023-03-07 17:09:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0020, Acc_1: 0.9375, Acc_2: 0.8203, 
2023-03-07 17:09:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0020, Acc_1: 0.9219, Acc_2: 0.8125, 
2023-03-07 17:09:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0014, Loss_2: 0.0044, Acc_1: 0.9219, Acc_2: 0.6875, 
2023-03-07 17:09:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.8906, Acc_2: 0.8281, 
2023-03-07 17:10:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0031, Acc_1: 0.9062, Acc_2: 0.7266, 
2023-03-07 17:10:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0019, Acc_1: 0.9141, Acc_2: 0.8281, 
2023-03-07 17:10:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.8672, Acc_2: 0.7969, 
2023-03-07 17:10:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0019, Acc_1: 0.9297, Acc_2: 0.8438, 
2023-03-07 17:10:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0029, Acc_1: 0.8906, Acc_2: 0.7656, 
2023-03-07 17:10:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0035, Acc_1: 0.9219, Acc_2: 0.7734, 
2023-03-07 17:10:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0032, Acc_1: 0.9219, Acc_2: 0.7969, 
2023-03-07 17:10:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0023, Acc_1: 0.9062, Acc_2: 0.8047, 
2023-03-07 17:10:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0070, Loss_2: 0.0296, Acc_1: 0.8499, Acc_2: 0.3820, F1-score_1: 0.8119, F1-score_2: 0.3124
2023-03-07 17:10:41 - __main__ - INFO - Epoch [16/100]
2023-03-07 17:10:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0023, Acc_1: 0.9297, Acc_2: 0.7891, 
2023-03-07 17:10:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0020, Acc_1: 0.9375, Acc_2: 0.8516, 
2023-03-07 17:10:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-07 17:10:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0021, Acc_1: 0.9297, Acc_2: 0.8594, 
2023-03-07 17:11:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9297, Acc_2: 0.8594, 
2023-03-07 17:11:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0025, Acc_1: 0.9062, Acc_2: 0.7969, 
2023-03-07 17:11:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0021, Acc_1: 0.9219, Acc_2: 0.8281, 
2023-03-07 17:11:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0032, Acc_1: 0.8672, Acc_2: 0.7578, 
2023-03-07 17:11:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0029, Acc_1: 0.9062, Acc_2: 0.8047, 
2023-03-07 17:11:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0026, Acc_1: 0.8906, Acc_2: 0.7734, 
2023-03-07 17:11:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0028, Acc_1: 0.8906, Acc_2: 0.7812, 
2023-03-07 17:11:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0018, Acc_1: 0.9297, Acc_2: 0.8594, 
2023-03-07 17:11:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0070, Loss_2: 0.0295, Acc_1: 0.8470, Acc_2: 0.4025, F1-score_1: 0.8034, F1-score_2: 0.3127
2023-03-07 17:11:39 - __main__ - INFO - Epoch [17/100]
2023-03-07 17:11:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0021, Acc_1: 0.9375, Acc_2: 0.8359, 
2023-03-07 17:11:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9297, Acc_2: 0.8516, 
2023-03-07 17:11:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-07 17:11:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9219, Acc_2: 0.8047, 
2023-03-07 17:11:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9062, Acc_2: 0.8125, 
2023-03-07 17:12:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0017, Acc_1: 0.9297, Acc_2: 0.8672, 
2023-03-07 17:12:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9453, Acc_2: 0.8281, 
2023-03-07 17:12:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0024, Acc_1: 0.9688, Acc_2: 0.8281, 
2023-03-07 17:12:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9219, Acc_2: 0.8359, 
2023-03-07 17:12:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0017, Acc_1: 0.9609, Acc_2: 0.8594, 
2023-03-07 17:12:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0017, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-07 17:12:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0019, Acc_1: 0.9375, Acc_2: 0.8438, 
2023-03-07 17:12:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0060, Loss_2: 0.0315, Acc_1: 0.8473, Acc_2: 0.3986, F1-score_1: 0.8087, F1-score_2: 0.3213
2023-03-07 17:12:36 - __main__ - INFO - Epoch [18/100]
2023-03-07 17:12:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0023, Acc_1: 0.9297, Acc_2: 0.8516, 
2023-03-07 17:12:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0016, Acc_1: 0.8984, Acc_2: 0.8203, 
2023-03-07 17:12:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0022, Acc_1: 0.8984, Acc_2: 0.7891, 
2023-03-07 17:12:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9688, Acc_2: 0.8672, 
2023-03-07 17:12:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8828, Acc_2: 0.8203, 
2023-03-07 17:13:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.9062, Acc_2: 0.8438, 
2023-03-07 17:13:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.8594, Acc_2: 0.7734, 
2023-03-07 17:13:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0010, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 17:13:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9453, Acc_2: 0.8750, 
2023-03-07 17:13:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0016, Acc_1: 0.9375, Acc_2: 0.8750, 
2023-03-07 17:13:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0014, Acc_1: 0.9453, Acc_2: 0.8594, 
2023-03-07 17:13:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0018, Acc_1: 0.9141, Acc_2: 0.8359, 
2023-03-07 17:13:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0076, Loss_2: 0.0311, Acc_1: 0.8429, Acc_2: 0.3991, F1-score_1: 0.7982, F1-score_2: 0.3247
2023-03-07 17:13:34 - __main__ - INFO - Epoch [19/100]
2023-03-07 17:13:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 17:13:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 17:13:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 17:13:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9531, Acc_2: 0.8594, 
2023-03-07 17:13:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8203, 
2023-03-07 17:13:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0016, Acc_1: 0.9375, Acc_2: 0.8516, 
2023-03-07 17:14:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9219, Acc_2: 0.8516, 
2023-03-07 17:14:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0030, Acc_1: 0.9375, Acc_2: 0.8281, 
2023-03-07 17:14:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0020, Acc_1: 0.8594, Acc_2: 0.7734, 
2023-03-07 17:14:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9609, Acc_2: 0.8359, 
2023-03-07 17:14:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.8516, Acc_2: 0.7812, 
2023-03-07 17:14:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.9141, Acc_2: 0.8125, 
2023-03-07 17:14:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0064, Loss_2: 0.0383, Acc_1: 0.8451, Acc_2: 0.3988, F1-score_1: 0.8008, F1-score_2: 0.3251
2023-03-07 17:14:32 - __main__ - INFO - Epoch [20/100]
2023-03-07 17:14:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9375, Acc_2: 0.8828, 
2023-03-07 17:14:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9375, Acc_2: 0.8672, 
2023-03-07 17:14:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 17:14:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.9609, Acc_2: 0.9062, 
2023-03-07 17:14:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8750, Acc_2: 0.8047, 
2023-03-07 17:14:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9531, Acc_2: 0.8672, 
2023-03-07 17:14:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-07 17:15:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9453, Acc_2: 0.8594, 
2023-03-07 17:15:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9297, Acc_2: 0.8516, 
2023-03-07 17:15:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.9297, Acc_2: 0.8672, 
2023-03-07 17:15:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9219, Acc_2: 0.8438, 
2023-03-07 17:15:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0022, Acc_1: 0.9375, Acc_2: 0.8438, 
2023-03-07 17:15:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0068, Loss_2: 0.0386, Acc_1: 0.8449, Acc_2: 0.4008, F1-score_1: 0.8070, F1-score_2: 0.3257
2023-03-07 17:15:30 - __main__ - INFO - Epoch [21/100]
2023-03-07 17:15:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 17:15:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9688, Acc_2: 0.8984, 
2023-03-07 17:15:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9062, Acc_2: 0.8359, 
2023-03-07 17:15:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9453, Acc_2: 0.8984, 
2023-03-07 17:15:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-07 17:15:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 17:15:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0012, Loss_2: 0.0010, Acc_1: 0.9531, Acc_2: 0.9062, 
2023-03-07 17:16:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9531, Acc_2: 0.8672, 
2023-03-07 17:16:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 17:16:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9453, Acc_2: 0.8438, 
2023-03-07 17:16:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-07 17:16:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9297, Acc_2: 0.8438, 
2023-03-07 17:16:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0068, Loss_2: 0.0367, Acc_1: 0.8465, Acc_2: 0.4035, F1-score_1: 0.8034, F1-score_2: 0.3187
2023-03-07 17:16:27 - __main__ - INFO - Epoch [22/100]
2023-03-07 17:16:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9453, Acc_2: 0.8750, 
2023-03-07 17:16:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 17:16:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:16:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 17:16:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0017, Acc_1: 0.8594, Acc_2: 0.7969, 
2023-03-07 17:16:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 17:16:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0020, Acc_1: 0.8906, Acc_2: 0.8047, 
2023-03-07 17:16:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9844, Acc_2: 0.8750, 
2023-03-07 17:17:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0032, Acc_1: 0.9062, Acc_2: 0.8359, 
2023-03-07 17:17:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9297, Acc_2: 0.8672, 
2023-03-07 17:17:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0023, Acc_1: 0.9219, Acc_2: 0.8672, 
2023-03-07 17:17:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 17:17:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0076, Loss_2: 0.0387, Acc_1: 0.8351, Acc_2: 0.3979, F1-score_1: 0.7926, F1-score_2: 0.3244
2023-03-07 17:17:25 - __main__ - INFO - Epoch [23/100]
2023-03-07 17:17:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 17:17:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0031, Acc_1: 0.9141, Acc_2: 0.7812, 
2023-03-07 17:17:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 17:17:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9062, Acc_2: 0.8359, 
2023-03-07 17:17:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8594, 
2023-03-07 17:17:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9531, Acc_2: 0.8594, 
2023-03-07 17:17:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0012, Acc_1: 0.9375, Acc_2: 0.8750, 
2023-03-07 17:17:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9453, Acc_2: 0.8750, 
2023-03-07 17:18:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0017, Acc_1: 0.9141, Acc_2: 0.8281, 
2023-03-07 17:18:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 17:18:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8516, Acc_2: 0.7969, 
2023-03-07 17:18:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9688, Acc_2: 0.9062, 
2023-03-07 17:18:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0067, Loss_2: 0.0406, Acc_1: 0.8397, Acc_2: 0.3888, F1-score_1: 0.7913, F1-score_2: 0.3220
2023-03-07 17:18:23 - __main__ - INFO - Epoch [24/100]
2023-03-07 17:18:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0011, Loss_2: 0.0012, Acc_1: 0.9688, Acc_2: 0.9453, 
2023-03-07 17:18:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.8828, 
2023-03-07 17:18:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9062, Acc_2: 0.8203, 
2023-03-07 17:18:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9297, Acc_2: 0.8828, 
2023-03-07 17:18:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 17:18:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0021, Acc_1: 0.9062, Acc_2: 0.7812, 
2023-03-07 17:18:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9141, Acc_2: 0.8203, 
2023-03-07 17:18:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 17:18:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9141, Acc_2: 0.8125, 
2023-03-07 17:19:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 17:19:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 17:19:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 17:19:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0067, Loss_2: 0.0371, Acc_1: 0.8400, Acc_2: 0.3915, F1-score_1: 0.8013, F1-score_2: 0.3180
2023-03-07 17:19:21 - __main__ - INFO - Epoch [25/100]
2023-03-07 17:19:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-07 17:19:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9141, Acc_2: 0.8438, 
2023-03-07 17:19:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9609, Acc_2: 0.9297, 
2023-03-07 17:19:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-07 17:19:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.8984, Acc_2: 0.7812, 
2023-03-07 17:19:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 17:19:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 17:19:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 17:19:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:19:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 17:20:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 17:20:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9375, Acc_2: 0.8750, 
2023-03-07 17:20:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0089, Loss_2: 0.0405, Acc_1: 0.8387, Acc_2: 0.3840, F1-score_1: 0.7942, F1-score_2: 0.3115
2023-03-07 17:20:18 - __main__ - INFO - Epoch [26/100]
2023-03-07 17:20:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9375, Acc_2: 0.8750, 
2023-03-07 17:20:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9453, Acc_2: 0.9062, 
2023-03-07 17:20:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 17:20:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 17:20:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 17:20:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8672, 
2023-03-07 17:20:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 17:20:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.9609, Acc_2: 0.9062, 
2023-03-07 17:20:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 17:20:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9219, Acc_2: 0.8438, 
2023-03-07 17:21:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.8594, 
2023-03-07 17:21:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 17:21:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0077, Loss_2: 0.0385, Acc_1: 0.8375, Acc_2: 0.3940, F1-score_1: 0.8001, F1-score_2: 0.3117
2023-03-07 17:21:16 - __main__ - INFO - Epoch [27/100]
2023-03-07 17:21:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 17:21:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9531, Acc_2: 0.9219, 
2023-03-07 17:21:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 17:21:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-07 17:21:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 17:21:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0014, Acc_1: 0.8828, Acc_2: 0.8125, 
2023-03-07 17:21:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 17:21:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 17:21:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:21:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-07 17:21:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0021, Acc_1: 0.9219, Acc_2: 0.8359, 
2023-03-07 17:22:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9688, Acc_2: 0.9219, 
2023-03-07 17:22:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0101, Loss_2: 0.0436, Acc_1: 0.8327, Acc_2: 0.3945, F1-score_1: 0.7906, F1-score_2: 0.3093
2023-03-07 17:22:13 - __main__ - INFO - Epoch [28/100]
2023-03-07 17:22:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8672, 
2023-03-07 17:22:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 17:22:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 17:22:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.8672, 
2023-03-07 17:22:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:22:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9531, Acc_2: 0.9219, 
2023-03-07 17:22:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 17:22:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 17:22:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9531, Acc_2: 0.8906, 
2023-03-07 17:22:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-07 17:22:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-07 17:22:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 17:23:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0080, Loss_2: 0.0458, Acc_1: 0.8312, Acc_2: 0.3843, F1-score_1: 0.7827, F1-score_2: 0.3100
2023-03-07 17:23:11 - __main__ - INFO - Epoch [29/100]
2023-03-07 17:23:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-07 17:23:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8281, Acc_2: 0.7891, 
2023-03-07 17:23:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:23:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.7969, 
2023-03-07 17:23:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0015, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 17:23:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 17:23:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 17:23:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 17:23:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.9688, Acc_2: 0.9141, 
2023-03-07 17:23:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 17:23:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 17:23:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 17:24:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0086, Loss_2: 0.0506, Acc_1: 0.8291, Acc_2: 0.3835, F1-score_1: 0.7813, F1-score_2: 0.3216
2023-03-07 17:24:09 - __main__ - INFO - Epoch [30/100]
2023-03-07 17:24:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 17:24:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 17:24:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 17:24:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 17:24:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.8594, 
2023-03-07 17:24:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 17:24:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:24:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 17:24:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0018, Loss_2: 0.0018, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 17:24:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8516, 
2023-03-07 17:24:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 17:24:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 17:25:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0087, Loss_2: 0.0467, Acc_1: 0.8229, Acc_2: 0.3923, F1-score_1: 0.7792, F1-score_2: 0.3127
2023-03-07 17:25:06 - __main__ - INFO - Epoch [31/100]
2023-03-07 17:25:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-07 17:25:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 17:25:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 17:25:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0017, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 17:25:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 17:25:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 17:25:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 17:25:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 17:25:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0015, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 17:25:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0026, Acc_1: 0.8906, Acc_2: 0.8047, 
2023-03-07 17:25:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-07 17:25:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0015, Acc_1: 0.8672, Acc_2: 0.8047, 
2023-03-07 17:26:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0091, Loss_2: 0.0441, Acc_1: 0.8224, Acc_2: 0.3956, F1-score_1: 0.7783, F1-score_2: 0.3222
2023-03-07 17:26:04 - __main__ - INFO - Epoch [32/100]
2023-03-07 17:26:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 17:26:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9609, Acc_2: 0.9297, 
2023-03-07 17:26:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0012, Acc_1: 0.9375, Acc_2: 0.8672, 
2023-03-07 17:26:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0019, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8828, 
2023-03-07 17:26:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 17:26:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0013, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 17:26:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9375, Acc_2: 0.8906, 
2023-03-07 17:26:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0014, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-07 17:26:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0012, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 17:26:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0012, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 17:26:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0016, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 17:26:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0016, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 17:27:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0101, Loss_2: 0.0413, Acc_1: 0.8173, Acc_2: 0.3835, F1-score_1: 0.7762, F1-score_2: 0.3079
2023-03-07 17:27:02 - __main__ - INFO - Epoch [33/100]
2023-03-07 17:27:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 17:27:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0022, Loss_2: 0.0016, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-07 17:27:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0015, Acc_1: 0.8906, Acc_2: 0.8281, 
2023-03-07 17:27:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 17:27:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0021, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-07 17:27:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0013, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 17:27:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 17:27:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0015, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 17:27:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0022, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 17:27:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 17:27:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0015, Loss_2: 0.0015, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 17:27:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 17:28:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0110, Loss_2: 0.0442, Acc_1: 0.8122, Acc_2: 0.3864, F1-score_1: 0.7719, F1-score_2: 0.3198
2023-03-07 17:28:00 - __main__ - INFO - Epoch [34/100]
2023-03-07 17:28:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-07 17:28:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 17:28:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 17:28:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 17:28:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8438, 
2023-03-07 17:28:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 17:28:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 17:28:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 17:28:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 17:28:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 17:28:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 17:28:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 17:28:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0128, Loss_2: 0.0448, Acc_1: 0.8147, Acc_2: 0.3765, F1-score_1: 0.7799, F1-score_2: 0.3066
2023-03-07 17:28:58 - __main__ - INFO - Epoch [35/100]
2023-03-07 17:29:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 17:29:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 17:29:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 17:29:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 17:29:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0013, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 17:29:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-07 17:29:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 17:29:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 17:29:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 17:29:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0022, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-07 17:29:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.8906, Acc_2: 0.8047, 
2023-03-07 17:29:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 17:29:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0140, Loss_2: 0.0432, Acc_1: 0.8147, Acc_2: 0.3845, F1-score_1: 0.7656, F1-score_2: 0.3165
2023-03-07 17:29:55 - __main__ - INFO - Epoch [36/100]
2023-03-07 17:30:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 17:30:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9062, Acc_2: 0.8359, 
2023-03-07 17:30:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 17:30:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 17:30:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:30:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:30:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-07 17:30:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 17:30:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 17:30:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 17:30:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 17:30:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 17:30:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0173, Loss_2: 0.0463, Acc_1: 0.8111, Acc_2: 0.3893, F1-score_1: 0.7711, F1-score_2: 0.3122
2023-03-07 17:30:53 - __main__ - INFO - Epoch [37/100]
2023-03-07 17:30:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 17:31:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 17:31:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 17:31:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:31:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 17:31:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 17:31:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 17:31:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9766, Acc_2: 0.9219, 
2023-03-07 17:31:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 17:31:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-07 17:31:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 17:31:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 17:31:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0168, Loss_2: 0.0507, Acc_1: 0.8217, Acc_2: 0.3945, F1-score_1: 0.7811, F1-score_2: 0.3213
2023-03-07 17:31:51 - __main__ - INFO - Epoch [38/100]
2023-03-07 17:31:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 17:32:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 17:32:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-07 17:32:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-07 17:32:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:32:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 17:32:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 17:32:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 17:32:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 17:32:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 17:32:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9219, Acc_2: 0.8516, 
2023-03-07 17:32:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 17:32:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0161, Loss_2: 0.0471, Acc_1: 0.8315, Acc_2: 0.3816, F1-score_1: 0.7891, F1-score_2: 0.3132
2023-03-07 17:32:48 - __main__ - INFO - Epoch [39/100]
2023-03-07 17:32:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 17:32:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 17:33:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 17:33:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:33:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 17:33:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 17:33:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:33:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 17:33:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 17:33:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.8906, 
2023-03-07 17:33:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 17:33:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0011, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 17:33:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0127, Loss_2: 0.0466, Acc_1: 0.8300, Acc_2: 0.4001, F1-score_1: 0.7861, F1-score_2: 0.3165
2023-03-07 17:33:46 - __main__ - INFO - Epoch [40/100]
2023-03-07 17:33:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 17:33:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 17:33:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9375, Acc_2: 0.8594, 
2023-03-07 17:34:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 17:34:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 17:34:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 17:34:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 17:34:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 17:34:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 17:34:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 17:34:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:34:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 17:34:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0175, Loss_2: 0.0527, Acc_1: 0.8240, Acc_2: 0.3935, F1-score_1: 0.7850, F1-score_2: 0.3178
2023-03-07 17:34:44 - __main__ - INFO - Epoch [41/100]
2023-03-07 17:34:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 17:34:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 17:34:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 17:35:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 17:35:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9375, Acc_2: 0.8906, 
2023-03-07 17:35:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 17:35:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 17:35:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 17:35:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 17:35:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:35:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 17:35:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-07 17:35:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0145, Loss_2: 0.0516, Acc_1: 0.8274, Acc_2: 0.3869, F1-score_1: 0.7878, F1-score_2: 0.3121
2023-03-07 17:35:42 - __main__ - INFO - Epoch [42/100]
2023-03-07 17:35:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 17:35:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 17:35:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 17:35:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 17:36:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 17:36:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 17:36:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 17:36:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 17:36:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 17:36:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 17:36:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 17:36:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 17:36:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0486, Acc_1: 0.8271, Acc_2: 0.3937, F1-score_1: 0.7909, F1-score_2: 0.3154
2023-03-07 17:36:39 - __main__ - INFO - Epoch [43/100]
2023-03-07 17:36:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 17:36:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 17:36:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 17:36:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:36:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 17:37:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 17:37:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 17:37:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 17:37:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 17:37:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 17:37:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 17:37:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9531, Acc_2: 0.9141, 
2023-03-07 17:37:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0148, Loss_2: 0.0499, Acc_1: 0.8283, Acc_2: 0.3937, F1-score_1: 0.7873, F1-score_2: 0.3183
2023-03-07 17:37:37 - __main__ - INFO - Epoch [44/100]
2023-03-07 17:37:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:37:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 17:37:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9688, Acc_2: 0.9531, 
2023-03-07 17:37:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 17:37:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 17:38:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 17:38:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 17:38:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 17:38:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 17:38:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 17:38:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 17:38:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 17:38:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0148, Loss_2: 0.0554, Acc_1: 0.8227, Acc_2: 0.3915, F1-score_1: 0.7826, F1-score_2: 0.3169
2023-03-07 17:38:35 - __main__ - INFO - Epoch [45/100]
2023-03-07 17:38:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 17:38:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 17:38:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 17:38:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 17:38:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 17:38:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 17:39:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9609, Acc_2: 0.9062, 
2023-03-07 17:39:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9688, Acc_2: 0.9766, 
2023-03-07 17:39:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 17:39:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 17:39:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 17:39:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 17:39:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0167, Loss_2: 0.0524, Acc_1: 0.8057, Acc_2: 0.3816, F1-score_1: 0.7607, F1-score_2: 0.3077
2023-03-07 17:39:32 - __main__ - INFO - Epoch [46/100]
2023-03-07 17:39:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 17:39:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 17:39:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 17:39:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 17:39:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 17:39:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0013, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 17:39:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 17:40:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 17:40:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 17:40:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 17:40:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 17:40:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9453, Acc_2: 0.8984, 
2023-03-07 17:40:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0132, Loss_2: 0.0413, Acc_1: 0.8052, Acc_2: 0.4030, F1-score_1: 0.7573, F1-score_2: 0.3212
2023-03-07 17:40:30 - __main__ - INFO - Epoch [47/100]
2023-03-07 17:40:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0029, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 17:40:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 17:40:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 17:40:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 17:40:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 17:40:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 17:40:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 17:41:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 17:41:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 17:41:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9453, Acc_2: 0.8984, 
2023-03-07 17:41:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 17:41:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 17:41:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0150, Loss_2: 0.0465, Acc_1: 0.8225, Acc_2: 0.3910, F1-score_1: 0.7834, F1-score_2: 0.3138
2023-03-07 17:41:27 - __main__ - INFO - Epoch [48/100]
2023-03-07 17:41:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 17:41:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 17:41:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 17:41:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 17:41:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 17:41:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0035, Loss_2: 0.0007, Acc_1: 0.9375, Acc_2: 0.8906, 
2023-03-07 17:41:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 17:41:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 17:42:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 17:42:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 17:42:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 17:42:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 17:42:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0144, Loss_2: 0.0470, Acc_1: 0.8251, Acc_2: 0.3956, F1-score_1: 0.7845, F1-score_2: 0.3131
2023-03-07 17:42:25 - __main__ - INFO - Epoch [49/100]
2023-03-07 17:42:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 17:42:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0010, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 17:42:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 17:42:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 17:42:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 17:42:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 17:42:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:42:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 17:43:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9609, Acc_2: 0.9375, 
2023-03-07 17:43:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-07 17:43:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9688, Acc_2: 0.9297, 
2023-03-07 17:43:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 17:43:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0131, Loss_2: 0.0563, Acc_1: 0.8200, Acc_2: 0.3891, F1-score_1: 0.7741, F1-score_2: 0.3099
2023-03-07 17:43:23 - __main__ - INFO - Epoch [50/100]
2023-03-07 17:43:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9297, Acc_2: 0.8828, 
2023-03-07 17:43:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 17:43:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 17:43:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 17:43:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 17:43:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 17:43:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 17:43:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0023, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 17:43:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 17:44:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 17:44:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-07 17:44:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 17:44:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0133, Loss_2: 0.0552, Acc_1: 0.8049, Acc_2: 0.3998, F1-score_1: 0.7601, F1-score_2: 0.3194
2023-03-07 17:44:20 - __main__ - INFO - Epoch [51/100]
2023-03-07 17:44:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 17:44:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 17:44:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 17:44:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 17:44:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 17:44:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 17:44:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 17:44:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 17:44:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 17:44:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 17:45:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 17:45:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 17:45:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0156, Loss_2: 0.0477, Acc_1: 0.8174, Acc_2: 0.3927, F1-score_1: 0.7833, F1-score_2: 0.3235
2023-03-07 17:45:18 - __main__ - INFO - Epoch [52/100]
2023-03-07 17:45:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 17:45:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 17:45:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 17:45:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 17:45:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 17:45:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 17:45:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 17:45:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 17:45:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 17:45:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 17:46:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 17:46:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 17:46:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0147, Loss_2: 0.0497, Acc_1: 0.8251, Acc_2: 0.3942, F1-score_1: 0.7877, F1-score_2: 0.3171
2023-03-07 17:46:16 - __main__ - INFO - Epoch [53/100]
2023-03-07 17:46:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 17:46:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 17:46:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 17:46:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 17:46:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:46:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 17:46:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 17:46:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:46:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:46:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 17:46:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 17:47:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:47:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0190, Loss_2: 0.0547, Acc_1: 0.8003, Acc_2: 0.3898, F1-score_1: 0.7620, F1-score_2: 0.3169
2023-03-07 17:47:13 - __main__ - INFO - Epoch [54/100]
2023-03-07 17:47:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 17:47:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 17:47:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 17:47:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 17:47:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 17:47:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 17:47:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 17:47:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 17:47:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 17:47:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 17:47:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 17:47:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 17:48:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0155, Loss_2: 0.0525, Acc_1: 0.8049, Acc_2: 0.3862, F1-score_1: 0.7600, F1-score_2: 0.3136
2023-03-07 17:48:11 - __main__ - INFO - Epoch [55/100]
2023-03-07 17:48:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 17:48:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 17:48:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 17:48:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 17:48:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 17:48:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 17:48:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 17:48:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 17:48:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 17:48:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 17:48:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0017, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 17:48:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:49:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0182, Loss_2: 0.0529, Acc_1: 0.8161, Acc_2: 0.3925, F1-score_1: 0.7757, F1-score_2: 0.3170
2023-03-07 17:49:09 - __main__ - INFO - Epoch [56/100]
2023-03-07 17:49:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 17:49:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 17:49:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 17:49:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 17:49:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 17:49:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 17:49:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 17:49:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 17:49:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 17:49:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 17:49:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 17:49:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 17:50:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0203, Loss_2: 0.0524, Acc_1: 0.7969, Acc_2: 0.3972, F1-score_1: 0.7506, F1-score_2: 0.3174
2023-03-07 17:50:06 - __main__ - INFO - Epoch [57/100]
2023-03-07 17:50:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 17:50:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 17:50:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 17:50:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 17:50:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 17:50:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 17:50:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 17:50:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 17:50:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 17:50:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 17:50:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 17:50:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-07 17:51:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0200, Loss_2: 0.0533, Acc_1: 0.8110, Acc_2: 0.3988, F1-score_1: 0.7709, F1-score_2: 0.3044
2023-03-07 17:51:04 - __main__ - INFO - Epoch [58/100]
2023-03-07 17:51:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 17:51:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9531, Acc_2: 0.9297, 
2023-03-07 17:51:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 17:51:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 17:51:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 17:51:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 17:51:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 17:51:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 17:51:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 17:51:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 17:51:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 17:51:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 17:52:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0185, Loss_2: 0.0525, Acc_1: 0.7921, Acc_2: 0.3956, F1-score_1: 0.7446, F1-score_2: 0.3178
2023-03-07 17:52:01 - __main__ - INFO - Epoch [59/100]
2023-03-07 17:52:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 17:52:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 17:52:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 17:52:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:52:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 17:52:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 17:52:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-07 17:52:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 17:52:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:52:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 17:52:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 17:52:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 17:52:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0122, Loss_2: 0.0531, Acc_1: 0.8196, Acc_2: 0.3889, F1-score_1: 0.7722, F1-score_2: 0.3034
2023-03-07 17:52:59 - __main__ - INFO - Epoch [60/100]
2023-03-07 17:53:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0026, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 17:53:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-07 17:53:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 17:53:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 17:53:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:53:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 17:53:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 17:53:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.9609, Acc_2: 0.9219, 
2023-03-07 17:53:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 17:53:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 17:53:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 17:53:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9531, Acc_2: 0.9219, 
2023-03-07 17:53:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0184, Loss_2: 0.0559, Acc_1: 0.8081, Acc_2: 0.3928, F1-score_1: 0.7650, F1-score_2: 0.3076
2023-03-07 17:53:57 - __main__ - INFO - Epoch [61/100]
2023-03-07 17:54:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 17:54:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 17:54:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 17:54:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 17:54:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 17:54:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 17:54:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 17:54:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 17:54:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 17:54:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0015, Loss_2: 0.0015, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 17:54:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 17:54:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 17:54:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0134, Loss_2: 0.0480, Acc_1: 0.7955, Acc_2: 0.3950, F1-score_1: 0.7434, F1-score_2: 0.3085
2023-03-07 17:54:54 - __main__ - INFO - Epoch [62/100]
2023-03-07 17:54:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 17:55:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:55:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 17:55:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 17:55:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 17:55:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-07 17:55:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 17:55:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 17:55:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 17:55:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 17:55:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 17:55:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0015, Loss_2: 0.0016, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 17:55:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0179, Loss_2: 0.0597, Acc_1: 0.7962, Acc_2: 0.4005, F1-score_1: 0.7505, F1-score_2: 0.3104
2023-03-07 17:55:52 - __main__ - INFO - Epoch [63/100]
2023-03-07 17:55:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 17:56:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 17:56:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 17:56:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 17:56:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 17:56:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9844, Acc_2: 0.9453, 
2023-03-07 17:56:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:56:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 17:56:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 17:56:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 17:56:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 17:56:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9375, Acc_2: 0.8906, 
2023-03-07 17:56:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0192, Loss_2: 0.0577, Acc_1: 0.8071, Acc_2: 0.3823, F1-score_1: 0.7660, F1-score_2: 0.3055
2023-03-07 17:56:50 - __main__ - INFO - Epoch [64/100]
2023-03-07 17:56:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 17:56:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 17:57:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 17:57:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 17:57:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 17:57:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 17:57:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9531, Acc_2: 0.9219, 
2023-03-07 17:57:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 17:57:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:57:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 17:57:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 17:57:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-07 17:57:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0168, Loss_2: 0.0529, Acc_1: 0.7987, Acc_2: 0.3913, F1-score_1: 0.7567, F1-score_2: 0.3085
2023-03-07 17:57:47 - __main__ - INFO - Epoch [65/100]
2023-03-07 17:57:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 17:57:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 17:58:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9531, Acc_2: 0.9141, 
2023-03-07 17:58:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 17:58:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 17:58:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 17:58:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 17:58:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 17:58:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 17:58:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 17:58:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 17:58:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 17:58:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0155, Loss_2: 0.0536, Acc_1: 0.8157, Acc_2: 0.3854, F1-score_1: 0.7738, F1-score_2: 0.3104
2023-03-07 17:58:45 - __main__ - INFO - Epoch [66/100]
2023-03-07 17:58:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 17:58:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 17:58:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 17:59:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 17:59:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-07 17:59:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 17:59:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 17:59:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 17:59:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 17:59:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 17:59:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 17:59:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 17:59:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0183, Loss_2: 0.0562, Acc_1: 0.8038, Acc_2: 0.3823, F1-score_1: 0.7625, F1-score_2: 0.3091
2023-03-07 17:59:42 - __main__ - INFO - Epoch [67/100]
2023-03-07 17:59:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 17:59:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-07 17:59:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 17:59:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 18:00:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 18:00:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 18:00:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:00:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 18:00:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 18:00:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 18:00:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-07 18:00:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:00:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0157, Loss_2: 0.0565, Acc_1: 0.8086, Acc_2: 0.3877, F1-score_1: 0.7663, F1-score_2: 0.3092
2023-03-07 18:00:40 - __main__ - INFO - Epoch [68/100]
2023-03-07 18:00:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:00:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:00:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:00:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:00:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:01:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:01:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 18:01:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 18:01:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 18:01:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:01:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:01:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:01:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0210, Loss_2: 0.0592, Acc_1: 0.8089, Acc_2: 0.3886, F1-score_1: 0.7658, F1-score_2: 0.3113
2023-03-07 18:01:37 - __main__ - INFO - Epoch [69/100]
2023-03-07 18:01:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:01:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 18:01:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-07 18:01:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 18:01:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 18:02:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 18:02:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 18:02:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:02:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 18:02:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 18:02:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 18:02:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:02:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0196, Loss_2: 0.0610, Acc_1: 0.8072, Acc_2: 0.3911, F1-score_1: 0.7628, F1-score_2: 0.3090
2023-03-07 18:02:35 - __main__ - INFO - Epoch [70/100]
2023-03-07 18:02:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 18:02:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 18:02:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 18:02:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-07 18:02:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 18:02:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 18:03:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 18:03:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 18:03:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 18:03:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 18:03:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 18:03:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:03:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0213, Loss_2: 0.0570, Acc_1: 0.8067, Acc_2: 0.3947, F1-score_1: 0.7649, F1-score_2: 0.3136
2023-03-07 18:03:33 - __main__ - INFO - Epoch [71/100]
2023-03-07 18:03:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 18:03:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 18:03:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 18:03:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:03:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 18:03:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 18:04:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:04:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 18:04:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 18:04:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:04:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:04:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 18:04:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0203, Loss_2: 0.0592, Acc_1: 0.8015, Acc_2: 0.3984, F1-score_1: 0.7569, F1-score_2: 0.3208
2023-03-07 18:04:30 - __main__ - INFO - Epoch [72/100]
2023-03-07 18:04:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 18:04:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:04:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 18:04:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 18:04:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 18:04:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:04:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:05:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:05:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 18:05:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:05:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 18:05:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 18:05:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0232, Loss_2: 0.0592, Acc_1: 0.8120, Acc_2: 0.3942, F1-score_1: 0.7683, F1-score_2: 0.3155
2023-03-07 18:05:28 - __main__ - INFO - Epoch [73/100]
2023-03-07 18:05:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:05:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 18:05:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 18:05:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 18:05:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 18:05:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:05:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 18:05:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 18:06:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:06:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:06:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 18:06:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:06:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0314, Loss_2: 0.0564, Acc_1: 0.8064, Acc_2: 0.3981, F1-score_1: 0.7572, F1-score_2: 0.3141
2023-03-07 18:06:26 - __main__ - INFO - Epoch [74/100]
2023-03-07 18:06:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 18:06:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:06:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:06:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 18:06:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 18:06:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:06:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:06:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 18:07:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-07 18:07:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 18:07:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 18:07:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 18:07:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0299, Loss_2: 0.0561, Acc_1: 0.8111, Acc_2: 0.3930, F1-score_1: 0.7675, F1-score_2: 0.3091
2023-03-07 18:07:23 - __main__ - INFO - Epoch [75/100]
2023-03-07 18:07:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 18:07:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 18:07:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 18:07:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 18:07:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 18:07:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 18:07:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 18:07:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 18:07:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0041, Loss_2: 0.0011, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 18:08:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 18:08:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 18:08:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 18:08:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0315, Loss_2: 0.0566, Acc_1: 0.7843, Acc_2: 0.3850, F1-score_1: 0.7324, F1-score_2: 0.3098
2023-03-07 18:08:21 - __main__ - INFO - Epoch [76/100]
2023-03-07 18:08:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 18:08:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:08:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 18:08:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 18:08:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:08:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:08:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-07 18:08:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 18:08:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:08:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 18:09:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 18:09:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 18:09:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0241, Loss_2: 0.0546, Acc_1: 0.8079, Acc_2: 0.3935, F1-score_1: 0.7648, F1-score_2: 0.3165
2023-03-07 18:09:19 - __main__ - INFO - Epoch [77/100]
2023-03-07 18:09:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:09:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-07 18:09:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 18:09:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 18:09:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 18:09:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:09:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-07 18:09:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:09:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 18:09:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 18:10:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 18:10:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 18:10:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0324, Loss_2: 0.0524, Acc_1: 0.7976, Acc_2: 0.3874, F1-score_1: 0.7511, F1-score_2: 0.3119
2023-03-07 18:10:17 - __main__ - INFO - Epoch [78/100]
2023-03-07 18:10:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:10:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 18:10:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 18:10:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:10:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 18:10:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 18:10:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 18:10:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-07 18:10:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 18:10:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 18:10:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 18:11:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 18:11:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0295, Loss_2: 0.0521, Acc_1: 0.8035, Acc_2: 0.3886, F1-score_1: 0.7599, F1-score_2: 0.3100
2023-03-07 18:11:14 - __main__ - INFO - Epoch [79/100]
2023-03-07 18:11:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:11:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 18:11:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 18:11:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 18:11:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:11:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 18:11:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 18:11:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 18:11:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 18:11:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 18:11:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:11:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:12:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0262, Loss_2: 0.0538, Acc_1: 0.8062, Acc_2: 0.4000, F1-score_1: 0.7635, F1-score_2: 0.3183
2023-03-07 18:12:12 - __main__ - INFO - Epoch [80/100]
2023-03-07 18:12:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 18:12:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:12:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:12:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:12:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 18:12:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 18:12:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 18:12:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0023, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 18:12:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 18:12:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 18:12:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9141, 
2023-03-07 18:12:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 18:13:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0316, Loss_2: 0.0598, Acc_1: 0.8064, Acc_2: 0.3857, F1-score_1: 0.7603, F1-score_2: 0.3107
2023-03-07 18:13:10 - __main__ - INFO - Epoch [81/100]
2023-03-07 18:13:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 18:13:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9844, Acc_2: 0.9766, 
2023-03-07 18:13:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 18:13:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 18:13:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 18:13:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 18:13:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 18:13:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:13:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 18:13:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 18:13:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 18:13:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0019, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 18:14:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0279, Loss_2: 0.0594, Acc_1: 0.7999, Acc_2: 0.3976, F1-score_1: 0.7566, F1-score_2: 0.3184
2023-03-07 18:14:09 - __main__ - INFO - Epoch [82/100]
2023-03-07 18:14:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:14:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 18:14:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 18:14:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 18:14:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:14:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 18:14:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 18:14:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:14:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 18:14:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 18:14:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 18:14:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 18:15:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0262, Loss_2: 0.0562, Acc_1: 0.8043, Acc_2: 0.3933, F1-score_1: 0.7616, F1-score_2: 0.3154
2023-03-07 18:15:07 - __main__ - INFO - Epoch [83/100]
2023-03-07 18:15:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 18:15:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 18:15:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:15:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 18:15:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 18:15:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 18:15:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 18:15:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 18:15:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:15:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:15:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 18:15:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 18:16:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0317, Loss_2: 0.0583, Acc_1: 0.8055, Acc_2: 0.3894, F1-score_1: 0.7616, F1-score_2: 0.3101
2023-03-07 18:16:05 - __main__ - INFO - Epoch [84/100]
2023-03-07 18:16:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:16:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 18:16:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 18:16:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 18:16:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 18:16:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:16:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:16:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:16:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 18:16:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 18:16:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:16:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-07 18:17:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0348, Loss_2: 0.0575, Acc_1: 0.7955, Acc_2: 0.4001, F1-score_1: 0.7457, F1-score_2: 0.3172
2023-03-07 18:17:02 - __main__ - INFO - Epoch [85/100]
2023-03-07 18:17:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:17:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:17:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:17:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-07 18:17:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 18:17:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 18:17:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:17:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 18:17:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:17:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:17:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 18:17:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:18:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0283, Loss_2: 0.0574, Acc_1: 0.8069, Acc_2: 0.4032, F1-score_1: 0.7642, F1-score_2: 0.3242
2023-03-07 18:18:00 - __main__ - INFO - Epoch [86/100]
2023-03-07 18:18:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 18:18:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 18:18:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 18:18:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 18:18:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:18:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:18:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-07 18:18:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 18:18:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 18:18:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:18:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 18:18:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:18:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0251, Loss_2: 0.0614, Acc_1: 0.8088, Acc_2: 0.3995, F1-score_1: 0.7659, F1-score_2: 0.3211
2023-03-07 18:18:57 - __main__ - INFO - Epoch [87/100]
2023-03-07 18:19:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 18:19:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 18:19:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:19:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 18:19:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 18:19:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 18:19:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 18:19:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 18:19:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 18:19:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:19:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 18:19:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:19:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0254, Loss_2: 0.0601, Acc_1: 0.8098, Acc_2: 0.3969, F1-score_1: 0.7677, F1-score_2: 0.3186
2023-03-07 18:19:55 - __main__ - INFO - Epoch [88/100]
2023-03-07 18:20:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 18:20:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 18:20:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 18:20:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 18:20:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 18:20:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:20:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 18:20:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 18:20:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 18:20:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 18:20:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:20:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:20:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0282, Loss_2: 0.0601, Acc_1: 0.8072, Acc_2: 0.4003, F1-score_1: 0.7647, F1-score_2: 0.3185
2023-03-07 18:20:53 - __main__ - INFO - Epoch [89/100]
2023-03-07 18:20:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-07 18:21:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 18:21:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 18:21:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 18:21:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 18:21:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 18:21:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 18:21:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 18:21:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 18:21:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:21:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 18:21:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:21:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0294, Loss_2: 0.0619, Acc_1: 0.8060, Acc_2: 0.3964, F1-score_1: 0.7595, F1-score_2: 0.3184
2023-03-07 18:21:50 - __main__ - INFO - Epoch [90/100]
2023-03-07 18:21:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 18:21:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 18:22:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 18:22:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 18:22:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:22:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:22:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-07 18:22:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 18:22:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-07 18:22:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 18:22:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 18:22:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:22:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0262, Loss_2: 0.0599, Acc_1: 0.8052, Acc_2: 0.3978, F1-score_1: 0.7595, F1-score_2: 0.3198
2023-03-07 18:22:48 - __main__ - INFO - Epoch [91/100]
2023-03-07 18:22:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:22:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 18:23:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 18:23:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-07 18:23:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 18:23:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 18:23:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:23:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:23:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 18:23:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 18:23:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:23:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 18:23:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0258, Loss_2: 0.0597, Acc_1: 0.8076, Acc_2: 0.3962, F1-score_1: 0.7636, F1-score_2: 0.3161
2023-03-07 18:23:46 - __main__ - INFO - Epoch [92/100]
2023-03-07 18:23:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 18:23:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:23:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 18:24:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:24:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:24:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:24:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:24:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:24:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 18:24:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:24:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 18:24:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:24:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0302, Loss_2: 0.0601, Acc_1: 0.8052, Acc_2: 0.3949, F1-score_1: 0.7634, F1-score_2: 0.3188
2023-03-07 18:24:43 - __main__ - INFO - Epoch [93/100]
2023-03-07 18:24:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:24:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:24:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 18:25:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 18:25:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 18:25:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 18:25:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 18:25:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 18:25:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 18:25:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 18:25:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 18:25:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 18:25:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0295, Loss_2: 0.0607, Acc_1: 0.8081, Acc_2: 0.3937, F1-score_1: 0.7651, F1-score_2: 0.3142
2023-03-07 18:25:41 - __main__ - INFO - Epoch [94/100]
2023-03-07 18:25:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 18:25:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 18:25:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:25:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 18:26:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-07 18:26:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 18:26:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 18:26:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:26:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:26:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-07 18:26:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 18:26:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:26:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0284, Loss_2: 0.0617, Acc_1: 0.8083, Acc_2: 0.3896, F1-score_1: 0.7645, F1-score_2: 0.3157
2023-03-07 18:26:39 - __main__ - INFO - Epoch [95/100]
2023-03-07 18:26:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 18:26:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 18:26:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 18:26:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 18:26:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 18:27:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 18:27:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 18:27:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 18:27:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9688, Acc_2: 0.9453, 
2023-03-07 18:27:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 18:27:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 18:27:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 18:27:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0265, Loss_2: 0.0620, Acc_1: 0.8086, Acc_2: 0.3959, F1-score_1: 0.7658, F1-score_2: 0.3170
2023-03-07 18:27:36 - __main__ - INFO - Epoch [96/100]
2023-03-07 18:27:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 18:27:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 18:27:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 18:27:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 18:27:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:28:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:28:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 18:28:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 18:28:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:28:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:28:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:28:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 18:28:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0280, Loss_2: 0.0617, Acc_1: 0.8089, Acc_2: 0.3932, F1-score_1: 0.7659, F1-score_2: 0.3152
2023-03-07 18:28:34 - __main__ - INFO - Epoch [97/100]
2023-03-07 18:28:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 18:28:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:28:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 18:28:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 18:28:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 18:28:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:29:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 18:29:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 18:29:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 18:29:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9453, 
2023-03-07 18:29:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 18:29:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:29:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0281, Loss_2: 0.0612, Acc_1: 0.8091, Acc_2: 0.3956, F1-score_1: 0.7669, F1-score_2: 0.3149
2023-03-07 18:29:32 - __main__ - INFO - Epoch [98/100]
2023-03-07 18:29:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 18:29:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 18:29:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 18:29:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 18:29:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 18:29:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 18:29:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 18:30:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 18:30:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:30:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 18:30:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 18:30:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:30:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0289, Loss_2: 0.0618, Acc_1: 0.8088, Acc_2: 0.3962, F1-score_1: 0.7674, F1-score_2: 0.3177
2023-03-07 18:30:30 - __main__ - INFO - Epoch [99/100]
2023-03-07 18:30:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 18:30:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:30:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:30:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 18:30:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 18:30:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 18:30:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 18:31:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 18:31:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:31:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 18:31:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 18:31:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 18:31:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0289, Loss_2: 0.0619, Acc_1: 0.8088, Acc_2: 0.3972, F1-score_1: 0.7674, F1-score_2: 0.3197
2023-03-07 18:31:30 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 18:31:30 - utils._noise - DEBUG - 6, 7
2023-03-07 18:31:30 - utils._noise - DEBUG - 13997
2023-03-07 18:31:30 - utils._noise - INFO - Actual noise 0.20
2023-03-07 18:31:30 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-07 18:31:30 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-07 18:31:32 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 18:31:32 - __main__ - INFO - Loading dataset...
2023-03-07 18:31:32 - __main__ - INFO - Building model...
2023-03-07 18:31:32 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-07 18:31:32 - __main__ - INFO - <bound method Module.parameters of NewsNet(
  (embedding): Embedding(20000, 300)
  (avgpool): AdaptiveAvgPool1d(output_size=4800)
  (fc1): Linear(in_features=4800, out_features=1200, bias=True)
  (bn1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ac): Softsign()
  (fc2): Linear(in_features=1200, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=7, bias=True)
)>
2023-03-07 18:31:32 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-07 18:31:32 - __main__ - INFO - Start train & evaluate
2023-03-07 18:31:32 - __main__ - INFO - Epoch [0/100]
2023-03-07 18:31:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0155, Loss_2: 0.0155, Acc_1: 0.1094, Acc_2: 0.1250, 
2023-03-07 18:31:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0130, Loss_2: 0.0145, Acc_1: 0.4219, Acc_2: 0.3203, 
2023-03-07 18:31:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0106, Loss_2: 0.0139, Acc_1: 0.5859, Acc_2: 0.3047, 
2023-03-07 18:31:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0102, Loss_2: 0.0141, Acc_1: 0.5938, Acc_2: 0.3438, 
2023-03-07 18:31:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0099, Loss_2: 0.0136, Acc_1: 0.6094, Acc_2: 0.3984, 
2023-03-07 18:31:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0092, Loss_2: 0.0134, Acc_1: 0.6484, Acc_2: 0.3672, 
2023-03-07 18:32:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0092, Loss_2: 0.0124, Acc_1: 0.6875, Acc_2: 0.4219, 
2023-03-07 18:32:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0089, Loss_2: 0.0129, Acc_1: 0.6250, Acc_2: 0.4062, 
2023-03-07 18:32:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0097, Loss_2: 0.0129, Acc_1: 0.6719, Acc_2: 0.4297, 
2023-03-07 18:32:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0085, Loss_2: 0.0135, Acc_1: 0.7344, Acc_2: 0.3906, 
2023-03-07 18:32:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0089, Loss_2: 0.0123, Acc_1: 0.6641, Acc_2: 0.3984, 
2023-03-07 18:32:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0124, Loss_2: 0.0141, Acc_1: 0.5625, Acc_2: 0.3047, 
2023-03-07 18:32:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0058, Loss_2: 0.0119, Acc_1: 0.8482, Acc_2: 0.4523, F1-score_1: 0.7871, F1-score_2: 0.2692
2023-03-07 18:32:30 - __main__ - INFO - Epoch [1/100]
2023-03-07 18:32:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0075, Loss_2: 0.0117, Acc_1: 0.7344, Acc_2: 0.4375, 
2023-03-07 18:32:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0077, Loss_2: 0.0118, Acc_1: 0.6875, Acc_2: 0.4375, 
2023-03-07 18:32:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0057, Loss_2: 0.0113, Acc_1: 0.7891, Acc_2: 0.4922, 
2023-03-07 18:32:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0070, Loss_2: 0.0123, Acc_1: 0.7812, Acc_2: 0.4453, 
2023-03-07 18:32:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0085, Loss_2: 0.0123, Acc_1: 0.6875, Acc_2: 0.3984, 
2023-03-07 18:32:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0079, Loss_2: 0.0124, Acc_1: 0.7266, Acc_2: 0.3906, 
2023-03-07 18:32:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0081, Loss_2: 0.0121, Acc_1: 0.7109, Acc_2: 0.4297, 
2023-03-07 18:33:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0066, Loss_2: 0.0122, Acc_1: 0.7734, Acc_2: 0.3750, 
2023-03-07 18:33:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0062, Loss_2: 0.0118, Acc_1: 0.7812, Acc_2: 0.4531, 
2023-03-07 18:33:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0085, Loss_2: 0.0128, Acc_1: 0.6484, Acc_2: 0.3906, 
2023-03-07 18:33:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0072, Loss_2: 0.0124, Acc_1: 0.7031, Acc_2: 0.3828, 
2023-03-07 18:33:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0075, Loss_2: 0.0137, Acc_1: 0.7422, Acc_2: 0.3281, 
2023-03-07 18:33:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0049, Loss_2: 0.0124, Acc_1: 0.8789, Acc_2: 0.4492, F1-score_1: 0.8376, F1-score_2: 0.3298
2023-03-07 18:33:28 - __main__ - INFO - Epoch [2/100]
2023-03-07 18:33:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0046, Loss_2: 0.0095, Acc_1: 0.8125, Acc_2: 0.5703, 
2023-03-07 18:33:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0055, Loss_2: 0.0099, Acc_1: 0.7656, Acc_2: 0.5000, 
2023-03-07 18:33:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0045, Loss_2: 0.0091, Acc_1: 0.7734, Acc_2: 0.6016, 
2023-03-07 18:33:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0060, Loss_2: 0.0106, Acc_1: 0.7500, Acc_2: 0.4922, 
2023-03-07 18:33:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0058, Loss_2: 0.0107, Acc_1: 0.7734, Acc_2: 0.5156, 
2023-03-07 18:33:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0056, Loss_2: 0.0109, Acc_1: 0.7812, Acc_2: 0.4609, 
2023-03-07 18:33:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0063, Loss_2: 0.0099, Acc_1: 0.7734, Acc_2: 0.5547, 
2023-03-07 18:33:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0063, Loss_2: 0.0109, Acc_1: 0.7266, Acc_2: 0.5000, 
2023-03-07 18:34:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0058, Loss_2: 0.0127, Acc_1: 0.7891, Acc_2: 0.4531, 
2023-03-07 18:34:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0060, Loss_2: 0.0107, Acc_1: 0.7812, Acc_2: 0.5391, 
2023-03-07 18:34:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0066, Loss_2: 0.0119, Acc_1: 0.7500, Acc_2: 0.4297, 
2023-03-07 18:34:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0072, Loss_2: 0.0124, Acc_1: 0.7109, Acc_2: 0.4219, 
2023-03-07 18:34:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0048, Loss_2: 0.0127, Acc_1: 0.8670, Acc_2: 0.4411, F1-score_1: 0.8208, F1-score_2: 0.3175
2023-03-07 18:34:26 - __main__ - INFO - Epoch [3/100]
2023-03-07 18:34:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0041, Loss_2: 0.0092, Acc_1: 0.7969, Acc_2: 0.5703, 
2023-03-07 18:34:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0031, Loss_2: 0.0084, Acc_1: 0.8438, Acc_2: 0.6172, 
2023-03-07 18:34:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0043, Loss_2: 0.0099, Acc_1: 0.8281, Acc_2: 0.5469, 
2023-03-07 18:34:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0052, Loss_2: 0.0100, Acc_1: 0.7734, Acc_2: 0.5469, 
2023-03-07 18:34:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0038, Loss_2: 0.0098, Acc_1: 0.8203, Acc_2: 0.5625, 
2023-03-07 18:34:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0050, Loss_2: 0.0101, Acc_1: 0.7969, Acc_2: 0.6016, 
2023-03-07 18:34:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0040, Loss_2: 0.0100, Acc_1: 0.8125, Acc_2: 0.5312, 
2023-03-07 18:34:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0052, Loss_2: 0.0108, Acc_1: 0.7969, Acc_2: 0.4688, 
2023-03-07 18:35:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0031, Loss_2: 0.0092, Acc_1: 0.8594, Acc_2: 0.5938, 
2023-03-07 18:35:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0035, Loss_2: 0.0109, Acc_1: 0.8750, Acc_2: 0.4766, 
2023-03-07 18:35:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0047, Loss_2: 0.0110, Acc_1: 0.7891, Acc_2: 0.5000, 
2023-03-07 18:35:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0058, Loss_2: 0.0109, Acc_1: 0.7734, Acc_2: 0.5156, 
2023-03-07 18:35:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0138, Acc_1: 0.8648, Acc_2: 0.4266, F1-score_1: 0.8260, F1-score_2: 0.3232
2023-03-07 18:35:24 - __main__ - INFO - Epoch [4/100]
2023-03-07 18:35:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0021, Loss_2: 0.0081, Acc_1: 0.8984, Acc_2: 0.6094, 
2023-03-07 18:35:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0026, Loss_2: 0.0082, Acc_1: 0.8828, Acc_2: 0.6094, 
2023-03-07 18:35:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0020, Loss_2: 0.0078, Acc_1: 0.8750, Acc_2: 0.6406, 
2023-03-07 18:35:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0021, Loss_2: 0.0084, Acc_1: 0.8906, Acc_2: 0.5703, 
2023-03-07 18:35:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0025, Loss_2: 0.0084, Acc_1: 0.8672, Acc_2: 0.5859, 
2023-03-07 18:35:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0031, Loss_2: 0.0097, Acc_1: 0.8281, Acc_2: 0.5234, 
2023-03-07 18:35:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0016, Loss_2: 0.0079, Acc_1: 0.8828, Acc_2: 0.5859, 
2023-03-07 18:35:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0023, Loss_2: 0.0083, Acc_1: 0.8984, Acc_2: 0.5547, 
2023-03-07 18:35:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0026, Loss_2: 0.0094, Acc_1: 0.8594, Acc_2: 0.5547, 
2023-03-07 18:36:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0035, Loss_2: 0.0102, Acc_1: 0.8359, Acc_2: 0.5703, 
2023-03-07 18:36:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0026, Loss_2: 0.0090, Acc_1: 0.8594, Acc_2: 0.5938, 
2023-03-07 18:36:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0035, Loss_2: 0.0100, Acc_1: 0.8047, Acc_2: 0.4844, 
2023-03-07 18:36:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0049, Loss_2: 0.0146, Acc_1: 0.8573, Acc_2: 0.4169, F1-score_1: 0.8156, F1-score_2: 0.3250
2023-03-07 18:36:21 - __main__ - INFO - Epoch [5/100]
2023-03-07 18:36:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0014, Loss_2: 0.0074, Acc_1: 0.9375, Acc_2: 0.6250, 
2023-03-07 18:36:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0009, Loss_2: 0.0076, Acc_1: 0.9062, Acc_2: 0.5469, 
2023-03-07 18:36:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0012, Loss_2: 0.0079, Acc_1: 0.9297, Acc_2: 0.6484, 
2023-03-07 18:36:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0022, Loss_2: 0.0073, Acc_1: 0.8750, Acc_2: 0.6562, 
2023-03-07 18:36:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0011, Loss_2: 0.0092, Acc_1: 0.9219, Acc_2: 0.5547, 
2023-03-07 18:36:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0017, Loss_2: 0.0083, Acc_1: 0.9141, Acc_2: 0.6094, 
2023-03-07 18:36:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0013, Loss_2: 0.0077, Acc_1: 0.9531, Acc_2: 0.6172, 
2023-03-07 18:36:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0073, Acc_1: 0.9297, Acc_2: 0.6406, 
2023-03-07 18:36:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0018, Loss_2: 0.0093, Acc_1: 0.9062, Acc_2: 0.5547, 
2023-03-07 18:36:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0016, Loss_2: 0.0079, Acc_1: 0.9141, Acc_2: 0.6016, 
2023-03-07 18:37:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0016, Loss_2: 0.0080, Acc_1: 0.8906, Acc_2: 0.6016, 
2023-03-07 18:37:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0015, Loss_2: 0.0083, Acc_1: 0.9062, Acc_2: 0.5703, 
2023-03-07 18:37:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0047, Loss_2: 0.0162, Acc_1: 0.8471, Acc_2: 0.4215, F1-score_1: 0.8049, F1-score_2: 0.3189
2023-03-07 18:37:19 - __main__ - INFO - Epoch [6/100]
2023-03-07 18:37:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0009, Loss_2: 0.0075, Acc_1: 0.9375, Acc_2: 0.6484, 
2023-03-07 18:37:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0069, Acc_1: 0.8906, Acc_2: 0.6250, 
2023-03-07 18:37:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0069, Acc_1: 0.9297, Acc_2: 0.6875, 
2023-03-07 18:37:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0070, Acc_1: 0.9062, Acc_2: 0.6562, 
2023-03-07 18:37:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0072, Acc_1: 0.9141, Acc_2: 0.6562, 
2023-03-07 18:37:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0020, Loss_2: 0.0082, Acc_1: 0.8750, Acc_2: 0.6172, 
2023-03-07 18:37:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0012, Loss_2: 0.0079, Acc_1: 0.8828, Acc_2: 0.5938, 
2023-03-07 18:37:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0016, Loss_2: 0.0078, Acc_1: 0.9141, Acc_2: 0.6797, 
2023-03-07 18:37:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0014, Loss_2: 0.0077, Acc_1: 0.8750, Acc_2: 0.6094, 
2023-03-07 18:37:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0075, Acc_1: 0.9062, Acc_2: 0.6562, 
2023-03-07 18:38:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0082, Acc_1: 0.9297, Acc_2: 0.6016, 
2023-03-07 18:38:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0078, Acc_1: 0.9141, Acc_2: 0.6094, 
2023-03-07 18:38:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0048, Loss_2: 0.0178, Acc_1: 0.8507, Acc_2: 0.4188, F1-score_1: 0.8125, F1-score_2: 0.3295
2023-03-07 18:38:17 - __main__ - INFO - Epoch [7/100]
2023-03-07 18:38:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0066, Acc_1: 0.9453, Acc_2: 0.7031, 
2023-03-07 18:38:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0055, Acc_1: 0.8906, Acc_2: 0.7109, 
2023-03-07 18:38:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0010, Loss_2: 0.0061, Acc_1: 0.8984, Acc_2: 0.6406, 
2023-03-07 18:38:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0068, Acc_1: 0.8828, Acc_2: 0.6484, 
2023-03-07 18:38:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0015, Loss_2: 0.0061, Acc_1: 0.9141, Acc_2: 0.7031, 
2023-03-07 18:38:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0010, Loss_2: 0.0075, Acc_1: 0.8984, Acc_2: 0.6406, 
2023-03-07 18:38:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0063, Acc_1: 0.9453, Acc_2: 0.6797, 
2023-03-07 18:38:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0087, Acc_1: 0.8828, Acc_2: 0.5625, 
2023-03-07 18:38:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0062, Acc_1: 0.8984, Acc_2: 0.6953, 
2023-03-07 18:38:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0083, Acc_1: 0.9297, Acc_2: 0.6094, 
2023-03-07 18:38:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0069, Acc_1: 0.9531, Acc_2: 0.6719, 
2023-03-07 18:39:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0018, Loss_2: 0.0084, Acc_1: 0.8594, Acc_2: 0.5625, 
2023-03-07 18:39:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0206, Acc_1: 0.8531, Acc_2: 0.3964, F1-score_1: 0.8132, F1-score_2: 0.3142
2023-03-07 18:39:15 - __main__ - INFO - Epoch [8/100]
2023-03-07 18:39:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0065, Acc_1: 0.9219, Acc_2: 0.6797, 
2023-03-07 18:39:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0010, Loss_2: 0.0063, Acc_1: 0.9219, Acc_2: 0.7188, 
2023-03-07 18:39:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0028, Loss_2: 0.0058, Acc_1: 0.8828, Acc_2: 0.6875, 
2023-03-07 18:39:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0052, Acc_1: 0.9688, Acc_2: 0.7266, 
2023-03-07 18:39:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0057, Acc_1: 0.9219, Acc_2: 0.7031, 
2023-03-07 18:39:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0058, Acc_1: 0.9375, Acc_2: 0.7031, 
2023-03-07 18:39:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0062, Acc_1: 0.9297, Acc_2: 0.6797, 
2023-03-07 18:39:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0067, Acc_1: 0.9062, Acc_2: 0.6641, 
2023-03-07 18:39:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0074, Acc_1: 0.9609, Acc_2: 0.7109, 
2023-03-07 18:39:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0069, Acc_1: 0.9297, Acc_2: 0.6562, 
2023-03-07 18:39:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0092, Acc_1: 0.9141, Acc_2: 0.5156, 
2023-03-07 18:39:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0019, Loss_2: 0.0069, Acc_1: 0.9062, Acc_2: 0.6094, 
2023-03-07 18:40:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0058, Loss_2: 0.0207, Acc_1: 0.8544, Acc_2: 0.4149, F1-score_1: 0.8166, F1-score_2: 0.3271
2023-03-07 18:40:12 - __main__ - INFO - Epoch [9/100]
2023-03-07 18:40:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0043, Acc_1: 0.9453, Acc_2: 0.7812, 
2023-03-07 18:40:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0053, Acc_1: 0.9297, Acc_2: 0.7422, 
2023-03-07 18:40:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0013, Loss_2: 0.0057, Acc_1: 0.8984, Acc_2: 0.7031, 
2023-03-07 18:40:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0054, Acc_1: 0.9688, Acc_2: 0.7188, 
2023-03-07 18:40:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0067, Acc_1: 0.9375, Acc_2: 0.7109, 
2023-03-07 18:40:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0060, Acc_1: 0.9219, Acc_2: 0.6484, 
2023-03-07 18:40:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0014, Loss_2: 0.0068, Acc_1: 0.9453, Acc_2: 0.7109, 
2023-03-07 18:40:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0049, Acc_1: 0.9688, Acc_2: 0.7344, 
2023-03-07 18:40:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0064, Acc_1: 0.9531, Acc_2: 0.6406, 
2023-03-07 18:40:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0061, Acc_1: 0.9375, Acc_2: 0.6641, 
2023-03-07 18:40:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0013, Loss_2: 0.0068, Acc_1: 0.9297, Acc_2: 0.6719, 
2023-03-07 18:40:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0082, Acc_1: 0.8828, Acc_2: 0.5703, 
2023-03-07 18:41:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0050, Loss_2: 0.0215, Acc_1: 0.8555, Acc_2: 0.4023, F1-score_1: 0.8178, F1-score_2: 0.3247
2023-03-07 18:41:10 - __main__ - INFO - Epoch [10/100]
2023-03-07 18:41:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0038, Acc_1: 0.9531, Acc_2: 0.7734, 
2023-03-07 18:41:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0029, Acc_1: 0.9297, Acc_2: 0.8438, 
2023-03-07 18:41:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0060, Acc_1: 0.9297, Acc_2: 0.7109, 
2023-03-07 18:41:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0043, Acc_1: 0.9062, Acc_2: 0.7734, 
2023-03-07 18:41:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0044, Acc_1: 0.9062, Acc_2: 0.7266, 
2023-03-07 18:41:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0012, Loss_2: 0.0049, Acc_1: 0.8750, Acc_2: 0.6719, 
2023-03-07 18:41:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0036, Acc_1: 0.9297, Acc_2: 0.7500, 
2023-03-07 18:41:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0043, Acc_1: 0.9297, Acc_2: 0.7500, 
2023-03-07 18:41:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0047, Acc_1: 0.9375, Acc_2: 0.7344, 
2023-03-07 18:41:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0046, Acc_1: 0.9219, Acc_2: 0.7344, 
2023-03-07 18:41:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0047, Acc_1: 0.9375, Acc_2: 0.7188, 
2023-03-07 18:41:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0046, Acc_1: 0.9688, Acc_2: 0.8125, 
2023-03-07 18:42:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0052, Loss_2: 0.0246, Acc_1: 0.8477, Acc_2: 0.4115, F1-score_1: 0.8089, F1-score_2: 0.3256
2023-03-07 18:42:08 - __main__ - INFO - Epoch [11/100]
2023-03-07 18:42:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0030, Acc_1: 0.8984, Acc_2: 0.7578, 
2023-03-07 18:42:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0037, Acc_1: 0.9141, Acc_2: 0.7734, 
2023-03-07 18:42:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0038, Acc_1: 0.8906, Acc_2: 0.7266, 
2023-03-07 18:42:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0045, Acc_1: 0.9062, Acc_2: 0.7422, 
2023-03-07 18:42:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0038, Acc_1: 0.9062, Acc_2: 0.7109, 
2023-03-07 18:42:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0043, Acc_1: 0.9453, Acc_2: 0.7812, 
2023-03-07 18:42:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0051, Acc_1: 0.9141, Acc_2: 0.6875, 
2023-03-07 18:42:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0040, Acc_1: 0.9453, Acc_2: 0.7500, 
2023-03-07 18:42:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0035, Acc_1: 0.9375, Acc_2: 0.7812, 
2023-03-07 18:42:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0034, Acc_1: 0.9688, Acc_2: 0.8125, 
2023-03-07 18:42:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0046, Acc_1: 0.9453, Acc_2: 0.7891, 
2023-03-07 18:42:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0039, Acc_1: 0.9141, Acc_2: 0.7344, 
2023-03-07 18:43:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0055, Loss_2: 0.0232, Acc_1: 0.8497, Acc_2: 0.3959, F1-score_1: 0.8095, F1-score_2: 0.3132
2023-03-07 18:43:06 - __main__ - INFO - Epoch [12/100]
2023-03-07 18:43:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0033, Acc_1: 0.9141, Acc_2: 0.7812, 
2023-03-07 18:43:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0028, Acc_1: 0.9297, Acc_2: 0.8438, 
2023-03-07 18:43:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0032, Acc_1: 0.9453, Acc_2: 0.7812, 
2023-03-07 18:43:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0025, Acc_1: 0.9609, Acc_2: 0.8125, 
2023-03-07 18:43:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0037, Acc_1: 0.8828, Acc_2: 0.7344, 
2023-03-07 18:43:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0034, Acc_1: 0.9062, Acc_2: 0.7578, 
2023-03-07 18:43:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0028, Acc_1: 0.9375, Acc_2: 0.8359, 
2023-03-07 18:43:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0044, Acc_1: 0.9297, Acc_2: 0.7656, 
2023-03-07 18:43:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0048, Acc_1: 0.9062, Acc_2: 0.7031, 
2023-03-07 18:43:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0031, Acc_1: 0.9219, Acc_2: 0.7578, 
2023-03-07 18:43:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0038, Acc_1: 0.9375, Acc_2: 0.8203, 
2023-03-07 18:43:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0059, Acc_1: 0.8828, Acc_2: 0.6797, 
2023-03-07 18:44:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0054, Loss_2: 0.0239, Acc_1: 0.8471, Acc_2: 0.4124, F1-score_1: 0.8083, F1-score_2: 0.3258
2023-03-07 18:44:03 - __main__ - INFO - Epoch [13/100]
2023-03-07 18:44:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0037, Acc_1: 0.9297, Acc_2: 0.8047, 
2023-03-07 18:44:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0031, Acc_1: 0.9531, Acc_2: 0.8203, 
2023-03-07 18:44:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0038, Acc_1: 0.9297, Acc_2: 0.8125, 
2023-03-07 18:44:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0029, Acc_1: 0.9219, Acc_2: 0.7734, 
2023-03-07 18:44:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0034, Acc_1: 0.9219, Acc_2: 0.7891, 
2023-03-07 18:44:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0031, Acc_1: 0.9297, Acc_2: 0.7891, 
2023-03-07 18:44:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0023, Acc_1: 0.8906, Acc_2: 0.7969, 
2023-03-07 18:44:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0026, Acc_1: 0.9297, Acc_2: 0.8359, 
2023-03-07 18:44:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0027, Acc_1: 0.9453, Acc_2: 0.8281, 
2023-03-07 18:44:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0040, Acc_1: 0.8984, Acc_2: 0.7422, 
2023-03-07 18:44:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0034, Acc_1: 0.9531, Acc_2: 0.8203, 
2023-03-07 18:44:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0037, Acc_1: 0.8672, Acc_2: 0.7344, 
2023-03-07 18:45:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0059, Loss_2: 0.0279, Acc_1: 0.8439, Acc_2: 0.4013, F1-score_1: 0.8051, F1-score_2: 0.3200
2023-03-07 18:45:01 - __main__ - INFO - Epoch [14/100]
2023-03-07 18:45:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0020, Acc_1: 0.9844, Acc_2: 0.8594, 
2023-03-07 18:45:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0031, Acc_1: 0.9219, Acc_2: 0.7891, 
2023-03-07 18:45:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0029, Acc_1: 0.9688, Acc_2: 0.8359, 
2023-03-07 18:45:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0034, Acc_1: 0.9297, Acc_2: 0.7812, 
2023-03-07 18:45:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0026, Acc_1: 0.9297, Acc_2: 0.7969, 
2023-03-07 18:45:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0025, Acc_1: 0.9453, Acc_2: 0.8516, 
2023-03-07 18:45:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0048, Acc_1: 0.8984, Acc_2: 0.7344, 
2023-03-07 18:45:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0031, Acc_1: 0.9219, Acc_2: 0.7969, 
2023-03-07 18:45:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0038, Acc_1: 0.9062, Acc_2: 0.7266, 
2023-03-07 18:45:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0031, Acc_1: 0.9141, Acc_2: 0.8125, 
2023-03-07 18:45:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0025, Acc_1: 0.9375, Acc_2: 0.8203, 
2023-03-07 18:45:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0017, Loss_2: 0.0021, Acc_1: 0.9219, Acc_2: 0.8203, 
2023-03-07 18:45:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0069, Loss_2: 0.0283, Acc_1: 0.8466, Acc_2: 0.3989, F1-score_1: 0.8090, F1-score_2: 0.3183
2023-03-07 18:45:59 - __main__ - INFO - Epoch [15/100]
2023-03-07 18:46:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0016, Acc_1: 0.9219, Acc_2: 0.8594, 
2023-03-07 18:46:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0025, Acc_1: 0.9141, Acc_2: 0.7812, 
2023-03-07 18:46:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.8750, Acc_2: 0.8203, 
2023-03-07 18:46:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0023, Acc_1: 0.8906, Acc_2: 0.8125, 
2023-03-07 18:46:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0027, Acc_1: 0.9297, Acc_2: 0.7812, 
2023-03-07 18:46:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0027, Acc_1: 0.9297, Acc_2: 0.8359, 
2023-03-07 18:46:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0017, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 18:46:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0033, Acc_1: 0.9453, Acc_2: 0.7734, 
2023-03-07 18:46:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0014, Loss_2: 0.0028, Acc_1: 0.8828, Acc_2: 0.7891, 
2023-03-07 18:46:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0021, Acc_1: 0.8984, Acc_2: 0.8203, 
2023-03-07 18:46:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0026, Acc_1: 0.9219, Acc_2: 0.8047, 
2023-03-07 18:46:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0023, Acc_1: 0.9219, Acc_2: 0.8516, 
2023-03-07 18:46:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0068, Loss_2: 0.0295, Acc_1: 0.8504, Acc_2: 0.3983, F1-score_1: 0.8137, F1-score_2: 0.3257
2023-03-07 18:46:56 - __main__ - INFO - Epoch [16/100]
2023-03-07 18:47:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0018, Acc_1: 0.9297, Acc_2: 0.7969, 
2023-03-07 18:47:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0026, Acc_1: 0.9219, Acc_2: 0.7891, 
2023-03-07 18:47:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9609, Acc_2: 0.8906, 
2023-03-07 18:47:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0026, Acc_1: 0.9141, Acc_2: 0.8125, 
2023-03-07 18:47:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0016, Acc_1: 0.9297, Acc_2: 0.8281, 
2023-03-07 18:47:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0021, Acc_1: 0.8906, Acc_2: 0.8125, 
2023-03-07 18:47:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0026, Acc_1: 0.9453, Acc_2: 0.8047, 
2023-03-07 18:47:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9453, Acc_2: 0.8672, 
2023-03-07 18:47:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0014, Acc_1: 0.8906, Acc_2: 0.7891, 
2023-03-07 18:47:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.8984, Acc_2: 0.8125, 
2023-03-07 18:47:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9453, Acc_2: 0.8281, 
2023-03-07 18:47:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0027, Acc_1: 0.9062, Acc_2: 0.7734, 
2023-03-07 18:47:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0061, Loss_2: 0.0302, Acc_1: 0.8490, Acc_2: 0.3996, F1-score_1: 0.8126, F1-score_2: 0.3212
2023-03-07 18:47:54 - __main__ - INFO - Epoch [17/100]
2023-03-07 18:47:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9375, Acc_2: 0.8125, 
2023-03-07 18:48:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 18:48:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0022, Acc_1: 0.9453, Acc_2: 0.8359, 
2023-03-07 18:48:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0031, Acc_1: 0.9297, Acc_2: 0.7969, 
2023-03-07 18:48:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0019, Acc_1: 0.9453, Acc_2: 0.8516, 
2023-03-07 18:48:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.9531, Acc_2: 0.8828, 
2023-03-07 18:48:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9531, Acc_2: 0.8516, 
2023-03-07 18:48:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 18:48:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0018, Acc_1: 0.9062, Acc_2: 0.8047, 
2023-03-07 18:48:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 18:48:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0018, Acc_1: 0.9453, Acc_2: 0.8438, 
2023-03-07 18:48:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0027, Acc_1: 0.8984, Acc_2: 0.8047, 
2023-03-07 18:48:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0062, Loss_2: 0.0300, Acc_1: 0.8453, Acc_2: 0.3957, F1-score_1: 0.8065, F1-score_2: 0.3192
2023-03-07 18:48:52 - __main__ - INFO - Epoch [18/100]
2023-03-07 18:48:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0015, Acc_1: 0.9375, Acc_2: 0.8750, 
2023-03-07 18:49:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8203, 
2023-03-07 18:49:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9531, Acc_2: 0.8438, 
2023-03-07 18:49:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0025, Acc_1: 0.9297, Acc_2: 0.8359, 
2023-03-07 18:49:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0032, Acc_1: 0.9297, Acc_2: 0.8125, 
2023-03-07 18:49:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0022, Acc_1: 0.8984, Acc_2: 0.7969, 
2023-03-07 18:49:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9375, Acc_2: 0.8516, 
2023-03-07 18:49:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9375, Acc_2: 0.8750, 
2023-03-07 18:49:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0011, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 18:49:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9453, Acc_2: 0.8750, 
2023-03-07 18:49:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0017, Acc_1: 0.9141, Acc_2: 0.8438, 
2023-03-07 18:49:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 18:49:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0065, Loss_2: 0.0328, Acc_1: 0.8456, Acc_2: 0.3947, F1-score_1: 0.8065, F1-score_2: 0.3194
2023-03-07 18:49:50 - __main__ - INFO - Epoch [19/100]
2023-03-07 18:49:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0020, Acc_1: 0.9141, Acc_2: 0.8125, 
2023-03-07 18:49:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 18:50:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9609, Acc_2: 0.9141, 
2023-03-07 18:50:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9141, Acc_2: 0.8125, 
2023-03-07 18:50:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.8828, Acc_2: 0.8047, 
2023-03-07 18:50:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0020, Acc_1: 0.9219, Acc_2: 0.8516, 
2023-03-07 18:50:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0022, Acc_1: 0.9297, Acc_2: 0.8281, 
2023-03-07 18:50:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.9297, Acc_2: 0.8438, 
2023-03-07 18:50:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0028, Acc_1: 0.9062, Acc_2: 0.8047, 
2023-03-07 18:50:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9297, Acc_2: 0.8594, 
2023-03-07 18:50:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-07 18:50:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0018, Acc_1: 0.9453, Acc_2: 0.9062, 
2023-03-07 18:50:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0073, Loss_2: 0.0347, Acc_1: 0.8473, Acc_2: 0.4025, F1-score_1: 0.8087, F1-score_2: 0.3212
2023-03-07 18:50:47 - __main__ - INFO - Epoch [20/100]
2023-03-07 18:50:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 18:50:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9453, Acc_2: 0.8594, 
2023-03-07 18:51:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.8984, Acc_2: 0.8203, 
2023-03-07 18:51:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 18:51:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9531, Acc_2: 0.8750, 
2023-03-07 18:51:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9141, Acc_2: 0.8047, 
2023-03-07 18:51:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.9141, Acc_2: 0.8203, 
2023-03-07 18:51:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9453, Acc_2: 0.8750, 
2023-03-07 18:51:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 18:51:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 18:51:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9375, Acc_2: 0.8516, 
2023-03-07 18:51:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9062, Acc_2: 0.8438, 
2023-03-07 18:51:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0068, Loss_2: 0.0336, Acc_1: 0.8431, Acc_2: 0.3981, F1-score_1: 0.8070, F1-score_2: 0.3248
2023-03-07 18:51:45 - __main__ - INFO - Epoch [21/100]
2023-03-07 18:51:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8047, 
2023-03-07 18:51:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 18:51:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9297, Acc_2: 0.8359, 
2023-03-07 18:52:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0028, Acc_1: 0.9141, Acc_2: 0.8203, 
2023-03-07 18:52:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.9297, Acc_2: 0.8438, 
2023-03-07 18:52:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 18:52:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9609, Acc_2: 0.8984, 
2023-03-07 18:52:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9375, Acc_2: 0.8750, 
2023-03-07 18:52:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 18:52:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9141, Acc_2: 0.8125, 
2023-03-07 18:52:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 18:52:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 18:52:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0064, Loss_2: 0.0351, Acc_1: 0.8438, Acc_2: 0.3981, F1-score_1: 0.8072, F1-score_2: 0.3231
2023-03-07 18:52:42 - __main__ - INFO - Epoch [22/100]
2023-03-07 18:52:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8125, 
2023-03-07 18:52:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 18:52:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 18:52:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.9375, Acc_2: 0.8438, 
2023-03-07 18:53:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9141, Acc_2: 0.8438, 
2023-03-07 18:53:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9609, Acc_2: 0.8984, 
2023-03-07 18:53:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.8594, 
2023-03-07 18:53:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-07 18:53:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9375, Acc_2: 0.8438, 
2023-03-07 18:53:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0018, Acc_1: 0.9062, Acc_2: 0.8047, 
2023-03-07 18:53:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8672, 
2023-03-07 18:53:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 18:53:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0069, Loss_2: 0.0361, Acc_1: 0.8500, Acc_2: 0.4000, F1-score_1: 0.8154, F1-score_2: 0.3178
2023-03-07 18:53:40 - __main__ - INFO - Epoch [23/100]
2023-03-07 18:53:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9453, Acc_2: 0.8984, 
2023-03-07 18:53:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 18:53:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8203, 
2023-03-07 18:53:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0021, Acc_1: 0.9219, Acc_2: 0.8125, 
2023-03-07 18:54:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 18:54:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9609, Acc_2: 0.9062, 
2023-03-07 18:54:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8594, 
2023-03-07 18:54:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-07 18:54:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 18:54:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9141, Acc_2: 0.8281, 
2023-03-07 18:54:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9531, Acc_2: 0.9219, 
2023-03-07 18:54:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 18:54:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0080, Loss_2: 0.0388, Acc_1: 0.8483, Acc_2: 0.3898, F1-score_1: 0.8109, F1-score_2: 0.3134
2023-03-07 18:54:38 - __main__ - INFO - Epoch [24/100]
2023-03-07 18:54:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0016, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 18:54:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8203, 
2023-03-07 18:54:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9375, Acc_2: 0.8594, 
2023-03-07 18:54:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.9141, Acc_2: 0.8125, 
2023-03-07 18:54:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 18:55:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.8516, 
2023-03-07 18:55:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 18:55:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 18:55:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9297, Acc_2: 0.8594, 
2023-03-07 18:55:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 18:55:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.9062, Acc_2: 0.8438, 
2023-03-07 18:55:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9297, Acc_2: 0.8516, 
2023-03-07 18:55:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0076, Loss_2: 0.0387, Acc_1: 0.8373, Acc_2: 0.3920, F1-score_1: 0.7933, F1-score_2: 0.3191
2023-03-07 18:55:35 - __main__ - INFO - Epoch [25/100]
2023-03-07 18:55:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 18:55:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 18:55:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.8984, Acc_2: 0.8281, 
2023-03-07 18:55:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9219, Acc_2: 0.8594, 
2023-03-07 18:55:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 18:55:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8750, Acc_2: 0.8125, 
2023-03-07 18:56:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 18:56:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 18:56:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9219, Acc_2: 0.8672, 
2023-03-07 18:56:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 18:56:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0020, Acc_1: 0.9297, Acc_2: 0.8594, 
2023-03-07 18:56:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0028, Acc_1: 0.8906, Acc_2: 0.8047, 
2023-03-07 18:56:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0080, Loss_2: 0.0374, Acc_1: 0.8327, Acc_2: 0.3949, F1-score_1: 0.7927, F1-score_2: 0.3178
2023-03-07 18:56:33 - __main__ - INFO - Epoch [26/100]
2023-03-07 18:56:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9531, Acc_2: 0.8594, 
2023-03-07 18:56:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 18:56:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0021, Acc_1: 0.9453, Acc_2: 0.8359, 
2023-03-07 18:56:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 18:56:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 18:56:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8828, 
2023-03-07 18:57:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 18:57:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 18:57:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0019, Acc_1: 0.9062, Acc_2: 0.8125, 
2023-03-07 18:57:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 18:57:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9062, Acc_2: 0.8438, 
2023-03-07 18:57:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 18:57:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0086, Loss_2: 0.0428, Acc_1: 0.8409, Acc_2: 0.3855, F1-score_1: 0.8018, F1-score_2: 0.3111
2023-03-07 18:57:31 - __main__ - INFO - Epoch [27/100]
2023-03-07 18:57:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 18:57:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0018, Loss_2: 0.0010, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 18:57:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9531, Acc_2: 0.8750, 
2023-03-07 18:57:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 18:57:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.8672, 
2023-03-07 18:57:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 18:57:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 18:58:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0024, Acc_1: 0.9219, Acc_2: 0.8672, 
2023-03-07 18:58:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-07 18:58:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0016, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 18:58:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0027, Acc_1: 0.9141, Acc_2: 0.8359, 
2023-03-07 18:58:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 18:58:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0110, Loss_2: 0.0469, Acc_1: 0.8203, Acc_2: 0.3765, F1-score_1: 0.7787, F1-score_2: 0.3100
2023-03-07 18:58:28 - __main__ - INFO - Epoch [28/100]
2023-03-07 18:58:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0021, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-07 18:58:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 18:58:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 18:58:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9141, Acc_2: 0.8438, 
2023-03-07 18:58:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 18:58:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 18:58:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 18:58:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0014, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 18:59:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0015, Acc_1: 0.8672, Acc_2: 0.7969, 
2023-03-07 18:59:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0015, Acc_1: 0.9219, Acc_2: 0.8594, 
2023-03-07 18:59:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 18:59:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0022, Acc_1: 0.9297, Acc_2: 0.8203, 
2023-03-07 18:59:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0082, Loss_2: 0.0385, Acc_1: 0.8344, Acc_2: 0.3908, F1-score_1: 0.7951, F1-score_2: 0.3118
2023-03-07 18:59:26 - __main__ - INFO - Epoch [29/100]
2023-03-07 18:59:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0017, Acc_1: 0.9453, Acc_2: 0.8906, 
2023-03-07 18:59:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 18:59:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 18:59:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 18:59:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 18:59:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0018, Acc_1: 0.9219, Acc_2: 0.8281, 
2023-03-07 18:59:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0013, Acc_1: 0.9219, Acc_2: 0.8672, 
2023-03-07 18:59:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 19:00:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9609, Acc_2: 0.8750, 
2023-03-07 19:00:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 19:00:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0017, Acc_1: 0.9297, Acc_2: 0.8672, 
2023-03-07 19:00:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.9766, Acc_2: 0.9531, 
2023-03-07 19:00:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0087, Loss_2: 0.0391, Acc_1: 0.8322, Acc_2: 0.3923, F1-score_1: 0.7892, F1-score_2: 0.3204
2023-03-07 19:00:24 - __main__ - INFO - Epoch [30/100]
2023-03-07 19:00:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 19:00:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 19:00:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:00:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:00:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 19:00:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 19:00:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:00:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0017, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 19:00:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0015, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 19:01:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 19:01:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0026, Acc_1: 0.9219, Acc_2: 0.8359, 
2023-03-07 19:01:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:01:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0093, Loss_2: 0.0411, Acc_1: 0.8174, Acc_2: 0.3865, F1-score_1: 0.7731, F1-score_2: 0.3132
2023-03-07 19:01:21 - __main__ - INFO - Epoch [31/100]
2023-03-07 19:01:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-07 19:01:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:01:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 19:01:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:01:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:01:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 19:01:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 19:01:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0011, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:01:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:01:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 19:02:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0015, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 19:02:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 19:02:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0081, Loss_2: 0.0378, Acc_1: 0.8166, Acc_2: 0.3950, F1-score_1: 0.7729, F1-score_2: 0.3235
2023-03-07 19:02:19 - __main__ - INFO - Epoch [32/100]
2023-03-07 19:02:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 19:02:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 19:02:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 19:02:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:02:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 19:02:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0022, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 19:02:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 19:02:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0014, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:02:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 19:02:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0016, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-07 19:03:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 19:03:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:03:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0088, Loss_2: 0.0427, Acc_1: 0.8232, Acc_2: 0.4052, F1-score_1: 0.7776, F1-score_2: 0.3223
2023-03-07 19:03:16 - __main__ - INFO - Epoch [33/100]
2023-03-07 19:03:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 19:03:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0017, Acc_1: 0.8906, Acc_2: 0.7891, 
2023-03-07 19:03:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 19:03:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0017, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-07 19:03:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9531, Acc_2: 0.9219, 
2023-03-07 19:03:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 19:03:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0015, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:03:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0011, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 19:03:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 19:03:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 19:03:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:04:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 19:04:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0123, Loss_2: 0.0441, Acc_1: 0.8201, Acc_2: 0.3916, F1-score_1: 0.7779, F1-score_2: 0.3114
2023-03-07 19:04:14 - __main__ - INFO - Epoch [34/100]
2023-03-07 19:04:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 19:04:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 19:04:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:04:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:04:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 19:04:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 19:04:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:04:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 19:04:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9453, Acc_2: 0.8984, 
2023-03-07 19:04:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 19:04:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 19:04:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:05:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0101, Loss_2: 0.0432, Acc_1: 0.8244, Acc_2: 0.3928, F1-score_1: 0.7817, F1-score_2: 0.3139
2023-03-07 19:05:12 - __main__ - INFO - Epoch [35/100]
2023-03-07 19:05:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 19:05:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 19:05:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 19:05:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 19:05:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:05:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:05:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 19:05:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 19:05:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-07 19:05:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 19:05:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 19:05:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 19:06:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0099, Loss_2: 0.0449, Acc_1: 0.8193, Acc_2: 0.3945, F1-score_1: 0.7768, F1-score_2: 0.3186
2023-03-07 19:06:09 - __main__ - INFO - Epoch [36/100]
2023-03-07 19:06:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9141, 
2023-03-07 19:06:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 19:06:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 19:06:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 19:06:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9453, Acc_2: 0.9141, 
2023-03-07 19:06:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 19:06:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 19:06:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 19:06:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 19:06:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:06:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 19:06:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 19:07:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0445, Acc_1: 0.8291, Acc_2: 0.3918, F1-score_1: 0.7837, F1-score_2: 0.3199
2023-03-07 19:07:07 - __main__ - INFO - Epoch [37/100]
2023-03-07 19:07:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-07 19:07:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:07:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:07:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 19:07:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 19:07:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:07:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.8828, 
2023-03-07 19:07:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:07:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:07:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 19:07:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 19:07:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9688, Acc_2: 0.9453, 
2023-03-07 19:08:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0103, Loss_2: 0.0460, Acc_1: 0.8166, Acc_2: 0.3884, F1-score_1: 0.7690, F1-score_2: 0.3231
2023-03-07 19:08:05 - __main__ - INFO - Epoch [38/100]
2023-03-07 19:08:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:08:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 19:08:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0013, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 19:08:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 19:08:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9531, Acc_2: 0.9141, 
2023-03-07 19:08:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:08:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9688, Acc_2: 0.9531, 
2023-03-07 19:08:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:08:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 19:08:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 19:08:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 19:08:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.9297, Acc_2: 0.8594, 
2023-03-07 19:09:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0453, Acc_1: 0.8181, Acc_2: 0.3933, F1-score_1: 0.7723, F1-score_2: 0.3205
2023-03-07 19:09:02 - __main__ - INFO - Epoch [39/100]
2023-03-07 19:09:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 19:09:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 19:09:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 19:09:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 19:09:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 19:09:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-07 19:09:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 19:09:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9531, Acc_2: 0.9141, 
2023-03-07 19:09:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:09:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 19:09:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 19:09:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 19:10:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0111, Loss_2: 0.0448, Acc_1: 0.8190, Acc_2: 0.3842, F1-score_1: 0.7735, F1-score_2: 0.3120
2023-03-07 19:10:00 - __main__ - INFO - Epoch [40/100]
2023-03-07 19:10:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:10:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 19:10:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:10:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:10:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 19:10:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 19:10:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-07 19:10:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 19:10:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 19:10:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 19:10:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9766, Acc_2: 0.9531, 
2023-03-07 19:10:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:10:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0459, Acc_1: 0.8235, Acc_2: 0.3967, F1-score_1: 0.7783, F1-score_2: 0.3178
2023-03-07 19:10:58 - __main__ - INFO - Epoch [41/100]
2023-03-07 19:11:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 19:11:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 19:11:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:11:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 19:11:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 19:11:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 19:11:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-07 19:11:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 19:11:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:11:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 19:11:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 19:11:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-07 19:11:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0477, Acc_1: 0.8242, Acc_2: 0.3939, F1-score_1: 0.7776, F1-score_2: 0.3203
2023-03-07 19:11:55 - __main__ - INFO - Epoch [42/100]
2023-03-07 19:12:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0020, Acc_1: 0.8984, Acc_2: 0.8281, 
2023-03-07 19:12:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:12:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 19:12:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 19:12:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 19:12:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8594, 
2023-03-07 19:12:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 19:12:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 19:12:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 19:12:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0015, Acc_1: 0.8672, Acc_2: 0.7891, 
2023-03-07 19:12:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:12:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 19:12:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0153, Loss_2: 0.0468, Acc_1: 0.8213, Acc_2: 0.3893, F1-score_1: 0.7778, F1-score_2: 0.3085
2023-03-07 19:12:53 - __main__ - INFO - Epoch [43/100]
2023-03-07 19:12:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:13:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 19:13:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:13:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 19:13:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8594, 
2023-03-07 19:13:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 19:13:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 19:13:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:13:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 19:13:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0021, Loss_2: 0.0008, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 19:13:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 19:13:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 19:13:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0122, Loss_2: 0.0420, Acc_1: 0.8259, Acc_2: 0.4035, F1-score_1: 0.7850, F1-score_2: 0.3251
2023-03-07 19:13:51 - __main__ - INFO - Epoch [44/100]
2023-03-07 19:13:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:13:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 19:14:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 19:14:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 19:14:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:14:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 19:14:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 19:14:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:14:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:14:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:14:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8594, 
2023-03-07 19:14:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 19:14:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0160, Loss_2: 0.0521, Acc_1: 0.8207, Acc_2: 0.3939, F1-score_1: 0.7730, F1-score_2: 0.3208
2023-03-07 19:14:48 - __main__ - INFO - Epoch [45/100]
2023-03-07 19:14:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:14:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:15:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:15:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:15:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:15:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 19:15:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:15:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:15:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 19:15:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:15:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:15:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 19:15:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0131, Loss_2: 0.0450, Acc_1: 0.8200, Acc_2: 0.3842, F1-score_1: 0.7764, F1-score_2: 0.3178
2023-03-07 19:15:46 - __main__ - INFO - Epoch [46/100]
2023-03-07 19:15:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 19:15:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 19:15:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 19:16:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 19:16:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:16:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-07 19:16:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0010, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 19:16:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 19:16:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:16:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:16:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 19:16:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 19:16:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0151, Loss_2: 0.0449, Acc_1: 0.8105, Acc_2: 0.3978, F1-score_1: 0.7726, F1-score_2: 0.3197
2023-03-07 19:16:44 - __main__ - INFO - Epoch [47/100]
2023-03-07 19:16:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 19:16:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 19:16:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:17:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 19:17:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:17:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-07 19:17:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 19:17:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:17:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:17:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:17:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 19:17:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:17:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0121, Loss_2: 0.0481, Acc_1: 0.8159, Acc_2: 0.4010, F1-score_1: 0.7771, F1-score_2: 0.3231
2023-03-07 19:17:41 - __main__ - INFO - Epoch [48/100]
2023-03-07 19:17:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:17:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:17:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 19:17:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 19:18:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 19:18:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:18:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:18:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:18:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:18:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:18:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:18:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:18:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0147, Loss_2: 0.0512, Acc_1: 0.8176, Acc_2: 0.4044, F1-score_1: 0.7752, F1-score_2: 0.3256
2023-03-07 19:18:39 - __main__ - INFO - Epoch [49/100]
2023-03-07 19:18:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:18:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:18:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 19:18:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 19:18:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 19:19:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:19:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 19:19:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:19:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 19:19:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 19:19:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:19:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:19:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0518, Acc_1: 0.8122, Acc_2: 0.4049, F1-score_1: 0.7656, F1-score_2: 0.3222
2023-03-07 19:19:36 - __main__ - INFO - Epoch [50/100]
2023-03-07 19:19:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:19:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 19:19:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:19:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:19:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 19:20:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-07 19:20:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:20:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:20:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 19:20:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:20:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 19:20:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 19:20:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0158, Loss_2: 0.0528, Acc_1: 0.8067, Acc_2: 0.3996, F1-score_1: 0.7588, F1-score_2: 0.3203
2023-03-07 19:20:34 - __main__ - INFO - Epoch [51/100]
2023-03-07 19:20:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 19:20:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 19:20:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 19:20:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:20:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 19:20:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 19:21:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 19:21:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 19:21:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:21:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:21:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 19:21:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 19:21:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0182, Loss_2: 0.0530, Acc_1: 0.8176, Acc_2: 0.3925, F1-score_1: 0.7724, F1-score_2: 0.3180
2023-03-07 19:21:32 - __main__ - INFO - Epoch [52/100]
2023-03-07 19:21:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 19:21:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 19:21:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 19:21:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 19:21:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:21:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:21:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:22:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:22:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:22:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 19:22:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:22:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 19:22:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0179, Loss_2: 0.0495, Acc_1: 0.8088, Acc_2: 0.3952, F1-score_1: 0.7668, F1-score_2: 0.3231
2023-03-07 19:22:29 - __main__ - INFO - Epoch [53/100]
2023-03-07 19:22:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 19:22:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:22:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 19:22:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 19:22:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 19:22:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 19:22:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:23:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:23:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:23:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:23:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:23:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 19:23:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0248, Loss_2: 0.0474, Acc_1: 0.7874, Acc_2: 0.3882, F1-score_1: 0.7399, F1-score_2: 0.3101
2023-03-07 19:23:27 - __main__ - INFO - Epoch [54/100]
2023-03-07 19:23:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 19:23:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 19:23:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 19:23:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:23:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0018, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 19:23:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 19:23:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 19:23:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 19:24:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:24:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:24:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-07 19:24:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 19:24:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0212, Loss_2: 0.0454, Acc_1: 0.8140, Acc_2: 0.4129, F1-score_1: 0.7727, F1-score_2: 0.3270
2023-03-07 19:24:25 - __main__ - INFO - Epoch [55/100]
2023-03-07 19:24:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 19:24:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:24:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 19:24:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:24:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 19:24:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 19:24:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 19:24:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 19:24:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 19:25:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 19:25:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 19:25:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:25:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0178, Loss_2: 0.0493, Acc_1: 0.8117, Acc_2: 0.3991, F1-score_1: 0.7723, F1-score_2: 0.3251
2023-03-07 19:25:22 - __main__ - INFO - Epoch [56/100]
2023-03-07 19:25:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:25:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:25:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:25:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 19:25:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 19:25:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 19:25:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:25:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 19:25:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:26:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 19:26:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 19:26:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:26:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0199, Loss_2: 0.0501, Acc_1: 0.8110, Acc_2: 0.3899, F1-score_1: 0.7711, F1-score_2: 0.3214
2023-03-07 19:26:20 - __main__ - INFO - Epoch [57/100]
2023-03-07 19:26:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:26:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0010, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:26:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 19:26:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:26:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:26:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-07 19:26:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 19:26:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0012, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 19:26:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 19:26:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0015, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:27:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 19:27:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 19:27:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0176, Loss_2: 0.0457, Acc_1: 0.8094, Acc_2: 0.4059, F1-score_1: 0.7673, F1-score_2: 0.3295
2023-03-07 19:27:18 - __main__ - INFO - Epoch [58/100]
2023-03-07 19:27:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:27:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:27:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:27:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-07 19:27:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:27:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:27:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:27:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9609, Acc_2: 0.9375, 
2023-03-07 19:27:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 19:27:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 19:27:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 19:28:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:28:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0169, Loss_2: 0.0546, Acc_1: 0.8088, Acc_2: 0.3950, F1-score_1: 0.7674, F1-score_2: 0.3253
2023-03-07 19:28:15 - __main__ - INFO - Epoch [59/100]
2023-03-07 19:28:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 19:28:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:28:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:28:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 19:28:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 19:28:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 19:28:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:28:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:28:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:28:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:28:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9609, Acc_2: 0.9375, 
2023-03-07 19:29:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 19:29:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0174, Loss_2: 0.0522, Acc_1: 0.7998, Acc_2: 0.3944, F1-score_1: 0.7621, F1-score_2: 0.3210
2023-03-07 19:29:13 - __main__ - INFO - Epoch [60/100]
2023-03-07 19:29:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 19:29:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:29:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:29:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:29:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 19:29:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 19:29:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 19:29:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:29:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:29:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:29:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 19:29:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 19:30:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0162, Loss_2: 0.0531, Acc_1: 0.8128, Acc_2: 0.3916, F1-score_1: 0.7705, F1-score_2: 0.3185
2023-03-07 19:30:11 - __main__ - INFO - Epoch [61/100]
2023-03-07 19:30:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:30:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 19:30:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 19:30:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 19:30:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:30:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 19:30:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:30:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 19:30:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 19:30:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9609, Acc_2: 0.9375, 
2023-03-07 19:30:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:30:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:31:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0216, Loss_2: 0.0539, Acc_1: 0.8133, Acc_2: 0.3991, F1-score_1: 0.7735, F1-score_2: 0.3230
2023-03-07 19:31:08 - __main__ - INFO - Epoch [62/100]
2023-03-07 19:31:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 19:31:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:31:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 19:31:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 19:31:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 19:31:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:31:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 19:31:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:31:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 19:31:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:31:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 19:31:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 19:32:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0212, Loss_2: 0.0556, Acc_1: 0.8042, Acc_2: 0.3905, F1-score_1: 0.7615, F1-score_2: 0.3152
2023-03-07 19:32:06 - __main__ - INFO - Epoch [63/100]
2023-03-07 19:32:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:32:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 19:32:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:32:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:32:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 19:32:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 19:32:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 19:32:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:32:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 19:32:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 19:32:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:32:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:33:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0213, Loss_2: 0.0528, Acc_1: 0.8096, Acc_2: 0.3981, F1-score_1: 0.7693, F1-score_2: 0.3266
2023-03-07 19:33:04 - __main__ - INFO - Epoch [64/100]
2023-03-07 19:33:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 19:33:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:33:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 19:33:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:33:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:33:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:33:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:33:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:33:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:33:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 19:33:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:33:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 19:34:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0215, Loss_2: 0.0499, Acc_1: 0.8139, Acc_2: 0.3937, F1-score_1: 0.7728, F1-score_2: 0.3135
2023-03-07 19:34:01 - __main__ - INFO - Epoch [65/100]
2023-03-07 19:34:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:34:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:34:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:34:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 19:34:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 19:34:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:34:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:34:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 19:34:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:34:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:34:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:34:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:34:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0183, Loss_2: 0.0479, Acc_1: 0.8025, Acc_2: 0.3859, F1-score_1: 0.7577, F1-score_2: 0.3131
2023-03-07 19:34:59 - __main__ - INFO - Epoch [66/100]
2023-03-07 19:35:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 19:35:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 19:35:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 19:35:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:35:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:35:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:35:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:35:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:35:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:35:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:35:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0020, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:35:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-07 19:35:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0182, Loss_2: 0.0505, Acc_1: 0.7965, Acc_2: 0.3937, F1-score_1: 0.7506, F1-score_2: 0.3230
2023-03-07 19:35:57 - __main__ - INFO - Epoch [67/100]
2023-03-07 19:36:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:36:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9453, Acc_2: 0.9141, 
2023-03-07 19:36:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 19:36:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 19:36:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:36:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:36:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 19:36:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:36:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 19:36:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:36:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:36:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0013, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 19:36:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0250, Loss_2: 0.0543, Acc_1: 0.8045, Acc_2: 0.3898, F1-score_1: 0.7632, F1-score_2: 0.3171
2023-03-07 19:36:54 - __main__ - INFO - Epoch [68/100]
2023-03-07 19:36:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 19:37:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 19:37:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 19:37:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:37:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 19:37:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:37:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 19:37:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9453, Acc_2: 0.8984, 
2023-03-07 19:37:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 19:37:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:37:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 19:37:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:37:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0276, Loss_2: 0.0533, Acc_1: 0.8016, Acc_2: 0.3949, F1-score_1: 0.7560, F1-score_2: 0.3171
2023-03-07 19:37:52 - __main__ - INFO - Epoch [69/100]
2023-03-07 19:37:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0017, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:38:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:38:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9609, Acc_2: 0.9375, 
2023-03-07 19:38:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:38:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 19:38:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 19:38:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:38:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-07 19:38:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 19:38:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 19:38:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 19:38:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 19:38:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0197, Loss_2: 0.0529, Acc_1: 0.8088, Acc_2: 0.3891, F1-score_1: 0.7648, F1-score_2: 0.3164
2023-03-07 19:38:49 - __main__ - INFO - Epoch [70/100]
2023-03-07 19:38:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 19:38:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 19:39:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:39:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:39:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-07 19:39:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:39:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 19:39:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 19:39:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 19:39:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 19:39:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:39:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 19:39:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0275, Loss_2: 0.0567, Acc_1: 0.7974, Acc_2: 0.3986, F1-score_1: 0.7523, F1-score_2: 0.3238
2023-03-07 19:39:47 - __main__ - INFO - Epoch [71/100]
2023-03-07 19:39:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:39:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 19:40:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:40:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:40:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:40:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 19:40:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9141, 
2023-03-07 19:40:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 19:40:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 19:40:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:40:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:40:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:40:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0275, Loss_2: 0.0559, Acc_1: 0.7974, Acc_2: 0.3995, F1-score_1: 0.7540, F1-score_2: 0.3211
2023-03-07 19:40:45 - __main__ - INFO - Epoch [72/100]
2023-03-07 19:40:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 19:40:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 19:40:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:41:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:41:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:41:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:41:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:41:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:41:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:41:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:41:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:41:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 19:41:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0274, Loss_2: 0.0558, Acc_1: 0.7906, Acc_2: 0.4015, F1-score_1: 0.7455, F1-score_2: 0.3163
2023-03-07 19:41:42 - __main__ - INFO - Epoch [73/100]
2023-03-07 19:41:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:41:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 19:41:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 19:41:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:42:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:42:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 19:42:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:42:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:42:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 19:42:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:42:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 19:42:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9531, Acc_2: 0.9219, 
2023-03-07 19:42:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0280, Loss_2: 0.0553, Acc_1: 0.8084, Acc_2: 0.4008, F1-score_1: 0.7626, F1-score_2: 0.3142
2023-03-07 19:42:40 - __main__ - INFO - Epoch [74/100]
2023-03-07 19:42:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 19:42:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 19:42:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 19:42:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:42:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 19:43:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 19:43:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:43:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:43:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:43:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 19:43:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 19:43:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:43:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0301, Loss_2: 0.0526, Acc_1: 0.8083, Acc_2: 0.4000, F1-score_1: 0.7620, F1-score_2: 0.3169
2023-03-07 19:43:37 - __main__ - INFO - Epoch [75/100]
2023-03-07 19:43:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:43:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 19:43:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 19:43:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 19:43:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 19:44:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:44:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:44:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 19:44:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-07 19:44:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9609, Acc_2: 0.9688, 
2023-03-07 19:44:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:44:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 19:44:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0315, Loss_2: 0.0568, Acc_1: 0.7962, Acc_2: 0.3927, F1-score_1: 0.7475, F1-score_2: 0.3111
2023-03-07 19:44:35 - __main__ - INFO - Epoch [76/100]
2023-03-07 19:44:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:44:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 19:44:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 19:44:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:44:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 19:44:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 19:45:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:45:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 19:45:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 19:45:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 19:45:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 19:45:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 19:45:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0244, Loss_2: 0.0554, Acc_1: 0.8091, Acc_2: 0.3855, F1-score_1: 0.7562, F1-score_2: 0.3066
2023-03-07 19:45:33 - __main__ - INFO - Epoch [77/100]
2023-03-07 19:45:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:45:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0014, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:45:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 19:45:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:45:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:45:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 19:46:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 19:46:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 19:46:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:46:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:46:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:46:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:46:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0414, Loss_2: 0.0566, Acc_1: 0.7943, Acc_2: 0.3903, F1-score_1: 0.7511, F1-score_2: 0.3149
2023-03-07 19:46:30 - __main__ - INFO - Epoch [78/100]
2023-03-07 19:46:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0011, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9141, 
2023-03-07 19:46:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 19:46:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:46:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:46:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:46:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 19:46:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:47:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:47:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 19:47:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:47:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 19:47:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:47:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0318, Loss_2: 0.0578, Acc_1: 0.8013, Acc_2: 0.3984, F1-score_1: 0.7605, F1-score_2: 0.3205
2023-03-07 19:47:28 - __main__ - INFO - Epoch [79/100]
2023-03-07 19:47:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 19:47:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0034, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 19:47:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 19:47:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 19:47:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:47:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:47:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 19:47:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9688, Acc_2: 0.9688, 
2023-03-07 19:48:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:48:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 19:48:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:48:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:48:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0303, Loss_2: 0.0505, Acc_1: 0.8033, Acc_2: 0.3981, F1-score_1: 0.7589, F1-score_2: 0.3128
2023-03-07 19:48:26 - __main__ - INFO - Epoch [80/100]
2023-03-07 19:48:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 19:48:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 19:48:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9766, Acc_2: 0.9531, 
2023-03-07 19:48:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 19:48:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:48:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 19:48:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:48:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 19:49:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:49:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:49:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 19:49:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:49:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0278, Loss_2: 0.0536, Acc_1: 0.7996, Acc_2: 0.3998, F1-score_1: 0.7559, F1-score_2: 0.3186
2023-03-07 19:49:23 - __main__ - INFO - Epoch [81/100]
2023-03-07 19:49:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 19:49:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:49:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 19:49:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:49:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 19:49:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:49:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:49:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 19:49:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:50:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 19:50:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 19:50:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:50:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0292, Loss_2: 0.0543, Acc_1: 0.8072, Acc_2: 0.3944, F1-score_1: 0.7638, F1-score_2: 0.3172
2023-03-07 19:50:21 - __main__ - INFO - Epoch [82/100]
2023-03-07 19:50:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 19:50:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:50:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 19:50:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:50:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 19:50:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:50:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 19:50:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:50:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:50:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 19:51:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 19:51:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:51:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0301, Loss_2: 0.0550, Acc_1: 0.7986, Acc_2: 0.3981, F1-score_1: 0.7547, F1-score_2: 0.3162
2023-03-07 19:51:18 - __main__ - INFO - Epoch [83/100]
2023-03-07 19:51:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:51:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 19:51:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 19:51:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:51:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 19:51:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:51:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 19:51:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 19:51:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:51:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 19:52:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 19:52:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:52:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0289, Loss_2: 0.0554, Acc_1: 0.8023, Acc_2: 0.3901, F1-score_1: 0.7499, F1-score_2: 0.3149
2023-03-07 19:52:16 - __main__ - INFO - Epoch [84/100]
2023-03-07 19:52:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:52:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9609, 
2023-03-07 19:52:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:52:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 19:52:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:52:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:52:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 19:52:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:52:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:52:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 19:52:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:53:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 19:53:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0331, Loss_2: 0.0571, Acc_1: 0.8100, Acc_2: 0.3896, F1-score_1: 0.7640, F1-score_2: 0.3128
2023-03-07 19:53:14 - __main__ - INFO - Epoch [85/100]
2023-03-07 19:53:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:53:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 19:53:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 19:53:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:53:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 19:53:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 19:53:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:53:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 19:53:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:53:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:53:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:53:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:54:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0306, Loss_2: 0.0598, Acc_1: 0.8060, Acc_2: 0.3947, F1-score_1: 0.7613, F1-score_2: 0.3162
2023-03-07 19:54:11 - __main__ - INFO - Epoch [86/100]
2023-03-07 19:54:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 19:54:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:54:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:54:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 19:54:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:54:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:54:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:54:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 19:54:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 19:54:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 19:54:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:54:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 19:55:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0306, Loss_2: 0.0573, Acc_1: 0.8069, Acc_2: 0.3979, F1-score_1: 0.7634, F1-score_2: 0.3169
2023-03-07 19:55:09 - __main__ - INFO - Epoch [87/100]
2023-03-07 19:55:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:55:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:55:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:55:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 19:55:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 19:55:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:55:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 19:55:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 19:55:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 19:55:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 19:55:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 19:55:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 19:56:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0302, Loss_2: 0.0611, Acc_1: 0.8106, Acc_2: 0.3920, F1-score_1: 0.7670, F1-score_2: 0.3154
2023-03-07 19:56:07 - __main__ - INFO - Epoch [88/100]
2023-03-07 19:56:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 19:56:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 19:56:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 19:56:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:56:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 19:56:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 19:56:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:56:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:56:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 19:56:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 19:56:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:56:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:57:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0298, Loss_2: 0.0587, Acc_1: 0.8084, Acc_2: 0.3950, F1-score_1: 0.7624, F1-score_2: 0.3183
2023-03-07 19:57:04 - __main__ - INFO - Epoch [89/100]
2023-03-07 19:57:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 19:57:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 19:57:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:57:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 19:57:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:57:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 19:57:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:57:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:57:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 19:57:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:57:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 19:57:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 19:58:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0317, Loss_2: 0.0601, Acc_1: 0.8096, Acc_2: 0.3879, F1-score_1: 0.7665, F1-score_2: 0.3146
2023-03-07 19:58:02 - __main__ - INFO - Epoch [90/100]
2023-03-07 19:58:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 19:58:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 19:58:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 19:58:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 19:58:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 19:58:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:58:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 19:58:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 19:58:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 19:58:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 19:58:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 19:58:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 19:58:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0311, Loss_2: 0.0594, Acc_1: 0.8103, Acc_2: 0.3927, F1-score_1: 0.7663, F1-score_2: 0.3153
2023-03-07 19:58:59 - __main__ - INFO - Epoch [91/100]
2023-03-07 19:59:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 19:59:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 19:59:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 19:59:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 19:59:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 19:59:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 19:59:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 19:59:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 19:59:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 19:59:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 19:59:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 19:59:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 19:59:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0310, Loss_2: 0.0595, Acc_1: 0.8117, Acc_2: 0.3942, F1-score_1: 0.7677, F1-score_2: 0.3182
2023-03-07 19:59:57 - __main__ - INFO - Epoch [92/100]
2023-03-07 20:00:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 20:00:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 20:00:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 20:00:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 20:00:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 20:00:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 20:00:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 20:00:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 20:00:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 20:00:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 20:00:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 20:00:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 20:00:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0309, Loss_2: 0.0614, Acc_1: 0.8128, Acc_2: 0.3862, F1-score_1: 0.7688, F1-score_2: 0.3139
2023-03-07 20:00:55 - __main__ - INFO - Epoch [93/100]
2023-03-07 20:01:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 20:01:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 20:01:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 20:01:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 20:01:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 20:01:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9453, 
2023-03-07 20:01:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-07 20:01:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 20:01:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 20:01:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 20:01:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 20:01:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 20:01:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0301, Loss_2: 0.0602, Acc_1: 0.8088, Acc_2: 0.3916, F1-score_1: 0.7653, F1-score_2: 0.3154
2023-03-07 20:01:52 - __main__ - INFO - Epoch [94/100]
2023-03-07 20:01:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 20:02:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 20:02:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 20:02:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 20:02:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 20:02:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 20:02:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 20:02:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 20:02:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 20:02:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 20:02:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 20:02:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 20:02:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0307, Loss_2: 0.0620, Acc_1: 0.8094, Acc_2: 0.3932, F1-score_1: 0.7644, F1-score_2: 0.3169
2023-03-07 20:02:50 - __main__ - INFO - Epoch [95/100]
2023-03-07 20:02:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 20:02:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 20:03:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 20:03:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 20:03:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 20:03:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 20:03:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 20:03:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 20:03:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 20:03:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 20:03:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 20:03:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 20:03:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0299, Loss_2: 0.0619, Acc_1: 0.8111, Acc_2: 0.3927, F1-score_1: 0.7658, F1-score_2: 0.3193
2023-03-07 20:03:48 - __main__ - INFO - Epoch [96/100]
2023-03-07 20:03:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 20:03:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 20:04:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 20:04:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 20:04:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 20:04:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 20:04:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 20:04:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 20:04:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 20:04:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 20:04:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 20:04:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 20:04:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0298, Loss_2: 0.0611, Acc_1: 0.8115, Acc_2: 0.3945, F1-score_1: 0.7658, F1-score_2: 0.3181
2023-03-07 20:04:45 - __main__ - INFO - Epoch [97/100]
2023-03-07 20:04:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 20:04:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 20:04:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 20:05:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 20:05:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 20:05:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 20:05:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 20:05:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 20:05:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-07 20:05:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 20:05:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 20:05:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 20:05:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0296, Loss_2: 0.0612, Acc_1: 0.8117, Acc_2: 0.3989, F1-score_1: 0.7663, F1-score_2: 0.3198
2023-03-07 20:05:43 - __main__ - INFO - Epoch [98/100]
2023-03-07 20:05:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 20:05:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 20:05:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 20:05:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 20:06:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 20:06:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 20:06:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 20:06:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 20:06:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 20:06:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 20:06:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 20:06:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 20:06:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0296, Loss_2: 0.0615, Acc_1: 0.8122, Acc_2: 0.3961, F1-score_1: 0.7677, F1-score_2: 0.3194
2023-03-07 20:06:40 - __main__ - INFO - Epoch [99/100]
2023-03-07 20:06:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 20:06:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 20:06:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 20:06:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-07 20:07:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 20:07:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 20:07:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 20:07:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 20:07:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 20:07:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 20:07:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 20:07:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 20:07:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0300, Loss_2: 0.0618, Acc_1: 0.8122, Acc_2: 0.3932, F1-score_1: 0.7676, F1-score_2: 0.3177
2023-03-07 20:07:40 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 20:07:40 - utils._noise - DEBUG - 6, 7
2023-03-07 20:07:40 - utils._noise - DEBUG - 13997
2023-03-07 20:07:40 - utils._noise - INFO - Actual noise 0.20
2023-03-07 20:07:40 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-07 20:07:40 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-07 20:07:42 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 20:07:42 - __main__ - INFO - Loading dataset...
2023-03-07 20:07:42 - __main__ - INFO - Building model...
2023-03-07 20:07:42 - __main__ - INFO - <bound method Module.parameters of NewsNetCNN(
  (embedding): Embedding(20000, 300)
  (convs): ModuleList(
    (0): Conv2d(1, 300, kernel_size=(3, 300), stride=(1, 1))
    (1): Conv2d(1, 300, kernel_size=(4, 300), stride=(1, 1))
    (2): Conv2d(1, 300, kernel_size=(5, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (linear): Linear(in_features=900, out_features=7, bias=True)
)>
2023-03-07 20:07:42 - __main__ - INFO - <bound method Module.parameters of NewsNet(
  (embedding): Embedding(20000, 300)
  (avgpool): AdaptiveAvgPool1d(output_size=4800)
  (fc1): Linear(in_features=4800, out_features=1200, bias=True)
  (bn1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ac): Softsign()
  (fc2): Linear(in_features=1200, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=7, bias=True)
)>
2023-03-07 20:07:42 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-07 20:07:42 - __main__ - INFO - Start train & evaluate
2023-03-07 20:07:42 - __main__ - INFO - Epoch [0/100]
2023-03-07 20:07:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0161, Loss_2: 0.0155, Acc_1: 0.1797, Acc_2: 0.1484, 
2023-03-07 20:07:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0124, Loss_2: 0.0136, Acc_1: 0.4375, Acc_2: 0.3047, 
2023-03-07 20:07:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0117, Loss_2: 0.0141, Acc_1: 0.5312, Acc_2: 0.3125, 
2023-03-07 20:07:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0116, Loss_2: 0.0146, Acc_1: 0.5625, Acc_2: 0.2969, 
2023-03-07 20:08:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0101, Loss_2: 0.0141, Acc_1: 0.6406, Acc_2: 0.3203, 
2023-03-07 20:08:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0090, Loss_2: 0.0131, Acc_1: 0.6875, Acc_2: 0.4219, 
2023-03-07 20:08:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0075, Loss_2: 0.0132, Acc_1: 0.7109, Acc_2: 0.3828, 
2023-03-07 20:08:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0090, Loss_2: 0.0131, Acc_1: 0.6719, Acc_2: 0.3984, 
2023-03-07 20:08:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0099, Loss_2: 0.0133, Acc_1: 0.6484, Acc_2: 0.3359, 
2023-03-07 20:08:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0100, Loss_2: 0.0132, Acc_1: 0.6250, Acc_2: 0.3906, 
2023-03-07 20:08:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0094, Loss_2: 0.0132, Acc_1: 0.6328, Acc_2: 0.3125, 
2023-03-07 20:08:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0069, Loss_2: 0.0129, Acc_1: 0.7422, Acc_2: 0.3594, 
2023-03-07 20:08:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0056, Loss_2: 0.0120, Acc_1: 0.8371, Acc_2: 0.4519, F1-score_1: 0.7405, F1-score_2: 0.2759
2023-03-07 20:08:40 - __main__ - INFO - Epoch [1/100]
2023-03-07 20:08:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0071, Loss_2: 0.0117, Acc_1: 0.7422, Acc_2: 0.5156, 
2023-03-07 20:08:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0080, Loss_2: 0.0117, Acc_1: 0.6641, Acc_2: 0.4766, 
2023-03-07 20:08:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0084, Loss_2: 0.0131, Acc_1: 0.7266, Acc_2: 0.4062, 
2023-03-07 20:08:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0087, Loss_2: 0.0131, Acc_1: 0.6875, Acc_2: 0.4219, 
2023-03-07 20:09:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0056, Loss_2: 0.0114, Acc_1: 0.8438, Acc_2: 0.5078, 
2023-03-07 20:09:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0073, Loss_2: 0.0126, Acc_1: 0.7578, Acc_2: 0.3906, 
2023-03-07 20:09:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0080, Loss_2: 0.0114, Acc_1: 0.7031, Acc_2: 0.4766, 
2023-03-07 20:09:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0070, Loss_2: 0.0120, Acc_1: 0.7266, Acc_2: 0.4141, 
2023-03-07 20:09:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0077, Loss_2: 0.0118, Acc_1: 0.7422, Acc_2: 0.4531, 
2023-03-07 20:09:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0085, Loss_2: 0.0115, Acc_1: 0.6719, Acc_2: 0.4688, 
2023-03-07 20:09:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0079, Loss_2: 0.0124, Acc_1: 0.6797, Acc_2: 0.4297, 
2023-03-07 20:09:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0062, Loss_2: 0.0111, Acc_1: 0.7734, Acc_2: 0.4375, 
2023-03-07 20:09:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0052, Loss_2: 0.0123, Acc_1: 0.8675, Acc_2: 0.4601, F1-score_1: 0.8341, F1-score_2: 0.3455
2023-03-07 20:09:38 - __main__ - INFO - Epoch [2/100]
2023-03-07 20:09:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0056, Loss_2: 0.0097, Acc_1: 0.7656, Acc_2: 0.6328, 
2023-03-07 20:09:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0054, Loss_2: 0.0100, Acc_1: 0.7891, Acc_2: 0.5547, 
2023-03-07 20:09:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0066, Loss_2: 0.0096, Acc_1: 0.7578, Acc_2: 0.5625, 
2023-03-07 20:09:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0059, Loss_2: 0.0101, Acc_1: 0.7500, Acc_2: 0.5312, 
2023-03-07 20:09:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0060, Loss_2: 0.0108, Acc_1: 0.7188, Acc_2: 0.4688, 
2023-03-07 20:10:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0047, Loss_2: 0.0098, Acc_1: 0.8047, Acc_2: 0.5391, 
2023-03-07 20:10:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0062, Loss_2: 0.0104, Acc_1: 0.7656, Acc_2: 0.5078, 
2023-03-07 20:10:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0056, Loss_2: 0.0105, Acc_1: 0.7969, Acc_2: 0.5781, 
2023-03-07 20:10:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0071, Loss_2: 0.0128, Acc_1: 0.7266, Acc_2: 0.4219, 
2023-03-07 20:10:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0047, Loss_2: 0.0114, Acc_1: 0.8047, Acc_2: 0.4844, 
2023-03-07 20:10:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0055, Loss_2: 0.0114, Acc_1: 0.7812, Acc_2: 0.5391, 
2023-03-07 20:10:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0065, Loss_2: 0.0126, Acc_1: 0.7344, Acc_2: 0.4141, 
2023-03-07 20:10:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0126, Acc_1: 0.8752, Acc_2: 0.4370, F1-score_1: 0.8361, F1-score_2: 0.3350
2023-03-07 20:10:35 - __main__ - INFO - Epoch [3/100]
2023-03-07 20:10:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0033, Loss_2: 0.0091, Acc_1: 0.8906, Acc_2: 0.6250, 
2023-03-07 20:10:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0036, Loss_2: 0.0078, Acc_1: 0.8359, Acc_2: 0.6641, 
2023-03-07 20:10:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0037, Loss_2: 0.0086, Acc_1: 0.8125, Acc_2: 0.5703, 
2023-03-07 20:10:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0038, Loss_2: 0.0100, Acc_1: 0.8281, Acc_2: 0.5000, 
2023-03-07 20:10:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0042, Loss_2: 0.0098, Acc_1: 0.7734, Acc_2: 0.5469, 
2023-03-07 20:10:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0038, Loss_2: 0.0097, Acc_1: 0.8281, Acc_2: 0.5391, 
2023-03-07 20:11:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0046, Loss_2: 0.0104, Acc_1: 0.7812, Acc_2: 0.5312, 
2023-03-07 20:11:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0040, Loss_2: 0.0101, Acc_1: 0.8359, Acc_2: 0.5703, 
2023-03-07 20:11:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0042, Loss_2: 0.0110, Acc_1: 0.8359, Acc_2: 0.5078, 
2023-03-07 20:11:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0046, Loss_2: 0.0110, Acc_1: 0.8203, Acc_2: 0.4922, 
2023-03-07 20:11:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0049, Loss_2: 0.0106, Acc_1: 0.7891, Acc_2: 0.5547, 
2023-03-07 20:11:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0030, Loss_2: 0.0112, Acc_1: 0.8906, Acc_2: 0.4766, 
2023-03-07 20:11:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0044, Loss_2: 0.0141, Acc_1: 0.8575, Acc_2: 0.4300, F1-score_1: 0.8182, F1-score_2: 0.3084
2023-03-07 20:11:33 - __main__ - INFO - Epoch [4/100]
2023-03-07 20:11:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0020, Loss_2: 0.0076, Acc_1: 0.9141, Acc_2: 0.6562, 
2023-03-07 20:11:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0029, Loss_2: 0.0078, Acc_1: 0.8281, Acc_2: 0.6172, 
2023-03-07 20:11:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0022, Loss_2: 0.0073, Acc_1: 0.8750, Acc_2: 0.6641, 
2023-03-07 20:11:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0024, Loss_2: 0.0084, Acc_1: 0.8984, Acc_2: 0.6016, 
2023-03-07 20:11:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0022, Loss_2: 0.0080, Acc_1: 0.8438, Acc_2: 0.6172, 
2023-03-07 20:11:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0027, Loss_2: 0.0090, Acc_1: 0.8906, Acc_2: 0.5547, 
2023-03-07 20:12:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0028, Loss_2: 0.0082, Acc_1: 0.8750, Acc_2: 0.5938, 
2023-03-07 20:12:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0018, Loss_2: 0.0084, Acc_1: 0.9062, Acc_2: 0.6328, 
2023-03-07 20:12:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0026, Loss_2: 0.0086, Acc_1: 0.8359, Acc_2: 0.5781, 
2023-03-07 20:12:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0027, Loss_2: 0.0093, Acc_1: 0.8750, Acc_2: 0.5625, 
2023-03-07 20:12:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0033, Loss_2: 0.0113, Acc_1: 0.8359, Acc_2: 0.4688, 
2023-03-07 20:12:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0026, Loss_2: 0.0092, Acc_1: 0.8594, Acc_2: 0.5625, 
2023-03-07 20:12:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0047, Loss_2: 0.0150, Acc_1: 0.8499, Acc_2: 0.4175, F1-score_1: 0.8031, F1-score_2: 0.3175
2023-03-07 20:12:30 - __main__ - INFO - Epoch [5/100]
2023-03-07 20:12:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0016, Loss_2: 0.0071, Acc_1: 0.8828, Acc_2: 0.6797, 
2023-03-07 20:12:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0014, Loss_2: 0.0070, Acc_1: 0.9375, Acc_2: 0.6406, 
2023-03-07 20:12:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0013, Loss_2: 0.0062, Acc_1: 0.8906, Acc_2: 0.6953, 
2023-03-07 20:12:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0014, Loss_2: 0.0080, Acc_1: 0.9062, Acc_2: 0.5703, 
2023-03-07 20:12:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0013, Loss_2: 0.0082, Acc_1: 0.9062, Acc_2: 0.6562, 
2023-03-07 20:12:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0018, Loss_2: 0.0065, Acc_1: 0.9062, Acc_2: 0.6953, 
2023-03-07 20:12:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0017, Loss_2: 0.0074, Acc_1: 0.8828, Acc_2: 0.6172, 
2023-03-07 20:13:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0081, Acc_1: 0.9219, Acc_2: 0.6016, 
2023-03-07 20:13:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0013, Loss_2: 0.0074, Acc_1: 0.9062, Acc_2: 0.6953, 
2023-03-07 20:13:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0018, Loss_2: 0.0082, Acc_1: 0.9141, Acc_2: 0.6250, 
2023-03-07 20:13:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0026, Loss_2: 0.0097, Acc_1: 0.8438, Acc_2: 0.5391, 
2023-03-07 20:13:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0012, Loss_2: 0.0072, Acc_1: 0.9297, Acc_2: 0.6719, 
2023-03-07 20:13:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0039, Loss_2: 0.0158, Acc_1: 0.8471, Acc_2: 0.4005, F1-score_1: 0.8008, F1-score_2: 0.3204
2023-03-07 20:13:28 - __main__ - INFO - Epoch [6/100]
2023-03-07 20:13:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0069, Acc_1: 0.8828, Acc_2: 0.7031, 
2023-03-07 20:13:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0071, Acc_1: 0.8828, Acc_2: 0.6328, 
2023-03-07 20:13:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0065, Acc_1: 0.9297, Acc_2: 0.6562, 
2023-03-07 20:13:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0015, Loss_2: 0.0093, Acc_1: 0.8672, Acc_2: 0.5547, 
2023-03-07 20:13:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0014, Loss_2: 0.0070, Acc_1: 0.8750, Acc_2: 0.6172, 
2023-03-07 20:13:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0066, Acc_1: 0.9375, Acc_2: 0.6484, 
2023-03-07 20:13:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0011, Loss_2: 0.0078, Acc_1: 0.8984, Acc_2: 0.6406, 
2023-03-07 20:13:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0013, Loss_2: 0.0079, Acc_1: 0.9219, Acc_2: 0.6406, 
2023-03-07 20:14:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0070, Acc_1: 0.9453, Acc_2: 0.6719, 
2023-03-07 20:14:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0079, Acc_1: 0.9297, Acc_2: 0.6250, 
2023-03-07 20:14:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0071, Acc_1: 0.9453, Acc_2: 0.6484, 
2023-03-07 20:14:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0076, Acc_1: 0.9062, Acc_2: 0.5938, 
2023-03-07 20:14:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0161, Acc_1: 0.8463, Acc_2: 0.4176, F1-score_1: 0.8038, F1-score_2: 0.3151
2023-03-07 20:14:26 - __main__ - INFO - Epoch [7/100]
2023-03-07 20:14:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0061, Acc_1: 0.8906, Acc_2: 0.6719, 
2023-03-07 20:14:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0059, Acc_1: 0.9219, Acc_2: 0.6875, 
2023-03-07 20:14:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0056, Acc_1: 0.9141, Acc_2: 0.7109, 
2023-03-07 20:14:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0068, Acc_1: 0.9297, Acc_2: 0.6875, 
2023-03-07 20:14:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0051, Acc_1: 0.9062, Acc_2: 0.7344, 
2023-03-07 20:14:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0013, Loss_2: 0.0067, Acc_1: 0.8984, Acc_2: 0.6641, 
2023-03-07 20:14:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0076, Acc_1: 0.9062, Acc_2: 0.6484, 
2023-03-07 20:14:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0020, Loss_2: 0.0072, Acc_1: 0.9062, Acc_2: 0.6250, 
2023-03-07 20:15:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0065, Acc_1: 0.8828, Acc_2: 0.6328, 
2023-03-07 20:15:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0016, Loss_2: 0.0077, Acc_1: 0.9297, Acc_2: 0.6250, 
2023-03-07 20:15:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0052, Acc_1: 0.9141, Acc_2: 0.6797, 
2023-03-07 20:15:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0085, Acc_1: 0.9375, Acc_2: 0.6250, 
2023-03-07 20:15:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0051, Loss_2: 0.0184, Acc_1: 0.8415, Acc_2: 0.4253, F1-score_1: 0.8013, F1-score_2: 0.3338
2023-03-07 20:15:24 - __main__ - INFO - Epoch [8/100]
2023-03-07 20:15:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0052, Acc_1: 0.9531, Acc_2: 0.7656, 
2023-03-07 20:15:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0044, Acc_1: 0.9375, Acc_2: 0.7812, 
2023-03-07 20:15:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0061, Acc_1: 0.9297, Acc_2: 0.6484, 
2023-03-07 20:15:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0052, Acc_1: 0.9062, Acc_2: 0.7031, 
2023-03-07 20:15:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0057, Acc_1: 0.9219, Acc_2: 0.7031, 
2023-03-07 20:15:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0070, Acc_1: 0.9297, Acc_2: 0.6562, 
2023-03-07 20:15:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0048, Acc_1: 0.9297, Acc_2: 0.7266, 
2023-03-07 20:15:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0054, Acc_1: 0.9688, Acc_2: 0.6875, 
2023-03-07 20:15:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0068, Acc_1: 0.9297, Acc_2: 0.6953, 
2023-03-07 20:16:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0059, Acc_1: 0.9375, Acc_2: 0.7109, 
2023-03-07 20:16:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0077, Acc_1: 0.9688, Acc_2: 0.6094, 
2023-03-07 20:16:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0058, Acc_1: 0.9453, Acc_2: 0.6797, 
2023-03-07 20:16:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0049, Loss_2: 0.0195, Acc_1: 0.8471, Acc_2: 0.3972, F1-score_1: 0.8031, F1-score_2: 0.3209
2023-03-07 20:16:21 - __main__ - INFO - Epoch [9/100]
2023-03-07 20:16:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0046, Acc_1: 0.9062, Acc_2: 0.7578, 
2023-03-07 20:16:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0009, Loss_2: 0.0049, Acc_1: 0.8750, Acc_2: 0.7266, 
2023-03-07 20:16:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0041, Acc_1: 0.8828, Acc_2: 0.7188, 
2023-03-07 20:16:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0051, Acc_1: 0.9219, Acc_2: 0.7188, 
2023-03-07 20:16:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0041, Acc_1: 0.9375, Acc_2: 0.7734, 
2023-03-07 20:16:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0058, Acc_1: 0.9062, Acc_2: 0.6797, 
2023-03-07 20:16:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0061, Acc_1: 0.9219, Acc_2: 0.6875, 
2023-03-07 20:16:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0062, Acc_1: 0.8828, Acc_2: 0.6797, 
2023-03-07 20:16:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0051, Acc_1: 0.9453, Acc_2: 0.7422, 
2023-03-07 20:16:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0010, Loss_2: 0.0053, Acc_1: 0.9531, Acc_2: 0.7500, 
2023-03-07 20:17:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0059, Acc_1: 0.9453, Acc_2: 0.7109, 
2023-03-07 20:17:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0073, Acc_1: 0.9375, Acc_2: 0.6797, 
2023-03-07 20:17:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0054, Loss_2: 0.0205, Acc_1: 0.8497, Acc_2: 0.4127, F1-score_1: 0.8134, F1-score_2: 0.3177
2023-03-07 20:17:19 - __main__ - INFO - Epoch [10/100]
2023-03-07 20:17:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0056, Acc_1: 0.9141, Acc_2: 0.7344, 
2023-03-07 20:17:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0035, Acc_1: 0.9219, Acc_2: 0.7500, 
2023-03-07 20:17:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0014, Loss_2: 0.0042, Acc_1: 0.9141, Acc_2: 0.7812, 
2023-03-07 20:17:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0059, Acc_1: 0.9297, Acc_2: 0.7344, 
2023-03-07 20:17:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0044, Acc_1: 0.9297, Acc_2: 0.7422, 
2023-03-07 20:17:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0053, Acc_1: 0.8984, Acc_2: 0.6875, 
2023-03-07 20:17:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0038, Acc_1: 0.9219, Acc_2: 0.8047, 
2023-03-07 20:17:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0042, Acc_1: 0.9375, Acc_2: 0.7812, 
2023-03-07 20:17:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0042, Acc_1: 0.9453, Acc_2: 0.7422, 
2023-03-07 20:17:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0059, Acc_1: 0.9219, Acc_2: 0.7109, 
2023-03-07 20:18:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0049, Acc_1: 0.9453, Acc_2: 0.6953, 
2023-03-07 20:18:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0040, Acc_1: 0.9531, Acc_2: 0.7656, 
2023-03-07 20:18:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0046, Loss_2: 0.0228, Acc_1: 0.8514, Acc_2: 0.4012, F1-score_1: 0.8137, F1-score_2: 0.3120
2023-03-07 20:18:16 - __main__ - INFO - Epoch [11/100]
2023-03-07 20:18:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0031, Acc_1: 0.9219, Acc_2: 0.7812, 
2023-03-07 20:18:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0038, Acc_1: 0.9062, Acc_2: 0.7500, 
2023-03-07 20:18:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0032, Acc_1: 0.9375, Acc_2: 0.7969, 
2023-03-07 20:18:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0046, Acc_1: 0.9375, Acc_2: 0.7734, 
2023-03-07 20:18:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0034, Acc_1: 0.8750, Acc_2: 0.7188, 
2023-03-07 20:18:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0045, Acc_1: 0.9297, Acc_2: 0.7500, 
2023-03-07 20:18:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0049, Acc_1: 0.9062, Acc_2: 0.7109, 
2023-03-07 20:18:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0037, Acc_1: 0.8828, Acc_2: 0.7500, 
2023-03-07 20:18:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0021, Acc_1: 0.9453, Acc_2: 0.8672, 
2023-03-07 20:18:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0042, Acc_1: 0.9062, Acc_2: 0.7188, 
2023-03-07 20:18:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0034, Acc_1: 0.9375, Acc_2: 0.7891, 
2023-03-07 20:19:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0036, Acc_1: 0.9297, Acc_2: 0.8047, 
2023-03-07 20:19:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0056, Loss_2: 0.0241, Acc_1: 0.8533, Acc_2: 0.3952, F1-score_1: 0.8136, F1-score_2: 0.3148
2023-03-07 20:19:14 - __main__ - INFO - Epoch [12/100]
2023-03-07 20:19:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0035, Acc_1: 0.9453, Acc_2: 0.8047, 
2023-03-07 20:19:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0026, Acc_1: 0.9375, Acc_2: 0.8203, 
2023-03-07 20:19:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0026, Acc_1: 0.9375, Acc_2: 0.8203, 
2023-03-07 20:19:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0036, Acc_1: 0.9375, Acc_2: 0.7656, 
2023-03-07 20:19:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0030, Acc_1: 0.9531, Acc_2: 0.7969, 
2023-03-07 20:19:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0039, Acc_1: 0.9375, Acc_2: 0.7188, 
2023-03-07 20:19:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0036, Acc_1: 0.9453, Acc_2: 0.7891, 
2023-03-07 20:19:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0032, Acc_1: 0.8984, Acc_2: 0.7656, 
2023-03-07 20:19:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0052, Acc_1: 0.9141, Acc_2: 0.7422, 
2023-03-07 20:19:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0044, Acc_1: 0.8906, Acc_2: 0.7422, 
2023-03-07 20:19:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0030, Acc_1: 0.9297, Acc_2: 0.8047, 
2023-03-07 20:19:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0031, Acc_1: 0.8984, Acc_2: 0.8047, 
2023-03-07 20:20:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0060, Loss_2: 0.0245, Acc_1: 0.8531, Acc_2: 0.3933, F1-score_1: 0.8115, F1-score_2: 0.3187
2023-03-07 20:20:12 - __main__ - INFO - Epoch [13/100]
2023-03-07 20:20:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0022, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 20:20:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0021, Acc_1: 0.9375, Acc_2: 0.8594, 
2023-03-07 20:20:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0026, Acc_1: 0.9453, Acc_2: 0.8047, 
2023-03-07 20:20:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0039, Acc_1: 0.9062, Acc_2: 0.7734, 
2023-03-07 20:20:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0027, Acc_1: 0.9375, Acc_2: 0.8203, 
2023-03-07 20:20:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0024, Acc_1: 0.9219, Acc_2: 0.8047, 
2023-03-07 20:20:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0025, Acc_1: 0.9453, Acc_2: 0.8516, 
2023-03-07 20:20:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0037, Acc_1: 0.9453, Acc_2: 0.8203, 
2023-03-07 20:20:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0029, Acc_1: 0.9375, Acc_2: 0.7969, 
2023-03-07 20:20:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0041, Acc_1: 0.8672, Acc_2: 0.7109, 
2023-03-07 20:20:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0038, Acc_1: 0.9531, Acc_2: 0.7578, 
2023-03-07 20:20:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0039, Acc_1: 0.9141, Acc_2: 0.7422, 
2023-03-07 20:21:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0074, Loss_2: 0.0266, Acc_1: 0.8453, Acc_2: 0.3964, F1-score_1: 0.8053, F1-score_2: 0.3195
2023-03-07 20:21:09 - __main__ - INFO - Epoch [14/100]
2023-03-07 20:21:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0026, Acc_1: 0.8984, Acc_2: 0.7812, 
2023-03-07 20:21:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0025, Acc_1: 0.9375, Acc_2: 0.8516, 
2023-03-07 20:21:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0029, Acc_1: 0.9453, Acc_2: 0.8438, 
2023-03-07 20:21:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0027, Acc_1: 0.9453, Acc_2: 0.7969, 
2023-03-07 20:21:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0033, Acc_1: 0.9219, Acc_2: 0.7734, 
2023-03-07 20:21:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0046, Acc_1: 0.8984, Acc_2: 0.7188, 
2023-03-07 20:21:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0028, Acc_1: 0.9141, Acc_2: 0.8203, 
2023-03-07 20:21:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0025, Acc_1: 0.9375, Acc_2: 0.8125, 
2023-03-07 20:21:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0032, Acc_1: 0.8750, Acc_2: 0.7578, 
2023-03-07 20:21:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0024, Acc_1: 0.9531, Acc_2: 0.8828, 
2023-03-07 20:21:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0031, Acc_1: 0.9375, Acc_2: 0.7891, 
2023-03-07 20:21:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0033, Acc_1: 0.9141, Acc_2: 0.8125, 
2023-03-07 20:22:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0051, Loss_2: 0.0288, Acc_1: 0.8456, Acc_2: 0.3881, F1-score_1: 0.8089, F1-score_2: 0.3120
2023-03-07 20:22:07 - __main__ - INFO - Epoch [15/100]
2023-03-07 20:22:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0021, Acc_1: 0.9766, Acc_2: 0.8906, 
2023-03-07 20:22:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9141, Acc_2: 0.8281, 
2023-03-07 20:22:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0021, Acc_1: 0.9531, Acc_2: 0.8438, 
2023-03-07 20:22:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0027, Acc_1: 0.8906, Acc_2: 0.7969, 
2023-03-07 20:22:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0023, Acc_1: 0.9688, Acc_2: 0.8672, 
2023-03-07 20:22:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0022, Acc_1: 0.9219, Acc_2: 0.8203, 
2023-03-07 20:22:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0037, Acc_1: 0.9453, Acc_2: 0.7969, 
2023-03-07 20:22:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0023, Acc_1: 0.9219, Acc_2: 0.8125, 
2023-03-07 20:22:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9531, Acc_2: 0.8672, 
2023-03-07 20:22:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0030, Acc_1: 0.9453, Acc_2: 0.8438, 
2023-03-07 20:22:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0028, Acc_1: 0.9453, Acc_2: 0.8047, 
2023-03-07 20:22:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0027, Acc_1: 0.9219, Acc_2: 0.7812, 
2023-03-07 20:23:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0284, Acc_1: 0.8446, Acc_2: 0.3981, F1-score_1: 0.8036, F1-score_2: 0.3210
2023-03-07 20:23:05 - __main__ - INFO - Epoch [16/100]
2023-03-07 20:23:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.9219, Acc_2: 0.8516, 
2023-03-07 20:23:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9531, Acc_2: 0.8984, 
2023-03-07 20:23:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0031, Acc_1: 0.9297, Acc_2: 0.7891, 
2023-03-07 20:23:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9219, Acc_2: 0.8125, 
2023-03-07 20:23:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0023, Acc_1: 0.9375, Acc_2: 0.8047, 
2023-03-07 20:23:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0020, Acc_1: 0.9062, Acc_2: 0.7969, 
2023-03-07 20:23:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0020, Acc_1: 0.8828, Acc_2: 0.7656, 
2023-03-07 20:23:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.9531, Acc_2: 0.8672, 
2023-03-07 20:23:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9375, Acc_2: 0.8906, 
2023-03-07 20:23:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0034, Acc_1: 0.9375, Acc_2: 0.7422, 
2023-03-07 20:23:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0036, Acc_1: 0.9062, Acc_2: 0.7734, 
2023-03-07 20:23:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0022, Acc_1: 0.9297, Acc_2: 0.8125, 
2023-03-07 20:24:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0071, Loss_2: 0.0312, Acc_1: 0.8465, Acc_2: 0.3865, F1-score_1: 0.8086, F1-score_2: 0.3145
2023-03-07 20:24:02 - __main__ - INFO - Epoch [17/100]
2023-03-07 20:24:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9531, Acc_2: 0.9062, 
2023-03-07 20:24:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0023, Acc_1: 0.8750, Acc_2: 0.7734, 
2023-03-07 20:24:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0017, Acc_1: 0.9141, Acc_2: 0.7969, 
2023-03-07 20:24:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0020, Acc_1: 0.8438, Acc_2: 0.7656, 
2023-03-07 20:24:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 20:24:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.8984, Acc_2: 0.8125, 
2023-03-07 20:24:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0021, Acc_1: 0.9141, Acc_2: 0.8359, 
2023-03-07 20:24:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9453, Acc_2: 0.8594, 
2023-03-07 20:24:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0025, Acc_1: 0.8984, Acc_2: 0.8125, 
2023-03-07 20:24:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0013, Loss_2: 0.0037, Acc_1: 0.9375, Acc_2: 0.8438, 
2023-03-07 20:24:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0021, Acc_1: 0.9453, Acc_2: 0.8516, 
2023-03-07 20:24:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0023, Acc_1: 0.9141, Acc_2: 0.7969, 
2023-03-07 20:25:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0067, Loss_2: 0.0304, Acc_1: 0.8405, Acc_2: 0.3855, F1-score_1: 0.7921, F1-score_2: 0.3091
2023-03-07 20:25:00 - __main__ - INFO - Epoch [18/100]
2023-03-07 20:25:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0021, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-07 20:25:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9062, Acc_2: 0.8438, 
2023-03-07 20:25:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0019, Acc_1: 0.9062, Acc_2: 0.8047, 
2023-03-07 20:25:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.9453, Acc_2: 0.8516, 
2023-03-07 20:25:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0019, Acc_1: 0.9453, Acc_2: 0.8594, 
2023-03-07 20:25:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9219, Acc_2: 0.8125, 
2023-03-07 20:25:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9453, Acc_2: 0.8906, 
2023-03-07 20:25:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.9531, Acc_2: 0.8125, 
2023-03-07 20:25:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9375, Acc_2: 0.8750, 
2023-03-07 20:25:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0018, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 20:25:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0031, Acc_1: 0.9141, Acc_2: 0.7656, 
2023-03-07 20:25:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0020, Acc_1: 0.9375, Acc_2: 0.8203, 
2023-03-07 20:25:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0068, Loss_2: 0.0327, Acc_1: 0.8463, Acc_2: 0.3828, F1-score_1: 0.8083, F1-score_2: 0.3017
2023-03-07 20:25:58 - __main__ - INFO - Epoch [19/100]
2023-03-07 20:26:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9375, Acc_2: 0.8281, 
2023-03-07 20:26:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9688, Acc_2: 0.8672, 
2023-03-07 20:26:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0022, Acc_1: 0.9141, Acc_2: 0.7891, 
2023-03-07 20:26:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 20:26:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9375, Acc_2: 0.8438, 
2023-03-07 20:26:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9141, Acc_2: 0.8203, 
2023-03-07 20:26:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9219, Acc_2: 0.8672, 
2023-03-07 20:26:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9297, Acc_2: 0.8594, 
2023-03-07 20:26:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0017, Acc_1: 0.9531, Acc_2: 0.8594, 
2023-03-07 20:26:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0015, Acc_1: 0.9219, Acc_2: 0.8203, 
2023-03-07 20:26:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8203, 
2023-03-07 20:26:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9219, Acc_2: 0.8047, 
2023-03-07 20:26:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0073, Loss_2: 0.0302, Acc_1: 0.8412, Acc_2: 0.3804, F1-score_1: 0.8035, F1-score_2: 0.3148
2023-03-07 20:26:55 - __main__ - INFO - Epoch [20/100]
2023-03-07 20:27:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 20:27:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9531, Acc_2: 0.9062, 
2023-03-07 20:27:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-07 20:27:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 20:27:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 20:27:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9062, Acc_2: 0.8047, 
2023-03-07 20:27:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 20:27:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8438, 
2023-03-07 20:27:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0023, Acc_1: 0.9062, Acc_2: 0.7969, 
2023-03-07 20:27:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.9609, Acc_2: 0.8906, 
2023-03-07 20:27:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 20:27:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0028, Acc_1: 0.9062, Acc_2: 0.7969, 
2023-03-07 20:27:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0084, Loss_2: 0.0323, Acc_1: 0.8419, Acc_2: 0.3911, F1-score_1: 0.7981, F1-score_2: 0.3083
2023-03-07 20:27:53 - __main__ - INFO - Epoch [21/100]
2023-03-07 20:27:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0016, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 20:28:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8047, 
2023-03-07 20:28:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9453, Acc_2: 0.8750, 
2023-03-07 20:28:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-07 20:28:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-07 20:28:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 20:28:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9062, Acc_2: 0.8359, 
2023-03-07 20:28:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 20:28:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9297, Acc_2: 0.8672, 
2023-03-07 20:28:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9219, Acc_2: 0.8359, 
2023-03-07 20:28:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-07 20:28:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0015, Acc_1: 0.8906, Acc_2: 0.7812, 
2023-03-07 20:28:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0075, Loss_2: 0.0343, Acc_1: 0.8395, Acc_2: 0.3989, F1-score_1: 0.7976, F1-score_2: 0.3233
2023-03-07 20:28:50 - __main__ - INFO - Epoch [22/100]
2023-03-07 20:28:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 20:28:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8984, Acc_2: 0.8047, 
2023-03-07 20:29:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9141, Acc_2: 0.8359, 
2023-03-07 20:29:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 20:29:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0016, Acc_1: 0.9297, Acc_2: 0.8672, 
2023-03-07 20:29:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 20:29:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 20:29:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.9688, Acc_2: 0.8828, 
2023-03-07 20:29:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 20:29:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9531, Acc_2: 0.9062, 
2023-03-07 20:29:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8203, 
2023-03-07 20:29:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0034, Acc_1: 0.8828, Acc_2: 0.7891, 
2023-03-07 20:29:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0076, Loss_2: 0.0313, Acc_1: 0.8344, Acc_2: 0.3888, F1-score_1: 0.7887, F1-score_2: 0.3106
2023-03-07 20:29:48 - __main__ - INFO - Epoch [23/100]
2023-03-07 20:29:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9531, Acc_2: 0.8828, 
2023-03-07 20:29:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0022, Acc_1: 0.8984, Acc_2: 0.8281, 
2023-03-07 20:30:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0018, Acc_1: 0.9062, Acc_2: 0.7812, 
2023-03-07 20:30:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9375, Acc_2: 0.8438, 
2023-03-07 20:30:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9375, Acc_2: 0.8828, 
2023-03-07 20:30:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-07 20:30:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 20:30:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9375, Acc_2: 0.8906, 
2023-03-07 20:30:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0019, Acc_1: 0.9375, Acc_2: 0.8125, 
2023-03-07 20:30:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 20:30:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-07 20:30:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9141, Acc_2: 0.8047, 
2023-03-07 20:30:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0069, Loss_2: 0.0347, Acc_1: 0.8409, Acc_2: 0.3939, F1-score_1: 0.8012, F1-score_2: 0.3138
2023-03-07 20:30:46 - __main__ - INFO - Epoch [24/100]
2023-03-07 20:30:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 20:30:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 20:30:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 20:31:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-07 20:31:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0023, Acc_1: 0.8906, Acc_2: 0.7812, 
2023-03-07 20:31:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9453, Acc_2: 0.8672, 
2023-03-07 20:31:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8828, Acc_2: 0.8203, 
2023-03-07 20:31:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 20:31:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9688, Acc_2: 0.9453, 
2023-03-07 20:31:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9297, Acc_2: 0.8594, 
2023-03-07 20:31:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.8750, Acc_2: 0.7969, 
2023-03-07 20:31:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 20:31:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0073, Loss_2: 0.0291, Acc_1: 0.8443, Acc_2: 0.3993, F1-score_1: 0.8050, F1-score_2: 0.3117
2023-03-07 20:31:44 - __main__ - INFO - Epoch [25/100]
2023-03-07 20:31:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 20:31:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9219, Acc_2: 0.8438, 
2023-03-07 20:31:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0021, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 20:32:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 20:32:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9453, Acc_2: 0.8906, 
2023-03-07 20:32:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 20:32:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9531, Acc_2: 0.9062, 
2023-03-07 20:32:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0011, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 20:32:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9531, Acc_2: 0.9141, 
2023-03-07 20:32:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 20:32:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9375, Acc_2: 0.8906, 
2023-03-07 20:32:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0010, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 20:32:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0080, Loss_2: 0.0328, Acc_1: 0.8405, Acc_2: 0.3928, F1-score_1: 0.7915, F1-score_2: 0.3140
2023-03-07 20:32:41 - __main__ - INFO - Epoch [26/100]
2023-03-07 20:32:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8516, Acc_2: 0.7734, 
2023-03-07 20:32:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 20:32:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9375, Acc_2: 0.8594, 
2023-03-07 20:32:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 20:33:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 20:33:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 20:33:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9531, Acc_2: 0.8906, 
2023-03-07 20:33:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8438, 
2023-03-07 20:33:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 20:33:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 20:33:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0025, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 20:33:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 20:33:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0084, Loss_2: 0.0370, Acc_1: 0.8451, Acc_2: 0.3871, F1-score_1: 0.8073, F1-score_2: 0.3215
2023-03-07 20:33:39 - __main__ - INFO - Epoch [27/100]
2023-03-07 20:33:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9688, Acc_2: 0.9375, 
2023-03-07 20:33:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 20:33:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 20:33:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 20:33:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-07 20:34:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 20:34:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8438, 
2023-03-07 20:34:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.9609, Acc_2: 0.9062, 
2023-03-07 20:34:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-07 20:34:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9453, Acc_2: 0.8906, 
2023-03-07 20:34:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0010, Acc_1: 0.9219, Acc_2: 0.8516, 
2023-03-07 20:34:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 20:34:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0067, Loss_2: 0.0346, Acc_1: 0.8404, Acc_2: 0.3984, F1-score_1: 0.8011, F1-score_2: 0.3229
2023-03-07 20:34:37 - __main__ - INFO - Epoch [28/100]
2023-03-07 20:34:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 20:34:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9297, Acc_2: 0.8828, 
2023-03-07 20:34:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 20:34:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 20:34:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 20:35:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 20:35:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 20:35:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 20:35:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 20:35:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8047, 
2023-03-07 20:35:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9297, Acc_2: 0.8594, 
2023-03-07 20:35:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9219, Acc_2: 0.8516, 
2023-03-07 20:35:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0078, Loss_2: 0.0385, Acc_1: 0.8417, Acc_2: 0.3932, F1-score_1: 0.8028, F1-score_2: 0.3202
2023-03-07 20:35:34 - __main__ - INFO - Epoch [29/100]
2023-03-07 20:35:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 20:35:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 20:35:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 20:35:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9453, Acc_2: 0.8594, 
2023-03-07 20:35:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 20:35:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9453, Acc_2: 0.8906, 
2023-03-07 20:36:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 20:36:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 20:36:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9062, Acc_2: 0.7891, 
2023-03-07 20:36:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0013, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8359, 
2023-03-07 20:36:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 20:36:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0018, Acc_1: 0.9375, Acc_2: 0.8672, 
2023-03-07 20:36:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0097, Loss_2: 0.0387, Acc_1: 0.8164, Acc_2: 0.3961, F1-score_1: 0.7741, F1-score_2: 0.3192
2023-03-07 20:36:32 - __main__ - INFO - Epoch [30/100]
2023-03-07 20:36:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0020, Acc_1: 0.9219, Acc_2: 0.8438, 
2023-03-07 20:36:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0017, Loss_2: 0.0024, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-07 20:36:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9375, Acc_2: 0.8750, 
2023-03-07 20:36:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 20:36:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8203, 
2023-03-07 20:36:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0022, Acc_1: 0.9141, Acc_2: 0.8438, 
2023-03-07 20:36:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9219, Acc_2: 0.8359, 
2023-03-07 20:37:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 20:37:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 20:37:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 20:37:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 20:37:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 20:37:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0098, Loss_2: 0.0388, Acc_1: 0.8059, Acc_2: 0.3915, F1-score_1: 0.7668, F1-score_2: 0.3158
2023-03-07 20:37:30 - __main__ - INFO - Epoch [31/100]
2023-03-07 20:37:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.9531, Acc_2: 0.9062, 
2023-03-07 20:37:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0013, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 20:37:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 20:37:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 20:37:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0011, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 20:37:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 20:37:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.8828, 
2023-03-07 20:38:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 20:38:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 20:38:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 20:38:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 20:38:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 20:38:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0096, Loss_2: 0.0398, Acc_1: 0.8132, Acc_2: 0.3869, F1-score_1: 0.7758, F1-score_2: 0.3080
2023-03-07 20:38:27 - __main__ - INFO - Epoch [32/100]
2023-03-07 20:38:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 20:38:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 20:38:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0016, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 20:38:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 20:38:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 20:38:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 20:38:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 20:38:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 20:39:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 20:39:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0019, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 20:39:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 20:39:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0012, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 20:39:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0092, Loss_2: 0.0412, Acc_1: 0.8110, Acc_2: 0.3860, F1-score_1: 0.7542, F1-score_2: 0.3152
2023-03-07 20:39:25 - __main__ - INFO - Epoch [33/100]
2023-03-07 20:39:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0015, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 20:39:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 20:39:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 20:39:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 20:39:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0022, Loss_2: 0.0023, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-07 20:39:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 20:39:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9688, Acc_2: 0.9141, 
2023-03-07 20:39:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0012, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 20:39:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0022, Acc_1: 0.9219, Acc_2: 0.8594, 
2023-03-07 20:40:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.9531, Acc_2: 0.9297, 
2023-03-07 20:40:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0028, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 20:40:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 20:40:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0449, Acc_1: 0.8091, Acc_2: 0.3685, F1-score_1: 0.7587, F1-score_2: 0.2984
2023-03-07 20:40:23 - __main__ - INFO - Epoch [34/100]
2023-03-07 20:40:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 20:40:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 20:40:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 20:40:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 20:40:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0023, Acc_1: 0.9375, Acc_2: 0.8906, 
2023-03-07 20:40:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 20:40:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 20:40:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 20:40:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 20:41:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0015, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-07 20:41:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 20:41:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 20:41:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0088, Loss_2: 0.0366, Acc_1: 0.8135, Acc_2: 0.3882, F1-score_1: 0.7616, F1-score_2: 0.3042
2023-03-07 20:41:20 - __main__ - INFO - Epoch [35/100]
2023-03-07 20:41:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 20:41:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 20:41:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 20:41:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 20:41:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 20:41:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 20:41:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 20:41:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 20:41:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 20:41:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 20:42:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 20:42:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0012, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 20:42:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0088, Loss_2: 0.0358, Acc_1: 0.8067, Acc_2: 0.3896, F1-score_1: 0.7540, F1-score_2: 0.3086
2023-03-07 20:42:18 - __main__ - INFO - Epoch [36/100]
2023-03-07 20:42:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 20:42:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 20:42:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 20:42:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 20:42:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9453, Acc_2: 0.9062, 
2023-03-07 20:42:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 20:42:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 20:42:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 20:42:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0023, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 20:42:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 20:43:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 20:43:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9219, Acc_2: 0.8672, 
2023-03-07 20:43:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0131, Loss_2: 0.0410, Acc_1: 0.8222, Acc_2: 0.3927, F1-score_1: 0.7785, F1-score_2: 0.3061
2023-03-07 20:43:16 - __main__ - INFO - Epoch [37/100]
2023-03-07 20:43:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 20:43:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-07 20:43:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 20:43:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 20:43:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 20:43:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 20:43:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 20:43:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 20:43:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9453, Acc_2: 0.8984, 
2023-03-07 20:43:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0011, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 20:43:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 20:44:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-07 20:44:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0444, Acc_1: 0.8137, Acc_2: 0.3796, F1-score_1: 0.7720, F1-score_2: 0.3128
2023-03-07 20:44:13 - __main__ - INFO - Epoch [38/100]
2023-03-07 20:44:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 20:44:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-07 20:44:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 20:44:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 20:44:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 20:44:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 20:44:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 20:44:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-07 20:44:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 20:44:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 20:44:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 20:44:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0021, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 20:45:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0114, Loss_2: 0.0443, Acc_1: 0.8144, Acc_2: 0.3889, F1-score_1: 0.7713, F1-score_2: 0.3146
2023-03-07 20:45:11 - __main__ - INFO - Epoch [39/100]
2023-03-07 20:45:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 20:45:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 20:45:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 20:45:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 20:45:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 20:45:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 20:45:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-07 20:45:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 20:45:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 20:45:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 20:45:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9609, Acc_2: 0.9219, 
2023-03-07 20:45:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 20:46:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0113, Loss_2: 0.0438, Acc_1: 0.8181, Acc_2: 0.3910, F1-score_1: 0.7754, F1-score_2: 0.3019
2023-03-07 20:46:09 - __main__ - INFO - Epoch [40/100]
2023-03-07 20:46:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 20:46:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 20:46:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 20:46:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 20:46:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 20:46:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 20:46:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 20:46:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 20:46:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 20:46:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.9688, Acc_2: 0.8984, 
2023-03-07 20:46:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 20:46:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 20:47:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0149, Loss_2: 0.0416, Acc_1: 0.8147, Acc_2: 0.3911, F1-score_1: 0.7698, F1-score_2: 0.3146
2023-03-07 20:47:06 - __main__ - INFO - Epoch [41/100]
2023-03-07 20:47:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 20:47:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 20:47:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9531, Acc_2: 0.9297, 
2023-03-07 20:47:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 20:47:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 20:47:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0015, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 20:47:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9531, Acc_2: 0.9141, 
2023-03-07 20:47:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 20:47:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 20:47:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 20:47:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 20:47:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 20:48:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0379, Acc_1: 0.8208, Acc_2: 0.3927, F1-score_1: 0.7763, F1-score_2: 0.3126
2023-03-07 20:48:04 - __main__ - INFO - Epoch [42/100]
2023-03-07 20:48:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9453, Acc_2: 0.9062, 
2023-03-07 20:48:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 20:48:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 20:48:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 20:48:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 20:48:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 20:48:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0017, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 20:48:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 20:48:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-07 20:48:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 20:48:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 20:48:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 20:49:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0115, Loss_2: 0.0405, Acc_1: 0.8234, Acc_2: 0.3860, F1-score_1: 0.7796, F1-score_2: 0.3130
2023-03-07 20:49:02 - __main__ - INFO - Epoch [43/100]
2023-03-07 20:49:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 20:49:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9531, Acc_2: 0.9219, 
2023-03-07 20:49:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 20:49:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 20:49:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-07 20:49:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9453, Acc_2: 0.8828, 
2023-03-07 20:49:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 20:49:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 20:49:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 20:49:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 20:49:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 20:49:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 20:49:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0143, Loss_2: 0.0444, Acc_1: 0.8176, Acc_2: 0.3869, F1-score_1: 0.7735, F1-score_2: 0.3176
2023-03-07 20:49:59 - __main__ - INFO - Epoch [44/100]
2023-03-07 20:50:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9531, Acc_2: 0.9141, 
2023-03-07 20:50:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 20:50:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 20:50:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9531, Acc_2: 0.9297, 
2023-03-07 20:50:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 20:50:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 20:50:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9531, Acc_2: 0.9141, 
2023-03-07 20:50:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 20:50:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 20:50:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 20:50:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 20:50:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 20:50:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0132, Loss_2: 0.0434, Acc_1: 0.8205, Acc_2: 0.3945, F1-score_1: 0.7775, F1-score_2: 0.3119
2023-03-07 20:50:57 - __main__ - INFO - Epoch [45/100]
2023-03-07 20:51:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0022, Acc_1: 0.8984, Acc_2: 0.8203, 
2023-03-07 20:51:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 20:51:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 20:51:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 20:51:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 20:51:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 20:51:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 20:51:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 20:51:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 20:51:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 20:51:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-07 20:51:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 20:51:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0123, Loss_2: 0.0422, Acc_1: 0.8072, Acc_2: 0.3889, F1-score_1: 0.7640, F1-score_2: 0.3119
2023-03-07 20:51:55 - __main__ - INFO - Epoch [46/100]
2023-03-07 20:52:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 20:52:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 20:52:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 20:52:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 20:52:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0011, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-07 20:52:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 20:52:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 20:52:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 20:52:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 20:52:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 20:52:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9609, Acc_2: 0.9297, 
2023-03-07 20:52:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 20:52:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0459, Acc_1: 0.8218, Acc_2: 0.3888, F1-score_1: 0.7761, F1-score_2: 0.3134
2023-03-07 20:52:52 - __main__ - INFO - Epoch [47/100]
2023-03-07 20:52:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 20:53:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 20:53:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 20:53:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 20:53:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 20:53:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 20:53:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 20:53:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0019, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 20:53:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 20:53:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9609, Acc_2: 0.9453, 
2023-03-07 20:53:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 20:53:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 20:53:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0165, Loss_2: 0.0470, Acc_1: 0.8152, Acc_2: 0.3867, F1-score_1: 0.7715, F1-score_2: 0.3150
2023-03-07 20:53:50 - __main__ - INFO - Epoch [48/100]
2023-03-07 20:53:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 20:53:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 20:54:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 20:54:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 20:54:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 20:54:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 20:54:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 20:54:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 20:54:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 20:54:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 20:54:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 20:54:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 20:54:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0147, Loss_2: 0.0486, Acc_1: 0.8196, Acc_2: 0.3891, F1-score_1: 0.7772, F1-score_2: 0.3176
2023-03-07 20:54:48 - __main__ - INFO - Epoch [49/100]
2023-03-07 20:54:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 20:54:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 20:55:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 20:55:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 20:55:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 20:55:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 20:55:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 20:55:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9453, Acc_2: 0.9141, 
2023-03-07 20:55:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0023, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-07 20:55:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 20:55:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 20:55:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 20:55:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0199, Loss_2: 0.0477, Acc_1: 0.8115, Acc_2: 0.3820, F1-score_1: 0.7683, F1-score_2: 0.3044
2023-03-07 20:55:45 - __main__ - INFO - Epoch [50/100]
2023-03-07 20:55:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 20:55:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 20:55:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 20:56:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 20:56:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 20:56:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 20:56:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 20:56:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 20:56:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 20:56:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 20:56:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 20:56:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 20:56:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0210, Loss_2: 0.0452, Acc_1: 0.8042, Acc_2: 0.3954, F1-score_1: 0.7605, F1-score_2: 0.3157
2023-03-07 20:56:43 - __main__ - INFO - Epoch [51/100]
2023-03-07 20:56:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 20:56:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 20:56:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-07 20:56:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 20:57:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 20:57:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-07 20:57:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 20:57:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 20:57:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 20:57:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 20:57:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 20:57:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 20:57:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0198, Loss_2: 0.0457, Acc_1: 0.8032, Acc_2: 0.3978, F1-score_1: 0.7654, F1-score_2: 0.3127
2023-03-07 20:57:41 - __main__ - INFO - Epoch [52/100]
2023-03-07 20:57:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0013, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 20:57:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 20:57:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 20:57:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 20:58:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 20:58:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8906, Acc_2: 0.8125, 
2023-03-07 20:58:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9531, Acc_2: 0.9219, 
2023-03-07 20:58:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 20:58:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 20:58:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-07 20:58:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-07 20:58:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 20:58:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0170, Loss_2: 0.0466, Acc_1: 0.8038, Acc_2: 0.3830, F1-score_1: 0.7597, F1-score_2: 0.3172
2023-03-07 20:58:39 - __main__ - INFO - Epoch [53/100]
2023-03-07 20:58:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 20:58:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 20:58:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 20:58:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 20:58:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 20:59:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9609, Acc_2: 0.9453, 
2023-03-07 20:59:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-07 20:59:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 20:59:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 20:59:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 20:59:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 20:59:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 20:59:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0195, Loss_2: 0.0479, Acc_1: 0.8106, Acc_2: 0.3928, F1-score_1: 0.7737, F1-score_2: 0.3197
2023-03-07 20:59:36 - __main__ - INFO - Epoch [54/100]
2023-03-07 20:59:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 20:59:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 20:59:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 20:59:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-07 20:59:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 21:00:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 21:00:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:00:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 21:00:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 21:00:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 21:00:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 21:00:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:00:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0212, Loss_2: 0.0479, Acc_1: 0.8118, Acc_2: 0.3995, F1-score_1: 0.7707, F1-score_2: 0.3228
2023-03-07 21:00:34 - __main__ - INFO - Epoch [55/100]
2023-03-07 21:00:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 21:00:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 21:00:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 21:00:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 21:00:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:00:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 21:01:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 21:01:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 21:01:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:01:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:01:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 21:01:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 21:01:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0203, Loss_2: 0.0533, Acc_1: 0.8111, Acc_2: 0.3869, F1-score_1: 0.7659, F1-score_2: 0.3087
2023-03-07 21:01:32 - __main__ - INFO - Epoch [56/100]
2023-03-07 21:01:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 21:01:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 21:01:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 21:01:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 21:01:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 21:01:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 21:01:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 21:02:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 21:02:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 21:02:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:02:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 21:02:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 21:02:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0222, Loss_2: 0.0537, Acc_1: 0.7962, Acc_2: 0.3913, F1-score_1: 0.7603, F1-score_2: 0.3146
2023-03-07 21:02:29 - __main__ - INFO - Epoch [57/100]
2023-03-07 21:02:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 21:02:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 21:02:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 21:02:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:02:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 21:02:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 21:02:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 21:03:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0022, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 21:03:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 21:03:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 21:03:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 21:03:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-07 21:03:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0180, Loss_2: 0.0527, Acc_1: 0.8091, Acc_2: 0.3820, F1-score_1: 0.7629, F1-score_2: 0.3118
2023-03-07 21:03:27 - __main__ - INFO - Epoch [58/100]
2023-03-07 21:03:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 21:03:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:03:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 21:03:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 21:03:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-07 21:03:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 21:03:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 21:03:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 21:04:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:04:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 21:04:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:04:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 21:04:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0192, Loss_2: 0.0500, Acc_1: 0.8167, Acc_2: 0.3923, F1-score_1: 0.7731, F1-score_2: 0.3080
2023-03-07 21:04:24 - __main__ - INFO - Epoch [59/100]
2023-03-07 21:04:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9297, 
2023-03-07 21:04:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:04:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:04:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 21:04:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:04:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 21:04:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 21:04:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 21:04:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 21:05:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 21:05:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 21:05:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 21:05:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0218, Loss_2: 0.0512, Acc_1: 0.8093, Acc_2: 0.3843, F1-score_1: 0.7580, F1-score_2: 0.3141
2023-03-07 21:05:22 - __main__ - INFO - Epoch [60/100]
2023-03-07 21:05:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0017, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:05:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 21:05:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 21:05:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 21:05:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 21:05:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 21:05:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 21:05:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 21:05:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 21:06:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 21:06:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:06:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 21:06:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0277, Loss_2: 0.0552, Acc_1: 0.8084, Acc_2: 0.3781, F1-score_1: 0.7622, F1-score_2: 0.3013
2023-03-07 21:06:20 - __main__ - INFO - Epoch [61/100]
2023-03-07 21:06:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 21:06:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 21:06:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-07 21:06:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:06:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 21:06:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 21:06:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 21:06:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 21:06:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 21:06:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:07:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 21:07:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:07:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0212, Loss_2: 0.0520, Acc_1: 0.8066, Acc_2: 0.3944, F1-score_1: 0.7577, F1-score_2: 0.3199
2023-03-07 21:07:17 - __main__ - INFO - Epoch [62/100]
2023-03-07 21:07:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0018, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 21:07:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0012, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 21:07:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 21:07:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:07:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 21:07:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 21:07:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:07:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 21:07:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 21:07:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:07:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 21:08:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 21:08:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0226, Loss_2: 0.0514, Acc_1: 0.8105, Acc_2: 0.3898, F1-score_1: 0.7625, F1-score_2: 0.3120
2023-03-07 21:08:15 - __main__ - INFO - Epoch [63/100]
2023-03-07 21:08:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:08:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-07 21:08:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:08:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 21:08:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 21:08:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 21:08:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 21:08:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 21:08:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 21:08:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 21:08:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 21:09:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:09:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0219, Loss_2: 0.0508, Acc_1: 0.7952, Acc_2: 0.3893, F1-score_1: 0.7448, F1-score_2: 0.3113
2023-03-07 21:09:13 - __main__ - INFO - Epoch [64/100]
2023-03-07 21:09:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 21:09:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 21:09:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 21:09:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 21:09:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 21:09:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-07 21:09:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 21:09:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-07 21:09:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 21:09:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 21:09:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:09:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:10:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0254, Loss_2: 0.0525, Acc_1: 0.8127, Acc_2: 0.3876, F1-score_1: 0.7670, F1-score_2: 0.3115
2023-03-07 21:10:10 - __main__ - INFO - Epoch [65/100]
2023-03-07 21:10:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 21:10:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 21:10:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 21:10:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0017, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 21:10:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 21:10:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:10:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 21:10:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:10:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:10:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 21:10:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 21:10:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:11:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0235, Loss_2: 0.0528, Acc_1: 0.8169, Acc_2: 0.3944, F1-score_1: 0.7699, F1-score_2: 0.3176
2023-03-07 21:11:08 - __main__ - INFO - Epoch [66/100]
2023-03-07 21:11:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 21:11:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 21:11:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 21:11:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 21:11:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 21:11:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 21:11:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 21:11:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 21:11:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 21:11:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 21:11:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 21:11:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 21:12:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0255, Loss_2: 0.0512, Acc_1: 0.8084, Acc_2: 0.3952, F1-score_1: 0.7626, F1-score_2: 0.3142
2023-03-07 21:12:06 - __main__ - INFO - Epoch [67/100]
2023-03-07 21:12:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 21:12:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 21:12:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 21:12:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 21:12:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-07 21:12:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 21:12:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 21:12:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 21:12:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9688, Acc_2: 0.9375, 
2023-03-07 21:12:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 21:12:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 21:12:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-07 21:13:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0258, Loss_2: 0.0519, Acc_1: 0.8003, Acc_2: 0.3867, F1-score_1: 0.7579, F1-score_2: 0.3101
2023-03-07 21:13:03 - __main__ - INFO - Epoch [68/100]
2023-03-07 21:13:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-07 21:13:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 21:13:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 21:13:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-07 21:13:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 21:13:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:13:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 21:13:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 21:13:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 21:13:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 21:13:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 21:13:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 21:14:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0226, Loss_2: 0.0533, Acc_1: 0.8139, Acc_2: 0.3869, F1-score_1: 0.7645, F1-score_2: 0.3105
2023-03-07 21:14:01 - __main__ - INFO - Epoch [69/100]
2023-03-07 21:14:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-07 21:14:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 21:14:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 21:14:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 21:14:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 21:14:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 21:14:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 21:14:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 21:14:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 21:14:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 21:14:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-07 21:14:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 21:14:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0260, Loss_2: 0.0526, Acc_1: 0.8072, Acc_2: 0.3859, F1-score_1: 0.7565, F1-score_2: 0.3086
2023-03-07 21:14:59 - __main__ - INFO - Epoch [70/100]
2023-03-07 21:15:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 21:15:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-07 21:15:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0018, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 21:15:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:15:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-07 21:15:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 21:15:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:15:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 21:15:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-07 21:15:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:15:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 21:15:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 21:15:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0269, Loss_2: 0.0547, Acc_1: 0.8094, Acc_2: 0.3995, F1-score_1: 0.7595, F1-score_2: 0.3215
2023-03-07 21:15:57 - __main__ - INFO - Epoch [71/100]
2023-03-07 21:16:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 21:16:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:16:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 21:16:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 21:16:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 21:16:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 21:16:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:16:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 21:16:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 21:16:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 21:16:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:16:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 21:16:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0265, Loss_2: 0.0545, Acc_1: 0.8033, Acc_2: 0.3879, F1-score_1: 0.7552, F1-score_2: 0.3110
2023-03-07 21:16:54 - __main__ - INFO - Epoch [72/100]
2023-03-07 21:17:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 21:17:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 21:17:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:17:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 21:17:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 21:17:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 21:17:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:17:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 21:17:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:17:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 21:17:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 21:17:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:17:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0236, Loss_2: 0.0559, Acc_1: 0.8083, Acc_2: 0.3847, F1-score_1: 0.7610, F1-score_2: 0.3028
2023-03-07 21:17:52 - __main__ - INFO - Epoch [73/100]
2023-03-07 21:17:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 21:18:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-07 21:18:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:18:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-07 21:18:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:18:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 21:18:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:18:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9297, Acc_2: 0.8828, 
2023-03-07 21:18:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-07 21:18:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:18:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 21:18:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:18:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0173, Loss_2: 0.0566, Acc_1: 0.7870, Acc_2: 0.3832, F1-score_1: 0.7388, F1-score_2: 0.3036
2023-03-07 21:18:50 - __main__ - INFO - Epoch [74/100]
2023-03-07 21:18:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:18:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 21:19:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-07 21:19:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:19:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 21:19:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 21:19:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 21:19:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-07 21:19:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 21:19:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:19:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 21:19:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 21:19:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0242, Loss_2: 0.0581, Acc_1: 0.8091, Acc_2: 0.3852, F1-score_1: 0.7598, F1-score_2: 0.2971
2023-03-07 21:19:47 - __main__ - INFO - Epoch [75/100]
2023-03-07 21:19:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:19:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 21:20:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-07 21:20:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 21:20:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9141, 
2023-03-07 21:20:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:20:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:20:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:20:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9531, Acc_2: 0.9375, 
2023-03-07 21:20:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 21:20:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0014, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 21:20:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 21:20:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0211, Loss_2: 0.0555, Acc_1: 0.8072, Acc_2: 0.3882, F1-score_1: 0.7671, F1-score_2: 0.3057
2023-03-07 21:20:45 - __main__ - INFO - Epoch [76/100]
2023-03-07 21:20:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 21:20:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 21:20:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 21:21:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 21:21:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0016, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:21:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:21:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 21:21:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:21:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 21:21:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 21:21:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:21:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 21:21:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0243, Loss_2: 0.0566, Acc_1: 0.8139, Acc_2: 0.3838, F1-score_1: 0.7671, F1-score_2: 0.3111
2023-03-07 21:21:43 - __main__ - INFO - Epoch [77/100]
2023-03-07 21:21:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 21:21:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:21:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:21:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 21:22:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:22:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 21:22:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 21:22:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 21:22:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-07 21:22:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 21:22:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:22:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-07 21:22:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0229, Loss_2: 0.0610, Acc_1: 0.8013, Acc_2: 0.3879, F1-score_1: 0.7586, F1-score_2: 0.3061
2023-03-07 21:22:41 - __main__ - INFO - Epoch [78/100]
2023-03-07 21:22:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:22:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:22:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 21:22:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:23:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 21:23:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:23:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:23:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 21:23:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:23:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 21:23:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:23:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-07 21:23:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0247, Loss_2: 0.0543, Acc_1: 0.8100, Acc_2: 0.3952, F1-score_1: 0.7625, F1-score_2: 0.3135
2023-03-07 21:23:38 - __main__ - INFO - Epoch [79/100]
2023-03-07 21:23:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:23:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 21:23:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:23:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:23:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 21:24:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 21:24:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:24:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 21:24:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 21:24:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:24:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 21:24:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 21:24:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0292, Loss_2: 0.0592, Acc_1: 0.7957, Acc_2: 0.3804, F1-score_1: 0.7568, F1-score_2: 0.3043
2023-03-07 21:24:36 - __main__ - INFO - Epoch [80/100]
2023-03-07 21:24:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 21:24:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:24:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9453, 
2023-03-07 21:24:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-07 21:24:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0020, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:24:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-07 21:25:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-07 21:25:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:25:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:25:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0022, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-07 21:25:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.9297, Acc_2: 0.8672, 
2023-03-07 21:25:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0020, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-07 21:25:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0279, Loss_2: 0.0529, Acc_1: 0.7996, Acc_2: 0.3983, F1-score_1: 0.7508, F1-score_2: 0.3110
2023-03-07 21:25:34 - __main__ - INFO - Epoch [81/100]
2023-03-07 21:25:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0023, Acc_1: 0.8906, Acc_2: 0.8281, 
2023-03-07 21:25:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-07 21:25:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9453, Acc_2: 0.9141, 
2023-03-07 21:25:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:25:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 21:25:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9453, Acc_2: 0.9141, 
2023-03-07 21:26:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 21:26:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:26:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 21:26:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:26:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 21:26:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 21:26:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0206, Loss_2: 0.0594, Acc_1: 0.8008, Acc_2: 0.3799, F1-score_1: 0.7473, F1-score_2: 0.3086
2023-03-07 21:26:32 - __main__ - INFO - Epoch [82/100]
2023-03-07 21:26:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 21:26:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-07 21:26:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-07 21:26:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 21:26:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 21:26:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 21:26:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:27:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:27:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 21:27:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:27:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-07 21:27:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-07 21:27:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0196, Loss_2: 0.0545, Acc_1: 0.8142, Acc_2: 0.3923, F1-score_1: 0.7686, F1-score_2: 0.3080
2023-03-07 21:27:29 - __main__ - INFO - Epoch [83/100]
2023-03-07 21:27:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9844, Acc_2: 0.9688, 
2023-03-07 21:27:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0029, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 21:27:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 21:27:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 21:27:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 21:27:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 21:27:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:28:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 21:28:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 21:28:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 21:28:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-07 21:28:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:28:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0216, Loss_2: 0.0574, Acc_1: 0.8088, Acc_2: 0.3910, F1-score_1: 0.7576, F1-score_2: 0.3096
2023-03-07 21:28:27 - __main__ - INFO - Epoch [84/100]
2023-03-07 21:28:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:28:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-07 21:28:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-07 21:28:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 21:28:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 21:28:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 21:28:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 21:28:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 21:29:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:29:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 21:29:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9219, 
2023-03-07 21:29:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-07 21:29:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0226, Loss_2: 0.0556, Acc_1: 0.8077, Acc_2: 0.3835, F1-score_1: 0.7643, F1-score_2: 0.3079
2023-03-07 21:29:25 - __main__ - INFO - Epoch [85/100]
2023-03-07 21:29:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:29:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 21:29:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 21:29:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:29:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 21:29:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 21:29:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 21:29:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 21:29:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 21:30:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 21:30:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:30:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:30:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0263, Loss_2: 0.0583, Acc_1: 0.8106, Acc_2: 0.3889, F1-score_1: 0.7669, F1-score_2: 0.3097
2023-03-07 21:30:23 - __main__ - INFO - Epoch [86/100]
2023-03-07 21:30:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 21:30:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:30:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:30:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:30:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 21:30:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:30:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-07 21:30:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:30:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:31:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-07 21:31:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 21:31:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 21:31:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0243, Loss_2: 0.0574, Acc_1: 0.8122, Acc_2: 0.3877, F1-score_1: 0.7701, F1-score_2: 0.3088
2023-03-07 21:31:20 - __main__ - INFO - Epoch [87/100]
2023-03-07 21:31:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 21:31:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:31:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:31:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 21:31:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:31:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 21:31:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 21:31:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-07 21:31:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9609, 
2023-03-07 21:31:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:32:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 21:32:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 21:32:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0240, Loss_2: 0.0577, Acc_1: 0.8123, Acc_2: 0.3869, F1-score_1: 0.7700, F1-score_2: 0.3080
2023-03-07 21:32:18 - __main__ - INFO - Epoch [88/100]
2023-03-07 21:32:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-07 21:32:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:32:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:32:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-07 21:32:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:32:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:32:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:32:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:32:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:32:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:32:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-07 21:33:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 21:33:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0231, Loss_2: 0.0595, Acc_1: 0.8106, Acc_2: 0.3905, F1-score_1: 0.7634, F1-score_2: 0.3107
2023-03-07 21:33:15 - __main__ - INFO - Epoch [89/100]
2023-03-07 21:33:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 21:33:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 21:33:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 21:33:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:33:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:33:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-07 21:33:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 21:33:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 21:33:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:33:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:33:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9688, Acc_2: 0.9609, 
2023-03-07 21:34:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:34:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0226, Loss_2: 0.0606, Acc_1: 0.8118, Acc_2: 0.3857, F1-score_1: 0.7676, F1-score_2: 0.3081
2023-03-07 21:34:13 - __main__ - INFO - Epoch [90/100]
2023-03-07 21:34:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:34:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 21:34:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:34:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:34:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:34:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:34:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 21:34:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 21:34:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 21:34:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:34:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:34:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 21:35:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0259, Loss_2: 0.0600, Acc_1: 0.8084, Acc_2: 0.3835, F1-score_1: 0.7613, F1-score_2: 0.3076
2023-03-07 21:35:11 - __main__ - INFO - Epoch [91/100]
2023-03-07 21:35:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 21:35:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:35:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9453, 
2023-03-07 21:35:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:35:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 21:35:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:35:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 21:35:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:35:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 21:35:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 21:35:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:35:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 21:36:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0255, Loss_2: 0.0602, Acc_1: 0.8096, Acc_2: 0.3865, F1-score_1: 0.7630, F1-score_2: 0.3119
2023-03-07 21:36:08 - __main__ - INFO - Epoch [92/100]
2023-03-07 21:36:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 21:36:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-07 21:36:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 21:36:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9297, 
2023-03-07 21:36:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:36:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 21:36:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 21:36:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:36:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 21:36:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:36:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:36:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:37:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0271, Loss_2: 0.0592, Acc_1: 0.8106, Acc_2: 0.3877, F1-score_1: 0.7672, F1-score_2: 0.3126
2023-03-07 21:37:06 - __main__ - INFO - Epoch [93/100]
2023-03-07 21:37:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:37:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:37:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-07 21:37:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-07 21:37:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 21:37:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 21:37:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:37:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:37:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 21:37:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:37:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-07 21:37:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:38:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0255, Loss_2: 0.0592, Acc_1: 0.8128, Acc_2: 0.3882, F1-score_1: 0.7697, F1-score_2: 0.3125
2023-03-07 21:38:04 - __main__ - INFO - Epoch [94/100]
2023-03-07 21:38:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:38:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:38:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 21:38:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:38:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 21:38:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:38:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-07 21:38:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 21:38:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 21:38:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:38:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:38:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 21:39:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0261, Loss_2: 0.0585, Acc_1: 0.8123, Acc_2: 0.3847, F1-score_1: 0.7691, F1-score_2: 0.3092
2023-03-07 21:39:02 - __main__ - INFO - Epoch [95/100]
2023-03-07 21:39:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 21:39:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-07 21:39:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 21:39:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:39:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 21:39:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9609, Acc_2: 0.9609, 
2023-03-07 21:39:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 21:39:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:39:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 21:39:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-07 21:39:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:39:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 21:40:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0265, Loss_2: 0.0586, Acc_1: 0.8100, Acc_2: 0.3871, F1-score_1: 0.7657, F1-score_2: 0.3133
2023-03-07 21:40:00 - __main__ - INFO - Epoch [96/100]
2023-03-07 21:40:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 21:40:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-07 21:40:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 21:40:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 21:40:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 21:40:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:40:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-07 21:40:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 21:40:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 21:40:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 21:40:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:40:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:40:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0254, Loss_2: 0.0591, Acc_1: 0.8108, Acc_2: 0.3847, F1-score_1: 0.7657, F1-score_2: 0.3124
2023-03-07 21:40:57 - __main__ - INFO - Epoch [97/100]
2023-03-07 21:41:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-07 21:41:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:41:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:41:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:41:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-07 21:41:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 21:41:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:41:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 21:41:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:41:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:41:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:41:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 21:41:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0255, Loss_2: 0.0593, Acc_1: 0.8103, Acc_2: 0.3840, F1-score_1: 0.7657, F1-score_2: 0.3093
2023-03-07 21:41:55 - __main__ - INFO - Epoch [98/100]
2023-03-07 21:42:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-07 21:42:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-07 21:42:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:42:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-07 21:42:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 21:42:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:42:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:42:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9531, 
2023-03-07 21:42:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-07 21:42:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-07 21:42:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:42:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-07 21:42:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0255, Loss_2: 0.0582, Acc_1: 0.8101, Acc_2: 0.3908, F1-score_1: 0.7659, F1-score_2: 0.3126
2023-03-07 21:42:53 - __main__ - INFO - Epoch [99/100]
2023-03-07 21:42:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-07 21:43:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 21:43:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 21:43:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 21:43:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 21:43:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 21:43:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 21:43:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 21:43:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-07 21:43:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9531, Acc_2: 0.9531, 
2023-03-07 21:43:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 21:43:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-07 21:43:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0256, Loss_2: 0.0589, Acc_1: 0.8106, Acc_2: 0.3874, F1-score_1: 0.7669, F1-score_2: 0.3145
2023-03-07 21:43:52 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 21:43:53 - utils._noise - DEBUG - 6, 7
2023-03-07 21:43:53 - utils._noise - DEBUG - 13997
2023-03-07 21:43:53 - utils._noise - INFO - Actual noise 0.20
2023-03-07 21:43:53 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-07 21:43:53 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-07 21:43:55 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-07 21:43:55 - __main__ - INFO - Loading dataset...
2023-03-07 21:43:55 - __main__ - INFO - Building model...
2023-03-07 21:43:55 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-07 21:43:55 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-07 21:43:55 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-07 21:43:55 - __main__ - INFO - Start train & evaluate
2023-03-07 21:43:55 - __main__ - INFO - Epoch [0/100]
2023-03-07 21:44:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0152, Loss_2: 0.0152, Acc_1: 0.1875, Acc_2: 0.1719, 
2023-03-07 21:44:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0141, Loss_2: 0.0142, Acc_1: 0.2344, Acc_2: 0.2578, 
2023-03-07 21:44:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0137, Loss_2: 0.0137, Acc_1: 0.3672, Acc_2: 0.3516, 
2023-03-07 21:44:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0136, Loss_2: 0.0136, Acc_1: 0.4062, Acc_2: 0.3438, 
2023-03-07 21:44:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0134, Loss_2: 0.0130, Acc_1: 0.2969, Acc_2: 0.3281, 
2023-03-07 21:44:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0123, Loss_2: 0.0140, Acc_1: 0.4688, Acc_2: 0.3359, 
2023-03-07 21:44:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0141, Loss_2: 0.0141, Acc_1: 0.3672, Acc_2: 0.2734, 
2023-03-07 21:44:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0132, Loss_2: 0.0128, Acc_1: 0.4297, Acc_2: 0.4453, 
2023-03-07 21:44:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0128, Loss_2: 0.0135, Acc_1: 0.3672, Acc_2: 0.3750, 
2023-03-07 21:45:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0121, Loss_2: 0.0120, Acc_1: 0.4609, Acc_2: 0.3984, 
2023-03-07 21:45:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0132, Loss_2: 0.0193, Acc_1: 0.4062, Acc_2: 0.1875, 
2023-03-07 21:45:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0130, Loss_2: 0.0143, Acc_1: 0.4297, Acc_2: 0.2422, 
2023-03-07 21:45:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0134, Acc_1: 0.4621, Acc_2: 0.3128, F1-score_1: 0.2433, F1-score_2: 0.1499
2023-03-07 21:45:28 - __main__ - INFO - Epoch [1/100]
2023-03-07 21:45:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0124, Loss_2: 0.0138, Acc_1: 0.4219, Acc_2: 0.2578, 
2023-03-07 21:45:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0143, Loss_2: 0.0138, Acc_1: 0.2734, Acc_2: 0.2578, 
2023-03-07 21:45:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0130, Loss_2: 0.0122, Acc_1: 0.4531, Acc_2: 0.4375, 
2023-03-07 21:45:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0136, Loss_2: 0.0137, Acc_1: 0.3750, Acc_2: 0.3594, 
2023-03-07 21:46:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0123, Loss_2: 0.0129, Acc_1: 0.4922, Acc_2: 0.4453, 
2023-03-07 21:46:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0119, Loss_2: 0.0127, Acc_1: 0.4609, Acc_2: 0.4453, 
2023-03-07 21:46:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0115, Loss_2: 0.0113, Acc_1: 0.3906, Acc_2: 0.4766, 
2023-03-07 21:46:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0132, Loss_2: 0.0126, Acc_1: 0.3516, Acc_2: 0.4062, 
2023-03-07 21:46:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0104, Loss_2: 0.0135, Acc_1: 0.5234, Acc_2: 0.2344, 
2023-03-07 21:46:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0100, Loss_2: 0.0117, Acc_1: 0.5156, Acc_2: 0.5156, 
2023-03-07 21:46:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0113, Loss_2: 0.0126, Acc_1: 0.4609, Acc_2: 0.3516, 
2023-03-07 21:46:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0103, Loss_2: 0.0115, Acc_1: 0.5469, Acc_2: 0.4375, 
2023-03-07 21:47:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0094, Loss_2: 0.0100, Acc_1: 0.6321, Acc_2: 0.5757, F1-score_1: 0.4895, F1-score_2: 0.3662
2023-03-07 21:47:01 - __main__ - INFO - Epoch [2/100]
2023-03-07 21:47:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0101, Loss_2: 0.0104, Acc_1: 0.5781, Acc_2: 0.5000, 
2023-03-07 21:47:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0103, Loss_2: 0.0109, Acc_1: 0.5156, Acc_2: 0.5078, 
2023-03-07 21:47:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0083, Loss_2: 0.0104, Acc_1: 0.5938, Acc_2: 0.5234, 
2023-03-07 21:47:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0088, Loss_2: 0.0097, Acc_1: 0.6172, Acc_2: 0.6172, 
2023-03-07 21:47:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0082, Loss_2: 0.0098, Acc_1: 0.6172, Acc_2: 0.5547, 
2023-03-07 21:47:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0099, Loss_2: 0.0101, Acc_1: 0.5859, Acc_2: 0.5781, 
2023-03-07 21:47:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0082, Loss_2: 0.0102, Acc_1: 0.6484, Acc_2: 0.5000, 
2023-03-07 21:47:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0082, Loss_2: 0.0099, Acc_1: 0.6406, Acc_2: 0.5312, 
2023-03-07 21:48:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0093, Loss_2: 0.0102, Acc_1: 0.6250, Acc_2: 0.5625, 
2023-03-07 21:48:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0082, Loss_2: 0.0092, Acc_1: 0.6484, Acc_2: 0.5859, 
2023-03-07 21:48:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0085, Loss_2: 0.0109, Acc_1: 0.6016, Acc_2: 0.4922, 
2023-03-07 21:48:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0092, Loss_2: 0.0110, Acc_1: 0.6562, Acc_2: 0.5000, 
2023-03-07 21:48:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0064, Loss_2: 0.0090, Acc_1: 0.7418, Acc_2: 0.6112, F1-score_1: 0.6433, F1-score_2: 0.5313
2023-03-07 21:48:34 - __main__ - INFO - Epoch [3/100]
2023-03-07 21:48:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0070, Loss_2: 0.0093, Acc_1: 0.7109, Acc_2: 0.5781, 
2023-03-07 21:48:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0082, Loss_2: 0.0086, Acc_1: 0.6328, Acc_2: 0.6172, 
2023-03-07 21:48:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0058, Loss_2: 0.0081, Acc_1: 0.7109, Acc_2: 0.5859, 
2023-03-07 21:48:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0085, Loss_2: 0.0095, Acc_1: 0.6406, Acc_2: 0.6016, 
2023-03-07 21:49:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0076, Loss_2: 0.0086, Acc_1: 0.6797, Acc_2: 0.6484, 
2023-03-07 21:49:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0073, Loss_2: 0.0091, Acc_1: 0.6797, Acc_2: 0.5625, 
2023-03-07 21:49:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0075, Loss_2: 0.0092, Acc_1: 0.6484, Acc_2: 0.6016, 
2023-03-07 21:49:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0086, Loss_2: 0.0108, Acc_1: 0.6016, Acc_2: 0.5078, 
2023-03-07 21:49:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0062, Loss_2: 0.0081, Acc_1: 0.7344, Acc_2: 0.6641, 
2023-03-07 21:49:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0077, Loss_2: 0.0090, Acc_1: 0.6641, Acc_2: 0.5859, 
2023-03-07 21:49:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0059, Loss_2: 0.0076, Acc_1: 0.7031, Acc_2: 0.6328, 
2023-03-07 21:49:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0076, Loss_2: 0.0085, Acc_1: 0.6562, Acc_2: 0.6172, 
2023-03-07 21:50:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0065, Acc_1: 0.7403, Acc_2: 0.7150, F1-score_1: 0.6735, F1-score_2: 0.6384
2023-03-07 21:50:07 - __main__ - INFO - Epoch [4/100]
2023-03-07 21:50:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0074, Loss_2: 0.0088, Acc_1: 0.6797, Acc_2: 0.6328, 
2023-03-07 21:50:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0076, Loss_2: 0.0080, Acc_1: 0.6172, Acc_2: 0.6328, 
2023-03-07 21:50:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0068, Loss_2: 0.0055, Acc_1: 0.6797, Acc_2: 0.7109, 
2023-03-07 21:50:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0063, Loss_2: 0.0082, Acc_1: 0.6875, Acc_2: 0.5938, 
2023-03-07 21:50:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0039, Loss_2: 0.0055, Acc_1: 0.7656, Acc_2: 0.6875, 
2023-03-07 21:50:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0050, Loss_2: 0.0056, Acc_1: 0.7422, Acc_2: 0.7422, 
2023-03-07 21:50:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0050, Loss_2: 0.0055, Acc_1: 0.7109, Acc_2: 0.6797, 
2023-03-07 21:50:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0051, Loss_2: 0.0050, Acc_1: 0.7109, Acc_2: 0.7344, 
2023-03-07 21:51:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0071, Loss_2: 0.0074, Acc_1: 0.6719, Acc_2: 0.6641, 
2023-03-07 21:51:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0067, Loss_2: 0.0068, Acc_1: 0.6719, Acc_2: 0.6641, 
2023-03-07 21:51:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0072, Loss_2: 0.0075, Acc_1: 0.6328, Acc_2: 0.6328, 
2023-03-07 21:51:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0049, Loss_2: 0.0049, Acc_1: 0.7656, Acc_2: 0.7578, 
2023-03-07 21:51:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0048, Loss_2: 0.0047, Acc_1: 0.7590, Acc_2: 0.7597, F1-score_1: 0.6936, F1-score_2: 0.6930
2023-03-07 21:51:39 - __main__ - INFO - Epoch [5/100]
2023-03-07 21:51:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0047, Loss_2: 0.0048, Acc_1: 0.7422, Acc_2: 0.7031, 
2023-03-07 21:51:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0042, Loss_2: 0.0047, Acc_1: 0.7500, Acc_2: 0.7266, 
2023-03-07 21:51:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0051, Loss_2: 0.0048, Acc_1: 0.7266, Acc_2: 0.7266, 
2023-03-07 21:52:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0050, Loss_2: 0.0051, Acc_1: 0.7422, Acc_2: 0.7344, 
2023-03-07 21:52:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0054, Loss_2: 0.0057, Acc_1: 0.7031, Acc_2: 0.7031, 
2023-03-07 21:52:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0040, Loss_2: 0.0048, Acc_1: 0.7500, Acc_2: 0.7188, 
2023-03-07 21:52:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0044, Loss_2: 0.0043, Acc_1: 0.7344, Acc_2: 0.7188, 
2023-03-07 21:52:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0044, Loss_2: 0.0047, Acc_1: 0.7031, Acc_2: 0.7109, 
2023-03-07 21:52:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0052, Loss_2: 0.0073, Acc_1: 0.6953, Acc_2: 0.6484, 
2023-03-07 21:52:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0057, Loss_2: 0.0081, Acc_1: 0.7266, Acc_2: 0.5781, 
2023-03-07 21:52:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0031, Loss_2: 0.0052, Acc_1: 0.7891, Acc_2: 0.7188, 
2023-03-07 21:52:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0042, Loss_2: 0.0054, Acc_1: 0.7422, Acc_2: 0.6875, 
2023-03-07 21:53:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0037, Loss_2: 0.0052, Acc_1: 0.7853, Acc_2: 0.7167, F1-score_1: 0.7173, F1-score_2: 0.6542
2023-03-07 21:53:12 - __main__ - INFO - Epoch [6/100]
2023-03-07 21:53:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0027, Loss_2: 0.0043, Acc_1: 0.7969, Acc_2: 0.7266, 
2023-03-07 21:53:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0021, Loss_2: 0.0029, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-07 21:53:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0017, Loss_2: 0.0027, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-07 21:53:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0034, Loss_2: 0.0049, Acc_1: 0.7500, Acc_2: 0.6953, 
2023-03-07 21:53:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0021, Loss_2: 0.0035, Acc_1: 0.8047, Acc_2: 0.7578, 
2023-03-07 21:53:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0036, Loss_2: 0.0057, Acc_1: 0.7500, Acc_2: 0.7031, 
2023-03-07 21:53:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0025, Loss_2: 0.0048, Acc_1: 0.7969, Acc_2: 0.7188, 
2023-03-07 21:54:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0016, Loss_2: 0.0026, Acc_1: 0.8359, Acc_2: 0.7812, 
2023-03-07 21:54:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0031, Loss_2: 0.0045, Acc_1: 0.7656, Acc_2: 0.7422, 
2023-03-07 21:54:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0024, Loss_2: 0.0033, Acc_1: 0.8047, Acc_2: 0.7578, 
2023-03-07 21:54:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0028, Loss_2: 0.0037, Acc_1: 0.7656, Acc_2: 0.7344, 
2023-03-07 21:54:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0025, Loss_2: 0.0035, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-07 21:54:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0037, Acc_1: 0.7829, Acc_2: 0.7755, F1-score_1: 0.7139, F1-score_2: 0.7038
2023-03-07 21:54:45 - __main__ - INFO - Epoch [7/100]
2023-03-07 21:54:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0016, Loss_2: 0.0021, Acc_1: 0.7969, Acc_2: 0.7734, 
2023-03-07 21:54:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0014, Loss_2: 0.0015, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 21:55:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0054, Loss_2: 0.0040, Acc_1: 0.6797, Acc_2: 0.7500, 
2023-03-07 21:55:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0015, Loss_2: 0.0014, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 21:55:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0019, Loss_2: 0.0022, Acc_1: 0.7969, Acc_2: 0.7734, 
2023-03-07 21:55:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0032, Loss_2: 0.0043, Acc_1: 0.7500, Acc_2: 0.6953, 
2023-03-07 21:55:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0013, Loss_2: 0.0023, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-07 21:55:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0011, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 21:55:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0021, Loss_2: 0.0030, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-07 21:55:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0018, Loss_2: 0.0021, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-07 21:55:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0018, Loss_2: 0.0012, Acc_1: 0.7969, Acc_2: 0.8359, 
2023-03-07 21:56:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0012, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 21:56:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0028, Acc_1: 0.7741, Acc_2: 0.7775, F1-score_1: 0.7097, F1-score_2: 0.7140
2023-03-07 21:56:18 - __main__ - INFO - Epoch [8/100]
2023-03-07 21:56:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0015, Loss_2: 0.0019, Acc_1: 0.8047, Acc_2: 0.7812, 
2023-03-07 21:56:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-07 21:56:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 21:56:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0010, Loss_2: 0.0014, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 21:56:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0010, Loss_2: 0.0012, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-07 21:56:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-07 21:57:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-07 21:57:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 21:57:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0014, Loss_2: 0.0016, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-07 21:57:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0014, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.8281, 
2023-03-07 21:57:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0010, Acc_1: 0.8125, Acc_2: 0.7812, 
2023-03-07 21:57:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 21:57:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0023, Loss_2: 0.0024, Acc_1: 0.7882, Acc_2: 0.7789, F1-score_1: 0.7254, F1-score_2: 0.7218
2023-03-07 21:57:51 - __main__ - INFO - Epoch [9/100]
2023-03-07 21:57:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0019, Acc_1: 0.7812, Acc_2: 0.7500, 
2023-03-07 21:58:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0009, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-07 21:58:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-07 21:58:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 21:58:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0017, Loss_2: 0.0018, Acc_1: 0.7578, Acc_2: 0.7344, 
2023-03-07 21:58:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-07 21:58:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-07 21:58:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-07 21:58:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 21:58:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-07 21:59:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0014, Loss_2: 0.0014, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-07 21:59:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 21:59:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0020, Acc_1: 0.7850, Acc_2: 0.7982, F1-score_1: 0.7211, F1-score_2: 0.7392
2023-03-07 21:59:24 - __main__ - INFO - Epoch [10/100]
2023-03-07 21:59:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 21:59:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 21:59:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 21:59:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-07 21:59:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0014, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-07 22:00:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 22:00:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 22:00:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 22:00:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-07 22:00:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 22:00:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 22:00:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-07 22:00:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0022, Acc_1: 0.7826, Acc_2: 0.7818, F1-score_1: 0.7120, F1-score_2: 0.7151
2023-03-07 22:00:57 - __main__ - INFO - Epoch [11/100]
2023-03-07 22:01:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0008, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-07 22:01:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 22:01:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 22:01:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0025, Loss_2: 0.0006, Acc_1: 0.7578, Acc_2: 0.8203, 
2023-03-07 22:01:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0014, Loss_2: 0.0009, Acc_1: 0.7734, Acc_2: 0.7969, 
2023-03-07 22:01:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-07 22:01:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-07 22:01:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-07 22:01:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-07 22:02:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-07 22:02:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-07 22:02:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 22:02:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.7996, Acc_2: 0.7919, F1-score_1: 0.7293, F1-score_2: 0.7315
2023-03-07 22:02:31 - __main__ - INFO - Epoch [12/100]
2023-03-07 22:02:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0020, Loss_2: 0.0020, Acc_1: 0.7500, Acc_2: 0.7656, 
2023-03-07 22:02:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 22:02:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-07 22:02:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 22:03:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-07 22:03:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 22:03:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:03:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-07 22:03:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 22:03:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 22:03:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 22:03:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 22:04:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0020, Acc_1: 0.7935, Acc_2: 0.7789, F1-score_1: 0.7272, F1-score_2: 0.7159
2023-03-07 22:04:04 - __main__ - INFO - Epoch [13/100]
2023-03-07 22:04:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 22:04:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-07 22:04:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-07 22:04:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:04:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-07 22:04:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 22:04:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 22:04:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 22:05:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 22:05:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 22:05:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 22:05:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 22:05:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0022, Acc_1: 0.7974, Acc_2: 0.7891, F1-score_1: 0.7265, F1-score_2: 0.7320
2023-03-07 22:05:37 - __main__ - INFO - Epoch [14/100]
2023-03-07 22:05:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 22:05:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 22:05:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:06:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 22:06:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 22:06:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 22:06:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 22:06:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 22:06:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 22:06:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 22:06:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 22:06:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 22:07:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0013, Acc_1: 0.7843, Acc_2: 0.7780, F1-score_1: 0.7136, F1-score_2: 0.7170
2023-03-07 22:07:09 - __main__ - INFO - Epoch [15/100]
2023-03-07 22:07:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 22:07:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-07 22:07:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 22:07:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 22:07:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 22:07:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-07 22:07:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 22:08:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 22:08:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 22:08:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 22:08:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 22:08:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 22:08:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0016, Acc_1: 0.7880, Acc_2: 0.7807, F1-score_1: 0.7238, F1-score_2: 0.7146
2023-03-07 22:08:43 - __main__ - INFO - Epoch [16/100]
2023-03-07 22:08:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 22:08:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 22:09:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-07 22:09:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 22:09:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 22:09:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-07 22:09:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-07 22:09:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 22:09:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:09:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 22:09:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0015, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-07 22:10:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 22:10:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0029, Acc_1: 0.7926, Acc_2: 0.7704, F1-score_1: 0.7307, F1-score_2: 0.7181
2023-03-07 22:10:16 - __main__ - INFO - Epoch [17/100]
2023-03-07 22:10:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 22:10:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 22:10:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 22:10:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 22:10:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 22:10:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-07 22:11:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0023, Loss_2: 0.0018, Acc_1: 0.7500, Acc_2: 0.7656, 
2023-03-07 22:11:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 22:11:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-07 22:11:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 22:11:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 22:11:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 22:11:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0020, Acc_1: 0.7928, Acc_2: 0.7823, F1-score_1: 0.7338, F1-score_2: 0.7257
2023-03-07 22:11:49 - __main__ - INFO - Epoch [18/100]
2023-03-07 22:11:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-07 22:12:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 22:12:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 22:12:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 22:12:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 22:12:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 22:12:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 22:12:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 22:12:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 22:12:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-07 22:13:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 22:13:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 22:13:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0024, Acc_1: 0.7894, Acc_2: 0.7660, F1-score_1: 0.7270, F1-score_2: 0.7087
2023-03-07 22:13:21 - __main__ - INFO - Epoch [19/100]
2023-03-07 22:13:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-07 22:13:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-07 22:13:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-07 22:13:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 22:13:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 22:14:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-07 22:14:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:14:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 22:14:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-07 22:14:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 22:14:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 22:14:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 22:14:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0024, Acc_1: 0.7982, Acc_2: 0.7787, F1-score_1: 0.7331, F1-score_2: 0.7114
2023-03-07 22:14:54 - __main__ - INFO - Epoch [20/100]
2023-03-07 22:15:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 22:15:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 22:15:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 22:15:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-07 22:15:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 22:15:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 22:15:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 22:15:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.7656, 
2023-03-07 22:15:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-07 22:16:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 22:16:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 22:16:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-07 22:16:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0035, Acc_1: 0.7858, Acc_2: 0.7770, F1-score_1: 0.7191, F1-score_2: 0.7156
2023-03-07 22:16:27 - __main__ - INFO - Epoch [21/100]
2023-03-07 22:16:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-07 22:16:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 22:16:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-07 22:16:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 22:16:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 22:17:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 22:17:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:17:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-07 22:17:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-07 22:17:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 22:17:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-07 22:17:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 22:18:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0022, Acc_1: 0.7792, Acc_2: 0.7765, F1-score_1: 0.7151, F1-score_2: 0.7222
2023-03-07 22:18:00 - __main__ - INFO - Epoch [22/100]
2023-03-07 22:18:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-07 22:18:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 22:18:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 22:18:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 22:18:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:18:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 22:18:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 22:18:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 22:18:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 22:19:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 22:19:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 22:19:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-07 22:19:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0019, Acc_1: 0.7785, Acc_2: 0.7765, F1-score_1: 0.7101, F1-score_2: 0.7169
2023-03-07 22:19:33 - __main__ - INFO - Epoch [23/100]
2023-03-07 22:19:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 22:19:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0033, Loss_2: 0.0048, Acc_1: 0.7266, Acc_2: 0.7188, 
2023-03-07 22:19:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 22:19:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 22:20:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-07 22:20:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0019, Loss_2: 0.0022, Acc_1: 0.7656, Acc_2: 0.7578, 
2023-03-07 22:20:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 22:20:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 22:20:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 22:20:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 22:20:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-07 22:20:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 22:21:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0020, Acc_1: 0.7903, Acc_2: 0.7875, F1-score_1: 0.7255, F1-score_2: 0.7282
2023-03-07 22:21:06 - __main__ - INFO - Epoch [24/100]
2023-03-07 22:21:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 22:21:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 22:21:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 22:21:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 22:21:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-07 22:21:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 22:21:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-07 22:21:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 22:22:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 22:22:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 22:22:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 22:22:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 22:22:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0014, Acc_1: 0.7921, Acc_2: 0.7874, F1-score_1: 0.7220, F1-score_2: 0.7231
2023-03-07 22:22:38 - __main__ - INFO - Epoch [25/100]
2023-03-07 22:22:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-07 22:22:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-07 22:22:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 22:23:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 22:23:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 22:23:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-07 22:23:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 22:23:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 22:23:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0028, Acc_1: 0.7891, Acc_2: 0.7266, 
2023-03-07 22:23:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0017, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-07 22:23:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0010, Loss_2: 0.0012, Acc_1: 0.8125, Acc_2: 0.7812, 
2023-03-07 22:23:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 22:24:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0024, Acc_1: 0.7678, Acc_2: 0.7685, F1-score_1: 0.7098, F1-score_2: 0.7083
2023-03-07 22:24:11 - __main__ - INFO - Epoch [26/100]
2023-03-07 22:24:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 22:24:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 22:24:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 22:24:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-07 22:24:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-07 22:24:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 22:24:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 22:25:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 22:25:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 22:25:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 22:25:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-07 22:25:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 22:25:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0017, Acc_1: 0.7976, Acc_2: 0.7891, F1-score_1: 0.7310, F1-score_2: 0.7267
2023-03-07 22:25:44 - __main__ - INFO - Epoch [27/100]
2023-03-07 22:25:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-07 22:25:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 22:26:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0009, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-07 22:26:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 22:26:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 22:26:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:26:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-07 22:26:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0013, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-07 22:26:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:26:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-07 22:26:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 22:27:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 22:27:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0039, Loss_2: 0.0016, Acc_1: 0.7879, Acc_2: 0.7824, F1-score_1: 0.7182, F1-score_2: 0.7190
2023-03-07 22:27:17 - __main__ - INFO - Epoch [28/100]
2023-03-07 22:27:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 22:27:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:27:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-07 22:27:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 22:27:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 22:27:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 22:28:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-07 22:28:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-07 22:28:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-07 22:28:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-07 22:28:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 22:28:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 22:28:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0017, Acc_1: 0.7913, Acc_2: 0.7829, F1-score_1: 0.7227, F1-score_2: 0.7212
2023-03-07 22:28:50 - __main__ - INFO - Epoch [29/100]
2023-03-07 22:28:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0019, Loss_2: 0.0019, Acc_1: 0.7578, Acc_2: 0.7812, 
2023-03-07 22:29:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 22:29:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:29:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:29:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 22:29:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 22:29:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-07 22:29:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 22:29:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 22:29:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-07 22:30:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 22:30:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-07 22:30:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0019, Acc_1: 0.7967, Acc_2: 0.7879, F1-score_1: 0.7282, F1-score_2: 0.7263
2023-03-07 22:30:22 - __main__ - INFO - Epoch [30/100]
2023-03-07 22:30:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-07 22:30:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-07 22:30:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-07 22:30:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 22:30:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 22:31:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 22:31:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-07 22:31:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-07 22:31:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 22:31:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-07 22:31:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-07 22:31:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-07 22:31:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0015, Acc_1: 0.7979, Acc_2: 0.7886, F1-score_1: 0.7274, F1-score_2: 0.7234
2023-03-07 22:31:55 - __main__ - INFO - Epoch [31/100]
2023-03-07 22:32:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 22:32:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-07 22:32:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-07 22:32:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:32:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 22:32:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-07 22:32:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 22:32:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-07 22:32:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-07 22:33:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-07 22:33:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-07 22:33:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-07 22:33:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0026, Acc_1: 0.7772, Acc_2: 0.7950, F1-score_1: 0.7187, F1-score_2: 0.7331
2023-03-07 22:33:28 - __main__ - INFO - Epoch [32/100]
2023-03-07 22:33:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 22:33:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-07 22:33:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-07 22:33:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 22:34:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-07 22:34:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-07 22:34:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-07 22:34:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-07 22:34:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-07 22:34:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-07 22:34:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 22:34:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-07 22:35:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0036, Acc_1: 0.7869, Acc_2: 0.7826, F1-score_1: 0.7173, F1-score_2: 0.7193
2023-03-07 22:35:01 - __main__ - INFO - Epoch [33/100]
2023-03-07 22:35:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-07 22:35:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 22:35:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-07 22:35:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 22:35:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-07 22:35:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 22:35:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-07 22:35:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-07 22:36:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 22:36:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-07 22:36:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 22:36:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-07 22:36:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0026, Acc_1: 0.7850, Acc_2: 0.7870, F1-score_1: 0.7189, F1-score_2: 0.7240
2023-03-07 22:36:34 - __main__ - INFO - Epoch [34/100]
2023-03-07 22:36:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-07 22:36:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-07 22:36:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-07 22:36:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-07 22:37:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 08:17:46 - utils._utils - DEBUG - [Args] (seed: 1), (model1: None), (model2: None), (noise_rate: 0.2)
2023-03-08 08:17:48 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 08:17:48 - utils._noise - DEBUG - 6, 7
2023-03-08 08:17:48 - utils._noise - DEBUG - 13997
2023-03-08 08:17:48 - utils._noise - INFO - Actual noise 0.20
2023-03-08 08:17:48 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-08 08:17:48 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-08 08:17:50 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 08:17:50 - __main__ - INFO - Loading dataset...
2023-03-08 08:17:50 - __main__ - INFO - Building model...
2023-03-08 08:17:55 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-08 08:17:55 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-08 08:17:55 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-08 08:17:55 - __main__ - INFO - Start train & evaluate
2023-03-08 08:17:55 - __main__ - INFO - Epoch [0/100]
2023-03-08 08:18:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0152, Loss_2: 0.0152, Acc_1: 0.1875, Acc_2: 0.1719, 
2023-03-08 08:18:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0141, Loss_2: 0.0142, Acc_1: 0.2344, Acc_2: 0.2578, 
2023-03-08 08:18:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0137, Loss_2: 0.0137, Acc_1: 0.3672, Acc_2: 0.3516, 
2023-03-08 08:18:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0136, Loss_2: 0.0136, Acc_1: 0.4062, Acc_2: 0.3438, 
2023-03-08 08:18:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0134, Loss_2: 0.0130, Acc_1: 0.2969, Acc_2: 0.3281, 
2023-03-08 08:18:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0123, Loss_2: 0.0140, Acc_1: 0.4688, Acc_2: 0.3359, 
2023-03-08 08:18:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0141, Loss_2: 0.0141, Acc_1: 0.3672, Acc_2: 0.2734, 
2023-03-08 08:18:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0132, Loss_2: 0.0128, Acc_1: 0.4297, Acc_2: 0.4453, 
2023-03-08 08:18:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0128, Loss_2: 0.0135, Acc_1: 0.3672, Acc_2: 0.3750, 
2023-03-08 08:19:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0121, Loss_2: 0.0120, Acc_1: 0.4609, Acc_2: 0.3984, 
2023-03-08 08:19:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0132, Loss_2: 0.0193, Acc_1: 0.4062, Acc_2: 0.1875, 
2023-03-08 08:19:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0130, Loss_2: 0.0143, Acc_1: 0.4297, Acc_2: 0.2422, 
2023-03-08 08:19:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0134, Acc_1: 0.4621, Acc_2: 0.3128, F1-score_1: 0.2433, F1-score_2: 0.1499
2023-03-08 08:19:28 - __main__ - INFO - Epoch [1/100]
2023-03-08 08:19:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0124, Loss_2: 0.0138, Acc_1: 0.4219, Acc_2: 0.2578, 
2023-03-08 08:19:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0143, Loss_2: 0.0138, Acc_1: 0.2734, Acc_2: 0.2578, 
2023-03-08 08:19:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0130, Loss_2: 0.0122, Acc_1: 0.4531, Acc_2: 0.4375, 
2023-03-08 08:19:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0136, Loss_2: 0.0137, Acc_1: 0.3750, Acc_2: 0.3594, 
2023-03-08 08:20:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0123, Loss_2: 0.0129, Acc_1: 0.4922, Acc_2: 0.4453, 
2023-03-08 08:20:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0119, Loss_2: 0.0127, Acc_1: 0.4609, Acc_2: 0.4453, 
2023-03-08 08:20:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0115, Loss_2: 0.0113, Acc_1: 0.3906, Acc_2: 0.4766, 
2023-03-08 08:20:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0132, Loss_2: 0.0126, Acc_1: 0.3516, Acc_2: 0.4062, 
2023-03-08 08:20:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0104, Loss_2: 0.0135, Acc_1: 0.5234, Acc_2: 0.2344, 
2023-03-08 08:20:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0100, Loss_2: 0.0117, Acc_1: 0.5156, Acc_2: 0.5156, 
2023-03-08 08:20:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0113, Loss_2: 0.0126, Acc_1: 0.4609, Acc_2: 0.3516, 
2023-03-08 08:20:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0103, Loss_2: 0.0115, Acc_1: 0.5469, Acc_2: 0.4375, 
2023-03-08 08:21:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0094, Loss_2: 0.0100, Acc_1: 0.6321, Acc_2: 0.5757, F1-score_1: 0.4895, F1-score_2: 0.3662
2023-03-08 08:21:00 - __main__ - INFO - Epoch [2/100]
2023-03-08 08:21:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0101, Loss_2: 0.0104, Acc_1: 0.5781, Acc_2: 0.5000, 
2023-03-08 08:21:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0103, Loss_2: 0.0109, Acc_1: 0.5156, Acc_2: 0.5078, 
2023-03-08 08:21:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0083, Loss_2: 0.0104, Acc_1: 0.5938, Acc_2: 0.5234, 
2023-03-08 08:21:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0088, Loss_2: 0.0097, Acc_1: 0.6172, Acc_2: 0.6172, 
2023-03-08 08:21:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0082, Loss_2: 0.0098, Acc_1: 0.6172, Acc_2: 0.5547, 
2023-03-08 08:21:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0099, Loss_2: 0.0101, Acc_1: 0.5859, Acc_2: 0.5781, 
2023-03-08 08:21:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0082, Loss_2: 0.0102, Acc_1: 0.6484, Acc_2: 0.5000, 
2023-03-08 08:21:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0082, Loss_2: 0.0099, Acc_1: 0.6406, Acc_2: 0.5312, 
2023-03-08 08:21:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0093, Loss_2: 0.0102, Acc_1: 0.6250, Acc_2: 0.5625, 
2023-03-08 08:22:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0082, Loss_2: 0.0092, Acc_1: 0.6484, Acc_2: 0.5859, 
2023-03-08 08:22:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0085, Loss_2: 0.0109, Acc_1: 0.6016, Acc_2: 0.4922, 
2023-03-08 08:22:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0092, Loss_2: 0.0110, Acc_1: 0.6562, Acc_2: 0.5000, 
2023-03-08 08:22:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0064, Loss_2: 0.0090, Acc_1: 0.7418, Acc_2: 0.6112, F1-score_1: 0.6433, F1-score_2: 0.5313
2023-03-08 08:22:32 - __main__ - INFO - Epoch [3/100]
2023-03-08 08:22:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0070, Loss_2: 0.0093, Acc_1: 0.7109, Acc_2: 0.5781, 
2023-03-08 08:22:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0082, Loss_2: 0.0086, Acc_1: 0.6328, Acc_2: 0.6172, 
2023-03-08 08:22:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0058, Loss_2: 0.0081, Acc_1: 0.7109, Acc_2: 0.5859, 
2023-03-08 08:22:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0085, Loss_2: 0.0095, Acc_1: 0.6406, Acc_2: 0.6016, 
2023-03-08 08:23:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0076, Loss_2: 0.0086, Acc_1: 0.6797, Acc_2: 0.6484, 
2023-03-08 08:23:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0073, Loss_2: 0.0091, Acc_1: 0.6797, Acc_2: 0.5625, 
2023-03-08 08:23:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0075, Loss_2: 0.0092, Acc_1: 0.6484, Acc_2: 0.6016, 
2023-03-08 08:23:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0086, Loss_2: 0.0108, Acc_1: 0.6016, Acc_2: 0.5078, 
2023-03-08 08:23:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0062, Loss_2: 0.0081, Acc_1: 0.7344, Acc_2: 0.6641, 
2023-03-08 08:23:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0077, Loss_2: 0.0090, Acc_1: 0.6641, Acc_2: 0.5859, 
2023-03-08 08:23:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0059, Loss_2: 0.0076, Acc_1: 0.7031, Acc_2: 0.6328, 
2023-03-08 08:23:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0076, Loss_2: 0.0085, Acc_1: 0.6562, Acc_2: 0.6172, 
2023-03-08 08:24:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0065, Acc_1: 0.7403, Acc_2: 0.7150, F1-score_1: 0.6735, F1-score_2: 0.6384
2023-03-08 08:24:04 - __main__ - INFO - Epoch [4/100]
2023-03-08 08:24:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0074, Loss_2: 0.0088, Acc_1: 0.6797, Acc_2: 0.6328, 
2023-03-08 08:24:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0076, Loss_2: 0.0080, Acc_1: 0.6172, Acc_2: 0.6328, 
2023-03-08 08:24:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0068, Loss_2: 0.0055, Acc_1: 0.6797, Acc_2: 0.7109, 
2023-03-08 08:24:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0063, Loss_2: 0.0082, Acc_1: 0.6875, Acc_2: 0.5938, 
2023-03-08 08:24:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0039, Loss_2: 0.0055, Acc_1: 0.7656, Acc_2: 0.6875, 
2023-03-08 08:24:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0050, Loss_2: 0.0056, Acc_1: 0.7422, Acc_2: 0.7422, 
2023-03-08 08:24:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0050, Loss_2: 0.0055, Acc_1: 0.7109, Acc_2: 0.6797, 
2023-03-08 08:24:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0051, Loss_2: 0.0050, Acc_1: 0.7109, Acc_2: 0.7344, 
2023-03-08 08:25:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0071, Loss_2: 0.0074, Acc_1: 0.6719, Acc_2: 0.6641, 
2023-03-08 08:25:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0067, Loss_2: 0.0068, Acc_1: 0.6719, Acc_2: 0.6641, 
2023-03-08 08:25:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0072, Loss_2: 0.0075, Acc_1: 0.6328, Acc_2: 0.6328, 
2023-03-08 08:25:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0049, Loss_2: 0.0049, Acc_1: 0.7656, Acc_2: 0.7578, 
2023-03-08 08:25:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0048, Loss_2: 0.0047, Acc_1: 0.7590, Acc_2: 0.7597, F1-score_1: 0.6936, F1-score_2: 0.6930
2023-03-08 08:25:38 - __main__ - INFO - Epoch [5/100]
2023-03-08 08:25:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0047, Loss_2: 0.0048, Acc_1: 0.7422, Acc_2: 0.7031, 
2023-03-08 08:25:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0042, Loss_2: 0.0047, Acc_1: 0.7500, Acc_2: 0.7266, 
2023-03-08 08:25:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0051, Loss_2: 0.0048, Acc_1: 0.7266, Acc_2: 0.7266, 
2023-03-08 08:26:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0050, Loss_2: 0.0051, Acc_1: 0.7422, Acc_2: 0.7344, 
2023-03-08 08:26:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0054, Loss_2: 0.0057, Acc_1: 0.7031, Acc_2: 0.7031, 
2023-03-08 08:26:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0040, Loss_2: 0.0048, Acc_1: 0.7500, Acc_2: 0.7188, 
2023-03-08 08:26:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0044, Loss_2: 0.0043, Acc_1: 0.7344, Acc_2: 0.7188, 
2023-03-08 08:26:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0044, Loss_2: 0.0047, Acc_1: 0.7031, Acc_2: 0.7109, 
2023-03-08 08:26:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0052, Loss_2: 0.0073, Acc_1: 0.6953, Acc_2: 0.6484, 
2023-03-08 08:26:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0057, Loss_2: 0.0081, Acc_1: 0.7266, Acc_2: 0.5781, 
2023-03-08 08:26:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0031, Loss_2: 0.0052, Acc_1: 0.7891, Acc_2: 0.7188, 
2023-03-08 08:26:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0042, Loss_2: 0.0054, Acc_1: 0.7422, Acc_2: 0.6875, 
2023-03-08 08:27:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0037, Loss_2: 0.0052, Acc_1: 0.7853, Acc_2: 0.7167, F1-score_1: 0.7173, F1-score_2: 0.6542
2023-03-08 08:27:11 - __main__ - INFO - Epoch [6/100]
2023-03-08 08:27:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0027, Loss_2: 0.0043, Acc_1: 0.7969, Acc_2: 0.7266, 
2023-03-08 08:27:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0021, Loss_2: 0.0029, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 08:27:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0017, Loss_2: 0.0027, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 08:27:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0034, Loss_2: 0.0049, Acc_1: 0.7500, Acc_2: 0.6953, 
2023-03-08 08:27:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0021, Loss_2: 0.0035, Acc_1: 0.8047, Acc_2: 0.7578, 
2023-03-08 08:27:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0036, Loss_2: 0.0057, Acc_1: 0.7500, Acc_2: 0.7031, 
2023-03-08 08:27:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0025, Loss_2: 0.0048, Acc_1: 0.7969, Acc_2: 0.7188, 
2023-03-08 08:28:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0016, Loss_2: 0.0026, Acc_1: 0.8359, Acc_2: 0.7812, 
2023-03-08 08:28:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0031, Loss_2: 0.0045, Acc_1: 0.7656, Acc_2: 0.7422, 
2023-03-08 08:28:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0024, Loss_2: 0.0033, Acc_1: 0.8047, Acc_2: 0.7578, 
2023-03-08 08:28:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0028, Loss_2: 0.0037, Acc_1: 0.7656, Acc_2: 0.7344, 
2023-03-08 08:28:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0025, Loss_2: 0.0035, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 08:28:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0037, Acc_1: 0.7829, Acc_2: 0.7755, F1-score_1: 0.7139, F1-score_2: 0.7038
2023-03-08 08:28:44 - __main__ - INFO - Epoch [7/100]
2023-03-08 08:28:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0016, Loss_2: 0.0021, Acc_1: 0.7969, Acc_2: 0.7734, 
2023-03-08 08:28:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0014, Loss_2: 0.0015, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 08:29:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0054, Loss_2: 0.0040, Acc_1: 0.6797, Acc_2: 0.7500, 
2023-03-08 08:29:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0015, Loss_2: 0.0014, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 08:29:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0019, Loss_2: 0.0022, Acc_1: 0.7969, Acc_2: 0.7734, 
2023-03-08 08:29:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0032, Loss_2: 0.0043, Acc_1: 0.7500, Acc_2: 0.6953, 
2023-03-08 08:29:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0013, Loss_2: 0.0023, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 08:29:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0011, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 08:29:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0021, Loss_2: 0.0030, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-08 08:29:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0018, Loss_2: 0.0021, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-08 08:29:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0018, Loss_2: 0.0012, Acc_1: 0.7969, Acc_2: 0.8359, 
2023-03-08 08:30:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0012, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 08:30:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0028, Acc_1: 0.7741, Acc_2: 0.7775, F1-score_1: 0.7097, F1-score_2: 0.7140
2023-03-08 08:30:17 - __main__ - INFO - Epoch [8/100]
2023-03-08 08:30:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0015, Loss_2: 0.0019, Acc_1: 0.8047, Acc_2: 0.7812, 
2023-03-08 08:30:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 08:30:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 08:30:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0010, Loss_2: 0.0014, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 08:30:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0010, Loss_2: 0.0012, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-08 08:30:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 08:31:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 08:31:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 08:31:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0014, Loss_2: 0.0016, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 08:31:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0014, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.8281, 
2023-03-08 08:31:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0010, Acc_1: 0.8125, Acc_2: 0.7812, 
2023-03-08 08:31:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 08:31:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0023, Loss_2: 0.0024, Acc_1: 0.7882, Acc_2: 0.7789, F1-score_1: 0.7254, F1-score_2: 0.7218
2023-03-08 08:31:50 - __main__ - INFO - Epoch [9/100]
2023-03-08 08:31:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0019, Acc_1: 0.7812, Acc_2: 0.7500, 
2023-03-08 08:32:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0009, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 08:32:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 08:32:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 08:32:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0017, Loss_2: 0.0018, Acc_1: 0.7578, Acc_2: 0.7344, 
2023-03-08 08:32:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 08:32:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 08:32:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 08:32:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 08:32:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 08:33:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0014, Loss_2: 0.0014, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 08:33:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 08:33:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0020, Acc_1: 0.7850, Acc_2: 0.7982, F1-score_1: 0.7211, F1-score_2: 0.7392
2023-03-08 08:33:25 - __main__ - INFO - Epoch [10/100]
2023-03-08 08:33:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 08:33:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 08:33:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 08:33:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 08:34:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0014, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 08:34:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 08:34:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 08:34:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 08:34:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-08 08:34:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 08:34:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 08:34:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 08:35:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0022, Acc_1: 0.7826, Acc_2: 0.7818, F1-score_1: 0.7120, F1-score_2: 0.7151
2023-03-08 08:35:08 - __main__ - INFO - Epoch [11/100]
2023-03-08 08:35:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0008, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 08:35:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 08:35:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 08:35:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0025, Loss_2: 0.0006, Acc_1: 0.7578, Acc_2: 0.8203, 
2023-03-08 08:35:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0014, Loss_2: 0.0009, Acc_1: 0.7734, Acc_2: 0.7969, 
2023-03-08 08:35:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 08:35:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 08:36:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 08:36:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 08:36:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 08:36:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 08:36:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 08:36:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.7996, Acc_2: 0.7919, F1-score_1: 0.7293, F1-score_2: 0.7315
2023-03-08 08:36:46 - __main__ - INFO - Epoch [12/100]
2023-03-08 08:36:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0020, Loss_2: 0.0020, Acc_1: 0.7500, Acc_2: 0.7656, 
2023-03-08 08:36:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 08:37:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 08:37:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 08:37:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 08:37:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 08:37:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 08:37:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 08:37:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 08:37:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 08:37:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 08:38:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 08:38:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0020, Acc_1: 0.7935, Acc_2: 0.7789, F1-score_1: 0.7272, F1-score_2: 0.7159
2023-03-08 08:38:19 - __main__ - INFO - Epoch [13/100]
2023-03-08 08:38:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 08:38:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 08:38:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 08:38:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 08:38:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 08:39:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 08:39:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 08:39:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 08:39:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 08:39:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 08:39:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 08:39:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 08:40:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0022, Acc_1: 0.7974, Acc_2: 0.7891, F1-score_1: 0.7265, F1-score_2: 0.7320
2023-03-08 08:40:01 - __main__ - INFO - Epoch [14/100]
2023-03-08 08:40:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 08:40:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 08:40:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 08:40:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 08:40:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 08:40:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 08:40:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 08:40:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 08:41:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 08:41:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 08:41:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 08:41:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 08:41:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0013, Acc_1: 0.7843, Acc_2: 0.7780, F1-score_1: 0.7136, F1-score_2: 0.7170
2023-03-08 08:41:42 - __main__ - INFO - Epoch [15/100]
2023-03-08 08:41:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 08:41:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 08:42:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 08:42:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 08:42:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 08:42:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 08:42:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 08:42:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 08:42:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 08:42:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 08:43:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 08:43:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 08:43:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0016, Acc_1: 0.7880, Acc_2: 0.7807, F1-score_1: 0.7238, F1-score_2: 0.7146
2023-03-08 08:43:24 - __main__ - INFO - Epoch [16/100]
2023-03-08 08:43:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 08:43:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 08:43:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 08:43:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 08:44:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 08:44:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 08:44:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-08 08:44:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 08:44:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 08:44:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 08:44:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0015, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 08:44:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 08:45:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0029, Acc_1: 0.7926, Acc_2: 0.7704, F1-score_1: 0.7307, F1-score_2: 0.7181
2023-03-08 08:45:06 - __main__ - INFO - Epoch [17/100]
2023-03-08 08:45:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 08:45:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 08:45:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 08:45:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 08:45:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 08:45:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 08:45:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0023, Loss_2: 0.0018, Acc_1: 0.7500, Acc_2: 0.7656, 
2023-03-08 08:46:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 08:46:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 08:46:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 08:46:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 08:46:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 08:46:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0020, Acc_1: 0.7928, Acc_2: 0.7823, F1-score_1: 0.7338, F1-score_2: 0.7257
2023-03-08 08:46:47 - __main__ - INFO - Epoch [18/100]
2023-03-08 08:46:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 08:47:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 08:47:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 08:47:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 08:47:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 08:47:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 08:47:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 08:47:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 08:47:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 08:48:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 08:48:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 08:48:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 08:48:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0024, Acc_1: 0.7894, Acc_2: 0.7660, F1-score_1: 0.7270, F1-score_2: 0.7087
2023-03-08 08:48:29 - __main__ - INFO - Epoch [19/100]
2023-03-08 08:48:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 08:48:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-08 08:48:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 08:48:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 08:49:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 08:49:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 08:49:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 08:49:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 08:49:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 08:49:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 08:49:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 08:49:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 08:50:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0024, Acc_1: 0.7982, Acc_2: 0.7787, F1-score_1: 0.7331, F1-score_2: 0.7114
2023-03-08 08:50:06 - __main__ - INFO - Epoch [20/100]
2023-03-08 08:50:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 08:50:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 08:50:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 08:50:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 08:50:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 08:50:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 08:50:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 08:50:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.7656, 
2023-03-08 08:51:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 08:51:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 08:51:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 08:51:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 08:51:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0035, Acc_1: 0.7858, Acc_2: 0.7770, F1-score_1: 0.7191, F1-score_2: 0.7156
2023-03-08 08:51:38 - __main__ - INFO - Epoch [21/100]
2023-03-08 08:51:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 08:51:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 08:51:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 08:52:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 08:52:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 08:52:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 08:52:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 08:52:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 08:52:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 08:52:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 08:52:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 08:52:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 08:53:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0022, Acc_1: 0.7792, Acc_2: 0.7765, F1-score_1: 0.7151, F1-score_2: 0.7222
2023-03-08 08:53:11 - __main__ - INFO - Epoch [22/100]
2023-03-08 08:53:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 08:53:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 08:53:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 08:53:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 08:53:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 08:53:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 08:53:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 08:54:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 08:54:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 08:54:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 08:54:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 08:54:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 08:54:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0019, Acc_1: 0.7785, Acc_2: 0.7765, F1-score_1: 0.7101, F1-score_2: 0.7169
2023-03-08 08:54:43 - __main__ - INFO - Epoch [23/100]
2023-03-08 08:54:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 08:54:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0033, Loss_2: 0.0048, Acc_1: 0.7266, Acc_2: 0.7188, 
2023-03-08 08:55:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 08:55:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 08:55:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 08:55:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0019, Loss_2: 0.0022, Acc_1: 0.7656, Acc_2: 0.7578, 
2023-03-08 08:55:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 08:55:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 08:55:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 08:55:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 08:55:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 08:56:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 08:56:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0020, Acc_1: 0.7903, Acc_2: 0.7875, F1-score_1: 0.7255, F1-score_2: 0.7282
2023-03-08 08:56:16 - __main__ - INFO - Epoch [24/100]
2023-03-08 08:56:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 08:56:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 08:56:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 08:56:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 08:56:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 08:56:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 08:57:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-08 08:57:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 08:57:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 08:57:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 08:57:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 08:57:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 08:57:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0014, Acc_1: 0.7921, Acc_2: 0.7874, F1-score_1: 0.7220, F1-score_2: 0.7231
2023-03-08 08:57:49 - __main__ - INFO - Epoch [25/100]
2023-03-08 08:57:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 08:58:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 08:58:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 08:58:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 08:58:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 08:58:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 08:58:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 08:58:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 08:58:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0028, Acc_1: 0.7891, Acc_2: 0.7266, 
2023-03-08 08:58:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0017, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-08 08:59:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0010, Loss_2: 0.0012, Acc_1: 0.8125, Acc_2: 0.7812, 
2023-03-08 08:59:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 08:59:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0024, Acc_1: 0.7678, Acc_2: 0.7685, F1-score_1: 0.7098, F1-score_2: 0.7083
2023-03-08 08:59:22 - __main__ - INFO - Epoch [26/100]
2023-03-08 08:59:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 08:59:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 08:59:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 08:59:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 08:59:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 09:00:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 09:00:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 09:00:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 09:00:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 09:00:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:00:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 09:00:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:00:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0017, Acc_1: 0.7976, Acc_2: 0.7891, F1-score_1: 0.7310, F1-score_2: 0.7267
2023-03-08 09:00:55 - __main__ - INFO - Epoch [27/100]
2023-03-08 09:01:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 09:01:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 09:01:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0009, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 09:01:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 09:01:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 09:01:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:01:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-08 09:01:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0013, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 09:01:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:02:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 09:02:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 09:02:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 09:02:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0039, Loss_2: 0.0016, Acc_1: 0.7879, Acc_2: 0.7824, F1-score_1: 0.7182, F1-score_2: 0.7190
2023-03-08 09:02:27 - __main__ - INFO - Epoch [28/100]
2023-03-08 09:02:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 09:02:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:02:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 09:02:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:03:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 09:03:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:03:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 09:03:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 09:03:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 09:03:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 09:03:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 09:03:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:04:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0017, Acc_1: 0.7913, Acc_2: 0.7829, F1-score_1: 0.7227, F1-score_2: 0.7212
2023-03-08 09:04:00 - __main__ - INFO - Epoch [29/100]
2023-03-08 09:04:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0019, Loss_2: 0.0019, Acc_1: 0.7578, Acc_2: 0.7812, 
2023-03-08 09:04:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:04:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:04:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:04:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 09:04:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:04:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 09:04:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 09:04:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:05:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 09:05:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:05:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 09:05:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0019, Acc_1: 0.7967, Acc_2: 0.7879, F1-score_1: 0.7282, F1-score_2: 0.7263
2023-03-08 09:05:33 - __main__ - INFO - Epoch [30/100]
2023-03-08 09:05:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 09:05:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 09:05:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-08 09:05:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 09:06:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:06:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 09:06:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 09:06:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 09:06:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:06:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 09:06:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:06:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 09:07:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0015, Acc_1: 0.7979, Acc_2: 0.7886, F1-score_1: 0.7274, F1-score_2: 0.7234
2023-03-08 09:07:07 - __main__ - INFO - Epoch [31/100]
2023-03-08 09:07:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 09:07:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 09:07:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 09:07:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:07:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 09:07:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 09:07:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 09:07:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 09:08:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 09:08:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 09:08:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-08 09:08:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:08:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0026, Acc_1: 0.7772, Acc_2: 0.7950, F1-score_1: 0.7187, F1-score_2: 0.7331
2023-03-08 09:08:39 - __main__ - INFO - Epoch [32/100]
2023-03-08 09:08:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 09:08:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 09:08:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 09:09:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:09:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:09:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 09:09:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 09:09:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 09:09:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 09:09:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 09:09:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 09:09:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 09:10:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0036, Acc_1: 0.7869, Acc_2: 0.7826, F1-score_1: 0.7173, F1-score_2: 0.7193
2023-03-08 09:10:12 - __main__ - INFO - Epoch [33/100]
2023-03-08 09:10:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 09:10:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:10:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 09:10:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:10:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:10:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:10:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 09:11:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 09:11:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:11:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 09:11:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:11:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:11:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0026, Acc_1: 0.7850, Acc_2: 0.7870, F1-score_1: 0.7189, F1-score_2: 0.7240
2023-03-08 09:11:45 - __main__ - INFO - Epoch [34/100]
2023-03-08 09:11:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:11:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 09:12:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:12:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:12:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:12:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:12:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 09:12:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:12:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 09:12:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 09:12:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 09:13:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 09:13:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0036, Loss_2: 0.0030, Acc_1: 0.7748, Acc_2: 0.7869, F1-score_1: 0.6977, F1-score_2: 0.7232
2023-03-08 09:13:18 - __main__ - INFO - Epoch [35/100]
2023-03-08 09:13:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 09:13:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 09:13:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 09:13:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:13:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:13:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 09:14:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0011, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 09:14:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 09:14:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 09:14:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 09:14:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 09:14:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 09:14:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0028, Acc_1: 0.7802, Acc_2: 0.7806, F1-score_1: 0.7154, F1-score_2: 0.7151
2023-03-08 09:14:50 - __main__ - INFO - Epoch [36/100]
2023-03-08 09:14:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-08 09:15:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 09:15:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-08 09:15:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:15:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 09:15:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 09:15:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 09:15:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 09:15:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 09:15:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 09:16:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 09:16:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 09:16:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0022, Acc_1: 0.7739, Acc_2: 0.7862, F1-score_1: 0.7070, F1-score_2: 0.7251
2023-03-08 09:16:24 - __main__ - INFO - Epoch [37/100]
2023-03-08 09:16:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 09:16:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.7734, Acc_2: 0.8047, 
2023-03-08 09:16:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:16:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 09:16:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 09:17:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 09:17:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 09:17:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0029, Loss_2: 0.0032, Acc_1: 0.7500, Acc_2: 0.7500, 
2023-03-08 09:17:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:17:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 09:17:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 09:17:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:17:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0034, Acc_1: 0.7699, Acc_2: 0.7855, F1-score_1: 0.7067, F1-score_2: 0.7194
2023-03-08 09:17:58 - __main__ - INFO - Epoch [38/100]
2023-03-08 09:18:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 09:18:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 09:18:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:18:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 09:18:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 09:18:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 09:18:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 09:18:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 09:18:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 09:19:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 09:19:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 09:19:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 09:19:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0029, Acc_1: 0.7833, Acc_2: 0.7807, F1-score_1: 0.7157, F1-score_2: 0.7176
2023-03-08 09:19:31 - __main__ - INFO - Epoch [39/100]
2023-03-08 09:19:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 09:19:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:19:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:19:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 09:20:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:20:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:20:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:20:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:20:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:20:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 09:20:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 09:20:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 09:21:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0027, Acc_1: 0.7779, Acc_2: 0.7867, F1-score_1: 0.7157, F1-score_2: 0.7261
2023-03-08 09:21:03 - __main__ - INFO - Epoch [40/100]
2023-03-08 09:21:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 09:21:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 09:21:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 09:21:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 09:21:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:21:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 09:21:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:21:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 09:22:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 09:22:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 09:22:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 09:22:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:22:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0030, Acc_1: 0.7819, Acc_2: 0.7736, F1-score_1: 0.7140, F1-score_2: 0.7096
2023-03-08 09:22:36 - __main__ - INFO - Epoch [41/100]
2023-03-08 09:22:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 09:22:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:22:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:23:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:23:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:23:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:23:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 09:23:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:23:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:23:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:23:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:23:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 09:24:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0033, Acc_1: 0.7867, Acc_2: 0.7914, F1-score_1: 0.7189, F1-score_2: 0.7228
2023-03-08 09:24:10 - __main__ - INFO - Epoch [42/100]
2023-03-08 09:24:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:24:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 09:24:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 09:24:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:24:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:24:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 09:24:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 09:25:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 09:25:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 09:25:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 09:25:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:25:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:25:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0036, Acc_1: 0.7845, Acc_2: 0.7709, F1-score_1: 0.7163, F1-score_2: 0.7027
2023-03-08 09:25:43 - __main__ - INFO - Epoch [43/100]
2023-03-08 09:25:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:25:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 09:26:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 09:26:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:26:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 09:26:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:26:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 09:26:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 09:26:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:26:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 09:26:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:27:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:27:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0040, Loss_2: 0.0038, Acc_1: 0.7724, Acc_2: 0.7779, F1-score_1: 0.7069, F1-score_2: 0.7075
2023-03-08 09:27:16 - __main__ - INFO - Epoch [44/100]
2023-03-08 09:27:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:27:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 09:27:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:27:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:27:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 09:27:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:28:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 09:28:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:28:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 09:28:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:28:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 09:28:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 09:28:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0026, Acc_1: 0.7862, Acc_2: 0.7796, F1-score_1: 0.7186, F1-score_2: 0.7087
2023-03-08 09:28:49 - __main__ - INFO - Epoch [45/100]
2023-03-08 09:28:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:29:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 09:29:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 09:29:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:29:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 09:29:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 09:29:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 09:29:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 09:29:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 09:29:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 09:30:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 09:30:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:30:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0027, Acc_1: 0.7816, Acc_2: 0.7853, F1-score_1: 0.7139, F1-score_2: 0.7133
2023-03-08 09:30:22 - __main__ - INFO - Epoch [46/100]
2023-03-08 09:30:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 09:30:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 09:30:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 09:30:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 09:30:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 09:31:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:31:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 09:31:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 09:31:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 09:31:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 09:31:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 09:31:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 09:31:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0026, Acc_1: 0.7799, Acc_2: 0.7814, F1-score_1: 0.7128, F1-score_2: 0.7109
2023-03-08 09:31:55 - __main__ - INFO - Epoch [47/100]
2023-03-08 09:32:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 09:32:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 09:32:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 09:32:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:32:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 09:32:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 09:32:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:32:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 09:32:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 09:33:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 09:33:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 09:33:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:33:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0035, Acc_1: 0.7862, Acc_2: 0.7914, F1-score_1: 0.7205, F1-score_2: 0.7251
2023-03-08 09:33:28 - __main__ - INFO - Epoch [48/100]
2023-03-08 09:33:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:33:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 09:33:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 09:33:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 09:34:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:34:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 09:34:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 09:34:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:34:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:34:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:34:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 09:34:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:35:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0019, Acc_1: 0.7772, Acc_2: 0.7853, F1-score_1: 0.7092, F1-score_2: 0.7140
2023-03-08 09:35:01 - __main__ - INFO - Epoch [49/100]
2023-03-08 09:35:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 09:35:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 09:35:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 09:35:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 09:35:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 09:35:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:35:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:35:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 09:36:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 09:36:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:36:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 09:36:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 09:36:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0031, Acc_1: 0.7695, Acc_2: 0.7853, F1-score_1: 0.7044, F1-score_2: 0.7167
2023-03-08 09:36:34 - __main__ - INFO - Epoch [50/100]
2023-03-08 09:36:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 09:36:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 09:36:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:37:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 09:37:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:37:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 09:37:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 09:37:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 09:37:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:37:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 09:37:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:37:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 09:38:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0028, Loss_2: 0.0024, Acc_1: 0.7726, Acc_2: 0.7933, F1-score_1: 0.7098, F1-score_2: 0.7227
2023-03-08 09:38:07 - __main__ - INFO - Epoch [51/100]
2023-03-08 09:38:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:38:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 09:38:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 09:38:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 09:38:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:38:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:38:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:39:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 09:39:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 09:39:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:39:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 09:39:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:39:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0027, Acc_1: 0.7809, Acc_2: 0.7906, F1-score_1: 0.7136, F1-score_2: 0.7173
2023-03-08 09:39:40 - __main__ - INFO - Epoch [52/100]
2023-03-08 09:39:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:39:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 09:39:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 09:40:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 09:40:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 09:40:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 09:40:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:40:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 09:40:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 09:40:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:40:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:40:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:41:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0038, Acc_1: 0.7828, Acc_2: 0.7828, F1-score_1: 0.7151, F1-score_2: 0.7215
2023-03-08 09:41:13 - __main__ - INFO - Epoch [53/100]
2023-03-08 09:41:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 09:41:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 09:41:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 09:41:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 09:41:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 09:41:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:41:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 09:42:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:42:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 09:42:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:42:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 09:42:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 09:42:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0023, Acc_1: 0.7648, Acc_2: 0.7943, F1-score_1: 0.7036, F1-score_2: 0.7312
2023-03-08 09:42:46 - __main__ - INFO - Epoch [54/100]
2023-03-08 09:42:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 09:42:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 09:43:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 09:43:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 09:43:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 09:43:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 09:43:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0012, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 09:43:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:43:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 09:43:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:43:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 09:44:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 09:44:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0034, Acc_1: 0.7666, Acc_2: 0.7892, F1-score_1: 0.7028, F1-score_2: 0.7302
2023-03-08 09:44:19 - __main__ - INFO - Epoch [55/100]
2023-03-08 09:44:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 09:44:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:44:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:44:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 09:44:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 09:44:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:45:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 09:45:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 09:45:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 09:45:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:45:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 09:45:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 09:45:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0035, Acc_1: 0.7865, Acc_2: 0.7911, F1-score_1: 0.7212, F1-score_2: 0.7258
2023-03-08 09:45:52 - __main__ - INFO - Epoch [56/100]
2023-03-08 09:45:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 09:46:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 09:46:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 09:46:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:46:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:46:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 09:46:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:46:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 09:46:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-08 09:46:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 09:47:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:47:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 09:47:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0034, Acc_1: 0.7897, Acc_2: 0.7845, F1-score_1: 0.7243, F1-score_2: 0.7150
2023-03-08 09:47:25 - __main__ - INFO - Epoch [57/100]
2023-03-08 09:47:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 09:47:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:47:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:47:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 09:47:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0005, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 09:48:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 09:48:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 09:48:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 09:48:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:48:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 09:48:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:48:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 09:48:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0041, Acc_1: 0.7897, Acc_2: 0.7909, F1-score_1: 0.7221, F1-score_2: 0.7276
2023-03-08 09:48:58 - __main__ - INFO - Epoch [58/100]
2023-03-08 09:49:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:49:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:49:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 09:49:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 09:49:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:49:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 09:49:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:49:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 09:49:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 09:50:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:50:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 09:50:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:50:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0030, Acc_1: 0.7860, Acc_2: 0.7780, F1-score_1: 0.7170, F1-score_2: 0.7183
2023-03-08 09:50:31 - __main__ - INFO - Epoch [59/100]
2023-03-08 09:50:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 09:50:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:50:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 09:50:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:51:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:51:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 09:51:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 09:51:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:51:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 09:51:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 09:51:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:51:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 09:52:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0032, Acc_1: 0.7869, Acc_2: 0.7906, F1-score_1: 0.7190, F1-score_2: 0.7209
2023-03-08 09:52:04 - __main__ - INFO - Epoch [60/100]
2023-03-08 09:52:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 09:52:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:52:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 09:52:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 09:52:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 09:52:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:52:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:52:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:53:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:53:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 09:53:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 09:53:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:53:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0035, Acc_1: 0.7736, Acc_2: 0.7846, F1-score_1: 0.7045, F1-score_2: 0.7162
2023-03-08 09:53:37 - __main__ - INFO - Epoch [61/100]
2023-03-08 09:53:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 09:53:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 09:53:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:54:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 09:54:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:54:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 09:54:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:54:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 09:54:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 09:54:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0019, Loss_2: 0.0014, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 09:54:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:54:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 09:55:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0033, Acc_1: 0.7882, Acc_2: 0.7690, F1-score_1: 0.7182, F1-score_2: 0.7064
2023-03-08 09:55:10 - __main__ - INFO - Epoch [62/100]
2023-03-08 09:55:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-08 09:55:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 09:55:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:55:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 09:55:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:55:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:55:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 09:56:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 09:56:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 09:56:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 09:56:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 09:56:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:56:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0028, Acc_1: 0.7906, Acc_2: 0.7901, F1-score_1: 0.7207, F1-score_2: 0.7243
2023-03-08 09:56:43 - __main__ - INFO - Epoch [63/100]
2023-03-08 09:56:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 09:56:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:57:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 09:57:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 09:57:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 09:57:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 09:57:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 09:57:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 09:57:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:57:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0013, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 09:57:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 09:58:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 09:58:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0026, Acc_1: 0.7806, Acc_2: 0.7692, F1-score_1: 0.7109, F1-score_2: 0.7067
2023-03-08 09:58:16 - __main__ - INFO - Epoch [64/100]
2023-03-08 09:58:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 09:58:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 09:58:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:58:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 09:58:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:58:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 09:59:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:59:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:59:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 09:59:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 09:59:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 09:59:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 09:59:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0028, Loss_2: 0.0036, Acc_1: 0.7729, Acc_2: 0.7563, F1-score_1: 0.7028, F1-score_2: 0.6961
2023-03-08 09:59:49 - __main__ - INFO - Epoch [65/100]
2023-03-08 09:59:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:00:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:00:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 10:00:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:00:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:00:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 10:00:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 10:00:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:00:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 10:00:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:01:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 10:01:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 10:01:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0039, Acc_1: 0.7823, Acc_2: 0.7853, F1-score_1: 0.7121, F1-score_2: 0.7229
2023-03-08 10:01:22 - __main__ - INFO - Epoch [66/100]
2023-03-08 10:01:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:01:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:01:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 10:01:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 10:01:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 10:02:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:02:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:02:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 10:02:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 10:02:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:02:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 10:02:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 10:02:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0021, Acc_1: 0.7880, Acc_2: 0.7923, F1-score_1: 0.7133, F1-score_2: 0.7272
2023-03-08 10:02:55 - __main__ - INFO - Epoch [67/100]
2023-03-08 10:03:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 10:03:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 10:03:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 10:03:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:03:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:03:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 10:03:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:03:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:03:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 10:04:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 10:04:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 10:04:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 10:04:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0018, Acc_1: 0.7736, Acc_2: 0.7794, F1-score_1: 0.6976, F1-score_2: 0.7158
2023-03-08 10:04:28 - __main__ - INFO - Epoch [68/100]
2023-03-08 10:04:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:04:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 10:04:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:04:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 10:05:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:05:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 10:05:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:05:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:05:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:05:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 10:05:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 10:05:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:06:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0028, Acc_1: 0.7797, Acc_2: 0.7991, F1-score_1: 0.7091, F1-score_2: 0.7302
2023-03-08 10:06:01 - __main__ - INFO - Epoch [69/100]
2023-03-08 10:06:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 10:06:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 10:06:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:06:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 10:06:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:06:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 10:06:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 10:06:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 10:07:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0011, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 10:07:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 10:07:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 10:07:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:07:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0024, Acc_1: 0.7857, Acc_2: 0.7948, F1-score_1: 0.7108, F1-score_2: 0.7293
2023-03-08 10:07:34 - __main__ - INFO - Epoch [70/100]
2023-03-08 10:07:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:07:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 10:07:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 10:07:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:08:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 10:08:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-08 10:08:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:08:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:08:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:08:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 10:08:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 10:08:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 10:09:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0031, Acc_1: 0.7865, Acc_2: 0.7943, F1-score_1: 0.7129, F1-score_2: 0.7328
2023-03-08 10:09:07 - __main__ - INFO - Epoch [71/100]
2023-03-08 10:09:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:09:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:09:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 10:09:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 10:09:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 10:09:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:09:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:09:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:10:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 10:10:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 10:10:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 10:10:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:10:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0024, Acc_1: 0.7852, Acc_2: 0.7919, F1-score_1: 0.7121, F1-score_2: 0.7269
2023-03-08 10:10:40 - __main__ - INFO - Epoch [72/100]
2023-03-08 10:10:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:10:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:10:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 10:11:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 10:11:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:11:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 10:11:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 10:11:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:11:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 10:11:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 10:11:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 10:11:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:12:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0023, Acc_1: 0.7770, Acc_2: 0.7921, F1-score_1: 0.7045, F1-score_2: 0.7264
2023-03-08 10:12:13 - __main__ - INFO - Epoch [73/100]
2023-03-08 10:12:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:12:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:12:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 10:12:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 10:12:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:12:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 10:12:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 10:13:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 10:13:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 10:13:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 10:13:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:13:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:13:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0023, Acc_1: 0.7824, Acc_2: 0.8001, F1-score_1: 0.7052, F1-score_2: 0.7321
2023-03-08 10:13:46 - __main__ - INFO - Epoch [74/100]
2023-03-08 10:13:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 10:13:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 10:14:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:14:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 10:14:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 10:14:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 10:14:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 10:14:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:14:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:14:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:14:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 10:15:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 10:15:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0022, Acc_1: 0.7605, Acc_2: 0.7838, F1-score_1: 0.6932, F1-score_2: 0.7173
2023-03-08 10:15:19 - __main__ - INFO - Epoch [75/100]
2023-03-08 10:15:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 10:15:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 10:15:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 10:15:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:15:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 10:15:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:16:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:16:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:16:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:16:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 10:16:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 10:16:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 10:16:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0027, Acc_1: 0.7716, Acc_2: 0.7741, F1-score_1: 0.7014, F1-score_2: 0.7066
2023-03-08 10:16:51 - __main__ - INFO - Epoch [76/100]
2023-03-08 10:16:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:17:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 10:17:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 10:17:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:17:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 10:17:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 10:17:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 10:17:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 10:17:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 10:17:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 10:18:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:18:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 10:18:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0020, Acc_1: 0.7712, Acc_2: 0.7862, F1-score_1: 0.6928, F1-score_2: 0.7181
2023-03-08 10:18:24 - __main__ - INFO - Epoch [77/100]
2023-03-08 10:18:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:18:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:18:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 10:18:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 10:18:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:19:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 10:19:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 10:19:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:19:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 10:19:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 10:19:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:19:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 10:19:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0028, Loss_2: 0.0030, Acc_1: 0.7743, Acc_2: 0.7930, F1-score_1: 0.7070, F1-score_2: 0.7208
2023-03-08 10:19:57 - __main__ - INFO - Epoch [78/100]
2023-03-08 10:20:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 10:20:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:20:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 10:20:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 10:20:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 10:20:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 10:20:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 10:20:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:20:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 10:21:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:21:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 10:21:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 10:21:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0028, Loss_2: 0.0033, Acc_1: 0.7612, Acc_2: 0.7935, F1-score_1: 0.6979, F1-score_2: 0.7250
2023-03-08 10:21:30 - __main__ - INFO - Epoch [79/100]
2023-03-08 10:21:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 10:21:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 10:21:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 10:21:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:22:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:22:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 10:22:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 10:22:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:22:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:22:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 10:22:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:22:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 10:23:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0024, Acc_1: 0.7672, Acc_2: 0.7779, F1-score_1: 0.6991, F1-score_2: 0.7070
2023-03-08 10:23:03 - __main__ - INFO - Epoch [80/100]
2023-03-08 10:23:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:23:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:23:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 10:23:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:23:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:23:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 10:23:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 10:23:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:24:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:24:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:24:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:24:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:24:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0018, Acc_1: 0.7770, Acc_2: 0.7858, F1-score_1: 0.7087, F1-score_2: 0.7180
2023-03-08 10:24:36 - __main__ - INFO - Epoch [81/100]
2023-03-08 10:24:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:24:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:24:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:25:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 10:25:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 10:25:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 10:25:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:25:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 10:25:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 10:25:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 10:25:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 10:25:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:26:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0023, Loss_2: 0.0017, Acc_1: 0.7772, Acc_2: 0.7918, F1-score_1: 0.7021, F1-score_2: 0.7220
2023-03-08 10:26:09 - __main__ - INFO - Epoch [82/100]
2023-03-08 10:26:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 10:26:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 10:26:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 10:26:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 10:26:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:26:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:26:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:27:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:27:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 10:27:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:27:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 10:27:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 10:27:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0012, Acc_1: 0.7804, Acc_2: 0.7882, F1-score_1: 0.7082, F1-score_2: 0.7236
2023-03-08 10:27:42 - __main__ - INFO - Epoch [83/100]
2023-03-08 10:27:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 10:27:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:28:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 10:28:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:28:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:28:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 10:28:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:28:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 10:28:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:28:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 10:28:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 10:29:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 10:29:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0013, Acc_1: 0.7685, Acc_2: 0.7884, F1-score_1: 0.6994, F1-score_2: 0.7270
2023-03-08 10:29:15 - __main__ - INFO - Epoch [84/100]
2023-03-08 10:29:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 10:29:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 10:29:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:29:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:29:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 10:29:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 10:30:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:30:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:30:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:30:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 10:30:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 10:30:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 10:30:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0013, Acc_1: 0.7758, Acc_2: 0.7906, F1-score_1: 0.7085, F1-score_2: 0.7253
2023-03-08 10:30:48 - __main__ - INFO - Epoch [85/100]
2023-03-08 10:30:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 10:31:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:31:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:31:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 10:31:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 10:31:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 10:31:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 10:31:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 10:31:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:31:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:32:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:32:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:32:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0014, Acc_1: 0.7655, Acc_2: 0.7787, F1-score_1: 0.6994, F1-score_2: 0.7180
2023-03-08 10:32:21 - __main__ - INFO - Epoch [86/100]
2023-03-08 10:32:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:32:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 10:32:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:32:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 10:32:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 10:33:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:33:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 10:33:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:33:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:33:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:33:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 10:33:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:33:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0015, Acc_1: 0.7753, Acc_2: 0.7880, F1-score_1: 0.7081, F1-score_2: 0.7263
2023-03-08 10:33:54 - __main__ - INFO - Epoch [87/100]
2023-03-08 10:34:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:34:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:34:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 10:34:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 10:34:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 10:34:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:34:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 10:34:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:34:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:35:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:35:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:35:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:35:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0016, Acc_1: 0.7779, Acc_2: 0.7947, F1-score_1: 0.7120, F1-score_2: 0.7310
2023-03-08 10:35:27 - __main__ - INFO - Epoch [88/100]
2023-03-08 10:35:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 10:35:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 10:35:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 10:35:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:35:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 10:36:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 10:36:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 10:36:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:36:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:36:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:36:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 10:36:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 10:37:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0017, Acc_1: 0.7590, Acc_2: 0.7838, F1-score_1: 0.6959, F1-score_2: 0.7231
2023-03-08 10:37:00 - __main__ - INFO - Epoch [89/100]
2023-03-08 10:37:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:37:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 10:37:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 10:37:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:37:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:37:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:37:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 10:37:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 10:37:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 10:38:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:38:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 10:38:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:38:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0018, Acc_1: 0.7668, Acc_2: 0.7887, F1-score_1: 0.7016, F1-score_2: 0.7258
2023-03-08 10:38:33 - __main__ - INFO - Epoch [90/100]
2023-03-08 10:38:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:38:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 10:38:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 10:38:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 10:39:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:39:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:39:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 10:39:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:39:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:39:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 10:39:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 10:39:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 10:40:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0018, Acc_1: 0.7746, Acc_2: 0.7923, F1-score_1: 0.7085, F1-score_2: 0.7290
2023-03-08 10:40:06 - __main__ - INFO - Epoch [91/100]
2023-03-08 10:40:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 10:40:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 10:40:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:40:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 10:40:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 10:40:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 10:40:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 10:40:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:41:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 10:41:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:41:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:41:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:41:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0018, Acc_1: 0.7758, Acc_2: 0.7940, F1-score_1: 0.7089, F1-score_2: 0.7297
2023-03-08 10:41:39 - __main__ - INFO - Epoch [92/100]
2023-03-08 10:41:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:41:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:41:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 10:42:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 10:42:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 10:42:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:42:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 10:42:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 10:42:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:42:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 10:42:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:42:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:43:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0019, Acc_1: 0.7753, Acc_2: 0.7931, F1-score_1: 0.7070, F1-score_2: 0.7283
2023-03-08 10:43:12 - __main__ - INFO - Epoch [93/100]
2023-03-08 10:43:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 10:43:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:43:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 10:43:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 10:43:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 10:43:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:43:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:44:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:44:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 10:44:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 10:44:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 10:44:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:44:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0025, Acc_1: 0.7666, Acc_2: 0.7894, F1-score_1: 0.7005, F1-score_2: 0.7264
2023-03-08 10:44:45 - __main__ - INFO - Epoch [94/100]
2023-03-08 10:44:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 10:44:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:45:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:45:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:45:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:45:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 10:45:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 10:45:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 10:45:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:45:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 10:45:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 10:46:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 10:46:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0023, Loss_2: 0.0023, Acc_1: 0.7714, Acc_2: 0.7913, F1-score_1: 0.7056, F1-score_2: 0.7280
2023-03-08 10:46:18 - __main__ - INFO - Epoch [95/100]
2023-03-08 10:46:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 10:46:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 10:46:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 10:46:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 10:46:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:46:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 10:47:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 10:47:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 10:47:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 10:47:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:47:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 10:47:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:47:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0021, Acc_1: 0.7714, Acc_2: 0.7896, F1-score_1: 0.7063, F1-score_2: 0.7237
2023-03-08 10:47:51 - __main__ - INFO - Epoch [96/100]
2023-03-08 10:47:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 10:48:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 10:48:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:48:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 10:48:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:48:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:48:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 10:48:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:48:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 10:48:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 10:49:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:49:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:49:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0023, Loss_2: 0.0018, Acc_1: 0.7706, Acc_2: 0.7872, F1-score_1: 0.7054, F1-score_2: 0.7210
2023-03-08 10:49:24 - __main__ - INFO - Epoch [97/100]
2023-03-08 10:49:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:49:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:49:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:49:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 10:49:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:50:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:50:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 10:50:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 10:50:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 10:50:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 10:50:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:50:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:50:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0019, Acc_1: 0.7700, Acc_2: 0.7853, F1-score_1: 0.7063, F1-score_2: 0.7201
2023-03-08 10:50:56 - __main__ - INFO - Epoch [98/100]
2023-03-08 10:51:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:51:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 10:51:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 10:51:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 10:51:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:51:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:51:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 10:51:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 10:51:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 10:52:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:52:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 10:52:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 10:52:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0022, Acc_1: 0.7716, Acc_2: 0.7880, F1-score_1: 0.7075, F1-score_2: 0.7224
2023-03-08 10:52:29 - __main__ - INFO - Epoch [99/100]
2023-03-08 10:52:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 10:52:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 10:52:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 10:52:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 10:53:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:53:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:53:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:53:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 10:53:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 10:53:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:53:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 10:53:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 10:54:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0021, Acc_1: 0.7729, Acc_2: 0.7887, F1-score_1: 0.7084, F1-score_2: 0.7232
2023-03-08 10:54:04 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 10:54:04 - utils._noise - DEBUG - 6, 7
2023-03-08 10:54:04 - utils._noise - DEBUG - 13997
2023-03-08 10:54:05 - utils._noise - INFO - Actual noise 0.20
2023-03-08 10:54:05 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-08 10:54:05 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-08 10:54:07 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 10:54:07 - __main__ - INFO - Loading dataset...
2023-03-08 10:54:07 - __main__ - INFO - Building model...
2023-03-08 10:54:07 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-08 10:54:07 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-08 10:54:07 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-08 10:54:07 - __main__ - INFO - Start train & evaluate
2023-03-08 10:54:07 - __main__ - INFO - Epoch [0/100]
2023-03-08 10:54:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0153, Loss_2: 0.0153, Acc_1: 0.1484, Acc_2: 0.0781, 
2023-03-08 10:54:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0149, Loss_2: 0.0148, Acc_1: 0.1484, Acc_2: 0.1641, 
2023-03-08 10:54:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0141, Loss_2: 0.0141, Acc_1: 0.3516, Acc_2: 0.3359, 
2023-03-08 10:54:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0143, Loss_2: 0.0143, Acc_1: 0.3203, Acc_2: 0.3203, 
2023-03-08 10:54:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0126, Loss_2: 0.0176, Acc_1: 0.4688, Acc_2: 0.2188, 
2023-03-08 10:54:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0133, Loss_2: 0.0146, Acc_1: 0.3516, Acc_2: 0.2188, 
2023-03-08 10:54:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0125, Loss_2: 0.0139, Acc_1: 0.4609, Acc_2: 0.2812, 
2023-03-08 10:54:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0123, Loss_2: 0.0142, Acc_1: 0.5078, Acc_2: 0.2422, 
2023-03-08 10:55:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0119, Loss_2: 0.0133, Acc_1: 0.4766, Acc_2: 0.3906, 
2023-03-08 10:55:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0129, Loss_2: 0.0130, Acc_1: 0.4219, Acc_2: 0.3438, 
2023-03-08 10:55:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0127, Loss_2: 0.0137, Acc_1: 0.4141, Acc_2: 0.3750, 
2023-03-08 10:55:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0135, Loss_2: 0.0143, Acc_1: 0.3203, Acc_2: 0.2578, 
2023-03-08 10:55:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0122, Loss_2: 0.0124, Acc_1: 0.4818, Acc_2: 0.3587, F1-score_1: 0.2715, F1-score_2: 0.1973
2023-03-08 10:55:40 - __main__ - INFO - Epoch [1/100]
2023-03-08 10:55:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0131, Loss_2: 0.0139, Acc_1: 0.3750, Acc_2: 0.2500, 
2023-03-08 10:55:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0123, Loss_2: 0.0128, Acc_1: 0.4219, Acc_2: 0.3281, 
2023-03-08 10:55:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0128, Loss_2: 0.0143, Acc_1: 0.4062, Acc_2: 0.3281, 
2023-03-08 10:56:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0109, Loss_2: 0.0128, Acc_1: 0.5234, Acc_2: 0.4531, 
2023-03-08 10:56:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0120, Loss_2: 0.0124, Acc_1: 0.3984, Acc_2: 0.3672, 
2023-03-08 10:56:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0116, Loss_2: 0.0126, Acc_1: 0.4688, Acc_2: 0.3516, 
2023-03-08 10:56:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0117, Loss_2: 0.0120, Acc_1: 0.4531, Acc_2: 0.4219, 
2023-03-08 10:56:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0116, Loss_2: 0.0122, Acc_1: 0.4609, Acc_2: 0.4766, 
2023-03-08 10:56:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0107, Loss_2: 0.0109, Acc_1: 0.5156, Acc_2: 0.4375, 
2023-03-08 10:56:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0101, Loss_2: 0.0111, Acc_1: 0.6250, Acc_2: 0.5312, 
2023-03-08 10:56:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0111, Loss_2: 0.0105, Acc_1: 0.5156, Acc_2: 0.5391, 
2023-03-08 10:56:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0110, Loss_2: 0.0110, Acc_1: 0.5781, Acc_2: 0.5312, 
2023-03-08 10:57:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0095, Loss_2: 0.0100, Acc_1: 0.6360, Acc_2: 0.5397, F1-score_1: 0.4957, F1-score_2: 0.4017
2023-03-08 10:57:12 - __main__ - INFO - Epoch [2/100]
2023-03-08 10:57:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0109, Loss_2: 0.0112, Acc_1: 0.4844, Acc_2: 0.5000, 
2023-03-08 10:57:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0089, Loss_2: 0.0103, Acc_1: 0.5938, Acc_2: 0.5781, 
2023-03-08 10:57:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0112, Loss_2: 0.0116, Acc_1: 0.4688, Acc_2: 0.4531, 
2023-03-08 10:57:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0094, Loss_2: 0.0094, Acc_1: 0.5781, Acc_2: 0.5938, 
2023-03-08 10:57:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0113, Loss_2: 0.0100, Acc_1: 0.5234, Acc_2: 0.5859, 
2023-03-08 10:57:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0093, Loss_2: 0.0095, Acc_1: 0.5781, Acc_2: 0.5781, 
2023-03-08 10:57:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0095, Loss_2: 0.0092, Acc_1: 0.6094, Acc_2: 0.6172, 
2023-03-08 10:58:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0093, Loss_2: 0.0092, Acc_1: 0.5469, Acc_2: 0.6172, 
2023-03-08 10:58:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0107, Loss_2: 0.0094, Acc_1: 0.5156, Acc_2: 0.5938, 
2023-03-08 10:58:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0108, Loss_2: 0.0109, Acc_1: 0.5078, Acc_2: 0.5547, 
2023-03-08 10:58:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0087, Loss_2: 0.0088, Acc_1: 0.5938, Acc_2: 0.5859, 
2023-03-08 10:58:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0104, Loss_2: 0.0091, Acc_1: 0.4844, Acc_2: 0.6016, 
2023-03-08 10:58:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0082, Loss_2: 0.0065, Acc_1: 0.6179, Acc_2: 0.7086, F1-score_1: 0.5494, F1-score_2: 0.6096
2023-03-08 10:58:45 - __main__ - INFO - Epoch [3/100]
2023-03-08 10:58:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0099, Loss_2: 0.0094, Acc_1: 0.5156, Acc_2: 0.6094, 
2023-03-08 10:58:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0086, Loss_2: 0.0084, Acc_1: 0.6328, Acc_2: 0.6094, 
2023-03-08 10:59:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0074, Loss_2: 0.0077, Acc_1: 0.6719, Acc_2: 0.6562, 
2023-03-08 10:59:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0078, Loss_2: 0.0063, Acc_1: 0.6172, Acc_2: 0.7188, 
2023-03-08 10:59:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0075, Loss_2: 0.0070, Acc_1: 0.6875, Acc_2: 0.6641, 
2023-03-08 10:59:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0089, Loss_2: 0.0085, Acc_1: 0.6094, Acc_2: 0.6406, 
2023-03-08 10:59:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0090, Loss_2: 0.0097, Acc_1: 0.5859, Acc_2: 0.5703, 
2023-03-08 10:59:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0083, Loss_2: 0.0085, Acc_1: 0.6484, Acc_2: 0.6641, 
2023-03-08 10:59:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0067, Loss_2: 0.0060, Acc_1: 0.6797, Acc_2: 0.7266, 
2023-03-08 10:59:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0071, Loss_2: 0.0067, Acc_1: 0.7109, Acc_2: 0.7188, 
2023-03-08 10:59:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0081, Loss_2: 0.0086, Acc_1: 0.6016, Acc_2: 0.6016, 
2023-03-08 11:00:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0069, Loss_2: 0.0075, Acc_1: 0.6953, Acc_2: 0.6562, 
2023-03-08 11:00:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0058, Loss_2: 0.0053, Acc_1: 0.7303, Acc_2: 0.7328, F1-score_1: 0.6393, F1-score_2: 0.6539
2023-03-08 11:00:18 - __main__ - INFO - Epoch [4/100]
2023-03-08 11:00:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0061, Loss_2: 0.0065, Acc_1: 0.6641, Acc_2: 0.7031, 
2023-03-08 11:00:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0045, Loss_2: 0.0061, Acc_1: 0.7578, Acc_2: 0.6562, 
2023-03-08 11:00:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0061, Loss_2: 0.0067, Acc_1: 0.6875, Acc_2: 0.6562, 
2023-03-08 11:00:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0045, Loss_2: 0.0046, Acc_1: 0.7344, Acc_2: 0.7891, 
2023-03-08 11:00:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0067, Loss_2: 0.0072, Acc_1: 0.6641, Acc_2: 0.6562, 
2023-03-08 11:00:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0075, Loss_2: 0.0065, Acc_1: 0.6328, Acc_2: 0.6875, 
2023-03-08 11:01:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0062, Loss_2: 0.0068, Acc_1: 0.6875, Acc_2: 0.6797, 
2023-03-08 11:01:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0094, Loss_2: 0.0084, Acc_1: 0.5625, Acc_2: 0.6094, 
2023-03-08 11:01:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0066, Loss_2: 0.0049, Acc_1: 0.6641, Acc_2: 0.7812, 
2023-03-08 11:01:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0076, Loss_2: 0.0068, Acc_1: 0.6328, Acc_2: 0.6719, 
2023-03-08 11:01:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0046, Loss_2: 0.0046, Acc_1: 0.7500, Acc_2: 0.7578, 
2023-03-08 11:01:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0049, Loss_2: 0.0052, Acc_1: 0.7734, Acc_2: 0.7188, 
2023-03-08 11:01:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0050, Loss_2: 0.0049, Acc_1: 0.7525, Acc_2: 0.7408, F1-score_1: 0.6869, F1-score_2: 0.6829
2023-03-08 11:01:51 - __main__ - INFO - Epoch [5/100]
2023-03-08 11:01:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0036, Loss_2: 0.0039, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 11:02:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0068, Loss_2: 0.0056, Acc_1: 0.6562, Acc_2: 0.6875, 
2023-03-08 11:02:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0047, Loss_2: 0.0036, Acc_1: 0.7500, Acc_2: 0.7656, 
2023-03-08 11:02:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0050, Loss_2: 0.0045, Acc_1: 0.7188, Acc_2: 0.7500, 
2023-03-08 11:02:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0046, Loss_2: 0.0041, Acc_1: 0.7188, Acc_2: 0.7422, 
2023-03-08 11:02:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0051, Loss_2: 0.0055, Acc_1: 0.7109, Acc_2: 0.6641, 
2023-03-08 11:02:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0029, Loss_2: 0.0028, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-08 11:02:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0047, Loss_2: 0.0054, Acc_1: 0.7422, Acc_2: 0.7188, 
2023-03-08 11:02:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0052, Loss_2: 0.0061, Acc_1: 0.7344, Acc_2: 0.6641, 
2023-03-08 11:02:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0066, Loss_2: 0.0056, Acc_1: 0.6797, Acc_2: 0.7031, 
2023-03-08 11:03:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0052, Loss_2: 0.0044, Acc_1: 0.7031, Acc_2: 0.7578, 
2023-03-08 11:03:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0041, Loss_2: 0.0037, Acc_1: 0.7266, Acc_2: 0.7500, 
2023-03-08 11:03:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0037, Acc_1: 0.7599, Acc_2: 0.7602, F1-score_1: 0.6913, F1-score_2: 0.7071
2023-03-08 11:03:24 - __main__ - INFO - Epoch [6/100]
2023-03-08 11:03:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0032, Loss_2: 0.0031, Acc_1: 0.7656, Acc_2: 0.7500, 
2023-03-08 11:03:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0020, Loss_2: 0.0014, Acc_1: 0.7891, Acc_2: 0.8281, 
2023-03-08 11:03:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0030, Loss_2: 0.0024, Acc_1: 0.7578, Acc_2: 0.7734, 
2023-03-08 11:03:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0044, Loss_2: 0.0034, Acc_1: 0.6953, Acc_2: 0.7656, 
2023-03-08 11:03:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0027, Loss_2: 0.0024, Acc_1: 0.7734, Acc_2: 0.7891, 
2023-03-08 11:04:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0030, Loss_2: 0.0021, Acc_1: 0.7656, Acc_2: 0.8047, 
2023-03-08 11:04:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0022, Loss_2: 0.0024, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 11:04:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0027, Loss_2: 0.0031, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-08 11:04:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0041, Loss_2: 0.0036, Acc_1: 0.7422, Acc_2: 0.7500, 
2023-03-08 11:04:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0026, Loss_2: 0.0027, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 11:04:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0019, Loss_2: 0.0017, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 11:04:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0031, Loss_2: 0.0035, Acc_1: 0.7734, Acc_2: 0.7500, 
2023-03-08 11:04:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0029, Acc_1: 0.7668, Acc_2: 0.7860, F1-score_1: 0.6960, F1-score_2: 0.7277
2023-03-08 11:04:57 - __main__ - INFO - Epoch [7/100]
2023-03-08 11:05:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0013, Loss_2: 0.0011, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 11:05:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-08 11:05:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0014, Loss_2: 0.0011, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 11:05:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0027, Loss_2: 0.0022, Acc_1: 0.7656, Acc_2: 0.7969, 
2023-03-08 11:05:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0015, Loss_2: 0.0016, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 11:05:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0014, Loss_2: 0.0009, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 11:05:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0018, Loss_2: 0.0015, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 11:05:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0034, Loss_2: 0.0032, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-08 11:05:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:06:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0010, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 11:06:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 11:06:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0016, Loss_2: 0.0016, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 11:06:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0031, Acc_1: 0.7765, Acc_2: 0.7797, F1-score_1: 0.7114, F1-score_2: 0.7219
2023-03-08 11:06:30 - __main__ - INFO - Epoch [8/100]
2023-03-08 11:06:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 11:06:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:06:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:06:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 11:07:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 11:07:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 11:07:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0013, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 11:07:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8281, 
2023-03-08 11:07:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 11:07:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0013, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 11:07:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:07:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 11:08:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0017, Acc_1: 0.7648, Acc_2: 0.7750, F1-score_1: 0.7077, F1-score_2: 0.7180
2023-03-08 11:08:03 - __main__ - INFO - Epoch [9/100]
2023-03-08 11:08:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 11:08:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-08 11:08:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 11:08:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 11:08:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:08:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:08:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 11:08:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 11:09:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 11:09:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 11:09:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 11:09:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 11:09:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0013, Acc_1: 0.7755, Acc_2: 0.7869, F1-score_1: 0.7150, F1-score_2: 0.7237
2023-03-08 11:09:35 - __main__ - INFO - Epoch [10/100]
2023-03-08 11:09:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 11:09:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 11:09:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 11:10:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 11:10:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 11:10:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 11:10:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 11:10:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 11:10:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 11:10:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0010, Loss_2: 0.0017, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 11:10:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:10:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 11:11:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0011, Loss_2: 0.0010, Acc_1: 0.7857, Acc_2: 0.7852, F1-score_1: 0.7207, F1-score_2: 0.7203
2023-03-08 11:11:08 - __main__ - INFO - Epoch [11/100]
2023-03-08 11:11:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 11:11:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 11:11:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 11:11:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 11:11:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 11:11:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 11:11:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 11:12:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 11:12:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:12:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:12:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 11:12:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:12:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0012, Acc_1: 0.7872, Acc_2: 0.7879, F1-score_1: 0.7214, F1-score_2: 0.7277
2023-03-08 11:12:41 - __main__ - INFO - Epoch [12/100]
2023-03-08 11:12:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:12:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 11:13:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 11:13:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0026, Loss_2: 0.0022, Acc_1: 0.7422, Acc_2: 0.7422, 
2023-03-08 11:13:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0013, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 11:13:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 11:13:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 11:13:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:13:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 11:13:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 11:13:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:13:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:14:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0020, Acc_1: 0.7682, Acc_2: 0.7756, F1-score_1: 0.7055, F1-score_2: 0.7117
2023-03-08 11:14:14 - __main__ - INFO - Epoch [13/100]
2023-03-08 11:14:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:14:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 11:14:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:14:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0010, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 11:14:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 11:14:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 11:15:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:15:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 11:15:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:15:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 11:15:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 11:15:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 11:15:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0018, Acc_1: 0.7738, Acc_2: 0.7731, F1-score_1: 0.7088, F1-score_2: 0.7084
2023-03-08 11:15:47 - __main__ - INFO - Epoch [14/100]
2023-03-08 11:15:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-08 11:15:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 11:16:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 11:16:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 11:16:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:16:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 11:16:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-08 11:16:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 11:16:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 11:16:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0010, Loss_2: 0.0012, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 11:17:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:17:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 11:17:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0019, Acc_1: 0.7784, Acc_2: 0.7894, F1-score_1: 0.7087, F1-score_2: 0.7256
2023-03-08 11:17:20 - __main__ - INFO - Epoch [15/100]
2023-03-08 11:17:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 11:17:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:17:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 11:17:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 11:17:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:17:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 11:18:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 11:18:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:18:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 11:18:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:18:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 11:18:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 11:18:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0027, Acc_1: 0.7750, Acc_2: 0.7789, F1-score_1: 0.7093, F1-score_2: 0.7192
2023-03-08 11:18:53 - __main__ - INFO - Epoch [16/100]
2023-03-08 11:18:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:19:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:19:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 11:19:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 11:19:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 11:19:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 11:19:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:19:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 11:19:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 11:19:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 11:20:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 11:20:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:20:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0004, Loss_2: 0.0023, Acc_1: 0.7809, Acc_2: 0.7860, F1-score_1: 0.7154, F1-score_2: 0.7238
2023-03-08 11:20:26 - __main__ - INFO - Epoch [17/100]
2023-03-08 11:20:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 11:20:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:20:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 11:20:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 11:20:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:21:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:21:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 11:21:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 11:21:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0016, Loss_2: 0.0008, Acc_1: 0.7656, Acc_2: 0.7891, 
2023-03-08 11:21:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 11:21:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 11:21:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-08 11:21:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0020, Acc_1: 0.7843, Acc_2: 0.7994, F1-score_1: 0.7135, F1-score_2: 0.7361
2023-03-08 11:21:59 - __main__ - INFO - Epoch [18/100]
2023-03-08 11:22:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 11:22:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 11:22:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 11:22:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 11:22:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:22:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:22:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 11:22:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 11:22:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 11:23:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 11:23:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 11:23:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:23:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0012, Acc_1: 0.7792, Acc_2: 0.7799, F1-score_1: 0.7104, F1-score_2: 0.7140
2023-03-08 11:23:32 - __main__ - INFO - Epoch [19/100]
2023-03-08 11:23:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 11:23:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:23:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 11:23:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 11:24:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 11:24:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 11:24:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:24:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 11:24:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 11:24:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 11:24:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:24:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 11:25:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0012, Loss_2: 0.0007, Acc_1: 0.7758, Acc_2: 0.7860, F1-score_1: 0.7113, F1-score_2: 0.7216
2023-03-08 11:25:05 - __main__ - INFO - Epoch [20/100]
2023-03-08 11:25:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 11:25:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:25:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:25:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 11:25:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 11:25:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:25:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 11:25:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 11:26:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 11:26:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:26:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 11:26:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 11:26:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.7711, Acc_2: 0.7867, F1-score_1: 0.7057, F1-score_2: 0.7230
2023-03-08 11:26:38 - __main__ - INFO - Epoch [21/100]
2023-03-08 11:26:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 11:26:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 11:26:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 11:27:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 11:27:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:27:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 11:27:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 11:27:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 11:27:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 11:27:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 11:27:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 11:27:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 11:28:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0020, Acc_1: 0.7743, Acc_2: 0.7897, F1-score_1: 0.7043, F1-score_2: 0.7235
2023-03-08 11:28:11 - __main__ - INFO - Epoch [22/100]
2023-03-08 11:28:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:28:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 11:28:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 11:28:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 11:28:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 11:28:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:28:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 11:29:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 11:29:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 11:29:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:29:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 11:29:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 11:29:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0024, Acc_1: 0.7722, Acc_2: 0.7899, F1-score_1: 0.7036, F1-score_2: 0.7270
2023-03-08 11:29:44 - __main__ - INFO - Epoch [23/100]
2023-03-08 11:29:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0009, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 11:29:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 11:30:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:30:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 11:30:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:30:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:30:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 11:30:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 11:30:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 11:30:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 11:30:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:31:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 11:31:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0021, Acc_1: 0.7780, Acc_2: 0.7908, F1-score_1: 0.7074, F1-score_2: 0.7251
2023-03-08 11:31:17 - __main__ - INFO - Epoch [24/100]
2023-03-08 11:31:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:31:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 11:31:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 11:31:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 11:31:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 11:31:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 11:32:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 11:32:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 11:32:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 11:32:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0014, Loss_2: 0.0004, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-08 11:32:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 11:32:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:32:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0021, Acc_1: 0.7643, Acc_2: 0.7785, F1-score_1: 0.7007, F1-score_2: 0.7120
2023-03-08 11:32:50 - __main__ - INFO - Epoch [25/100]
2023-03-08 11:32:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 11:33:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:33:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 11:33:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 11:33:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:33:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 11:33:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 11:33:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:33:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 11:33:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:34:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:34:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:34:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0021, Acc_1: 0.7796, Acc_2: 0.7729, F1-score_1: 0.7130, F1-score_2: 0.7079
2023-03-08 11:34:23 - __main__ - INFO - Epoch [26/100]
2023-03-08 11:34:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 11:34:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 11:34:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 11:34:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 11:34:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:35:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 11:35:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-08 11:35:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 11:35:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 11:35:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:35:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 11:35:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:35:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0017, Acc_1: 0.7797, Acc_2: 0.7612, F1-score_1: 0.7181, F1-score_2: 0.7057
2023-03-08 11:35:56 - __main__ - INFO - Epoch [27/100]
2023-03-08 11:36:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 11:36:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 11:36:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 11:36:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8516, 
2023-03-08 11:36:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 11:36:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 11:36:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 11:36:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:36:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:37:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:37:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 11:37:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 11:37:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0008, Loss_2: 0.0018, Acc_1: 0.7728, Acc_2: 0.7819, F1-score_1: 0.7077, F1-score_2: 0.7180
2023-03-08 11:37:29 - __main__ - INFO - Epoch [28/100]
2023-03-08 11:37:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 11:37:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-08 11:37:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:37:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:38:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:38:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 11:38:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 11:38:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 11:38:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 11:38:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:38:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:38:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 11:39:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0011, Loss_2: 0.0014, Acc_1: 0.7739, Acc_2: 0.7852, F1-score_1: 0.7085, F1-score_2: 0.7189
2023-03-08 11:39:02 - __main__ - INFO - Epoch [29/100]
2023-03-08 11:39:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:39:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:39:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:39:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 11:39:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 11:39:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:39:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:39:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 11:40:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 11:40:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 11:40:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 11:40:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:40:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0007, Loss_2: 0.0020, Acc_1: 0.7835, Acc_2: 0.7891, F1-score_1: 0.7177, F1-score_2: 0.7224
2023-03-08 11:40:34 - __main__ - INFO - Epoch [30/100]
2023-03-08 11:40:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 11:40:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 11:40:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 11:41:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 11:41:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 11:41:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 11:41:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 11:41:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:41:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 11:41:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:41:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 11:41:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 11:42:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0018, Acc_1: 0.7660, Acc_2: 0.7838, F1-score_1: 0.7006, F1-score_2: 0.7188
2023-03-08 11:42:07 - __main__ - INFO - Epoch [31/100]
2023-03-08 11:42:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 11:42:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 11:42:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:42:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:42:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 11:42:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-08 11:42:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:43:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 11:43:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 11:43:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:43:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:43:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 11:43:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0020, Acc_1: 0.7615, Acc_2: 0.7649, F1-score_1: 0.6964, F1-score_2: 0.7015
2023-03-08 11:43:40 - __main__ - INFO - Epoch [32/100]
2023-03-08 11:43:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 11:43:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:43:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 11:44:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 11:44:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:44:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 11:44:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:44:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 11:44:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 11:44:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 11:44:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 11:44:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:45:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0026, Acc_1: 0.7602, Acc_2: 0.7852, F1-score_1: 0.6931, F1-score_2: 0.7208
2023-03-08 11:45:13 - __main__ - INFO - Epoch [33/100]
2023-03-08 11:45:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:45:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 11:45:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 11:45:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:45:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 11:45:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:45:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 11:46:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:46:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:46:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:46:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 11:46:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 11:46:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0037, Acc_1: 0.7707, Acc_2: 0.7921, F1-score_1: 0.7021, F1-score_2: 0.7191
2023-03-08 11:46:46 - __main__ - INFO - Epoch [34/100]
2023-03-08 11:46:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:46:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 11:47:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 11:47:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 11:47:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 11:47:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:47:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 11:47:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 11:47:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:47:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 11:47:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 11:48:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 11:48:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0028, Acc_1: 0.7762, Acc_2: 0.7724, F1-score_1: 0.7065, F1-score_2: 0.7124
2023-03-08 11:48:19 - __main__ - INFO - Epoch [35/100]
2023-03-08 11:48:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 11:48:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 11:48:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 11:48:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 11:48:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 11:48:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 11:49:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 11:49:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:49:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:49:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:49:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 11:49:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 11:49:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0038, Acc_1: 0.7787, Acc_2: 0.7896, F1-score_1: 0.7060, F1-score_2: 0.7252
2023-03-08 11:49:52 - __main__ - INFO - Epoch [36/100]
2023-03-08 11:49:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 11:50:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 11:50:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 11:50:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 11:50:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:50:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 11:50:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 11:50:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 11:50:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 11:50:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:51:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:51:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 11:51:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0025, Acc_1: 0.7753, Acc_2: 0.7899, F1-score_1: 0.7039, F1-score_2: 0.7265
2023-03-08 11:51:26 - __main__ - INFO - Epoch [37/100]
2023-03-08 11:51:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 11:51:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:51:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 11:51:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 11:51:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 11:52:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:52:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:52:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 11:52:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 11:52:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 11:52:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:52:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 11:52:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0022, Acc_1: 0.7729, Acc_2: 0.7770, F1-score_1: 0.7073, F1-score_2: 0.7117
2023-03-08 11:52:59 - __main__ - INFO - Epoch [38/100]
2023-03-08 11:53:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 11:53:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 11:53:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 11:53:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:53:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:53:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 11:53:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:53:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 11:53:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 11:54:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 11:54:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:54:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:54:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0040, Acc_1: 0.7697, Acc_2: 0.7756, F1-score_1: 0.7019, F1-score_2: 0.7112
2023-03-08 11:54:32 - __main__ - INFO - Epoch [39/100]
2023-03-08 11:54:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 11:54:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 11:54:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 11:54:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 11:55:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 11:55:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 11:55:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 11:55:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 11:55:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 11:55:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 11:55:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 11:55:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:56:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0030, Acc_1: 0.7605, Acc_2: 0.7709, F1-score_1: 0.6984, F1-score_2: 0.7079
2023-03-08 11:56:05 - __main__ - INFO - Epoch [40/100]
2023-03-08 11:56:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 11:56:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 11:56:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 11:56:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 11:56:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 11:56:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 11:56:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 11:56:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 11:57:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 11:57:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 11:57:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 11:57:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 11:57:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0031, Acc_1: 0.7700, Acc_2: 0.7777, F1-score_1: 0.7022, F1-score_2: 0.7179
2023-03-08 11:57:38 - __main__ - INFO - Epoch [41/100]
2023-03-08 11:57:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 11:57:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 11:57:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 11:58:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0011, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 11:58:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 11:58:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 11:58:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 11:58:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 11:58:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 11:58:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 11:58:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 11:58:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:59:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0022, Acc_1: 0.7733, Acc_2: 0.7835, F1-score_1: 0.7003, F1-score_2: 0.7188
2023-03-08 11:59:11 - __main__ - INFO - Epoch [42/100]
2023-03-08 11:59:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 11:59:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:59:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 11:59:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 11:59:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 11:59:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 11:59:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 12:00:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 12:00:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 12:00:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:00:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:00:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 12:00:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0026, Acc_1: 0.7739, Acc_2: 0.7756, F1-score_1: 0.7054, F1-score_2: 0.7128
2023-03-08 12:00:44 - __main__ - INFO - Epoch [43/100]
2023-03-08 12:00:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 12:00:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 12:01:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0011, Loss_2: 0.0025, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 12:01:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 12:01:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 12:01:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 12:01:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 12:01:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:01:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 12:01:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 12:01:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 12:02:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:02:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0034, Loss_2: 0.0032, Acc_1: 0.7741, Acc_2: 0.7780, F1-score_1: 0.7052, F1-score_2: 0.7124
2023-03-08 12:02:17 - __main__ - INFO - Epoch [44/100]
2023-03-08 12:02:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 12:02:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:02:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 12:02:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:02:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 12:02:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 12:03:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 12:03:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 12:03:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-08 12:03:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 12:03:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 12:03:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 12:03:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0038, Loss_2: 0.0042, Acc_1: 0.7977, Acc_2: 0.7694, F1-score_1: 0.7241, F1-score_2: 0.7079
2023-03-08 12:03:50 - __main__ - INFO - Epoch [45/100]
2023-03-08 12:03:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 12:04:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 12:04:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 12:04:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 12:04:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 12:04:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 12:04:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 12:04:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 12:04:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:04:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 12:05:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 12:05:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 12:05:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0029, Acc_1: 0.7711, Acc_2: 0.7823, F1-score_1: 0.7062, F1-score_2: 0.7145
2023-03-08 12:05:23 - __main__ - INFO - Epoch [46/100]
2023-03-08 12:05:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 12:05:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 12:05:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 12:05:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 12:05:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 12:06:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:06:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 12:06:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 12:06:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 12:06:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 12:06:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 12:06:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 12:06:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0040, Loss_2: 0.0030, Acc_1: 0.7716, Acc_2: 0.7787, F1-score_1: 0.7042, F1-score_2: 0.7155
2023-03-08 12:06:56 - __main__ - INFO - Epoch [47/100]
2023-03-08 12:07:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:07:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 12:07:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 12:07:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:07:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:07:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 12:07:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 12:07:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 12:07:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 12:08:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 12:08:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 12:08:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 12:08:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0038, Loss_2: 0.0018, Acc_1: 0.7724, Acc_2: 0.7884, F1-score_1: 0.7011, F1-score_2: 0.7237
2023-03-08 12:08:29 - __main__ - INFO - Epoch [48/100]
2023-03-08 12:08:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:08:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 12:08:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:08:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 12:09:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 12:09:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 12:09:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 12:09:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:09:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 12:09:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 12:09:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 12:09:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:10:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0048, Loss_2: 0.0026, Acc_1: 0.7639, Acc_2: 0.7779, F1-score_1: 0.7022, F1-score_2: 0.7140
2023-03-08 12:10:02 - __main__ - INFO - Epoch [49/100]
2023-03-08 12:10:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 12:10:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 12:10:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 12:10:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:10:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 12:10:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 12:10:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:10:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 12:11:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 12:11:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 12:11:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0010, Loss_2: 0.0010, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 12:11:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 12:11:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0029, Acc_1: 0.7734, Acc_2: 0.7831, F1-score_1: 0.7048, F1-score_2: 0.7185
2023-03-08 12:11:35 - __main__ - INFO - Epoch [50/100]
2023-03-08 12:11:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 12:11:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 12:11:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 12:12:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:12:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:12:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 12:12:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 12:12:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:12:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 12:12:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:12:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 12:12:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:13:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0025, Acc_1: 0.7660, Acc_2: 0.7897, F1-score_1: 0.6970, F1-score_2: 0.7219
2023-03-08 12:13:08 - __main__ - INFO - Epoch [51/100]
2023-03-08 12:13:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 12:13:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:13:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 12:13:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:13:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:13:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 12:13:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:14:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0012, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 12:14:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 12:14:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 12:14:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 12:14:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 12:14:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0054, Loss_2: 0.0034, Acc_1: 0.7626, Acc_2: 0.7901, F1-score_1: 0.6957, F1-score_2: 0.7159
2023-03-08 12:14:41 - __main__ - INFO - Epoch [52/100]
2023-03-08 12:14:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:14:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 12:15:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 12:15:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 12:15:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 12:15:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 12:15:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:15:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 12:15:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 12:15:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 12:15:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 12:15:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 12:16:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0039, Loss_2: 0.0019, Acc_1: 0.7660, Acc_2: 0.7838, F1-score_1: 0.7020, F1-score_2: 0.7150
2023-03-08 12:16:16 - __main__ - INFO - Epoch [53/100]
2023-03-08 12:16:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 12:16:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 12:16:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 12:16:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:16:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:16:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 12:17:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 12:17:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 12:17:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 12:17:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 12:17:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 12:17:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 12:17:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0025, Acc_1: 0.7802, Acc_2: 0.7865, F1-score_1: 0.7056, F1-score_2: 0.7204
2023-03-08 12:17:49 - __main__ - INFO - Epoch [54/100]
2023-03-08 12:17:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 12:18:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 12:18:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 12:18:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 12:18:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:18:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 12:18:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 12:18:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 12:18:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 12:18:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:19:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 12:19:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:19:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0040, Loss_2: 0.0016, Acc_1: 0.7673, Acc_2: 0.7887, F1-score_1: 0.7009, F1-score_2: 0.7249
2023-03-08 12:19:22 - __main__ - INFO - Epoch [55/100]
2023-03-08 12:19:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:19:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:19:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 12:19:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:19:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:20:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:20:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 12:20:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 12:20:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 12:20:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 12:20:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:20:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 12:20:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0028, Acc_1: 0.7763, Acc_2: 0.7899, F1-score_1: 0.7062, F1-score_2: 0.7211
2023-03-08 12:20:54 - __main__ - INFO - Epoch [56/100]
2023-03-08 12:21:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:21:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:21:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 12:21:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:21:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 12:21:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:21:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 12:21:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:21:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 12:22:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 12:22:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 12:22:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 12:22:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0026, Acc_1: 0.7653, Acc_2: 0.7846, F1-score_1: 0.6954, F1-score_2: 0.7191
2023-03-08 12:22:27 - __main__ - INFO - Epoch [57/100]
2023-03-08 12:22:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:22:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:22:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:22:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:22:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:23:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:23:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 12:23:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:23:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 12:23:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:23:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 12:23:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:24:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0024, Acc_1: 0.7716, Acc_2: 0.7833, F1-score_1: 0.7020, F1-score_2: 0.7189
2023-03-08 12:24:00 - __main__ - INFO - Epoch [58/100]
2023-03-08 12:24:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 12:24:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0009, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 12:24:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 12:24:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:24:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 12:24:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 12:24:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:24:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 12:24:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 12:25:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:25:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:25:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 12:25:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0025, Acc_1: 0.7656, Acc_2: 0.7901, F1-score_1: 0.7005, F1-score_2: 0.7257
2023-03-08 12:25:33 - __main__ - INFO - Epoch [59/100]
2023-03-08 12:25:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 12:25:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 12:25:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:25:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:26:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 12:26:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 12:26:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:26:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 12:26:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:26:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 12:26:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:26:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 12:27:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0017, Acc_1: 0.7666, Acc_2: 0.7821, F1-score_1: 0.7001, F1-score_2: 0.7190
2023-03-08 12:27:06 - __main__ - INFO - Epoch [60/100]
2023-03-08 12:27:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:27:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 12:27:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 12:27:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 12:27:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 12:27:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 12:27:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 12:27:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:28:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0014, Loss_2: 0.0016, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 12:28:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:28:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 12:28:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:28:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0017, Acc_1: 0.7651, Acc_2: 0.7792, F1-score_1: 0.6999, F1-score_2: 0.7133
2023-03-08 12:28:39 - __main__ - INFO - Epoch [61/100]
2023-03-08 12:28:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:28:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:28:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:29:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 12:29:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 12:29:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 12:29:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-08 12:29:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 12:29:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 12:29:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 12:29:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 12:29:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 12:30:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0027, Acc_1: 0.7682, Acc_2: 0.7782, F1-score_1: 0.6992, F1-score_2: 0.7140
2023-03-08 12:30:12 - __main__ - INFO - Epoch [62/100]
2023-03-08 12:30:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 12:30:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 12:30:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 12:30:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 12:30:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:30:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 12:30:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 12:31:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:31:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 12:31:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 12:31:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 12:31:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:31:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0027, Acc_1: 0.7736, Acc_2: 0.7858, F1-score_1: 0.7037, F1-score_2: 0.7202
2023-03-08 12:31:44 - __main__ - INFO - Epoch [63/100]
2023-03-08 12:31:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:31:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:32:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 12:32:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 12:32:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:32:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 12:32:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 12:32:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 12:32:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:32:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 12:32:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 12:33:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:33:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0025, Acc_1: 0.7765, Acc_2: 0.7908, F1-score_1: 0.7038, F1-score_2: 0.7266
2023-03-08 12:33:17 - __main__ - INFO - Epoch [64/100]
2023-03-08 12:33:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 12:33:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 12:33:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:33:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 12:33:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 12:33:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:34:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 12:34:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 12:34:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:34:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 12:34:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 12:34:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 12:34:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0023, Acc_1: 0.7738, Acc_2: 0.7855, F1-score_1: 0.7037, F1-score_2: 0.7179
2023-03-08 12:34:50 - __main__ - INFO - Epoch [65/100]
2023-03-08 12:34:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 12:35:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:35:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 12:35:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 12:35:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:35:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 12:35:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:35:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 12:35:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 12:35:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:36:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:36:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0015, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 12:36:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0037, Loss_2: 0.0038, Acc_1: 0.7634, Acc_2: 0.7668, F1-score_1: 0.6939, F1-score_2: 0.6999
2023-03-08 12:36:23 - __main__ - INFO - Epoch [66/100]
2023-03-08 12:36:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:36:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 12:36:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:36:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 12:36:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:37:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:37:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 12:37:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:37:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 12:37:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 12:37:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 12:37:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:37:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0040, Loss_2: 0.0041, Acc_1: 0.7643, Acc_2: 0.7845, F1-score_1: 0.6946, F1-score_2: 0.7133
2023-03-08 12:37:56 - __main__ - INFO - Epoch [67/100]
2023-03-08 12:38:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 12:38:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 12:38:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:38:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 12:38:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 12:38:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 12:38:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 12:38:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:38:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 12:39:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 12:39:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 12:39:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 12:39:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0039, Loss_2: 0.0040, Acc_1: 0.7755, Acc_2: 0.7831, F1-score_1: 0.7060, F1-score_2: 0.7154
2023-03-08 12:39:29 - __main__ - INFO - Epoch [68/100]
2023-03-08 12:39:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 12:39:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:39:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 12:39:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-08 12:40:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:40:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:40:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:40:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 12:40:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 12:40:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:40:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:40:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 12:41:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0044, Loss_2: 0.0037, Acc_1: 0.7578, Acc_2: 0.7756, F1-score_1: 0.6913, F1-score_2: 0.7102
2023-03-08 12:41:02 - __main__ - INFO - Epoch [69/100]
2023-03-08 12:41:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 12:41:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 12:41:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 12:41:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 12:41:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 12:41:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 12:41:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:41:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:42:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:42:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 12:42:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:42:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 12:42:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0036, Acc_1: 0.7660, Acc_2: 0.7824, F1-score_1: 0.6989, F1-score_2: 0.7152
2023-03-08 12:42:35 - __main__ - INFO - Epoch [70/100]
2023-03-08 12:42:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 12:42:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 12:42:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:43:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 12:43:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 12:43:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 12:43:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 12:43:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:43:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 12:43:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 12:43:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:43:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 12:44:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0034, Acc_1: 0.7680, Acc_2: 0.7877, F1-score_1: 0.6993, F1-score_2: 0.7200
2023-03-08 12:44:08 - __main__ - INFO - Epoch [71/100]
2023-03-08 12:44:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:44:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 12:44:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 12:44:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:44:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 12:44:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 12:44:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:45:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 12:45:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 12:45:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 12:45:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 12:45:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 12:45:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0023, Acc_1: 0.7677, Acc_2: 0.7802, F1-score_1: 0.6961, F1-score_2: 0.7159
2023-03-08 12:45:41 - __main__ - INFO - Epoch [72/100]
2023-03-08 12:45:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 12:45:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0009, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:45:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 12:46:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:46:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:46:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 12:46:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:46:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 12:46:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 12:46:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:46:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 12:46:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 12:47:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0023, Acc_1: 0.7554, Acc_2: 0.7874, F1-score_1: 0.6878, F1-score_2: 0.7213
2023-03-08 12:47:13 - __main__ - INFO - Epoch [73/100]
2023-03-08 12:47:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 12:47:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 12:47:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:47:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 12:47:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:47:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9219, 
2023-03-08 12:47:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 12:48:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 12:48:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:48:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 12:48:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:48:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 12:48:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0025, Acc_1: 0.7753, Acc_2: 0.7846, F1-score_1: 0.7108, F1-score_2: 0.7222
2023-03-08 12:48:46 - __main__ - INFO - Epoch [74/100]
2023-03-08 12:48:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 12:48:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:49:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 12:49:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 12:49:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 12:49:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 12:49:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 12:49:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 12:49:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 12:49:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 12:49:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:50:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 12:50:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0023, Acc_1: 0.7724, Acc_2: 0.7843, F1-score_1: 0.7065, F1-score_2: 0.7225
2023-03-08 12:50:19 - __main__ - INFO - Epoch [75/100]
2023-03-08 12:50:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 12:50:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 12:50:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:50:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 12:50:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 12:50:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:51:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:51:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 12:51:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:51:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:51:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:51:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:51:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0030, Acc_1: 0.7672, Acc_2: 0.7872, F1-score_1: 0.7023, F1-score_2: 0.7200
2023-03-08 12:51:52 - __main__ - INFO - Epoch [76/100]
2023-03-08 12:51:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 12:52:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 12:52:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:52:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 12:52:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 12:52:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:52:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 12:52:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 12:52:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 12:52:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 12:53:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 12:53:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 12:53:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0032, Acc_1: 0.7722, Acc_2: 0.7673, F1-score_1: 0.7076, F1-score_2: 0.7006
2023-03-08 12:53:25 - __main__ - INFO - Epoch [77/100]
2023-03-08 12:53:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.7734, 
2023-03-08 12:53:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 12:53:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:53:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 12:53:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 12:54:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:54:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:54:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 12:54:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 12:54:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 12:54:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:54:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:54:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0041, Loss_2: 0.0036, Acc_1: 0.7529, Acc_2: 0.7829, F1-score_1: 0.6872, F1-score_2: 0.7125
2023-03-08 12:54:58 - __main__ - INFO - Epoch [78/100]
2023-03-08 12:55:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 12:55:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:55:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 12:55:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:55:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 12:55:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:55:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:55:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 12:55:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 12:56:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 12:56:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 12:56:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 12:56:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0047, Loss_2: 0.0029, Acc_1: 0.7668, Acc_2: 0.7860, F1-score_1: 0.6978, F1-score_2: 0.7192
2023-03-08 12:56:31 - __main__ - INFO - Epoch [79/100]
2023-03-08 12:56:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:56:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:56:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:56:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 12:57:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 12:57:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:57:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 12:57:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 12:57:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 12:57:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 12:57:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 12:57:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 12:58:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0043, Loss_2: 0.0027, Acc_1: 0.7812, Acc_2: 0.7668, F1-score_1: 0.7153, F1-score_2: 0.7024
2023-03-08 12:58:04 - __main__ - INFO - Epoch [80/100]
2023-03-08 12:58:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 12:58:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:58:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 12:58:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 12:58:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:58:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:58:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 12:58:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 12:59:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 12:59:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 12:59:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 12:59:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 12:59:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0025, Acc_1: 0.7862, Acc_2: 0.7812, F1-score_1: 0.7203, F1-score_2: 0.7149
2023-03-08 12:59:37 - __main__ - INFO - Epoch [81/100]
2023-03-08 12:59:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 12:59:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 12:59:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 13:00:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:00:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 13:00:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:00:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 13:00:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:00:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 13:00:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 13:00:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 13:00:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 13:01:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0038, Loss_2: 0.0024, Acc_1: 0.7807, Acc_2: 0.7831, F1-score_1: 0.7163, F1-score_2: 0.7150
2023-03-08 13:01:09 - __main__ - INFO - Epoch [82/100]
2023-03-08 13:01:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 13:01:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 13:01:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 13:01:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:01:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 13:01:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 13:01:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 13:02:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 13:02:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 13:02:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:02:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 13:02:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 13:02:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0045, Loss_2: 0.0027, Acc_1: 0.7697, Acc_2: 0.7824, F1-score_1: 0.7060, F1-score_2: 0.7101
2023-03-08 13:02:42 - __main__ - INFO - Epoch [83/100]
2023-03-08 13:02:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 13:02:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 13:03:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:03:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:03:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 13:03:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 13:03:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 13:03:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 13:03:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:03:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:03:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 13:04:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 13:04:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0041, Loss_2: 0.0030, Acc_1: 0.7709, Acc_2: 0.7751, F1-score_1: 0.7051, F1-score_2: 0.7050
2023-03-08 13:04:15 - __main__ - INFO - Epoch [84/100]
2023-03-08 13:04:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 13:04:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 13:04:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 13:04:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:04:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 13:04:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 13:05:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 13:05:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:05:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 13:05:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 13:05:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 13:05:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 13:05:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0042, Loss_2: 0.0025, Acc_1: 0.7629, Acc_2: 0.7804, F1-score_1: 0.6949, F1-score_2: 0.7129
2023-03-08 13:05:48 - __main__ - INFO - Epoch [85/100]
2023-03-08 13:05:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 13:06:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 13:06:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 13:06:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 13:06:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 13:06:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 13:06:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 13:06:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 13:06:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 13:06:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 13:07:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 13:07:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 13:07:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0046, Loss_2: 0.0026, Acc_1: 0.7677, Acc_2: 0.7733, F1-score_1: 0.7000, F1-score_2: 0.7087
2023-03-08 13:07:21 - __main__ - INFO - Epoch [86/100]
2023-03-08 13:07:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 13:07:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:07:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 13:07:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 13:07:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 13:08:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:08:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 13:08:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 13:08:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 13:08:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 13:08:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 13:08:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 13:08:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0025, Acc_1: 0.7751, Acc_2: 0.7724, F1-score_1: 0.7066, F1-score_2: 0.7059
2023-03-08 13:08:54 - __main__ - INFO - Epoch [87/100]
2023-03-08 13:08:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 13:09:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:09:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 13:09:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 13:09:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:09:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:09:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:09:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:09:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 13:09:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 13:10:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 13:10:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 13:10:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0040, Loss_2: 0.0034, Acc_1: 0.7707, Acc_2: 0.7699, F1-score_1: 0.7013, F1-score_2: 0.7010
2023-03-08 13:10:26 - __main__ - INFO - Epoch [88/100]
2023-03-08 13:10:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 13:10:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 13:10:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 13:10:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 13:10:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:11:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 13:11:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 13:11:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:11:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:11:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 13:11:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 13:11:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 13:11:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0032, Acc_1: 0.7738, Acc_2: 0.7689, F1-score_1: 0.7045, F1-score_2: 0.7019
2023-03-08 13:11:59 - __main__ - INFO - Epoch [89/100]
2023-03-08 13:12:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 13:12:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:12:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 13:12:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 13:12:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 13:12:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:12:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:12:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:12:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 13:13:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 13:13:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 13:13:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 13:13:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0027, Acc_1: 0.7755, Acc_2: 0.7706, F1-score_1: 0.7057, F1-score_2: 0.7025
2023-03-08 13:13:32 - __main__ - INFO - Epoch [90/100]
2023-03-08 13:13:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:13:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 13:13:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 13:13:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 13:14:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 13:14:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 13:14:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 13:14:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:14:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 13:14:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 13:14:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 13:14:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 13:15:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0024, Acc_1: 0.7743, Acc_2: 0.7772, F1-score_1: 0.7056, F1-score_2: 0.7070
2023-03-08 13:15:05 - __main__ - INFO - Epoch [91/100]
2023-03-08 13:15:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 13:15:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 13:15:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:15:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 13:15:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 13:15:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:15:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:15:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0018, Loss_2: 0.0018, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 13:16:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 13:16:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 13:16:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 13:16:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:16:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0036, Loss_2: 0.0036, Acc_1: 0.7699, Acc_2: 0.7646, F1-score_1: 0.7028, F1-score_2: 0.6992
2023-03-08 13:16:38 - __main__ - INFO - Epoch [92/100]
2023-03-08 13:16:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 13:16:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:16:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:17:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 13:17:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 13:17:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 13:17:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 13:17:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:17:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 13:17:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 13:17:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 13:17:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 13:18:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0038, Loss_2: 0.0037, Acc_1: 0.7665, Acc_2: 0.7638, F1-score_1: 0.7010, F1-score_2: 0.6983
2023-03-08 13:18:11 - __main__ - INFO - Epoch [93/100]
2023-03-08 13:18:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 13:18:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 13:18:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 13:18:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 13:18:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 13:18:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 13:18:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 13:19:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 13:19:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:19:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:19:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 13:19:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 13:19:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0037, Loss_2: 0.0037, Acc_1: 0.7646, Acc_2: 0.7643, F1-score_1: 0.7010, F1-score_2: 0.6984
2023-03-08 13:19:44 - __main__ - INFO - Epoch [94/100]
2023-03-08 13:19:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 13:19:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 13:20:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 13:20:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:20:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 13:20:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 13:20:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 13:20:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 13:20:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 13:20:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 13:20:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:21:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 13:21:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0032, Acc_1: 0.7685, Acc_2: 0.7636, F1-score_1: 0.7020, F1-score_2: 0.6975
2023-03-08 13:21:17 - __main__ - INFO - Epoch [95/100]
2023-03-08 13:21:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 13:21:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 13:21:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 13:21:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 13:21:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:21:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 13:22:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 13:22:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 13:22:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 13:22:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 13:22:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 13:22:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 13:22:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0034, Loss_2: 0.0033, Acc_1: 0.7648, Acc_2: 0.7678, F1-score_1: 0.6990, F1-score_2: 0.7022
2023-03-08 13:22:50 - __main__ - INFO - Epoch [96/100]
2023-03-08 13:22:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:23:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 13:23:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 13:23:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 13:23:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 13:23:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 13:23:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 13:23:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 13:23:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 13:23:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 13:24:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:24:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:24:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0029, Acc_1: 0.7653, Acc_2: 0.7682, F1-score_1: 0.7007, F1-score_2: 0.7023
2023-03-08 13:24:23 - __main__ - INFO - Epoch [97/100]
2023-03-08 13:24:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:24:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 13:24:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 13:24:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 13:24:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 13:25:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 13:25:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 13:25:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 13:25:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:25:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 13:25:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 13:25:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 13:25:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0027, Acc_1: 0.7672, Acc_2: 0.7700, F1-score_1: 0.7023, F1-score_2: 0.7037
2023-03-08 13:25:56 - __main__ - INFO - Epoch [98/100]
2023-03-08 13:26:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:26:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 13:26:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 13:26:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:26:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 13:26:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 13:26:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 13:26:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 13:26:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:27:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 13:27:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 13:27:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:27:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0027, Acc_1: 0.7683, Acc_2: 0.7712, F1-score_1: 0.7031, F1-score_2: 0.7049
2023-03-08 13:27:28 - __main__ - INFO - Epoch [99/100]
2023-03-08 13:27:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 13:27:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 13:27:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 13:27:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 13:28:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 13:28:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:28:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 13:28:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 13:28:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 13:28:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:28:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 13:28:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 13:29:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0028, Acc_1: 0.7672, Acc_2: 0.7665, F1-score_1: 0.7021, F1-score_2: 0.6998
2023-03-08 13:29:03 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 13:29:04 - utils._noise - DEBUG - 6, 7
2023-03-08 13:29:04 - utils._noise - DEBUG - 13997
2023-03-08 13:29:04 - utils._noise - INFO - Actual noise 0.20
2023-03-08 13:29:04 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-08 13:29:04 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-08 13:29:06 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 13:29:06 - __main__ - INFO - Loading dataset...
2023-03-08 13:29:06 - __main__ - INFO - Building model...
2023-03-08 13:29:06 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-08 13:29:06 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-08 13:29:06 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-08 13:29:06 - __main__ - INFO - Start train & evaluate
2023-03-08 13:29:06 - __main__ - INFO - Epoch [0/100]
2023-03-08 13:29:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0153, Loss_2: 0.0152, Acc_1: 0.1094, Acc_2: 0.0703, 
2023-03-08 13:29:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0150, Loss_2: 0.0150, Acc_1: 0.1719, Acc_2: 0.1797, 
2023-03-08 13:29:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0140, Loss_2: 0.0140, Acc_1: 0.3203, Acc_2: 0.3203, 
2023-03-08 13:29:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0132, Loss_2: 0.0135, Acc_1: 0.3828, Acc_2: 0.3203, 
2023-03-08 13:29:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0137, Loss_2: 0.0138, Acc_1: 0.3516, Acc_2: 0.2891, 
2023-03-08 13:29:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0135, Loss_2: 0.0134, Acc_1: 0.2891, Acc_2: 0.2969, 
2023-03-08 13:29:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0129, Loss_2: 0.0132, Acc_1: 0.4453, Acc_2: 0.3750, 
2023-03-08 13:29:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0135, Loss_2: 0.0129, Acc_1: 0.3438, Acc_2: 0.3281, 
2023-03-08 13:30:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0127, Loss_2: 0.0137, Acc_1: 0.3828, Acc_2: 0.3125, 
2023-03-08 13:30:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0118, Loss_2: 0.0123, Acc_1: 0.4375, Acc_2: 0.4062, 
2023-03-08 13:30:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0131, Loss_2: 0.0133, Acc_1: 0.3594, Acc_2: 0.3594, 
2023-03-08 13:30:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0115, Loss_2: 0.0130, Acc_1: 0.4922, Acc_2: 0.3594, 
2023-03-08 13:30:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0107, Loss_2: 0.0115, Acc_1: 0.5681, Acc_2: 0.4862, F1-score_1: 0.3387, F1-score_2: 0.2748
2023-03-08 13:30:39 - __main__ - INFO - Epoch [1/100]
2023-03-08 13:30:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0125, Loss_2: 0.0127, Acc_1: 0.3828, Acc_2: 0.3906, 
2023-03-08 13:30:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0114, Loss_2: 0.0125, Acc_1: 0.4922, Acc_2: 0.4062, 
2023-03-08 13:30:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0122, Loss_2: 0.0124, Acc_1: 0.4297, Acc_2: 0.4141, 
2023-03-08 13:31:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0110, Loss_2: 0.0123, Acc_1: 0.5625, Acc_2: 0.4375, 
2023-03-08 13:31:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0113, Loss_2: 0.0116, Acc_1: 0.4609, Acc_2: 0.4297, 
2023-03-08 13:31:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0107, Loss_2: 0.0105, Acc_1: 0.5234, Acc_2: 0.5391, 
2023-03-08 13:31:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0105, Loss_2: 0.0116, Acc_1: 0.5312, Acc_2: 0.4688, 
2023-03-08 13:31:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0112, Loss_2: 0.0117, Acc_1: 0.5078, Acc_2: 0.4766, 
2023-03-08 13:31:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0181, Loss_2: 0.0102, Acc_1: 0.3125, Acc_2: 0.5703, 
2023-03-08 13:31:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0141, Loss_2: 0.0109, Acc_1: 0.2656, Acc_2: 0.5469, 
2023-03-08 13:31:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0143, Loss_2: 0.0113, Acc_1: 0.2109, Acc_2: 0.5156, 
2023-03-08 13:31:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0142, Loss_2: 0.0113, Acc_1: 0.3125, Acc_2: 0.5156, 
2023-03-08 13:32:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0124, Loss_2: 0.0082, Acc_1: 0.4061, Acc_2: 0.6508, F1-score_1: 0.2902, F1-score_2: 0.4858
2023-03-08 13:32:11 - __main__ - INFO - Epoch [2/100]
2023-03-08 13:32:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0132, Loss_2: 0.0088, Acc_1: 0.3828, Acc_2: 0.5859, 
2023-03-08 13:32:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0122, Loss_2: 0.0091, Acc_1: 0.4609, Acc_2: 0.6484, 
2023-03-08 13:32:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0127, Loss_2: 0.0102, Acc_1: 0.4062, Acc_2: 0.5547, 
2023-03-08 13:32:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0112, Loss_2: 0.0095, Acc_1: 0.4688, Acc_2: 0.6250, 
2023-03-08 13:32:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0122, Loss_2: 0.0116, Acc_1: 0.4375, Acc_2: 0.4766, 
2023-03-08 13:32:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0158, Loss_2: 0.0090, Acc_1: 0.3047, Acc_2: 0.6562, 
2023-03-08 13:32:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0129, Loss_2: 0.0100, Acc_1: 0.4062, Acc_2: 0.5312, 
2023-03-08 13:33:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0134, Loss_2: 0.0107, Acc_1: 0.3438, Acc_2: 0.5938, 
2023-03-08 13:33:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0145, Loss_2: 0.0100, Acc_1: 0.2734, Acc_2: 0.5859, 
2023-03-08 13:33:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0126, Loss_2: 0.0076, Acc_1: 0.3828, Acc_2: 0.7109, 
2023-03-08 13:33:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0131, Loss_2: 0.0092, Acc_1: 0.3984, Acc_2: 0.6172, 
2023-03-08 13:33:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0117, Loss_2: 0.0075, Acc_1: 0.4453, Acc_2: 0.6797, 
2023-03-08 13:33:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0108, Loss_2: 0.0062, Acc_1: 0.4966, Acc_2: 0.7490, F1-score_1: 0.4253, F1-score_2: 0.6477
2023-03-08 13:33:44 - __main__ - INFO - Epoch [3/100]
2023-03-08 13:33:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0132, Loss_2: 0.0089, Acc_1: 0.3906, Acc_2: 0.6250, 
2023-03-08 13:33:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0113, Loss_2: 0.0077, Acc_1: 0.4922, Acc_2: 0.6406, 
2023-03-08 13:34:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0103, Loss_2: 0.0081, Acc_1: 0.4688, Acc_2: 0.6641, 
2023-03-08 13:34:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0118, Loss_2: 0.0088, Acc_1: 0.4609, Acc_2: 0.6484, 
2023-03-08 13:34:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0120, Loss_2: 0.0081, Acc_1: 0.4766, Acc_2: 0.6484, 
2023-03-08 13:34:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0109, Loss_2: 0.0064, Acc_1: 0.4844, Acc_2: 0.7031, 
2023-03-08 13:34:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0108, Loss_2: 0.0078, Acc_1: 0.5000, Acc_2: 0.6484, 
2023-03-08 13:34:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0123, Loss_2: 0.0100, Acc_1: 0.4062, Acc_2: 0.6172, 
2023-03-08 13:34:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0111, Loss_2: 0.0082, Acc_1: 0.4922, Acc_2: 0.6719, 
2023-03-08 13:34:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0097, Loss_2: 0.0077, Acc_1: 0.5391, Acc_2: 0.6484, 
2023-03-08 13:34:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0091, Loss_2: 0.0074, Acc_1: 0.5469, Acc_2: 0.6562, 
2023-03-08 13:35:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0108, Loss_2: 0.0098, Acc_1: 0.5391, Acc_2: 0.5703, 
2023-03-08 13:35:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0086, Loss_2: 0.0079, Acc_1: 0.6411, Acc_2: 0.6649, F1-score_1: 0.5323, F1-score_2: 0.6106
2023-03-08 13:35:18 - __main__ - INFO - Epoch [4/100]
2023-03-08 13:35:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0073, Loss_2: 0.0081, Acc_1: 0.6562, Acc_2: 0.6406, 
2023-03-08 13:35:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0079, Loss_2: 0.0072, Acc_1: 0.6250, Acc_2: 0.6719, 
2023-03-08 13:35:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0083, Loss_2: 0.0066, Acc_1: 0.5938, Acc_2: 0.6719, 
2023-03-08 13:35:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0071, Loss_2: 0.0061, Acc_1: 0.6719, Acc_2: 0.7031, 
2023-03-08 13:35:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0064, Loss_2: 0.0050, Acc_1: 0.6641, Acc_2: 0.7344, 
2023-03-08 13:35:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0072, Loss_2: 0.0056, Acc_1: 0.6797, Acc_2: 0.7188, 
2023-03-08 13:36:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0073, Loss_2: 0.0057, Acc_1: 0.6562, Acc_2: 0.6953, 
2023-03-08 13:36:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0070, Loss_2: 0.0051, Acc_1: 0.6641, Acc_2: 0.7656, 
2023-03-08 13:36:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0070, Loss_2: 0.0048, Acc_1: 0.6719, Acc_2: 0.7266, 
2023-03-08 13:36:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0059, Loss_2: 0.0042, Acc_1: 0.7109, Acc_2: 0.7656, 
2023-03-08 13:36:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0059, Loss_2: 0.0048, Acc_1: 0.7422, Acc_2: 0.7500, 
2023-03-08 13:36:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0075, Loss_2: 0.0054, Acc_1: 0.6172, Acc_2: 0.7578, 
2023-03-08 13:36:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0055, Loss_2: 0.0047, Acc_1: 0.7379, Acc_2: 0.7712, F1-score_1: 0.6335, F1-score_2: 0.6954
2023-03-08 13:36:50 - __main__ - INFO - Epoch [5/100]
2023-03-08 13:36:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0064, Loss_2: 0.0046, Acc_1: 0.6875, Acc_2: 0.7266, 
2023-03-08 13:37:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0069, Loss_2: 0.0055, Acc_1: 0.6797, Acc_2: 0.7109, 
2023-03-08 13:37:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0053, Loss_2: 0.0035, Acc_1: 0.6719, Acc_2: 0.7578, 
2023-03-08 13:37:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0053, Loss_2: 0.0040, Acc_1: 0.6953, Acc_2: 0.7656, 
2023-03-08 13:37:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0075, Loss_2: 0.0066, Acc_1: 0.6172, Acc_2: 0.7031, 
2023-03-08 13:37:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0041, Loss_2: 0.0030, Acc_1: 0.7422, Acc_2: 0.7969, 
2023-03-08 13:37:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0047, Loss_2: 0.0046, Acc_1: 0.7266, Acc_2: 0.7188, 
2023-03-08 13:37:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0050, Loss_2: 0.0034, Acc_1: 0.6797, Acc_2: 0.7812, 
2023-03-08 13:37:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0059, Loss_2: 0.0042, Acc_1: 0.6953, Acc_2: 0.7656, 
2023-03-08 13:37:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0270, Loss_2: 0.0083, Acc_1: 0.2344, Acc_2: 0.7266, 
2023-03-08 13:38:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0158, Loss_2: 0.0066, Acc_1: 0.1875, Acc_2: 0.7344, 
2023-03-08 13:38:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0149, Loss_2: 0.0058, Acc_1: 0.1875, Acc_2: 0.7578, 
2023-03-08 13:38:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0164, Loss_2: 0.0044, Acc_1: 0.2678, Acc_2: 0.7806, F1-score_1: 0.0992, F1-score_2: 0.7011
2023-03-08 13:38:23 - __main__ - INFO - Epoch [6/100]
2023-03-08 13:38:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0167, Loss_2: 0.0063, Acc_1: 0.2422, Acc_2: 0.8125, 
2023-03-08 13:38:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0133, Loss_2: 0.0041, Acc_1: 0.4062, Acc_2: 0.8281, 
2023-03-08 13:38:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0103, Loss_2: 0.0043, Acc_1: 0.5859, Acc_2: 0.7422, 
2023-03-08 13:38:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0106, Loss_2: 0.0044, Acc_1: 0.5391, Acc_2: 0.7969, 
2023-03-08 13:38:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0084, Loss_2: 0.0043, Acc_1: 0.5703, Acc_2: 0.7422, 
2023-03-08 13:39:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0082, Loss_2: 0.0026, Acc_1: 0.6250, Acc_2: 0.8203, 
2023-03-08 13:39:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0108, Loss_2: 0.0062, Acc_1: 0.4844, Acc_2: 0.6641, 
2023-03-08 13:39:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0081, Loss_2: 0.0036, Acc_1: 0.6406, Acc_2: 0.7812, 
2023-03-08 13:39:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0081, Loss_2: 0.0045, Acc_1: 0.5703, Acc_2: 0.7266, 
2023-03-08 13:39:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0071, Loss_2: 0.0046, Acc_1: 0.6562, Acc_2: 0.7344, 
2023-03-08 13:39:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0064, Loss_2: 0.0039, Acc_1: 0.6953, Acc_2: 0.7812, 
2023-03-08 13:39:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0053, Loss_2: 0.0031, Acc_1: 0.7109, Acc_2: 0.7812, 
2023-03-08 13:39:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0051, Loss_2: 0.0039, Acc_1: 0.7352, Acc_2: 0.7751, F1-score_1: 0.6548, F1-score_2: 0.7047
2023-03-08 13:39:56 - __main__ - INFO - Epoch [7/100]
2023-03-08 13:40:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0059, Loss_2: 0.0030, Acc_1: 0.6641, Acc_2: 0.7656, 
2023-03-08 13:40:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0045, Loss_2: 0.0018, Acc_1: 0.7266, Acc_2: 0.8047, 
2023-03-08 13:40:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0040, Loss_2: 0.0017, Acc_1: 0.7344, Acc_2: 0.8203, 
2023-03-08 13:40:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0033, Loss_2: 0.0018, Acc_1: 0.7656, Acc_2: 0.8125, 
2023-03-08 13:40:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0036, Loss_2: 0.0016, Acc_1: 0.7422, Acc_2: 0.8359, 
2023-03-08 13:40:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0061, Loss_2: 0.0032, Acc_1: 0.6484, Acc_2: 0.7344, 
2023-03-08 13:40:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0049, Loss_2: 0.0027, Acc_1: 0.6875, Acc_2: 0.7812, 
2023-03-08 13:40:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0032, Loss_2: 0.0016, Acc_1: 0.7656, Acc_2: 0.8203, 
2023-03-08 13:40:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0033, Loss_2: 0.0016, Acc_1: 0.7422, Acc_2: 0.8281, 
2023-03-08 13:41:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0031, Loss_2: 0.0012, Acc_1: 0.7891, Acc_2: 0.8516, 
2023-03-08 13:41:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0044, Loss_2: 0.0014, Acc_1: 0.7188, Acc_2: 0.8047, 
2023-03-08 13:41:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0047, Loss_2: 0.0020, Acc_1: 0.6953, Acc_2: 0.8125, 
2023-03-08 13:41:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0036, Loss_2: 0.0027, Acc_1: 0.7451, Acc_2: 0.7580, F1-score_1: 0.6845, F1-score_2: 0.6970
2023-03-08 13:41:29 - __main__ - INFO - Epoch [8/100]
2023-03-08 13:41:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0026, Loss_2: 0.0012, Acc_1: 0.7969, Acc_2: 0.8359, 
2023-03-08 13:41:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0023, Loss_2: 0.0012, Acc_1: 0.7578, Acc_2: 0.8047, 
2023-03-08 13:41:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0026, Loss_2: 0.0006, Acc_1: 0.7578, Acc_2: 0.8281, 
2023-03-08 13:41:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0020, Loss_2: 0.0010, Acc_1: 0.7812, Acc_2: 0.8125, 
2023-03-08 13:42:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0024, Loss_2: 0.0014, Acc_1: 0.7422, Acc_2: 0.8203, 
2023-03-08 13:42:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0015, Loss_2: 0.0012, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 13:42:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0013, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8828, 
2023-03-08 13:42:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0022, Loss_2: 0.0009, Acc_1: 0.7734, Acc_2: 0.8281, 
2023-03-08 13:42:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0028, Loss_2: 0.0017, Acc_1: 0.7656, Acc_2: 0.7891, 
2023-03-08 13:42:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0016, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.8438, 
2023-03-08 13:42:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0020, Loss_2: 0.0007, Acc_1: 0.7578, Acc_2: 0.8125, 
2023-03-08 13:42:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0018, Loss_2: 0.0006, Acc_1: 0.7500, Acc_2: 0.8047, 
2023-03-08 13:43:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0027, Acc_1: 0.7634, Acc_2: 0.7994, F1-score_1: 0.7043, F1-score_2: 0.7280
2023-03-08 13:43:01 - __main__ - INFO - Epoch [9/100]
2023-03-08 13:43:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0021, Loss_2: 0.0004, Acc_1: 0.7578, Acc_2: 0.8203, 
2023-03-08 13:43:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0015, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8672, 
2023-03-08 13:43:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0009, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 13:43:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0014, Loss_2: 0.0006, Acc_1: 0.7656, Acc_2: 0.8047, 
2023-03-08 13:43:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:43:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0039, Loss_2: 0.0024, Acc_1: 0.7344, Acc_2: 0.7500, 
2023-03-08 13:43:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8516, 
2023-03-08 13:43:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8594, 
2023-03-08 13:44:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 13:44:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 13:44:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0013, Loss_2: 0.0011, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-08 13:44:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0027, Loss_2: 0.0010, Acc_1: 0.7266, Acc_2: 0.7891, 
2023-03-08 13:44:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0023, Acc_1: 0.7756, Acc_2: 0.7763, F1-score_1: 0.7059, F1-score_2: 0.7078
2023-03-08 13:44:34 - __main__ - INFO - Epoch [10/100]
2023-03-08 13:44:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0022, Loss_2: 0.0010, Acc_1: 0.7422, Acc_2: 0.8047, 
2023-03-08 13:44:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-08 13:44:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0026, Loss_2: 0.0009, Acc_1: 0.7500, Acc_2: 0.7812, 
2023-03-08 13:45:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 13:45:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0007, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-08 13:45:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-08 13:45:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.8281, 
2023-03-08 13:45:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 13:45:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0015, Loss_2: 0.0005, Acc_1: 0.7500, Acc_2: 0.8125, 
2023-03-08 13:45:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 13:45:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 13:45:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0005, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-08 13:46:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0034, Acc_1: 0.7903, Acc_2: 0.7843, F1-score_1: 0.7274, F1-score_2: 0.7178
2023-03-08 13:46:07 - __main__ - INFO - Epoch [11/100]
2023-03-08 13:46:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0013, Loss_2: 0.0006, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-08 13:46:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-08 13:46:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 13:46:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 13:46:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.7812, Acc_2: 0.8047, 
2023-03-08 13:46:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0014, Loss_2: 0.0007, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 13:46:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8281, 
2023-03-08 13:47:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 13:47:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 13:47:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 13:47:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 13:47:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:47:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0035, Acc_1: 0.7930, Acc_2: 0.7801, F1-score_1: 0.7294, F1-score_2: 0.7173
2023-03-08 13:47:40 - __main__ - INFO - Epoch [12/100]
2023-03-08 13:47:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-08 13:47:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 13:47:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 13:48:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 13:48:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 13:48:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 13:48:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 13:48:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 13:48:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 13:48:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8438, 
2023-03-08 13:48:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 13:48:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:49:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0009, Loss_2: 0.0032, Acc_1: 0.7979, Acc_2: 0.7952, F1-score_1: 0.7277, F1-score_2: 0.7242
2023-03-08 13:49:13 - __main__ - INFO - Epoch [13/100]
2023-03-08 13:49:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 13:49:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0006, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 13:49:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 13:49:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:49:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:49:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 13:49:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 13:50:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0015, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 13:50:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0017, Loss_2: 0.0015, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 13:50:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0007, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 13:50:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8828, 
2023-03-08 13:50:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.9141, 
2023-03-08 13:50:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0025, Acc_1: 0.7894, Acc_2: 0.7874, F1-score_1: 0.7151, F1-score_2: 0.7157
2023-03-08 13:50:46 - __main__ - INFO - Epoch [14/100]
2023-03-08 13:50:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0011, Loss_2: 0.0006, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 13:50:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 13:51:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 13:51:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 13:51:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:51:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 13:51:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 13:51:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 13:51:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 13:51:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 13:51:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-08 13:52:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 13:52:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0033, Acc_1: 0.7914, Acc_2: 0.7804, F1-score_1: 0.7286, F1-score_2: 0.7109
2023-03-08 13:52:19 - __main__ - INFO - Epoch [15/100]
2023-03-08 13:52:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 13:52:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0008, Acc_1: 0.7734, Acc_2: 0.7891, 
2023-03-08 13:52:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:52:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 13:52:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:52:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 13:53:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 13:53:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 13:53:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 13:53:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:53:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:53:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 13:53:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0016, Acc_1: 0.7911, Acc_2: 0.7889, F1-score_1: 0.7249, F1-score_2: 0.7186
2023-03-08 13:53:52 - __main__ - INFO - Epoch [16/100]
2023-03-08 13:53:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 13:54:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 13:54:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 13:54:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0010, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 13:54:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 13:54:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 13:54:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 13:54:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 13:54:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 13:54:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 13:55:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 13:55:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 13:55:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0025, Acc_1: 0.7926, Acc_2: 0.7743, F1-score_1: 0.7267, F1-score_2: 0.7073
2023-03-08 13:55:25 - __main__ - INFO - Epoch [17/100]
2023-03-08 13:55:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 13:55:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 13:55:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 13:55:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 13:55:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:56:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 13:56:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 13:56:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:56:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 13:56:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 13:56:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 13:56:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 13:56:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0019, Acc_1: 0.7908, Acc_2: 0.7840, F1-score_1: 0.7193, F1-score_2: 0.7146
2023-03-08 13:56:58 - __main__ - INFO - Epoch [18/100]
2023-03-08 13:57:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 13:57:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 13:57:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0016, Loss_2: 0.0019, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-08 13:57:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 13:57:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:57:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 13:57:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 13:57:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 13:57:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0017, Loss_2: 0.0017, Acc_1: 0.7578, Acc_2: 0.7422, 
2023-03-08 13:58:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 13:58:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 13:58:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 13:58:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0030, Acc_1: 0.7947, Acc_2: 0.7955, F1-score_1: 0.7284, F1-score_2: 0.7261
2023-03-08 13:58:31 - __main__ - INFO - Epoch [19/100]
2023-03-08 13:58:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 13:58:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 13:58:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 13:58:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 13:59:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 13:59:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 13:59:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 13:59:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 13:59:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 13:59:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 13:59:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 13:59:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 14:00:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0020, Acc_1: 0.7821, Acc_2: 0.7801, F1-score_1: 0.7161, F1-score_2: 0.7172
2023-03-08 14:00:04 - __main__ - INFO - Epoch [20/100]
2023-03-08 14:00:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:00:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 14:00:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:00:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 14:00:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 14:00:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0017, Loss_2: 0.0010, Acc_1: 0.7578, Acc_2: 0.7812, 
2023-03-08 14:00:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:00:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:01:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 14:01:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 14:01:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 14:01:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 14:01:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0025, Acc_1: 0.7914, Acc_2: 0.7913, F1-score_1: 0.7245, F1-score_2: 0.7214
2023-03-08 14:01:37 - __main__ - INFO - Epoch [21/100]
2023-03-08 14:01:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 14:01:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 14:01:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 14:02:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 14:02:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 14:02:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 14:02:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 14:02:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:02:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 14:02:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:02:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:02:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0026, Loss_2: 0.0018, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-08 14:03:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0025, Acc_1: 0.7943, Acc_2: 0.7901, F1-score_1: 0.7282, F1-score_2: 0.7175
2023-03-08 14:03:10 - __main__ - INFO - Epoch [22/100]
2023-03-08 14:03:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 14:03:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8672, 
2023-03-08 14:03:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 14:03:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:03:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 14:03:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 14:03:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 14:04:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:04:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 14:04:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 14:04:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 14:04:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 14:04:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0019, Acc_1: 0.7721, Acc_2: 0.7874, F1-score_1: 0.7105, F1-score_2: 0.7169
2023-03-08 14:04:43 - __main__ - INFO - Epoch [23/100]
2023-03-08 14:04:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 14:04:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:05:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 14:05:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:05:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 14:05:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:05:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 14:05:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:05:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:05:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 14:05:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:06:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:06:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0023, Acc_1: 0.7976, Acc_2: 0.7916, F1-score_1: 0.7341, F1-score_2: 0.7230
2023-03-08 14:06:16 - __main__ - INFO - Epoch [24/100]
2023-03-08 14:06:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 14:06:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 14:06:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 14:06:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 14:06:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 14:06:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0018, Loss_2: 0.0016, Acc_1: 0.7578, Acc_2: 0.7578, 
2023-03-08 14:07:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 14:07:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 14:07:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:07:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 14:07:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 14:07:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 14:07:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0028, Acc_1: 0.7906, Acc_2: 0.7736, F1-score_1: 0.7277, F1-score_2: 0.7081
2023-03-08 14:07:48 - __main__ - INFO - Epoch [25/100]
2023-03-08 14:07:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:08:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 14:08:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 14:08:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 14:08:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 14:08:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 14:08:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:08:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 14:08:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 14:08:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 14:09:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:09:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:09:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0053, Loss_2: 0.0033, Acc_1: 0.7714, Acc_2: 0.7943, F1-score_1: 0.7152, F1-score_2: 0.7256
2023-03-08 14:09:21 - __main__ - INFO - Epoch [26/100]
2023-03-08 14:09:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 14:09:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 14:09:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 14:09:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 14:09:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 14:10:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 14:10:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 14:10:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 14:10:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 14:10:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 14:10:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:10:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 14:10:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0039, Acc_1: 0.7942, Acc_2: 0.7919, F1-score_1: 0.7295, F1-score_2: 0.7267
2023-03-08 14:10:54 - __main__ - INFO - Epoch [27/100]
2023-03-08 14:11:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:11:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 14:11:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:11:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 14:11:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 14:11:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 14:11:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:11:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 14:11:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 14:12:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 14:12:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 14:12:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 14:12:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0040, Loss_2: 0.0032, Acc_1: 0.7923, Acc_2: 0.7931, F1-score_1: 0.7299, F1-score_2: 0.7286
2023-03-08 14:12:27 - __main__ - INFO - Epoch [28/100]
2023-03-08 14:12:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 14:12:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 14:12:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 14:12:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 14:12:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 14:13:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 14:13:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 14:13:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 14:13:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 14:13:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 14:13:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 14:13:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 14:14:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0036, Acc_1: 0.7918, Acc_2: 0.7887, F1-score_1: 0.7263, F1-score_2: 0.7227
2023-03-08 14:14:00 - __main__ - INFO - Epoch [29/100]
2023-03-08 14:14:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:14:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:14:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 14:14:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 14:14:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:14:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:14:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 14:14:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:14:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0024, Loss_2: 0.0001, Acc_1: 0.7812, Acc_2: 0.8438, 
2023-03-08 14:15:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 14:15:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 14:15:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 14:15:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0049, Acc_1: 0.7853, Acc_2: 0.7748, F1-score_1: 0.7208, F1-score_2: 0.7012
2023-03-08 14:15:33 - __main__ - INFO - Epoch [30/100]
2023-03-08 14:15:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:15:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 14:15:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 14:15:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 14:16:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 14:16:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 14:16:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 14:16:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 14:16:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 14:16:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 14:16:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:16:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:17:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0024, Acc_1: 0.7996, Acc_2: 0.7836, F1-score_1: 0.7294, F1-score_2: 0.7192
2023-03-08 14:17:06 - __main__ - INFO - Epoch [31/100]
2023-03-08 14:17:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 14:17:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 14:17:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 14:17:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 14:17:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 14:17:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 14:17:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:17:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 14:18:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:18:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 14:18:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 14:18:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 14:18:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0028, Loss_2: 0.0018, Acc_1: 0.7923, Acc_2: 0.7969, F1-score_1: 0.7309, F1-score_2: 0.7318
2023-03-08 14:18:38 - __main__ - INFO - Epoch [32/100]
2023-03-08 14:18:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 14:18:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 14:18:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 14:19:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 14:19:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:19:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:19:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 14:19:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:19:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 14:19:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:19:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 14:19:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 14:20:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0018, Acc_1: 0.7957, Acc_2: 0.7964, F1-score_1: 0.7351, F1-score_2: 0.7282
2023-03-08 14:20:11 - __main__ - INFO - Epoch [33/100]
2023-03-08 14:20:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 14:20:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 14:20:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:20:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 14:20:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 14:20:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 14:20:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 14:21:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 14:21:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 14:21:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:21:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:21:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 14:21:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0013, Loss_2: 0.0016, Acc_1: 0.7848, Acc_2: 0.7892, F1-score_1: 0.7212, F1-score_2: 0.7239
2023-03-08 14:21:44 - __main__ - INFO - Epoch [34/100]
2023-03-08 14:21:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 14:21:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:22:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 14:22:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:22:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:22:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 14:22:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:22:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:22:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-08 14:22:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:22:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 14:23:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 14:23:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0026, Acc_1: 0.7948, Acc_2: 0.7843, F1-score_1: 0.7295, F1-score_2: 0.7157
2023-03-08 14:23:17 - __main__ - INFO - Epoch [35/100]
2023-03-08 14:23:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 14:23:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:23:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 14:23:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 14:23:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:23:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:24:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:24:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:24:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0010, Loss_2: 0.0004, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 14:24:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 14:24:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 14:24:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:24:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0024, Acc_1: 0.7831, Acc_2: 0.7913, F1-score_1: 0.7219, F1-score_2: 0.7105
2023-03-08 14:24:50 - __main__ - INFO - Epoch [36/100]
2023-03-08 14:24:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:25:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:25:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 14:25:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 14:25:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 14:25:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:25:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 14:25:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:25:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 14:25:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 14:26:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 14:26:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 14:26:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0026, Acc_1: 0.7848, Acc_2: 0.7880, F1-score_1: 0.7245, F1-score_2: 0.7221
2023-03-08 14:26:23 - __main__ - INFO - Epoch [37/100]
2023-03-08 14:26:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:26:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 14:26:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 14:26:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 14:26:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 14:27:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:27:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:27:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0009, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 14:27:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 14:27:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 14:27:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 14:27:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 14:27:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0035, Acc_1: 0.7799, Acc_2: 0.7829, F1-score_1: 0.7195, F1-score_2: 0.7105
2023-03-08 14:27:56 - __main__ - INFO - Epoch [38/100]
2023-03-08 14:28:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 14:28:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 14:28:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:28:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 14:28:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 14:28:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 14:28:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 14:28:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 14:28:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 14:29:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 14:29:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:29:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:29:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0054, Loss_2: 0.0036, Acc_1: 0.7750, Acc_2: 0.7872, F1-score_1: 0.7117, F1-score_2: 0.7152
2023-03-08 14:29:29 - __main__ - INFO - Epoch [39/100]
2023-03-08 14:29:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 14:29:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 14:29:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 14:29:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 14:30:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:30:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 14:30:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:30:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 14:30:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 14:30:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 14:30:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 14:30:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:31:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0037, Loss_2: 0.0023, Acc_1: 0.7811, Acc_2: 0.7865, F1-score_1: 0.7154, F1-score_2: 0.7194
2023-03-08 14:31:02 - __main__ - INFO - Epoch [40/100]
2023-03-08 14:31:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 14:31:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:31:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 14:31:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 14:31:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 14:31:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 14:31:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:31:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 14:32:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 14:32:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 14:32:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 14:32:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 14:32:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0011, Acc_1: 0.7772, Acc_2: 0.8032, F1-score_1: 0.7093, F1-score_2: 0.7327
2023-03-08 14:32:35 - __main__ - INFO - Epoch [41/100]
2023-03-08 14:32:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0016, Loss_2: 0.0008, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 14:32:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 14:32:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 14:33:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 14:33:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 14:33:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:33:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:33:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 14:33:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 14:33:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 14:33:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 14:33:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 14:34:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0031, Loss_2: 0.0024, Acc_1: 0.7838, Acc_2: 0.7936, F1-score_1: 0.7181, F1-score_2: 0.7248
2023-03-08 14:34:08 - __main__ - INFO - Epoch [42/100]
2023-03-08 14:34:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 14:34:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 14:34:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 14:34:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 14:34:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 14:34:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:34:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 14:35:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:35:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 14:35:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 14:35:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0016, Loss_2: 0.0012, Acc_1: 0.7500, Acc_2: 0.7578, 
2023-03-08 14:35:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 14:35:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0036, Loss_2: 0.0020, Acc_1: 0.7896, Acc_2: 0.7821, F1-score_1: 0.7258, F1-score_2: 0.7148
2023-03-08 14:35:41 - __main__ - INFO - Epoch [43/100]
2023-03-08 14:35:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 14:35:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 14:36:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 14:36:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:36:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 14:36:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 14:36:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:36:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 14:36:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 14:36:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 14:36:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:36:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:37:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0025, Acc_1: 0.7848, Acc_2: 0.7865, F1-score_1: 0.7191, F1-score_2: 0.7178
2023-03-08 14:37:14 - __main__ - INFO - Epoch [44/100]
2023-03-08 14:37:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 14:37:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 14:37:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:37:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:37:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 14:37:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 14:38:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 14:38:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 14:38:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 14:38:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 14:38:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:38:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:38:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0037, Loss_2: 0.0029, Acc_1: 0.7762, Acc_2: 0.7875, F1-score_1: 0.7128, F1-score_2: 0.7195
2023-03-08 14:38:47 - __main__ - INFO - Epoch [45/100]
2023-03-08 14:38:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 14:38:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:39:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 14:39:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:39:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:39:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 14:39:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 14:39:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:39:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 14:39:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 14:40:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 14:40:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0021, Loss_2: 0.0021, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-08 14:40:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0014, Acc_1: 0.7610, Acc_2: 0.7940, F1-score_1: 0.6934, F1-score_2: 0.7247
2023-03-08 14:40:20 - __main__ - INFO - Epoch [46/100]
2023-03-08 14:40:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:40:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 14:40:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 14:40:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 14:40:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:40:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 14:41:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 14:41:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:41:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 14:41:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:41:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 14:41:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:41:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0038, Loss_2: 0.0015, Acc_1: 0.7904, Acc_2: 0.7867, F1-score_1: 0.7227, F1-score_2: 0.7194
2023-03-08 14:41:53 - __main__ - INFO - Epoch [47/100]
2023-03-08 14:41:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 14:42:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 14:42:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 14:42:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 14:42:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 14:42:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 14:42:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:42:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 14:42:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 14:42:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 14:43:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 14:43:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:43:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0006, Acc_1: 0.7943, Acc_2: 0.7945, F1-score_1: 0.7252, F1-score_2: 0.7239
2023-03-08 14:43:26 - __main__ - INFO - Epoch [48/100]
2023-03-08 14:43:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 14:43:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0014, Loss_2: 0.0009, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 14:43:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 14:43:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 14:43:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:44:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:44:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:44:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 14:44:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:44:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 14:44:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 14:44:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:44:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0038, Loss_2: 0.0017, Acc_1: 0.7812, Acc_2: 0.7938, F1-score_1: 0.7134, F1-score_2: 0.7201
2023-03-08 14:44:59 - __main__ - INFO - Epoch [49/100]
2023-03-08 14:45:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0028, Loss_2: 0.0027, Acc_1: 0.7500, Acc_2: 0.7500, 
2023-03-08 14:45:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:45:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 14:45:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 14:45:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:45:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 14:45:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 14:45:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 14:45:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:46:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 14:46:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:46:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 14:46:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0035, Loss_2: 0.0020, Acc_1: 0.7855, Acc_2: 0.7850, F1-score_1: 0.7202, F1-score_2: 0.7136
2023-03-08 14:46:32 - __main__ - INFO - Epoch [50/100]
2023-03-08 14:46:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:46:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 14:46:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 14:46:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 14:47:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:47:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:47:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 14:47:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:47:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 14:47:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 14:47:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:47:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:48:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0016, Acc_1: 0.7884, Acc_2: 0.7962, F1-score_1: 0.7216, F1-score_2: 0.7278
2023-03-08 14:48:05 - __main__ - INFO - Epoch [51/100]
2023-03-08 14:48:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 14:48:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 14:48:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:48:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:48:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:48:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:48:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 14:48:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:49:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 14:49:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:49:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:49:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 14:49:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0015, Loss_2: 0.0012, Acc_1: 0.7869, Acc_2: 0.7965, F1-score_1: 0.7207, F1-score_2: 0.7245
2023-03-08 14:49:38 - __main__ - INFO - Epoch [52/100]
2023-03-08 14:49:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:49:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 14:49:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 14:50:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 14:50:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 14:50:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 14:50:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:50:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 14:50:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:50:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 14:50:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 14:50:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 14:51:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0030, Loss_2: 0.0022, Acc_1: 0.7796, Acc_2: 0.7862, F1-score_1: 0.7124, F1-score_2: 0.7158
2023-03-08 14:51:11 - __main__ - INFO - Epoch [53/100]
2023-03-08 14:51:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 14:51:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 14:51:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 14:51:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 14:51:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0015, Loss_2: 0.0013, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 14:51:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:51:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:52:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 14:52:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 14:52:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 14:52:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 14:52:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 14:52:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0015, Acc_1: 0.7799, Acc_2: 0.7875, F1-score_1: 0.7158, F1-score_2: 0.7169
2023-03-08 14:52:44 - __main__ - INFO - Epoch [54/100]
2023-03-08 14:52:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 14:52:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 14:53:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 14:53:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:53:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 14:53:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 14:53:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:53:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 14:53:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:53:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 14:53:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 14:54:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 14:54:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0016, Acc_1: 0.7772, Acc_2: 0.7792, F1-score_1: 0.7107, F1-score_2: 0.7094
2023-03-08 14:54:17 - __main__ - INFO - Epoch [55/100]
2023-03-08 14:54:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:54:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:54:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:54:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 14:54:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:54:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 14:55:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 14:55:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 14:55:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 14:55:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 14:55:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 14:55:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 14:55:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0012, Acc_1: 0.7843, Acc_2: 0.7835, F1-score_1: 0.7193, F1-score_2: 0.7120
2023-03-08 14:55:50 - __main__ - INFO - Epoch [56/100]
2023-03-08 14:55:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 14:56:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0015, Loss_2: 0.0017, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-08 14:56:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:56:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 14:56:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 14:56:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 14:56:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 14:56:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 14:56:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 14:56:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:57:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 14:57:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 14:57:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0009, Acc_1: 0.7833, Acc_2: 0.7903, F1-score_1: 0.7123, F1-score_2: 0.7225
2023-03-08 14:57:23 - __main__ - INFO - Epoch [57/100]
2023-03-08 14:57:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 14:57:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 14:57:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 14:57:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 14:57:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 14:58:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 14:58:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0020, Loss_2: 0.0002, Acc_1: 0.7812, Acc_2: 0.8125, 
2023-03-08 14:58:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 14:58:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 14:58:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 14:58:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 14:58:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 14:58:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0049, Loss_2: 0.0039, Acc_1: 0.7649, Acc_2: 0.7925, F1-score_1: 0.7081, F1-score_2: 0.7233
2023-03-08 14:58:56 - __main__ - INFO - Epoch [58/100]
2023-03-08 14:59:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 14:59:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 14:59:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 14:59:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:59:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 14:59:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:59:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 14:59:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 14:59:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8828, 
2023-03-08 15:00:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:00:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:00:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 15:00:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0013, Acc_1: 0.7891, Acc_2: 0.7891, F1-score_1: 0.7223, F1-score_2: 0.7162
2023-03-08 15:00:28 - __main__ - INFO - Epoch [59/100]
2023-03-08 15:00:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 15:00:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:00:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 15:00:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 15:01:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 15:01:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 15:01:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 15:01:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 15:01:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:01:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:01:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 15:01:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 15:02:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0016, Acc_1: 0.7833, Acc_2: 0.7869, F1-score_1: 0.7156, F1-score_2: 0.7148
2023-03-08 15:02:01 - __main__ - INFO - Epoch [60/100]
2023-03-08 15:02:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 15:02:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 15:02:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 15:02:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 15:02:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:02:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 15:02:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:02:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:03:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 15:03:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:03:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:03:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:03:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0020, Acc_1: 0.7865, Acc_2: 0.7947, F1-score_1: 0.7221, F1-score_2: 0.7220
2023-03-08 15:03:34 - __main__ - INFO - Epoch [61/100]
2023-03-08 15:03:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 15:03:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:03:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:04:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 15:04:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:04:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:04:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 15:04:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:04:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:04:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 15:04:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:04:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:05:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0011, Acc_1: 0.7790, Acc_2: 0.7928, F1-score_1: 0.7166, F1-score_2: 0.7181
2023-03-08 15:05:07 - __main__ - INFO - Epoch [62/100]
2023-03-08 15:05:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:05:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 15:05:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 15:05:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:05:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 15:05:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:05:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 15:05:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 15:06:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 15:06:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 15:06:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 15:06:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 15:06:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0024, Loss_2: 0.0015, Acc_1: 0.7779, Acc_2: 0.7960, F1-score_1: 0.7132, F1-score_2: 0.7236
2023-03-08 15:06:40 - __main__ - INFO - Epoch [63/100]
2023-03-08 15:06:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:06:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 15:06:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:07:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 15:07:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 15:07:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 15:07:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:07:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:07:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:07:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:07:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 15:07:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 15:08:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0023, Acc_1: 0.7702, Acc_2: 0.7884, F1-score_1: 0.7083, F1-score_2: 0.7227
2023-03-08 15:08:13 - __main__ - INFO - Epoch [64/100]
2023-03-08 15:08:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:08:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 15:08:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:08:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:08:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 15:08:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 15:08:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:09:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:09:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:09:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:09:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 15:09:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 15:09:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0017, Acc_1: 0.7843, Acc_2: 0.7906, F1-score_1: 0.7198, F1-score_2: 0.7172
2023-03-08 15:09:46 - __main__ - INFO - Epoch [65/100]
2023-03-08 15:09:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:09:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 15:10:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:10:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:10:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:10:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 15:10:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 15:10:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 15:10:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 15:10:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:10:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 15:11:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 15:11:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0019, Acc_1: 0.7648, Acc_2: 0.7756, F1-score_1: 0.7086, F1-score_2: 0.7125
2023-03-08 15:11:19 - __main__ - INFO - Epoch [66/100]
2023-03-08 15:11:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 15:11:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 15:11:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:11:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:11:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 15:11:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 15:12:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:12:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:12:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:12:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 15:12:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:12:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 15:12:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0012, Acc_1: 0.7811, Acc_2: 0.7768, F1-score_1: 0.7192, F1-score_2: 0.7111
2023-03-08 15:12:52 - __main__ - INFO - Epoch [67/100]
2023-03-08 15:12:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 15:13:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 15:13:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:13:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:13:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:13:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 15:13:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 15:13:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:13:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:13:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:14:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 15:14:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:14:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0013, Acc_1: 0.7852, Acc_2: 0.7852, F1-score_1: 0.7236, F1-score_2: 0.7194
2023-03-08 15:14:25 - __main__ - INFO - Epoch [68/100]
2023-03-08 15:14:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 15:14:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 15:14:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 15:14:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 15:14:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 15:15:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:15:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 15:15:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:15:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:15:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:15:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:15:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 15:15:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0013, Acc_1: 0.7935, Acc_2: 0.7838, F1-score_1: 0.7297, F1-score_2: 0.7171
2023-03-08 15:15:58 - __main__ - INFO - Epoch [69/100]
2023-03-08 15:16:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:16:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:16:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 15:16:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:16:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:16:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 15:16:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 15:16:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:16:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 15:17:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:17:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:17:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 15:17:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0014, Acc_1: 0.7823, Acc_2: 0.7945, F1-score_1: 0.7189, F1-score_2: 0.7236
2023-03-08 15:17:31 - __main__ - INFO - Epoch [70/100]
2023-03-08 15:17:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:17:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 15:17:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 15:17:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 15:18:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:18:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 15:18:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:18:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 15:18:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 15:18:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 15:18:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:18:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 15:19:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0019, Acc_1: 0.7768, Acc_2: 0.7880, F1-score_1: 0.7122, F1-score_2: 0.7229
2023-03-08 15:19:04 - __main__ - INFO - Epoch [71/100]
2023-03-08 15:19:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:19:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 15:19:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 15:19:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 15:19:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:19:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:19:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 15:19:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:20:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 15:20:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 15:20:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-08 15:20:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 15:20:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0021, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.7872, F1-score_1: 0.7301, F1-score_2: 0.7214
2023-03-08 15:20:37 - __main__ - INFO - Epoch [72/100]
2023-03-08 15:20:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:20:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:20:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 15:21:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:21:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 15:21:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:21:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 15:21:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 15:21:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 15:21:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:21:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:21:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 15:22:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0018, Loss_2: 0.0021, Acc_1: 0.7826, Acc_2: 0.7836, F1-score_1: 0.7229, F1-score_2: 0.7178
2023-03-08 15:22:10 - __main__ - INFO - Epoch [73/100]
2023-03-08 15:22:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 15:22:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:22:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:22:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:22:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 15:22:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 15:22:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 15:23:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 15:23:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 15:23:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 15:23:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 15:23:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:23:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0030, Acc_1: 0.7857, Acc_2: 0.7865, F1-score_1: 0.7237, F1-score_2: 0.7179
2023-03-08 15:23:43 - __main__ - INFO - Epoch [74/100]
2023-03-08 15:23:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 15:23:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 15:24:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:24:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 15:24:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 15:24:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:24:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 15:24:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:24:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:24:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:24:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 15:25:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:25:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0032, Loss_2: 0.0021, Acc_1: 0.7692, Acc_2: 0.7853, F1-score_1: 0.7058, F1-score_2: 0.7189
2023-03-08 15:25:16 - __main__ - INFO - Epoch [75/100]
2023-03-08 15:25:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:25:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 15:25:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 15:25:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:25:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 15:25:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 15:26:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 15:26:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:26:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:26:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 15:26:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 15:26:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 15:26:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0019, Loss_2: 0.0020, Acc_1: 0.7870, Acc_2: 0.7807, F1-score_1: 0.7183, F1-score_2: 0.7135
2023-03-08 15:26:49 - __main__ - INFO - Epoch [76/100]
2023-03-08 15:26:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 15:27:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 15:27:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:27:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:27:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:27:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 15:27:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 15:27:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:27:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 15:27:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 15:28:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:28:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:28:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0020, Acc_1: 0.7848, Acc_2: 0.7896, F1-score_1: 0.7202, F1-score_2: 0.7176
2023-03-08 15:28:22 - __main__ - INFO - Epoch [77/100]
2023-03-08 15:28:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 15:28:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 15:28:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 15:28:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 15:28:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:29:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:29:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 15:29:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:29:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:29:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-08 15:29:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:29:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:29:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0017, Loss_2: 0.0024, Acc_1: 0.7860, Acc_2: 0.7840, F1-score_1: 0.7228, F1-score_2: 0.7155
2023-03-08 15:29:55 - __main__ - INFO - Epoch [78/100]
2023-03-08 15:30:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:30:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 15:30:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:30:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:30:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:30:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 15:30:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0013, Loss_2: 0.0009, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 15:30:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:30:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 15:31:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:31:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 15:31:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:31:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0016, Loss_2: 0.0026, Acc_1: 0.7863, Acc_2: 0.7823, F1-score_1: 0.7258, F1-score_2: 0.7146
2023-03-08 15:31:28 - __main__ - INFO - Epoch [79/100]
2023-03-08 15:31:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:31:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 15:31:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:31:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 15:32:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:32:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 15:32:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 15:32:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:32:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 15:32:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:32:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 15:32:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 15:33:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0033, Acc_1: 0.7785, Acc_2: 0.7760, F1-score_1: 0.7116, F1-score_2: 0.7072
2023-03-08 15:33:01 - __main__ - INFO - Epoch [80/100]
2023-03-08 15:33:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 15:33:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:33:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 15:33:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 15:33:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:33:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:33:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 15:33:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:34:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:34:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:34:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 15:34:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 15:34:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0022, Loss_2: 0.0016, Acc_1: 0.7863, Acc_2: 0.7755, F1-score_1: 0.7215, F1-score_2: 0.7073
2023-03-08 15:34:34 - __main__ - INFO - Epoch [81/100]
2023-03-08 15:34:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:34:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:34:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:35:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:35:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:35:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:35:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:35:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:35:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 15:35:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 15:35:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 15:35:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 15:36:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0014, Loss_2: 0.0024, Acc_1: 0.7904, Acc_2: 0.7829, F1-score_1: 0.7260, F1-score_2: 0.7109
2023-03-08 15:36:07 - __main__ - INFO - Epoch [82/100]
2023-03-08 15:36:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:36:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 15:36:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:36:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 15:36:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8359, 
2023-03-08 15:36:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:36:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:36:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 15:37:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 15:37:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 15:37:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:37:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 15:37:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0020, Loss_2: 0.0022, Acc_1: 0.7896, Acc_2: 0.7845, F1-score_1: 0.7219, F1-score_2: 0.7115
2023-03-08 15:37:40 - __main__ - INFO - Epoch [83/100]
2023-03-08 15:37:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 15:37:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:37:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 15:38:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 15:38:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-08 15:38:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 15:38:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:38:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:38:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:38:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:38:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 15:38:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 15:39:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0031, Acc_1: 0.7930, Acc_2: 0.7804, F1-score_1: 0.7241, F1-score_2: 0.7097
2023-03-08 15:39:13 - __main__ - INFO - Epoch [84/100]
2023-03-08 15:39:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:39:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:39:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:39:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:39:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 15:39:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:39:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 15:40:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:40:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 15:40:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:40:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:40:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:40:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0027, Acc_1: 0.7787, Acc_2: 0.7712, F1-score_1: 0.7168, F1-score_2: 0.7028
2023-03-08 15:40:46 - __main__ - INFO - Epoch [85/100]
2023-03-08 15:40:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:40:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:41:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:41:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:41:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:41:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:41:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:41:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:41:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 15:41:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:41:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:42:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:42:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0033, Loss_2: 0.0034, Acc_1: 0.7819, Acc_2: 0.7777, F1-score_1: 0.7175, F1-score_2: 0.7080
2023-03-08 15:42:18 - __main__ - INFO - Epoch [86/100]
2023-03-08 15:42:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:42:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 15:42:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 15:42:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:42:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:42:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 15:43:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:43:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:43:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:43:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:43:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 15:43:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 15:43:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0029, Acc_1: 0.7852, Acc_2: 0.7762, F1-score_1: 0.7239, F1-score_2: 0.7049
2023-03-08 15:43:51 - __main__ - INFO - Epoch [87/100]
2023-03-08 15:43:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 15:44:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:44:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 15:44:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 15:44:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 15:44:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 15:44:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:44:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:44:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:44:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:45:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:45:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:45:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0030, Acc_1: 0.7879, Acc_2: 0.7762, F1-score_1: 0.7267, F1-score_2: 0.7058
2023-03-08 15:45:24 - __main__ - INFO - Epoch [88/100]
2023-03-08 15:45:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:45:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 15:45:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:45:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:45:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:46:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:46:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:46:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 15:46:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 15:46:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 15:46:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:46:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 15:46:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0034, Acc_1: 0.7826, Acc_2: 0.7680, F1-score_1: 0.7193, F1-score_2: 0.6977
2023-03-08 15:46:57 - __main__ - INFO - Epoch [89/100]
2023-03-08 15:47:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 15:47:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 15:47:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:47:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:47:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:47:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 15:47:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:47:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 15:47:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:48:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 15:48:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 15:48:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:48:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0027, Acc_1: 0.7853, Acc_2: 0.7846, F1-score_1: 0.7216, F1-score_2: 0.7114
2023-03-08 15:48:30 - __main__ - INFO - Epoch [90/100]
2023-03-08 15:48:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:48:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:48:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:48:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 15:49:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:49:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 15:49:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:49:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:49:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 15:49:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:49:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 15:49:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:50:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0025, Loss_2: 0.0031, Acc_1: 0.7750, Acc_2: 0.7836, F1-score_1: 0.7095, F1-score_2: 0.7108
2023-03-08 15:50:03 - __main__ - INFO - Epoch [91/100]
2023-03-08 15:50:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:50:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:50:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:50:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:50:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:50:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:50:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:50:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:51:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 15:51:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:51:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:51:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:51:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0030, Acc_1: 0.7801, Acc_2: 0.7845, F1-score_1: 0.7109, F1-score_2: 0.7126
2023-03-08 15:51:35 - __main__ - INFO - Epoch [92/100]
2023-03-08 15:51:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 15:51:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 15:51:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 15:52:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 15:52:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 15:52:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:52:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:52:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:52:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:52:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:52:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:52:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:53:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0035, Acc_1: 0.7806, Acc_2: 0.7818, F1-score_1: 0.7139, F1-score_2: 0.7097
2023-03-08 15:53:08 - __main__ - INFO - Epoch [93/100]
2023-03-08 15:53:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:53:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 15:53:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:53:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 15:53:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 15:53:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:53:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:54:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 15:54:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 15:54:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:54:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:54:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:54:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0028, Loss_2: 0.0028, Acc_1: 0.7767, Acc_2: 0.7716, F1-score_1: 0.7102, F1-score_2: 0.7028
2023-03-08 15:54:41 - __main__ - INFO - Epoch [94/100]
2023-03-08 15:54:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:54:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:55:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 15:55:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:55:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 15:55:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 15:55:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0011, Loss_2: 0.0014, Acc_1: 0.7656, Acc_2: 0.7578, 
2023-03-08 15:55:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 15:55:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:55:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 15:55:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 15:55:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:56:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0026, Loss_2: 0.0019, Acc_1: 0.7792, Acc_2: 0.7712, F1-score_1: 0.7126, F1-score_2: 0.7010
2023-03-08 15:56:14 - __main__ - INFO - Epoch [95/100]
2023-03-08 15:56:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:56:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:56:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 15:56:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 15:56:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 15:56:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:57:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:57:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 15:57:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 15:57:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:57:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:57:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:57:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0030, Acc_1: 0.7850, Acc_2: 0.7738, F1-score_1: 0.7191, F1-score_2: 0.7032
2023-03-08 15:57:47 - __main__ - INFO - Epoch [96/100]
2023-03-08 15:57:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:57:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:58:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:58:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 15:58:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 15:58:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:58:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:58:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 15:58:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 15:58:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 15:58:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 15:59:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 15:59:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0026, Acc_1: 0.7739, Acc_2: 0.7716, F1-score_1: 0.7047, F1-score_2: 0.7007
2023-03-08 15:59:20 - __main__ - INFO - Epoch [97/100]
2023-03-08 15:59:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 15:59:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 15:59:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 15:59:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 15:59:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 15:59:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:00:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 16:00:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 16:00:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 16:00:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 16:00:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 16:00:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 16:00:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0027, Loss_2: 0.0024, Acc_1: 0.7767, Acc_2: 0.7748, F1-score_1: 0.7078, F1-score_2: 0.7014
2023-03-08 16:00:52 - __main__ - INFO - Epoch [98/100]
2023-03-08 16:00:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 16:01:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 16:01:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 16:01:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 16:01:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 16:01:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 16:01:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 16:01:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 16:01:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 16:01:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 16:02:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 16:02:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 16:02:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0029, Loss_2: 0.0027, Acc_1: 0.7733, Acc_2: 0.7709, F1-score_1: 0.7060, F1-score_2: 0.6996
2023-03-08 16:02:26 - __main__ - INFO - Epoch [99/100]
2023-03-08 16:02:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:02:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 16:02:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 16:02:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 16:02:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 16:03:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 16:03:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 16:03:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 16:03:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 16:03:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 16:03:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 16:03:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 16:03:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0028, Loss_2: 0.0027, Acc_1: 0.7748, Acc_2: 0.7721, F1-score_1: 0.7064, F1-score_2: 0.7008
2023-03-08 16:04:01 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 16:04:01 - utils._noise - DEBUG - 6, 7
2023-03-08 16:04:01 - utils._noise - DEBUG - 13997
2023-03-08 16:04:01 - utils._noise - INFO - Actual noise 0.20
2023-03-08 16:04:01 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-08 16:04:01 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-08 16:04:03 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 16:04:03 - __main__ - INFO - Loading dataset...
2023-03-08 16:04:03 - __main__ - INFO - Building model...
2023-03-08 16:04:03 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-08 16:04:03 - __main__ - INFO - <bound method Module.parameters of NewsNet(
  (embedding): Embedding(20000, 300)
  (avgpool): AdaptiveAvgPool1d(output_size=4800)
  (fc1): Linear(in_features=4800, out_features=1200, bias=True)
  (bn1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ac): Softsign()
  (fc2): Linear(in_features=1200, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=7, bias=True)
)>
2023-03-08 16:04:03 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-08 16:04:03 - __main__ - INFO - Start train & evaluate
2023-03-08 16:04:03 - __main__ - INFO - Epoch [0/100]
2023-03-08 16:04:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0151, Loss_2: 0.0155, Acc_1: 0.1641, Acc_2: 0.1641, 
2023-03-08 16:04:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0133, Loss_2: 0.0146, Acc_1: 0.2969, Acc_2: 0.2891, 
2023-03-08 16:04:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0144, Loss_2: 0.0142, Acc_1: 0.2891, Acc_2: 0.3047, 
2023-03-08 16:04:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0134, Loss_2: 0.0136, Acc_1: 0.3594, Acc_2: 0.3281, 
2023-03-08 16:04:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0126, Loss_2: 0.0129, Acc_1: 0.4219, Acc_2: 0.4844, 
2023-03-08 16:04:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0135, Loss_2: 0.0136, Acc_1: 0.3359, Acc_2: 0.3516, 
2023-03-08 16:04:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0145, Loss_2: 0.0138, Acc_1: 0.2656, Acc_2: 0.3359, 
2023-03-08 16:04:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0139, Loss_2: 0.0133, Acc_1: 0.2969, Acc_2: 0.3828, 
2023-03-08 16:04:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0142, Loss_2: 0.0139, Acc_1: 0.3125, Acc_2: 0.2578, 
2023-03-08 16:04:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0136, Loss_2: 0.0129, Acc_1: 0.3750, Acc_2: 0.4062, 
2023-03-08 16:04:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0138, Loss_2: 0.0132, Acc_1: 0.2812, Acc_2: 0.3047, 
2023-03-08 16:04:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0135, Loss_2: 0.0124, Acc_1: 0.3281, Acc_2: 0.4297, 
2023-03-08 16:04:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0123, Loss_2: 0.0123, Acc_1: 0.4293, Acc_2: 0.4659, F1-score_1: 0.2211, F1-score_2: 0.3032
2023-03-08 16:04:57 - __main__ - INFO - Epoch [1/100]
2023-03-08 16:05:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0133, Loss_2: 0.0123, Acc_1: 0.3672, Acc_2: 0.4688, 
2023-03-08 16:05:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0123, Loss_2: 0.0119, Acc_1: 0.4219, Acc_2: 0.3906, 
2023-03-08 16:05:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0132, Loss_2: 0.0120, Acc_1: 0.3125, Acc_2: 0.4219, 
2023-03-08 16:05:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0129, Loss_2: 0.0120, Acc_1: 0.3906, Acc_2: 0.4531, 
2023-03-08 16:05:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0128, Loss_2: 0.0107, Acc_1: 0.4219, Acc_2: 0.4297, 
2023-03-08 16:05:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0130, Loss_2: 0.0124, Acc_1: 0.4219, Acc_2: 0.4453, 
2023-03-08 16:05:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0128, Loss_2: 0.0113, Acc_1: 0.3906, Acc_2: 0.4922, 
2023-03-08 16:05:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0126, Loss_2: 0.0120, Acc_1: 0.4453, Acc_2: 0.4766, 
2023-03-08 16:05:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0120, Loss_2: 0.0107, Acc_1: 0.4609, Acc_2: 0.4844, 
2023-03-08 16:05:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0114, Loss_2: 0.0126, Acc_1: 0.5000, Acc_2: 0.3984, 
2023-03-08 16:05:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0131, Loss_2: 0.0127, Acc_1: 0.3984, Acc_2: 0.4141, 
2023-03-08 16:05:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0111, Loss_2: 0.0125, Acc_1: 0.5000, Acc_2: 0.4297, 
2023-03-08 16:05:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0109, Loss_2: 0.0119, Acc_1: 0.5708, Acc_2: 0.4550, F1-score_1: 0.4253, F1-score_2: 0.3018
2023-03-08 16:05:50 - __main__ - INFO - Epoch [2/100]
2023-03-08 16:05:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0120, Loss_2: 0.0111, Acc_1: 0.5078, Acc_2: 0.4688, 
2023-03-08 16:05:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0113, Loss_2: 0.0109, Acc_1: 0.5156, Acc_2: 0.5156, 
2023-03-08 16:06:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0108, Loss_2: 0.0106, Acc_1: 0.5078, Acc_2: 0.4688, 
2023-03-08 16:06:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0110, Loss_2: 0.0093, Acc_1: 0.5391, Acc_2: 0.5703, 
2023-03-08 16:06:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0114, Loss_2: 0.0100, Acc_1: 0.5000, Acc_2: 0.5312, 
2023-03-08 16:06:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0102, Loss_2: 0.0109, Acc_1: 0.5469, Acc_2: 0.5156, 
2023-03-08 16:06:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0099, Loss_2: 0.0112, Acc_1: 0.5547, Acc_2: 0.5312, 
2023-03-08 16:06:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0105, Loss_2: 0.0103, Acc_1: 0.5391, Acc_2: 0.4688, 
2023-03-08 16:06:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0109, Loss_2: 0.0110, Acc_1: 0.5000, Acc_2: 0.4844, 
2023-03-08 16:06:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0118, Loss_2: 0.0112, Acc_1: 0.5000, Acc_2: 0.5547, 
2023-03-08 16:06:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0108, Loss_2: 0.0120, Acc_1: 0.5625, Acc_2: 0.4062, 
2023-03-08 16:06:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0108, Loss_2: 0.0106, Acc_1: 0.4922, Acc_2: 0.4844, 
2023-03-08 16:06:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0083, Loss_2: 0.0122, Acc_1: 0.6707, Acc_2: 0.4353, F1-score_1: 0.5252, F1-score_2: 0.3159
2023-03-08 16:06:43 - __main__ - INFO - Epoch [3/100]
2023-03-08 16:06:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0084, Loss_2: 0.0089, Acc_1: 0.6484, Acc_2: 0.5938, 
2023-03-08 16:06:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0085, Loss_2: 0.0074, Acc_1: 0.6172, Acc_2: 0.6562, 
2023-03-08 16:06:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0076, Loss_2: 0.0080, Acc_1: 0.6797, Acc_2: 0.6172, 
2023-03-08 16:06:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0114, Loss_2: 0.0103, Acc_1: 0.5469, Acc_2: 0.5234, 
2023-03-08 16:07:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0090, Loss_2: 0.0093, Acc_1: 0.6328, Acc_2: 0.5703, 
2023-03-08 16:07:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0079, Loss_2: 0.0092, Acc_1: 0.6797, Acc_2: 0.6328, 
2023-03-08 16:07:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0096, Loss_2: 0.0099, Acc_1: 0.6094, Acc_2: 0.5234, 
2023-03-08 16:07:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0082, Loss_2: 0.0101, Acc_1: 0.6484, Acc_2: 0.5625, 
2023-03-08 16:07:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0074, Loss_2: 0.0097, Acc_1: 0.6797, Acc_2: 0.5312, 
2023-03-08 16:07:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0077, Loss_2: 0.0083, Acc_1: 0.6875, Acc_2: 0.6094, 
2023-03-08 16:07:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0090, Loss_2: 0.0112, Acc_1: 0.7031, Acc_2: 0.4922, 
2023-03-08 16:07:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0100, Loss_2: 0.0097, Acc_1: 0.5469, Acc_2: 0.5547, 
2023-03-08 16:07:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0077, Loss_2: 0.0132, Acc_1: 0.6636, Acc_2: 0.4333, F1-score_1: 0.6084, F1-score_2: 0.3247
2023-03-08 16:07:37 - __main__ - INFO - Epoch [4/100]
2023-03-08 16:07:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0091, Loss_2: 0.0092, Acc_1: 0.6406, Acc_2: 0.5234, 
2023-03-08 16:07:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0082, Loss_2: 0.0086, Acc_1: 0.6172, Acc_2: 0.5625, 
2023-03-08 16:07:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0087, Loss_2: 0.0079, Acc_1: 0.6484, Acc_2: 0.6328, 
2023-03-08 16:07:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0073, Loss_2: 0.0088, Acc_1: 0.6406, Acc_2: 0.5547, 
2023-03-08 16:07:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0081, Loss_2: 0.0074, Acc_1: 0.6641, Acc_2: 0.6406, 
2023-03-08 16:07:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0076, Loss_2: 0.0087, Acc_1: 0.6953, Acc_2: 0.5312, 
2023-03-08 16:08:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0083, Loss_2: 0.0084, Acc_1: 0.6094, Acc_2: 0.6016, 
2023-03-08 16:08:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0110, Loss_2: 0.0101, Acc_1: 0.5000, Acc_2: 0.5703, 
2023-03-08 16:08:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0094, Loss_2: 0.0106, Acc_1: 0.6094, Acc_2: 0.5469, 
2023-03-08 16:08:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0089, Loss_2: 0.0093, Acc_1: 0.6719, Acc_2: 0.5547, 
2023-03-08 16:08:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0099, Loss_2: 0.0100, Acc_1: 0.5938, Acc_2: 0.5078, 
2023-03-08 16:08:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0073, Loss_2: 0.0096, Acc_1: 0.6797, Acc_2: 0.5469, 
2023-03-08 16:08:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0071, Loss_2: 0.0138, Acc_1: 0.7026, Acc_2: 0.4195, F1-score_1: 0.6328, F1-score_2: 0.3229
2023-03-08 16:08:30 - __main__ - INFO - Epoch [5/100]
2023-03-08 16:08:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0071, Loss_2: 0.0076, Acc_1: 0.7109, Acc_2: 0.6797, 
2023-03-08 16:08:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0086, Loss_2: 0.0073, Acc_1: 0.6094, Acc_2: 0.6875, 
2023-03-08 16:08:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0061, Loss_2: 0.0079, Acc_1: 0.7266, Acc_2: 0.6172, 
2023-03-08 16:08:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0045, Loss_2: 0.0078, Acc_1: 0.7969, Acc_2: 0.5859, 
2023-03-08 16:08:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0061, Loss_2: 0.0067, Acc_1: 0.6953, Acc_2: 0.6797, 
2023-03-08 16:08:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0058, Loss_2: 0.0083, Acc_1: 0.7812, Acc_2: 0.6250, 
2023-03-08 16:08:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0061, Loss_2: 0.0086, Acc_1: 0.7578, Acc_2: 0.5938, 
2023-03-08 16:09:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0076, Loss_2: 0.0099, Acc_1: 0.6641, Acc_2: 0.5234, 
2023-03-08 16:09:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0053, Loss_2: 0.0086, Acc_1: 0.7109, Acc_2: 0.5391, 
2023-03-08 16:09:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0064, Loss_2: 0.0087, Acc_1: 0.7109, Acc_2: 0.6016, 
2023-03-08 16:09:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0083, Loss_2: 0.0089, Acc_1: 0.5938, Acc_2: 0.5391, 
2023-03-08 16:09:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0074, Loss_2: 0.0091, Acc_1: 0.6641, Acc_2: 0.6406, 
2023-03-08 16:09:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0078, Loss_2: 0.0151, Acc_1: 0.6605, Acc_2: 0.4324, F1-score_1: 0.6142, F1-score_2: 0.3368
2023-03-08 16:09:23 - __main__ - INFO - Epoch [6/100]
2023-03-08 16:09:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0070, Loss_2: 0.0061, Acc_1: 0.6328, Acc_2: 0.7188, 
2023-03-08 16:09:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0054, Loss_2: 0.0065, Acc_1: 0.7344, Acc_2: 0.6797, 
2023-03-08 16:09:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0055, Loss_2: 0.0065, Acc_1: 0.7500, Acc_2: 0.7109, 
2023-03-08 16:09:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0054, Loss_2: 0.0063, Acc_1: 0.7422, Acc_2: 0.6875, 
2023-03-08 16:09:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0083, Loss_2: 0.0086, Acc_1: 0.6641, Acc_2: 0.6016, 
2023-03-08 16:09:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0044, Loss_2: 0.0060, Acc_1: 0.7812, Acc_2: 0.7031, 
2023-03-08 16:09:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0056, Loss_2: 0.0075, Acc_1: 0.8047, Acc_2: 0.6641, 
2023-03-08 16:09:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0062, Loss_2: 0.0084, Acc_1: 0.7344, Acc_2: 0.6172, 
2023-03-08 16:09:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0056, Loss_2: 0.0081, Acc_1: 0.7266, Acc_2: 0.5391, 
2023-03-08 16:10:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0048, Loss_2: 0.0070, Acc_1: 0.8047, Acc_2: 0.6406, 
2023-03-08 16:10:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0066, Loss_2: 0.0086, Acc_1: 0.7188, Acc_2: 0.5469, 
2023-03-08 16:10:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0045, Loss_2: 0.0072, Acc_1: 0.8281, Acc_2: 0.6562, 
2023-03-08 16:10:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0051, Loss_2: 0.0155, Acc_1: 0.7743, Acc_2: 0.4271, F1-score_1: 0.7002, F1-score_2: 0.3234
2023-03-08 16:10:17 - __main__ - INFO - Epoch [7/100]
2023-03-08 16:10:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0049, Loss_2: 0.0064, Acc_1: 0.7422, Acc_2: 0.6250, 
2023-03-08 16:10:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0032, Loss_2: 0.0051, Acc_1: 0.8047, Acc_2: 0.7109, 
2023-03-08 16:10:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0048, Loss_2: 0.0066, Acc_1: 0.7734, Acc_2: 0.6875, 
2023-03-08 16:10:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0036, Loss_2: 0.0066, Acc_1: 0.8203, Acc_2: 0.7266, 
2023-03-08 16:10:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0048, Loss_2: 0.0070, Acc_1: 0.7734, Acc_2: 0.6641, 
2023-03-08 16:10:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0035, Loss_2: 0.0058, Acc_1: 0.8203, Acc_2: 0.6797, 
2023-03-08 16:10:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0042, Loss_2: 0.0066, Acc_1: 0.7344, Acc_2: 0.6250, 
2023-03-08 16:10:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0044, Loss_2: 0.0071, Acc_1: 0.7812, Acc_2: 0.5938, 
2023-03-08 16:10:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0045, Loss_2: 0.0060, Acc_1: 0.7344, Acc_2: 0.6562, 
2023-03-08 16:10:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0036, Loss_2: 0.0080, Acc_1: 0.7578, Acc_2: 0.5469, 
2023-03-08 16:10:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0043, Loss_2: 0.0069, Acc_1: 0.7422, Acc_2: 0.6094, 
2023-03-08 16:10:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0038, Loss_2: 0.0065, Acc_1: 0.7734, Acc_2: 0.6562, 
2023-03-08 16:11:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0048, Loss_2: 0.0169, Acc_1: 0.7702, Acc_2: 0.4183, F1-score_1: 0.6996, F1-score_2: 0.3249
2023-03-08 16:11:10 - __main__ - INFO - Epoch [8/100]
2023-03-08 16:11:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0030, Loss_2: 0.0043, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 16:11:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0037, Loss_2: 0.0058, Acc_1: 0.8047, Acc_2: 0.7188, 
2023-03-08 16:11:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0030, Loss_2: 0.0046, Acc_1: 0.8203, Acc_2: 0.7109, 
2023-03-08 16:11:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0018, Loss_2: 0.0050, Acc_1: 0.8516, Acc_2: 0.6875, 
2023-03-08 16:11:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0026, Loss_2: 0.0056, Acc_1: 0.8516, Acc_2: 0.6953, 
2023-03-08 16:11:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0027, Loss_2: 0.0054, Acc_1: 0.8516, Acc_2: 0.7500, 
2023-03-08 16:11:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0015, Loss_2: 0.0051, Acc_1: 0.8594, Acc_2: 0.6875, 
2023-03-08 16:11:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0035, Loss_2: 0.0079, Acc_1: 0.8047, Acc_2: 0.6094, 
2023-03-08 16:11:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0050, Loss_2: 0.0072, Acc_1: 0.7578, Acc_2: 0.6953, 
2023-03-08 16:11:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0042, Loss_2: 0.0073, Acc_1: 0.7578, Acc_2: 0.6562, 
2023-03-08 16:11:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0022, Loss_2: 0.0057, Acc_1: 0.8516, Acc_2: 0.7188, 
2023-03-08 16:11:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0048, Loss_2: 0.0082, Acc_1: 0.7422, Acc_2: 0.6016, 
2023-03-08 16:12:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0048, Loss_2: 0.0179, Acc_1: 0.7714, Acc_2: 0.4129, F1-score_1: 0.7127, F1-score_2: 0.3285
2023-03-08 16:12:03 - __main__ - INFO - Epoch [9/100]
2023-03-08 16:12:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0013, Loss_2: 0.0039, Acc_1: 0.8750, Acc_2: 0.8047, 
2023-03-08 16:12:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0023, Loss_2: 0.0053, Acc_1: 0.7969, Acc_2: 0.7109, 
2023-03-08 16:12:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0022, Loss_2: 0.0056, Acc_1: 0.8359, Acc_2: 0.6953, 
2023-03-08 16:12:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0017, Loss_2: 0.0035, Acc_1: 0.8281, Acc_2: 0.7734, 
2023-03-08 16:12:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0033, Loss_2: 0.0054, Acc_1: 0.8125, Acc_2: 0.7266, 
2023-03-08 16:12:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0033, Loss_2: 0.0058, Acc_1: 0.8047, Acc_2: 0.7109, 
2023-03-08 16:12:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0023, Loss_2: 0.0048, Acc_1: 0.8516, Acc_2: 0.6484, 
2023-03-08 16:12:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0043, Acc_1: 0.8438, Acc_2: 0.7109, 
2023-03-08 16:12:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0021, Loss_2: 0.0064, Acc_1: 0.8516, Acc_2: 0.7031, 
2023-03-08 16:12:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0054, Loss_2: 0.0065, Acc_1: 0.6953, Acc_2: 0.6719, 
2023-03-08 16:12:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0032, Loss_2: 0.0057, Acc_1: 0.8359, Acc_2: 0.7422, 
2023-03-08 16:12:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0044, Loss_2: 0.0056, Acc_1: 0.7344, Acc_2: 0.6797, 
2023-03-08 16:12:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0059, Loss_2: 0.0199, Acc_1: 0.7266, Acc_2: 0.4119, F1-score_1: 0.6406, F1-score_2: 0.3108
2023-03-08 16:12:56 - __main__ - INFO - Epoch [10/100]
2023-03-08 16:13:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0023, Loss_2: 0.0040, Acc_1: 0.7969, Acc_2: 0.7500, 
2023-03-08 16:13:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0014, Loss_2: 0.0031, Acc_1: 0.8594, Acc_2: 0.7812, 
2023-03-08 16:13:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0023, Loss_2: 0.0048, Acc_1: 0.8125, Acc_2: 0.7656, 
2023-03-08 16:13:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0021, Loss_2: 0.0039, Acc_1: 0.8594, Acc_2: 0.7344, 
2023-03-08 16:13:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0025, Loss_2: 0.0043, Acc_1: 0.8672, Acc_2: 0.7812, 
2023-03-08 16:13:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0024, Loss_2: 0.0052, Acc_1: 0.8047, Acc_2: 0.6875, 
2023-03-08 16:13:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0032, Loss_2: 0.0054, Acc_1: 0.8047, Acc_2: 0.6953, 
2023-03-08 16:13:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0023, Loss_2: 0.0056, Acc_1: 0.8047, Acc_2: 0.6875, 
2023-03-08 16:13:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0016, Loss_2: 0.0045, Acc_1: 0.8438, Acc_2: 0.7031, 
2023-03-08 16:13:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0037, Loss_2: 0.0064, Acc_1: 0.8047, Acc_2: 0.6016, 
2023-03-08 16:13:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0028, Loss_2: 0.0054, Acc_1: 0.8203, Acc_2: 0.6875, 
2023-03-08 16:13:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0024, Loss_2: 0.0057, Acc_1: 0.8281, Acc_2: 0.6953, 
2023-03-08 16:13:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0052, Loss_2: 0.0219, Acc_1: 0.7700, Acc_2: 0.4079, F1-score_1: 0.7023, F1-score_2: 0.3351
2023-03-08 16:13:50 - __main__ - INFO - Epoch [11/100]
2023-03-08 16:13:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0018, Loss_2: 0.0035, Acc_1: 0.7969, Acc_2: 0.7109, 
2023-03-08 16:13:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0027, Loss_2: 0.0041, Acc_1: 0.7891, Acc_2: 0.7031, 
2023-03-08 16:14:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0013, Loss_2: 0.0039, Acc_1: 0.8281, Acc_2: 0.7578, 
2023-03-08 16:14:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0035, Acc_1: 0.8438, Acc_2: 0.7578, 
2023-03-08 16:14:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0019, Loss_2: 0.0044, Acc_1: 0.8125, Acc_2: 0.7344, 
2023-03-08 16:14:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0016, Loss_2: 0.0041, Acc_1: 0.8359, Acc_2: 0.7422, 
2023-03-08 16:14:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0013, Loss_2: 0.0039, Acc_1: 0.8359, Acc_2: 0.7500, 
2023-03-08 16:14:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0019, Loss_2: 0.0036, Acc_1: 0.8672, Acc_2: 0.7812, 
2023-03-08 16:14:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0019, Loss_2: 0.0037, Acc_1: 0.8594, Acc_2: 0.7734, 
2023-03-08 16:14:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0045, Acc_1: 0.8828, Acc_2: 0.7891, 
2023-03-08 16:14:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0014, Loss_2: 0.0048, Acc_1: 0.8203, Acc_2: 0.6875, 
2023-03-08 16:14:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0036, Loss_2: 0.0056, Acc_1: 0.8281, Acc_2: 0.6953, 
2023-03-08 16:14:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0049, Loss_2: 0.0231, Acc_1: 0.7541, Acc_2: 0.4146, F1-score_1: 0.6922, F1-score_2: 0.3364
2023-03-08 16:14:43 - __main__ - INFO - Epoch [12/100]
2023-03-08 16:14:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0022, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 16:14:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0023, Loss_2: 0.0050, Acc_1: 0.8281, Acc_2: 0.7656, 
2023-03-08 16:14:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0049, Acc_1: 0.8984, Acc_2: 0.6953, 
2023-03-08 16:14:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0046, Acc_1: 0.8984, Acc_2: 0.7500, 
2023-03-08 16:15:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0011, Loss_2: 0.0029, Acc_1: 0.8438, Acc_2: 0.7891, 
2023-03-08 16:15:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0014, Loss_2: 0.0037, Acc_1: 0.8516, Acc_2: 0.7656, 
2023-03-08 16:15:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0011, Loss_2: 0.0034, Acc_1: 0.8750, Acc_2: 0.8047, 
2023-03-08 16:15:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0013, Loss_2: 0.0033, Acc_1: 0.7969, Acc_2: 0.7266, 
2023-03-08 16:15:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0021, Loss_2: 0.0042, Acc_1: 0.8047, Acc_2: 0.6953, 
2023-03-08 16:15:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0037, Acc_1: 0.8281, Acc_2: 0.7266, 
2023-03-08 16:15:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0015, Loss_2: 0.0033, Acc_1: 0.8438, Acc_2: 0.7578, 
2023-03-08 16:15:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0025, Acc_1: 0.8516, Acc_2: 0.7891, 
2023-03-08 16:15:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0067, Loss_2: 0.0265, Acc_1: 0.7587, Acc_2: 0.4052, F1-score_1: 0.6894, F1-score_2: 0.3164
2023-03-08 16:15:36 - __main__ - INFO - Epoch [13/100]
2023-03-08 16:15:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0021, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 16:15:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0024, Acc_1: 0.8359, Acc_2: 0.7891, 
2023-03-08 16:15:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0023, Acc_1: 0.8828, Acc_2: 0.8203, 
2023-03-08 16:15:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0026, Acc_1: 0.8438, Acc_2: 0.7812, 
2023-03-08 16:15:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0023, Acc_1: 0.8750, Acc_2: 0.7812, 
2023-03-08 16:15:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0010, Loss_2: 0.0027, Acc_1: 0.8828, Acc_2: 0.8047, 
2023-03-08 16:16:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0011, Loss_2: 0.0039, Acc_1: 0.8281, Acc_2: 0.7188, 
2023-03-08 16:16:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0014, Loss_2: 0.0026, Acc_1: 0.8203, Acc_2: 0.7578, 
2023-03-08 16:16:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0016, Loss_2: 0.0027, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 16:16:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0037, Acc_1: 0.8906, Acc_2: 0.7656, 
2023-03-08 16:16:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0026, Acc_1: 0.8359, Acc_2: 0.7734, 
2023-03-08 16:16:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0014, Loss_2: 0.0032, Acc_1: 0.8750, Acc_2: 0.8203, 
2023-03-08 16:16:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0071, Loss_2: 0.0294, Acc_1: 0.7551, Acc_2: 0.4073, F1-score_1: 0.6911, F1-score_2: 0.3205
2023-03-08 16:16:29 - __main__ - INFO - Epoch [14/100]
2023-03-08 16:16:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0025, Acc_1: 0.8906, Acc_2: 0.8047, 
2023-03-08 16:16:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0026, Acc_1: 0.8672, Acc_2: 0.7969, 
2023-03-08 16:16:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0010, Loss_2: 0.0019, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-08 16:16:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0011, Loss_2: 0.0025, Acc_1: 0.8516, Acc_2: 0.7812, 
2023-03-08 16:16:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0025, Acc_1: 0.8672, Acc_2: 0.7891, 
2023-03-08 16:16:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0027, Acc_1: 0.8828, Acc_2: 0.8047, 
2023-03-08 16:16:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0025, Acc_1: 0.8438, Acc_2: 0.7578, 
2023-03-08 16:16:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0023, Acc_1: 0.8594, Acc_2: 0.8047, 
2023-03-08 16:17:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0012, Loss_2: 0.0033, Acc_1: 0.8359, Acc_2: 0.7578, 
2023-03-08 16:17:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0031, Acc_1: 0.8594, Acc_2: 0.7656, 
2023-03-08 16:17:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0025, Loss_2: 0.0039, Acc_1: 0.7969, Acc_2: 0.7656, 
2023-03-08 16:17:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0034, Acc_1: 0.8750, Acc_2: 0.7500, 
2023-03-08 16:17:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0074, Loss_2: 0.0285, Acc_1: 0.7519, Acc_2: 0.4073, F1-score_1: 0.6841, F1-score_2: 0.3274
2023-03-08 16:17:22 - __main__ - INFO - Epoch [15/100]
2023-03-08 16:17:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0019, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 16:17:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0023, Loss_2: 0.0034, Acc_1: 0.7969, Acc_2: 0.6875, 
2023-03-08 16:17:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0021, Acc_1: 0.8750, Acc_2: 0.8125, 
2023-03-08 16:17:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0024, Acc_1: 0.8281, Acc_2: 0.7578, 
2023-03-08 16:17:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0023, Acc_1: 0.8750, Acc_2: 0.8125, 
2023-03-08 16:17:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0020, Acc_1: 0.8906, Acc_2: 0.8281, 
2023-03-08 16:17:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0020, Acc_1: 0.8906, Acc_2: 0.8203, 
2023-03-08 16:17:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0030, Acc_1: 0.8984, Acc_2: 0.7969, 
2023-03-08 16:17:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0022, Acc_1: 0.8516, Acc_2: 0.7891, 
2023-03-08 16:17:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0015, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 16:18:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0031, Acc_1: 0.8750, Acc_2: 0.7578, 
2023-03-08 16:18:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0022, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 16:18:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0071, Loss_2: 0.0290, Acc_1: 0.7512, Acc_2: 0.3886, F1-score_1: 0.6837, F1-score_2: 0.3177
2023-03-08 16:18:16 - __main__ - INFO - Epoch [16/100]
2023-03-08 16:18:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0024, Acc_1: 0.8281, Acc_2: 0.7578, 
2023-03-08 16:18:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0022, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-08 16:18:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0018, Acc_1: 0.8672, Acc_2: 0.7969, 
2023-03-08 16:18:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 16:18:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0016, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 16:18:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0021, Acc_1: 0.8750, Acc_2: 0.7891, 
2023-03-08 16:18:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0014, Loss_2: 0.0024, Acc_1: 0.8125, Acc_2: 0.7578, 
2023-03-08 16:18:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0023, Acc_1: 0.8828, Acc_2: 0.7734, 
2023-03-08 16:18:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0022, Acc_1: 0.8359, Acc_2: 0.7656, 
2023-03-08 16:18:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0015, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 16:18:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0013, Loss_2: 0.0030, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 16:18:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0021, Acc_1: 0.8750, Acc_2: 0.7969, 
2023-03-08 16:19:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0086, Loss_2: 0.0311, Acc_1: 0.7522, Acc_2: 0.4025, F1-score_1: 0.6894, F1-score_2: 0.3155
2023-03-08 16:19:09 - __main__ - INFO - Epoch [17/100]
2023-03-08 16:19:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.9141, Acc_2: 0.8438, 
2023-03-08 16:19:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0018, Acc_1: 0.9375, Acc_2: 0.8438, 
2023-03-08 16:19:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0014, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-08 16:19:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0020, Loss_2: 0.0018, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 16:19:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0018, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 16:19:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0013, Loss_2: 0.0028, Acc_1: 0.8281, Acc_2: 0.7422, 
2023-03-08 16:19:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0017, Loss_2: 0.0015, Acc_1: 0.8750, Acc_2: 0.8203, 
2023-03-08 16:19:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0018, Acc_1: 0.8906, Acc_2: 0.8281, 
2023-03-08 16:19:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:19:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0018, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 16:19:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0023, Acc_1: 0.8438, Acc_2: 0.7812, 
2023-03-08 16:19:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0022, Acc_1: 0.8438, Acc_2: 0.7734, 
2023-03-08 16:20:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0090, Loss_2: 0.0333, Acc_1: 0.7542, Acc_2: 0.3989, F1-score_1: 0.6869, F1-score_2: 0.3076
2023-03-08 16:20:02 - __main__ - INFO - Epoch [18/100]
2023-03-08 16:20:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0020, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 16:20:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:20:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0014, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 16:20:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0018, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-08 16:20:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0019, Loss_2: 0.0025, Acc_1: 0.7969, Acc_2: 0.7656, 
2023-03-08 16:20:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0024, Acc_1: 0.8750, Acc_2: 0.7578, 
2023-03-08 16:20:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 16:20:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0014, Loss_2: 0.0020, Acc_1: 0.8359, Acc_2: 0.7656, 
2023-03-08 16:20:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0011, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 16:20:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0029, Acc_1: 0.8828, Acc_2: 0.7812, 
2023-03-08 16:20:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0028, Acc_1: 0.8281, Acc_2: 0.7812, 
2023-03-08 16:20:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0018, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-08 16:20:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0093, Loss_2: 0.0331, Acc_1: 0.7605, Acc_2: 0.3920, F1-score_1: 0.6967, F1-score_2: 0.3184
2023-03-08 16:20:55 - __main__ - INFO - Epoch [19/100]
2023-03-08 16:21:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0017, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 16:21:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 16:21:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0013, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 16:21:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0018, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 16:21:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0018, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 16:21:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0021, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 16:21:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0014, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-08 16:21:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0018, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-08 16:21:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0025, Acc_1: 0.8906, Acc_2: 0.8281, 
2023-03-08 16:21:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0016, Acc_1: 0.8594, Acc_2: 0.8047, 
2023-03-08 16:21:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0013, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 16:21:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0026, Acc_1: 0.8359, Acc_2: 0.7500, 
2023-03-08 16:21:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0091, Loss_2: 0.0355, Acc_1: 0.7627, Acc_2: 0.4003, F1-score_1: 0.6985, F1-score_2: 0.3292
2023-03-08 16:21:48 - __main__ - INFO - Epoch [20/100]
2023-03-08 16:21:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-08 16:21:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 16:22:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 16:22:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0015, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-08 16:22:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0010, Loss_2: 0.0020, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-08 16:22:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.9297, Acc_2: 0.8828, 
2023-03-08 16:22:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-08 16:22:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0020, Acc_1: 0.8984, Acc_2: 0.8203, 
2023-03-08 16:22:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 16:22:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0011, Acc_1: 0.8594, Acc_2: 0.7969, 
2023-03-08 16:22:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0018, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 16:22:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0022, Acc_1: 0.8516, Acc_2: 0.7812, 
2023-03-08 16:22:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0093, Loss_2: 0.0363, Acc_1: 0.7505, Acc_2: 0.4057, F1-score_1: 0.6816, F1-score_2: 0.3193
2023-03-08 16:22:41 - __main__ - INFO - Epoch [21/100]
2023-03-08 16:22:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0013, Acc_1: 0.9453, Acc_2: 0.8750, 
2023-03-08 16:22:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 16:22:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0020, Acc_1: 0.8906, Acc_2: 0.8281, 
2023-03-08 16:22:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0016, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 16:23:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0018, Acc_1: 0.8594, Acc_2: 0.8047, 
2023-03-08 16:23:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 16:23:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0022, Acc_1: 0.8516, Acc_2: 0.7656, 
2023-03-08 16:23:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0014, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 16:23:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0020, Acc_1: 0.8516, Acc_2: 0.7734, 
2023-03-08 16:23:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0016, Acc_1: 0.8203, Acc_2: 0.7812, 
2023-03-08 16:23:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0016, Acc_1: 0.8438, Acc_2: 0.7891, 
2023-03-08 16:23:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.9219, Acc_2: 0.8594, 
2023-03-08 16:23:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0098, Loss_2: 0.0383, Acc_1: 0.7512, Acc_2: 0.4000, F1-score_1: 0.6763, F1-score_2: 0.3221
2023-03-08 16:23:35 - __main__ - INFO - Epoch [22/100]
2023-03-08 16:23:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 16:23:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 16:23:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-08 16:23:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 16:23:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0009, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 16:23:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 16:24:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0017, Acc_1: 0.8281, Acc_2: 0.7812, 
2023-03-08 16:24:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 16:24:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8594, Acc_2: 0.8047, 
2023-03-08 16:24:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 16:24:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0010, Loss_2: 0.0017, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 16:24:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0016, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-08 16:24:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0081, Loss_2: 0.0382, Acc_1: 0.7638, Acc_2: 0.3945, F1-score_1: 0.6950, F1-score_2: 0.3223
2023-03-08 16:24:28 - __main__ - INFO - Epoch [23/100]
2023-03-08 16:24:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 16:24:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 16:24:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 16:24:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 16:24:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:24:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 16:24:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 16:24:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 16:25:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 16:25:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0011, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-08 16:25:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0015, Loss_2: 0.0017, Acc_1: 0.7969, Acc_2: 0.7578, 
2023-03-08 16:25:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0011, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 16:25:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0408, Acc_1: 0.7549, Acc_2: 0.3978, F1-score_1: 0.6863, F1-score_2: 0.3244
2023-03-08 16:25:21 - __main__ - INFO - Epoch [24/100]
2023-03-08 16:25:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 16:25:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 16:25:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 16:25:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 16:25:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 16:25:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8438, Acc_2: 0.7891, 
2023-03-08 16:25:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 16:25:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 16:25:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 16:25:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 16:26:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0014, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 16:26:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8984, 
2023-03-08 16:26:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0093, Loss_2: 0.0374, Acc_1: 0.7607, Acc_2: 0.4025, F1-score_1: 0.6874, F1-score_2: 0.3321
2023-03-08 16:26:14 - __main__ - INFO - Epoch [25/100]
2023-03-08 16:26:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 16:26:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.9297, 
2023-03-08 16:26:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 16:26:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:26:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 16:26:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0015, Acc_1: 0.8047, Acc_2: 0.7656, 
2023-03-08 16:26:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 16:26:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 16:26:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0018, Acc_1: 0.8828, Acc_2: 0.8047, 
2023-03-08 16:26:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-08 16:26:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 16:26:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0015, Acc_1: 0.8438, Acc_2: 0.7891, 
2023-03-08 16:27:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0089, Loss_2: 0.0373, Acc_1: 0.7670, Acc_2: 0.3957, F1-score_1: 0.6920, F1-score_2: 0.3201
2023-03-08 16:27:07 - __main__ - INFO - Epoch [26/100]
2023-03-08 16:27:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-08 16:27:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 16:27:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-08 16:27:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 16:27:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 16:27:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-08 16:27:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0015, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-08 16:27:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0021, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-08 16:27:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0012, Loss_2: 0.0016, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 16:27:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8203, 
2023-03-08 16:27:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0012, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 16:27:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-08 16:28:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0072, Loss_2: 0.0356, Acc_1: 0.7391, Acc_2: 0.3983, F1-score_1: 0.6777, F1-score_2: 0.3253
2023-03-08 16:28:01 - __main__ - INFO - Epoch [27/100]
2023-03-08 16:28:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0013, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-08 16:28:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 16:28:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 16:28:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-08 16:28:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 16:28:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 16:28:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0013, Loss_2: 0.0029, Acc_1: 0.7891, Acc_2: 0.7656, 
2023-03-08 16:28:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 16:28:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0012, Acc_1: 0.8516, Acc_2: 0.7812, 
2023-03-08 16:28:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0012, Acc_1: 0.8594, Acc_2: 0.7969, 
2023-03-08 16:28:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 16:28:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 16:28:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0082, Loss_2: 0.0370, Acc_1: 0.7661, Acc_2: 0.3888, F1-score_1: 0.6959, F1-score_2: 0.3166
2023-03-08 16:28:54 - __main__ - INFO - Epoch [28/100]
2023-03-08 16:28:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 16:29:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0009, Loss_2: 0.0017, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 16:29:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 16:29:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 16:29:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 16:29:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 16:29:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0015, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-08 16:29:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 16:29:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 16:29:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0017, Acc_1: 0.8281, Acc_2: 0.7891, 
2023-03-08 16:29:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-08 16:29:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0018, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-08 16:29:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0111, Loss_2: 0.0378, Acc_1: 0.7422, Acc_2: 0.3937, F1-score_1: 0.6808, F1-score_2: 0.3190
2023-03-08 16:29:47 - __main__ - INFO - Epoch [29/100]
2023-03-08 16:29:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0011, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 16:29:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 16:29:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 16:30:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.8984, Acc_2: 0.8281, 
2023-03-08 16:30:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 16:30:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 16:30:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.8828, 
2023-03-08 16:30:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 16:30:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 16:30:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 16:30:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 16:30:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 16:30:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0089, Loss_2: 0.0373, Acc_1: 0.7422, Acc_2: 0.4081, F1-score_1: 0.6749, F1-score_2: 0.3328
2023-03-08 16:30:41 - __main__ - INFO - Epoch [30/100]
2023-03-08 16:30:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0011, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-08 16:30:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 16:30:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 16:30:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 16:31:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 16:31:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-08 16:31:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-08 16:31:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-08 16:31:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 16:31:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 16:31:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0015, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 16:31:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 16:31:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0094, Loss_2: 0.0430, Acc_1: 0.7539, Acc_2: 0.3964, F1-score_1: 0.6801, F1-score_2: 0.3209
2023-03-08 16:31:34 - __main__ - INFO - Epoch [31/100]
2023-03-08 16:31:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 16:31:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0013, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 16:31:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-08 16:31:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-08 16:31:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 16:31:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 16:32:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 16:32:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-08 16:32:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 16:32:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 16:32:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:32:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 16:32:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0086, Loss_2: 0.0399, Acc_1: 0.7485, Acc_2: 0.3908, F1-score_1: 0.6793, F1-score_2: 0.3260
2023-03-08 16:32:27 - __main__ - INFO - Epoch [32/100]
2023-03-08 16:32:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 16:32:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 16:32:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 16:32:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 16:32:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 16:32:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:32:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 16:32:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 16:33:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 16:33:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 16:33:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 16:33:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 16:33:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0103, Loss_2: 0.0424, Acc_1: 0.7554, Acc_2: 0.4012, F1-score_1: 0.6892, F1-score_2: 0.3223
2023-03-08 16:33:20 - __main__ - INFO - Epoch [33/100]
2023-03-08 16:33:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 16:33:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 16:33:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 16:33:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 16:33:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 16:33:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 16:33:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 16:33:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 16:33:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 16:33:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 16:34:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 16:34:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 16:34:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0115, Loss_2: 0.0439, Acc_1: 0.7585, Acc_2: 0.3867, F1-score_1: 0.6868, F1-score_2: 0.3156
2023-03-08 16:34:13 - __main__ - INFO - Epoch [34/100]
2023-03-08 16:34:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 16:34:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 16:34:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 16:34:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 16:34:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 16:34:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-08 16:34:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 16:34:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 16:34:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 16:34:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 16:34:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 16:34:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 16:35:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0079, Loss_2: 0.0400, Acc_1: 0.7561, Acc_2: 0.3978, F1-score_1: 0.6893, F1-score_2: 0.3267
2023-03-08 16:35:07 - __main__ - INFO - Epoch [35/100]
2023-03-08 16:35:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 16:35:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 16:35:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-08 16:35:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 16:35:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 16:35:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 16:35:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 16:35:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-08 16:35:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 16:35:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 16:35:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 16:35:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 16:36:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0113, Loss_2: 0.0390, Acc_1: 0.7592, Acc_2: 0.4032, F1-score_1: 0.6911, F1-score_2: 0.3274
2023-03-08 16:36:00 - __main__ - INFO - Epoch [36/100]
2023-03-08 16:36:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 16:36:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 16:36:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 16:36:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 16:36:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 16:36:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 16:36:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 16:36:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9531, Acc_2: 0.9297, 
2023-03-08 16:36:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 16:36:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 16:36:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 16:36:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 16:36:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0100, Loss_2: 0.0406, Acc_1: 0.7291, Acc_2: 0.3915, F1-score_1: 0.6678, F1-score_2: 0.3076
2023-03-08 16:36:53 - __main__ - INFO - Epoch [37/100]
2023-03-08 16:36:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 16:37:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 16:37:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:37:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 16:37:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 16:37:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8594, Acc_2: 0.7969, 
2023-03-08 16:37:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 16:37:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-08 16:37:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 16:37:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:37:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 16:37:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:37:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0445, Acc_1: 0.7510, Acc_2: 0.3991, F1-score_1: 0.6834, F1-score_2: 0.3264
2023-03-08 16:37:46 - __main__ - INFO - Epoch [38/100]
2023-03-08 16:37:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0011, Loss_2: 0.0014, Acc_1: 0.8594, Acc_2: 0.7891, 
2023-03-08 16:37:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 16:37:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 16:38:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0013, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 16:38:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 16:38:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 16:38:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 16:38:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-08 16:38:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0011, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-08 16:38:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 16:38:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:38:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0014, Acc_1: 0.9375, Acc_2: 0.8594, 
2023-03-08 16:38:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0110, Loss_2: 0.0407, Acc_1: 0.7609, Acc_2: 0.4064, F1-score_1: 0.6957, F1-score_2: 0.3186
2023-03-08 16:38:40 - __main__ - INFO - Epoch [39/100]
2023-03-08 16:38:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 16:38:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 16:38:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 16:38:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 16:38:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-08 16:39:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 16:39:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 16:39:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 16:39:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-08 16:39:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:39:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 16:39:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0013, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 16:39:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0098, Loss_2: 0.0439, Acc_1: 0.7588, Acc_2: 0.3899, F1-score_1: 0.6922, F1-score_2: 0.3205
2023-03-08 16:39:33 - __main__ - INFO - Epoch [40/100]
2023-03-08 16:39:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 16:39:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0016, Acc_1: 0.8203, Acc_2: 0.7578, 
2023-03-08 16:39:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-08 16:39:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 16:39:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 16:39:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 16:39:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 16:40:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 16:40:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 16:40:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 16:40:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-08 16:40:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8203, 
2023-03-08 16:40:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0115, Loss_2: 0.0421, Acc_1: 0.7542, Acc_2: 0.3978, F1-score_1: 0.6911, F1-score_2: 0.3285
2023-03-08 16:40:26 - __main__ - INFO - Epoch [41/100]
2023-03-08 16:40:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 16:40:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 16:40:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 16:40:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 16:40:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 16:40:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-08 16:40:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 16:40:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 16:40:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 16:41:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 16:41:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 16:41:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 16:41:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0112, Loss_2: 0.0413, Acc_1: 0.7458, Acc_2: 0.4052, F1-score_1: 0.6845, F1-score_2: 0.3236
2023-03-08 16:41:19 - __main__ - INFO - Epoch [42/100]
2023-03-08 16:41:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 16:41:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 16:41:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 16:41:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0013, Acc_1: 0.8203, Acc_2: 0.7734, 
2023-03-08 16:41:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 16:41:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 16:41:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 16:41:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 16:41:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 16:41:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 16:41:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 16:42:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 16:42:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0078, Loss_2: 0.0419, Acc_1: 0.7619, Acc_2: 0.3961, F1-score_1: 0.6901, F1-score_2: 0.3138
2023-03-08 16:42:12 - __main__ - INFO - Epoch [43/100]
2023-03-08 16:42:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 16:42:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 16:42:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 16:42:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 16:42:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-08 16:42:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 16:42:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 16:42:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 16:42:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 16:42:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-08 16:42:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 16:42:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 16:43:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0119, Loss_2: 0.0482, Acc_1: 0.7303, Acc_2: 0.4013, F1-score_1: 0.6656, F1-score_2: 0.3223
2023-03-08 16:43:06 - __main__ - INFO - Epoch [44/100]
2023-03-08 16:43:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 16:43:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 16:43:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 16:43:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 16:43:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 16:43:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 16:43:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:43:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9141, 
2023-03-08 16:43:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 16:43:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 16:43:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:43:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 16:43:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0121, Loss_2: 0.0456, Acc_1: 0.7595, Acc_2: 0.3942, F1-score_1: 0.6984, F1-score_2: 0.3204
2023-03-08 16:43:59 - __main__ - INFO - Epoch [45/100]
2023-03-08 16:44:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:44:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 16:44:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 16:44:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 16:44:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 16:44:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 16:44:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 16:44:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 16:44:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 16:44:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:44:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 16:44:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 16:44:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0097, Loss_2: 0.0459, Acc_1: 0.7442, Acc_2: 0.4034, F1-score_1: 0.6849, F1-score_2: 0.3264
2023-03-08 16:44:53 - __main__ - INFO - Epoch [46/100]
2023-03-08 16:44:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-08 16:45:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 16:45:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 16:45:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 16:45:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 16:45:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 16:45:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 16:45:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 16:45:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 16:45:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 16:45:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 16:45:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 16:45:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0476, Acc_1: 0.7529, Acc_2: 0.4034, F1-score_1: 0.6913, F1-score_2: 0.3174
2023-03-08 16:45:46 - __main__ - INFO - Epoch [47/100]
2023-03-08 16:45:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 16:45:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 16:45:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 16:46:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 16:46:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 16:46:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 16:46:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:46:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 16:46:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 16:46:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0011, Acc_1: 0.9297, Acc_2: 0.8750, 
2023-03-08 16:46:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 16:46:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 16:46:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0111, Loss_2: 0.0446, Acc_1: 0.7617, Acc_2: 0.3972, F1-score_1: 0.6978, F1-score_2: 0.3161
2023-03-08 16:46:39 - __main__ - INFO - Epoch [48/100]
2023-03-08 16:46:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:46:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 16:46:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-08 16:46:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 16:46:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-08 16:47:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 16:47:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 16:47:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 16:47:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 16:47:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:47:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 16:47:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 16:47:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0133, Loss_2: 0.0477, Acc_1: 0.7525, Acc_2: 0.4006, F1-score_1: 0.6906, F1-score_2: 0.3298
2023-03-08 16:47:33 - __main__ - INFO - Epoch [49/100]
2023-03-08 16:47:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 16:47:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 16:47:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 16:47:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 16:47:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 16:47:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 16:47:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 16:48:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:48:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 16:48:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 16:48:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:48:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 16:48:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0143, Loss_2: 0.0477, Acc_1: 0.7413, Acc_2: 0.4006, F1-score_1: 0.6837, F1-score_2: 0.3223
2023-03-08 16:48:26 - __main__ - INFO - Epoch [50/100]
2023-03-08 16:48:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 16:48:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 16:48:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 16:48:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 16:48:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8047, 
2023-03-08 16:48:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8750, 
2023-03-08 16:48:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 16:48:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 16:48:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 16:49:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 16:49:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 16:49:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:49:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0108, Loss_2: 0.0519, Acc_1: 0.7605, Acc_2: 0.4022, F1-score_1: 0.7002, F1-score_2: 0.3252
2023-03-08 16:49:19 - __main__ - INFO - Epoch [51/100]
2023-03-08 16:49:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 16:49:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 16:49:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 16:49:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 16:49:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 16:49:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 16:49:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 16:49:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-08 16:49:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 16:49:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 16:49:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 16:50:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 16:50:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0111, Loss_2: 0.0499, Acc_1: 0.7556, Acc_2: 0.3979, F1-score_1: 0.6921, F1-score_2: 0.3233
2023-03-08 16:50:13 - __main__ - INFO - Epoch [52/100]
2023-03-08 16:50:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 16:50:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-08 16:50:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 16:50:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 16:50:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-08 16:50:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 16:50:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 16:50:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0016, Loss_2: 0.0018, Acc_1: 0.8047, Acc_2: 0.7422, 
2023-03-08 16:50:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 16:50:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 16:50:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 16:50:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 16:51:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0127, Loss_2: 0.0464, Acc_1: 0.7425, Acc_2: 0.4144, F1-score_1: 0.6797, F1-score_2: 0.3328
2023-03-08 16:51:06 - __main__ - INFO - Epoch [53/100]
2023-03-08 16:51:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 16:51:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 16:51:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 16:51:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 16:51:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-08 16:51:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 16:51:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-08 16:51:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 16:51:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 16:51:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 16:51:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 16:51:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 16:51:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0113, Loss_2: 0.0484, Acc_1: 0.7666, Acc_2: 0.4010, F1-score_1: 0.7039, F1-score_2: 0.3298
2023-03-08 16:51:59 - __main__ - INFO - Epoch [54/100]
2023-03-08 16:52:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 16:52:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 16:52:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 16:52:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 16:52:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-08 16:52:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 16:52:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:52:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 16:52:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 16:52:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 16:52:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 16:52:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:52:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0102, Loss_2: 0.0507, Acc_1: 0.7665, Acc_2: 0.3959, F1-score_1: 0.7027, F1-score_2: 0.3183
2023-03-08 16:52:52 - __main__ - INFO - Epoch [55/100]
2023-03-08 16:52:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 16:53:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 16:53:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 16:53:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 16:53:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 16:53:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-08 16:53:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 16:53:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 16:53:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 16:53:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 16:53:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 16:53:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 16:53:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0517, Acc_1: 0.7515, Acc_2: 0.4029, F1-score_1: 0.6911, F1-score_2: 0.3289
2023-03-08 16:53:46 - __main__ - INFO - Epoch [56/100]
2023-03-08 16:53:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:53:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:53:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-08 16:54:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 16:54:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:54:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 16:54:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 16:54:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0023, Loss_2: 0.0007, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 16:54:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 16:54:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 16:54:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 16:54:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 16:54:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0111, Loss_2: 0.0485, Acc_1: 0.7565, Acc_2: 0.4003, F1-score_1: 0.6915, F1-score_2: 0.3294
2023-03-08 16:54:39 - __main__ - INFO - Epoch [57/100]
2023-03-08 16:54:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 16:54:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-08 16:54:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:54:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 16:54:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 16:55:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 16:55:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 16:55:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 16:55:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 16:55:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 16:55:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9609, Acc_2: 0.9219, 
2023-03-08 16:55:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 16:55:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0541, Acc_1: 0.7536, Acc_2: 0.3966, F1-score_1: 0.6887, F1-score_2: 0.3246
2023-03-08 16:55:32 - __main__ - INFO - Epoch [58/100]
2023-03-08 16:55:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-08 16:55:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 16:55:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 16:55:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 16:55:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 16:55:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 16:55:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-08 16:56:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 16:56:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 16:56:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-08 16:56:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 16:56:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 16:56:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0089, Loss_2: 0.0519, Acc_1: 0.7653, Acc_2: 0.3923, F1-score_1: 0.7047, F1-score_2: 0.3161
2023-03-08 16:56:26 - __main__ - INFO - Epoch [59/100]
2023-03-08 16:56:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 16:56:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 16:56:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 16:56:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 16:56:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 16:56:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 16:56:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 16:56:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 16:56:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 16:57:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 16:57:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 16:57:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0012, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 16:57:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0110, Loss_2: 0.0515, Acc_1: 0.7361, Acc_2: 0.4066, F1-score_1: 0.6813, F1-score_2: 0.3332
2023-03-08 16:57:19 - __main__ - INFO - Epoch [60/100]
2023-03-08 16:57:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 16:57:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 16:57:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 16:57:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 16:57:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 16:57:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 16:57:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 16:57:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 16:57:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 16:57:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 16:57:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 16:58:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 16:58:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0114, Loss_2: 0.0497, Acc_1: 0.7532, Acc_2: 0.4027, F1-score_1: 0.6873, F1-score_2: 0.3261
2023-03-08 16:58:12 - __main__ - INFO - Epoch [61/100]
2023-03-08 16:58:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 16:58:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 16:58:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 16:58:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 16:58:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 16:58:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 16:58:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 16:58:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 16:58:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 16:58:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9531, Acc_2: 0.9453, 
2023-03-08 16:58:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 16:58:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 16:59:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0509, Acc_1: 0.7398, Acc_2: 0.3944, F1-score_1: 0.6708, F1-score_2: 0.3174
2023-03-08 16:59:06 - __main__ - INFO - Epoch [62/100]
2023-03-08 16:59:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 16:59:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 16:59:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 16:59:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 16:59:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 16:59:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 16:59:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 16:59:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 16:59:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 16:59:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 16:59:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 16:59:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-08 16:59:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0132, Loss_2: 0.0490, Acc_1: 0.7447, Acc_2: 0.3995, F1-score_1: 0.6862, F1-score_2: 0.3204
2023-03-08 16:59:59 - __main__ - INFO - Epoch [63/100]
2023-03-08 17:00:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 17:00:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:00:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-08 17:00:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 17:00:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:00:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 17:00:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 17:00:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 17:00:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 17:00:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 17:00:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 17:00:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 17:00:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0110, Loss_2: 0.0493, Acc_1: 0.7505, Acc_2: 0.4064, F1-score_1: 0.6878, F1-score_2: 0.3246
2023-03-08 17:00:52 - __main__ - INFO - Epoch [64/100]
2023-03-08 17:00:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 17:01:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 17:01:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 17:01:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:01:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 17:01:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 17:01:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 17:01:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 17:01:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 17:01:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 17:01:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:01:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:01:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0110, Loss_2: 0.0549, Acc_1: 0.7583, Acc_2: 0.3833, F1-score_1: 0.6967, F1-score_2: 0.3097
2023-03-08 17:01:45 - __main__ - INFO - Epoch [65/100]
2023-03-08 17:01:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:01:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 17:01:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 17:02:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:02:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-08 17:02:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 17:02:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 17:02:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 17:02:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:02:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 17:02:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:02:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 17:02:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0096, Loss_2: 0.0486, Acc_1: 0.7529, Acc_2: 0.3957, F1-score_1: 0.6894, F1-score_2: 0.3172
2023-03-08 17:02:39 - __main__ - INFO - Epoch [66/100]
2023-03-08 17:02:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 17:02:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 17:02:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 17:02:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-08 17:02:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:03:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 17:03:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:03:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 17:03:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 17:03:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 17:03:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 17:03:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 17:03:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0098, Loss_2: 0.0516, Acc_1: 0.7437, Acc_2: 0.3913, F1-score_1: 0.6822, F1-score_2: 0.3103
2023-03-08 17:03:32 - __main__ - INFO - Epoch [67/100]
2023-03-08 17:03:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:03:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:03:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:03:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 17:03:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 17:03:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 17:03:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-08 17:04:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 17:04:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9297, Acc_2: 0.8828, 
2023-03-08 17:04:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 17:04:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 17:04:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 17:04:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0091, Loss_2: 0.0548, Acc_1: 0.7537, Acc_2: 0.3972, F1-score_1: 0.6913, F1-score_2: 0.3166
2023-03-08 17:04:26 - __main__ - INFO - Epoch [68/100]
2023-03-08 17:04:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 17:04:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 17:04:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-08 17:04:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 17:04:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-08 17:04:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 17:04:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 17:04:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 17:04:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 17:05:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-08 17:05:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-08 17:05:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:05:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0103, Loss_2: 0.0477, Acc_1: 0.7364, Acc_2: 0.3969, F1-score_1: 0.6773, F1-score_2: 0.3238
2023-03-08 17:05:19 - __main__ - INFO - Epoch [69/100]
2023-03-08 17:05:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 17:05:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 17:05:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 17:05:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 17:05:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 17:05:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0016, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 17:05:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-08 17:05:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-08 17:05:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:05:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-08 17:05:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 17:06:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 17:06:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0095, Loss_2: 0.0492, Acc_1: 0.7361, Acc_2: 0.3978, F1-score_1: 0.6790, F1-score_2: 0.3231
2023-03-08 17:06:12 - __main__ - INFO - Epoch [70/100]
2023-03-08 17:06:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 17:06:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 17:06:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 17:06:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 17:06:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 17:06:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 17:06:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 17:06:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 17:06:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-08 17:06:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-08 17:06:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 17:06:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 17:07:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0099, Loss_2: 0.0512, Acc_1: 0.7468, Acc_2: 0.4035, F1-score_1: 0.6910, F1-score_2: 0.3233
2023-03-08 17:07:06 - __main__ - INFO - Epoch [71/100]
2023-03-08 17:07:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:07:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 17:07:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 17:07:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 17:07:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 17:07:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 17:07:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:07:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:07:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:07:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 17:07:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 17:07:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 17:07:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0091, Loss_2: 0.0458, Acc_1: 0.7508, Acc_2: 0.4020, F1-score_1: 0.6899, F1-score_2: 0.3225
2023-03-08 17:07:59 - __main__ - INFO - Epoch [72/100]
2023-03-08 17:08:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 17:08:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 17:08:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 17:08:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 17:08:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 17:08:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 17:08:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 17:08:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8203, Acc_2: 0.7812, 
2023-03-08 17:08:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 17:08:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 17:08:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 17:08:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:08:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0093, Loss_2: 0.0464, Acc_1: 0.7417, Acc_2: 0.4003, F1-score_1: 0.6850, F1-score_2: 0.3217
2023-03-08 17:08:52 - __main__ - INFO - Epoch [73/100]
2023-03-08 17:08:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 17:09:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 17:09:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 17:09:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-08 17:09:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 17:09:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 17:09:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 17:09:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 17:09:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 17:09:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 17:09:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:09:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 17:09:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0089, Loss_2: 0.0473, Acc_1: 0.7497, Acc_2: 0.4057, F1-score_1: 0.6876, F1-score_2: 0.3273
2023-03-08 17:09:45 - __main__ - INFO - Epoch [74/100]
2023-03-08 17:09:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:09:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 17:09:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 17:10:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 17:10:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 17:10:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 17:10:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 17:10:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 17:10:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 17:10:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 17:10:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 17:10:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 17:10:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0494, Acc_1: 0.7515, Acc_2: 0.4035, F1-score_1: 0.6859, F1-score_2: 0.3278
2023-03-08 17:10:39 - __main__ - INFO - Epoch [75/100]
2023-03-08 17:10:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:10:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-08 17:10:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 17:10:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 17:10:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:11:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 17:11:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:11:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:11:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 17:11:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 17:11:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 17:11:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 17:11:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0086, Loss_2: 0.0493, Acc_1: 0.7622, Acc_2: 0.3981, F1-score_1: 0.6979, F1-score_2: 0.3210
2023-03-08 17:11:32 - __main__ - INFO - Epoch [76/100]
2023-03-08 17:11:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 17:11:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:11:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 17:11:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:11:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:11:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 17:11:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 17:12:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 17:12:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-08 17:12:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 17:12:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 17:12:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:12:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0086, Loss_2: 0.0466, Acc_1: 0.7622, Acc_2: 0.4030, F1-score_1: 0.6974, F1-score_2: 0.3197
2023-03-08 17:12:25 - __main__ - INFO - Epoch [77/100]
2023-03-08 17:12:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 17:12:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 17:12:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 17:12:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 17:12:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 17:12:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 17:12:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 17:12:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:12:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:13:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:13:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 17:13:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 17:13:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0091, Loss_2: 0.0501, Acc_1: 0.7590, Acc_2: 0.3956, F1-score_1: 0.6956, F1-score_2: 0.3231
2023-03-08 17:13:18 - __main__ - INFO - Epoch [78/100]
2023-03-08 17:13:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 17:13:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:13:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 17:13:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9141, 
2023-03-08 17:13:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:13:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 17:13:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 17:13:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-08 17:13:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 17:13:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-08 17:13:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0010, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 17:14:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 17:14:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0095, Loss_2: 0.0525, Acc_1: 0.7573, Acc_2: 0.3932, F1-score_1: 0.6952, F1-score_2: 0.3236
2023-03-08 17:14:11 - __main__ - INFO - Epoch [79/100]
2023-03-08 17:14:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 17:14:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:14:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 17:14:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:14:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 17:14:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 17:14:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 17:14:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 17:14:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:14:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 17:14:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 17:14:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 17:15:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0080, Loss_2: 0.0509, Acc_1: 0.7532, Acc_2: 0.4069, F1-score_1: 0.6929, F1-score_2: 0.3231
2023-03-08 17:15:05 - __main__ - INFO - Epoch [80/100]
2023-03-08 17:15:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 17:15:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 17:15:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 17:15:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 17:15:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 17:15:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0017, Acc_1: 0.8516, Acc_2: 0.7734, 
2023-03-08 17:15:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:15:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 17:15:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-08 17:15:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 17:15:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 17:15:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 17:15:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0081, Loss_2: 0.0509, Acc_1: 0.7512, Acc_2: 0.4042, F1-score_1: 0.6905, F1-score_2: 0.3187
2023-03-08 17:15:58 - __main__ - INFO - Epoch [81/100]
2023-03-08 17:16:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 17:16:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 17:16:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:16:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 17:16:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 17:16:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 17:16:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 17:16:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-08 17:16:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-08 17:16:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 17:16:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:16:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 17:16:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0081, Loss_2: 0.0492, Acc_1: 0.7539, Acc_2: 0.4093, F1-score_1: 0.6834, F1-score_2: 0.3247
2023-03-08 17:16:51 - __main__ - INFO - Epoch [82/100]
2023-03-08 17:16:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 17:17:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:17:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 17:17:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 17:17:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 17:17:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 17:17:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 17:17:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 17:17:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:17:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 17:17:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:17:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-08 17:17:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0100, Loss_2: 0.0555, Acc_1: 0.7542, Acc_2: 0.3927, F1-score_1: 0.6911, F1-score_2: 0.3237
2023-03-08 17:17:45 - __main__ - INFO - Epoch [83/100]
2023-03-08 17:17:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 17:17:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 17:17:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 17:18:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:18:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:18:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 17:18:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:18:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 17:18:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:18:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 17:18:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 17:18:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:18:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0119, Loss_2: 0.0504, Acc_1: 0.7485, Acc_2: 0.4064, F1-score_1: 0.6833, F1-score_2: 0.3326
2023-03-08 17:18:38 - __main__ - INFO - Epoch [84/100]
2023-03-08 17:18:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 17:18:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 17:18:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:18:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:18:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 17:19:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:19:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:19:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 17:19:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 17:19:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:19:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:19:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 17:19:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0093, Loss_2: 0.0499, Acc_1: 0.7563, Acc_2: 0.3988, F1-score_1: 0.6893, F1-score_2: 0.3229
2023-03-08 17:19:31 - __main__ - INFO - Epoch [85/100]
2023-03-08 17:19:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 17:19:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 17:19:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 17:19:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 17:19:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 17:19:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 17:19:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:20:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 17:20:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-08 17:20:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 17:20:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 17:20:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 17:20:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0104, Loss_2: 0.0500, Acc_1: 0.7520, Acc_2: 0.4008, F1-score_1: 0.6867, F1-score_2: 0.3281
2023-03-08 17:20:25 - __main__ - INFO - Epoch [86/100]
2023-03-08 17:20:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:20:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:20:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 17:20:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:20:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:20:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 17:20:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 17:20:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:20:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 17:21:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 17:21:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:21:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 17:21:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0100, Loss_2: 0.0486, Acc_1: 0.7525, Acc_2: 0.4042, F1-score_1: 0.6881, F1-score_2: 0.3278
2023-03-08 17:21:18 - __main__ - INFO - Epoch [87/100]
2023-03-08 17:21:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 17:21:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-08 17:21:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 17:21:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:21:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 17:21:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:21:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 17:21:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 17:21:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 17:21:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 17:21:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-08 17:22:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:22:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0104, Loss_2: 0.0507, Acc_1: 0.7570, Acc_2: 0.4057, F1-score_1: 0.6906, F1-score_2: 0.3287
2023-03-08 17:22:11 - __main__ - INFO - Epoch [88/100]
2023-03-08 17:22:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 17:22:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:22:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 17:22:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 17:22:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 17:22:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 17:22:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:22:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-08 17:22:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 17:22:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:22:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 17:22:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 17:23:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0110, Loss_2: 0.0521, Acc_1: 0.7578, Acc_2: 0.4047, F1-score_1: 0.6911, F1-score_2: 0.3269
2023-03-08 17:23:04 - __main__ - INFO - Epoch [89/100]
2023-03-08 17:23:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 17:23:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 17:23:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 17:23:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-08 17:23:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 17:23:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 17:23:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 17:23:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 17:23:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 17:23:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-08 17:23:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:23:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:23:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0109, Loss_2: 0.0537, Acc_1: 0.7582, Acc_2: 0.4027, F1-score_1: 0.6929, F1-score_2: 0.3255
2023-03-08 17:23:58 - __main__ - INFO - Epoch [90/100]
2023-03-08 17:24:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 17:24:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:24:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 17:24:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 17:24:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 17:24:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 17:24:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:24:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-08 17:24:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 17:24:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 17:24:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 17:24:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 17:24:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0108, Loss_2: 0.0538, Acc_1: 0.7529, Acc_2: 0.4054, F1-score_1: 0.6855, F1-score_2: 0.3290
2023-03-08 17:24:51 - __main__ - INFO - Epoch [91/100]
2023-03-08 17:24:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 17:25:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 17:25:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 17:25:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:25:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-08 17:25:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 17:25:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 17:25:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 17:25:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 17:25:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 17:25:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 17:25:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:25:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0107, Loss_2: 0.0541, Acc_1: 0.7551, Acc_2: 0.3989, F1-score_1: 0.6883, F1-score_2: 0.3244
2023-03-08 17:25:44 - __main__ - INFO - Epoch [92/100]
2023-03-08 17:25:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-08 17:25:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:25:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:26:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:26:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 17:26:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:26:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 17:26:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:26:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 17:26:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 17:26:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-08 17:26:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 17:26:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0128, Loss_2: 0.0564, Acc_1: 0.7573, Acc_2: 0.3991, F1-score_1: 0.6906, F1-score_2: 0.3228
2023-03-08 17:26:38 - __main__ - INFO - Epoch [93/100]
2023-03-08 17:26:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 17:26:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 17:26:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:26:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 17:26:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 17:27:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 17:27:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 17:27:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 17:27:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:27:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 17:27:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 17:27:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 17:27:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0113, Loss_2: 0.0549, Acc_1: 0.7587, Acc_2: 0.4034, F1-score_1: 0.6919, F1-score_2: 0.3265
2023-03-08 17:27:31 - __main__ - INFO - Epoch [94/100]
2023-03-08 17:27:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 17:27:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:27:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 17:27:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 17:27:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:27:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:27:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 17:28:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 17:28:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 17:28:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 17:28:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 17:28:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 17:28:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0546, Acc_1: 0.7588, Acc_2: 0.4044, F1-score_1: 0.6920, F1-score_2: 0.3280
2023-03-08 17:28:24 - __main__ - INFO - Epoch [95/100]
2023-03-08 17:28:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:28:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 17:28:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-08 17:28:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 17:28:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 17:28:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 17:28:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:28:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 17:28:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:29:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 17:29:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 17:29:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 17:29:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0549, Acc_1: 0.7583, Acc_2: 0.4025, F1-score_1: 0.6910, F1-score_2: 0.3279
2023-03-08 17:29:17 - __main__ - INFO - Epoch [96/100]
2023-03-08 17:29:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:29:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-08 17:29:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-08 17:29:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 17:29:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 17:29:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 17:29:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:29:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:29:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 17:29:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 17:29:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 17:30:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 17:30:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0531, Acc_1: 0.7512, Acc_2: 0.4034, F1-score_1: 0.6840, F1-score_2: 0.3257
2023-03-08 17:30:11 - __main__ - INFO - Epoch [97/100]
2023-03-08 17:30:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:30:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 17:30:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 17:30:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 17:30:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:30:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:30:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 17:30:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 17:30:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:30:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:30:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 17:30:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 17:31:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0119, Loss_2: 0.0529, Acc_1: 0.7524, Acc_2: 0.4047, F1-score_1: 0.6848, F1-score_2: 0.3275
2023-03-08 17:31:04 - __main__ - INFO - Epoch [98/100]
2023-03-08 17:31:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 17:31:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 17:31:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 17:31:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 17:31:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:31:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 17:31:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 17:31:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 17:31:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:31:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 17:31:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 17:31:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 17:31:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0124, Loss_2: 0.0534, Acc_1: 0.7522, Acc_2: 0.4035, F1-score_1: 0.6847, F1-score_2: 0.3280
2023-03-08 17:31:57 - __main__ - INFO - Epoch [99/100]
2023-03-08 17:32:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 17:32:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 17:32:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 17:32:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 17:32:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 17:32:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-08 17:32:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 17:32:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 17:32:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 17:32:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 17:32:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:32:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 17:32:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0121, Loss_2: 0.0535, Acc_1: 0.7520, Acc_2: 0.4052, F1-score_1: 0.6848, F1-score_2: 0.3265
2023-03-08 17:32:52 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 17:32:53 - utils._noise - DEBUG - 6, 7
2023-03-08 17:32:53 - utils._noise - DEBUG - 13997
2023-03-08 17:32:53 - utils._noise - INFO - Actual noise 0.20
2023-03-08 17:32:53 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-08 17:32:53 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-08 17:32:55 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 17:32:55 - __main__ - INFO - Loading dataset...
2023-03-08 17:32:55 - __main__ - INFO - Building model...
2023-03-08 17:32:55 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-08 17:32:55 - __main__ - INFO - <bound method Module.parameters of NewsNet(
  (embedding): Embedding(20000, 300)
  (avgpool): AdaptiveAvgPool1d(output_size=4800)
  (fc1): Linear(in_features=4800, out_features=1200, bias=True)
  (bn1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ac): Softsign()
  (fc2): Linear(in_features=1200, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=7, bias=True)
)>
2023-03-08 17:32:55 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-08 17:32:55 - __main__ - INFO - Start train & evaluate
2023-03-08 17:32:55 - __main__ - INFO - Epoch [0/100]
2023-03-08 17:33:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0153, Loss_2: 0.0157, Acc_1: 0.0625, Acc_2: 0.1328, 
2023-03-08 17:33:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0150, Loss_2: 0.0149, Acc_1: 0.2109, Acc_2: 0.2969, 
2023-03-08 17:33:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0143, Loss_2: 0.0139, Acc_1: 0.2578, Acc_2: 0.3516, 
2023-03-08 17:33:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0137, Loss_2: 0.0133, Acc_1: 0.3672, Acc_2: 0.3828, 
2023-03-08 17:33:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0134, Loss_2: 0.0135, Acc_1: 0.3203, Acc_2: 0.2969, 
2023-03-08 17:33:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0141, Loss_2: 0.0135, Acc_1: 0.3203, Acc_2: 0.3281, 
2023-03-08 17:33:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0134, Loss_2: 0.0136, Acc_1: 0.3828, Acc_2: 0.3750, 
2023-03-08 17:33:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0142, Loss_2: 0.0132, Acc_1: 0.3125, Acc_2: 0.3672, 
2023-03-08 17:33:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0135, Loss_2: 0.0128, Acc_1: 0.3672, Acc_2: 0.3594, 
2023-03-08 17:33:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0132, Loss_2: 0.0134, Acc_1: 0.3828, Acc_2: 0.3203, 
2023-03-08 17:33:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0141, Loss_2: 0.0134, Acc_1: 0.3516, Acc_2: 0.3438, 
2023-03-08 17:33:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0135, Loss_2: 0.0139, Acc_1: 0.3281, Acc_2: 0.3125, 
2023-03-08 17:33:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0121, Acc_1: 0.4657, Acc_2: 0.4701, F1-score_1: 0.2788, F1-score_2: 0.3035
2023-03-08 17:33:48 - __main__ - INFO - Epoch [1/100]
2023-03-08 17:33:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0137, Loss_2: 0.0121, Acc_1: 0.3438, Acc_2: 0.4688, 
2023-03-08 17:33:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0111, Loss_2: 0.0105, Acc_1: 0.5000, Acc_2: 0.5469, 
2023-03-08 17:34:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0111, Loss_2: 0.0109, Acc_1: 0.5391, Acc_2: 0.4766, 
2023-03-08 17:34:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0126, Loss_2: 0.0121, Acc_1: 0.3750, Acc_2: 0.4297, 
2023-03-08 17:34:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0127, Loss_2: 0.0127, Acc_1: 0.4219, Acc_2: 0.4062, 
2023-03-08 17:34:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0112, Loss_2: 0.0124, Acc_1: 0.5391, Acc_2: 0.3750, 
2023-03-08 17:34:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0098, Loss_2: 0.0121, Acc_1: 0.5859, Acc_2: 0.4688, 
2023-03-08 17:34:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0118, Loss_2: 0.0134, Acc_1: 0.5234, Acc_2: 0.3828, 
2023-03-08 17:34:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0116, Loss_2: 0.0116, Acc_1: 0.4766, Acc_2: 0.4844, 
2023-03-08 17:34:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0118, Loss_2: 0.0119, Acc_1: 0.4688, Acc_2: 0.4453, 
2023-03-08 17:34:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0123, Loss_2: 0.0126, Acc_1: 0.4297, Acc_2: 0.3828, 
2023-03-08 17:34:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0095, Loss_2: 0.0111, Acc_1: 0.5781, Acc_2: 0.5000, 
2023-03-08 17:34:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0084, Loss_2: 0.0122, Acc_1: 0.6542, Acc_2: 0.4558, F1-score_1: 0.4801, F1-score_2: 0.3096
2023-03-08 17:34:41 - __main__ - INFO - Epoch [2/100]
2023-03-08 17:34:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0100, Loss_2: 0.0110, Acc_1: 0.5703, Acc_2: 0.5156, 
2023-03-08 17:34:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0113, Loss_2: 0.0097, Acc_1: 0.5156, Acc_2: 0.5781, 
2023-03-08 17:34:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0105, Loss_2: 0.0087, Acc_1: 0.5469, Acc_2: 0.5938, 
2023-03-08 17:34:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0109, Loss_2: 0.0102, Acc_1: 0.5156, Acc_2: 0.5156, 
2023-03-08 17:35:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0107, Loss_2: 0.0126, Acc_1: 0.5781, Acc_2: 0.4062, 
2023-03-08 17:35:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0101, Loss_2: 0.0110, Acc_1: 0.5469, Acc_2: 0.5078, 
2023-03-08 17:35:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0094, Loss_2: 0.0122, Acc_1: 0.6094, Acc_2: 0.4141, 
2023-03-08 17:35:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0103, Loss_2: 0.0117, Acc_1: 0.6016, Acc_2: 0.4844, 
2023-03-08 17:35:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0090, Loss_2: 0.0100, Acc_1: 0.6328, Acc_2: 0.5000, 
2023-03-08 17:35:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0106, Loss_2: 0.0113, Acc_1: 0.5234, Acc_2: 0.5391, 
2023-03-08 17:35:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0153, Loss_2: 0.0113, Acc_1: 0.3906, Acc_2: 0.4609, 
2023-03-08 17:35:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0123, Loss_2: 0.0116, Acc_1: 0.4453, Acc_2: 0.4922, 
2023-03-08 17:35:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0102, Loss_2: 0.0120, Acc_1: 0.4878, Acc_2: 0.4499, F1-score_1: 0.4157, F1-score_2: 0.3339
2023-03-08 17:35:35 - __main__ - INFO - Epoch [3/100]
2023-03-08 17:35:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0109, Loss_2: 0.0103, Acc_1: 0.4922, Acc_2: 0.5703, 
2023-03-08 17:35:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0100, Loss_2: 0.0096, Acc_1: 0.5469, Acc_2: 0.5703, 
2023-03-08 17:35:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0092, Loss_2: 0.0090, Acc_1: 0.5469, Acc_2: 0.6172, 
2023-03-08 17:35:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0108, Loss_2: 0.0099, Acc_1: 0.5312, Acc_2: 0.5547, 
2023-03-08 17:35:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0088, Loss_2: 0.0096, Acc_1: 0.6641, Acc_2: 0.5547, 
2023-03-08 17:35:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0086, Loss_2: 0.0093, Acc_1: 0.6562, Acc_2: 0.5391, 
2023-03-08 17:36:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0085, Loss_2: 0.0100, Acc_1: 0.6875, Acc_2: 0.5469, 
2023-03-08 17:36:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0084, Loss_2: 0.0103, Acc_1: 0.6797, Acc_2: 0.5391, 
2023-03-08 17:36:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0155, Loss_2: 0.0101, Acc_1: 0.3906, Acc_2: 0.5312, 
2023-03-08 17:36:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0116, Loss_2: 0.0113, Acc_1: 0.5391, Acc_2: 0.4453, 
2023-03-08 17:36:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0129, Loss_2: 0.0107, Acc_1: 0.4609, Acc_2: 0.4766, 
2023-03-08 17:36:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0093, Loss_2: 0.0113, Acc_1: 0.6094, Acc_2: 0.4609, 
2023-03-08 17:36:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0086, Loss_2: 0.0131, Acc_1: 0.6367, Acc_2: 0.4288, F1-score_1: 0.5535, F1-score_2: 0.3165
2023-03-08 17:36:28 - __main__ - INFO - Epoch [4/100]
2023-03-08 17:36:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0095, Loss_2: 0.0095, Acc_1: 0.6641, Acc_2: 0.5781, 
2023-03-08 17:36:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0094, Loss_2: 0.0088, Acc_1: 0.5703, Acc_2: 0.6172, 
2023-03-08 17:36:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0091, Loss_2: 0.0093, Acc_1: 0.6094, Acc_2: 0.5781, 
2023-03-08 17:36:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0085, Loss_2: 0.0078, Acc_1: 0.6094, Acc_2: 0.6172, 
2023-03-08 17:36:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0078, Loss_2: 0.0083, Acc_1: 0.6953, Acc_2: 0.6406, 
2023-03-08 17:36:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0115, Loss_2: 0.0090, Acc_1: 0.5469, Acc_2: 0.6250, 
2023-03-08 17:36:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0087, Loss_2: 0.0101, Acc_1: 0.6328, Acc_2: 0.5234, 
2023-03-08 17:36:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0084, Loss_2: 0.0086, Acc_1: 0.6641, Acc_2: 0.5312, 
2023-03-08 17:37:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0073, Loss_2: 0.0085, Acc_1: 0.6797, Acc_2: 0.6094, 
2023-03-08 17:37:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0073, Loss_2: 0.0096, Acc_1: 0.6719, Acc_2: 0.4766, 
2023-03-08 17:37:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0078, Loss_2: 0.0096, Acc_1: 0.6797, Acc_2: 0.6016, 
2023-03-08 17:37:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0073, Loss_2: 0.0090, Acc_1: 0.6641, Acc_2: 0.5625, 
2023-03-08 17:37:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0064, Loss_2: 0.0141, Acc_1: 0.7133, Acc_2: 0.4254, F1-score_1: 0.6412, F1-score_2: 0.3291
2023-03-08 17:37:21 - __main__ - INFO - Epoch [5/100]
2023-03-08 17:37:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0047, Loss_2: 0.0067, Acc_1: 0.7969, Acc_2: 0.7344, 
2023-03-08 17:37:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0071, Loss_2: 0.0073, Acc_1: 0.6953, Acc_2: 0.6797, 
2023-03-08 17:37:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0068, Loss_2: 0.0075, Acc_1: 0.7031, Acc_2: 0.7109, 
2023-03-08 17:37:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0063, Loss_2: 0.0085, Acc_1: 0.7188, Acc_2: 0.5703, 
2023-03-08 17:37:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0052, Loss_2: 0.0079, Acc_1: 0.7344, Acc_2: 0.5938, 
2023-03-08 17:37:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0068, Loss_2: 0.0082, Acc_1: 0.7188, Acc_2: 0.6562, 
2023-03-08 17:37:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0085, Loss_2: 0.0094, Acc_1: 0.6328, Acc_2: 0.5234, 
2023-03-08 17:37:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0050, Loss_2: 0.0088, Acc_1: 0.7344, Acc_2: 0.5703, 
2023-03-08 17:37:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0053, Loss_2: 0.0077, Acc_1: 0.7422, Acc_2: 0.5547, 
2023-03-08 17:37:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0075, Loss_2: 0.0097, Acc_1: 0.6562, Acc_2: 0.5312, 
2023-03-08 17:38:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0064, Loss_2: 0.0078, Acc_1: 0.7344, Acc_2: 0.6406, 
2023-03-08 17:38:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0059, Loss_2: 0.0076, Acc_1: 0.6719, Acc_2: 0.6406, 
2023-03-08 17:38:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0055, Loss_2: 0.0151, Acc_1: 0.7493, Acc_2: 0.4278, F1-score_1: 0.6671, F1-score_2: 0.3232
2023-03-08 17:38:14 - __main__ - INFO - Epoch [6/100]
2023-03-08 17:38:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0044, Loss_2: 0.0064, Acc_1: 0.7969, Acc_2: 0.6719, 
2023-03-08 17:38:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0048, Loss_2: 0.0062, Acc_1: 0.7578, Acc_2: 0.6406, 
2023-03-08 17:38:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0040, Loss_2: 0.0066, Acc_1: 0.7969, Acc_2: 0.6641, 
2023-03-08 17:38:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0059, Loss_2: 0.0078, Acc_1: 0.7188, Acc_2: 0.6250, 
2023-03-08 17:38:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0056, Loss_2: 0.0075, Acc_1: 0.7422, Acc_2: 0.6172, 
2023-03-08 17:38:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0038, Loss_2: 0.0068, Acc_1: 0.7500, Acc_2: 0.6719, 
2023-03-08 17:38:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0048, Loss_2: 0.0083, Acc_1: 0.7266, Acc_2: 0.5938, 
2023-03-08 17:38:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0049, Loss_2: 0.0066, Acc_1: 0.8281, Acc_2: 0.7344, 
2023-03-08 17:38:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0042, Loss_2: 0.0073, Acc_1: 0.7422, Acc_2: 0.6406, 
2023-03-08 17:38:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0052, Loss_2: 0.0075, Acc_1: 0.7422, Acc_2: 0.6016, 
2023-03-08 17:38:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0053, Loss_2: 0.0074, Acc_1: 0.7109, Acc_2: 0.6328, 
2023-03-08 17:38:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0052, Loss_2: 0.0093, Acc_1: 0.7500, Acc_2: 0.6094, 
2023-03-08 17:39:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0065, Loss_2: 0.0169, Acc_1: 0.7558, Acc_2: 0.4299, F1-score_1: 0.6930, F1-score_2: 0.3327
2023-03-08 17:39:08 - __main__ - INFO - Epoch [7/100]
2023-03-08 17:39:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0036, Loss_2: 0.0051, Acc_1: 0.7812, Acc_2: 0.6953, 
2023-03-08 17:39:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0035, Loss_2: 0.0050, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 17:39:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0048, Loss_2: 0.0062, Acc_1: 0.7656, Acc_2: 0.6484, 
2023-03-08 17:39:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0047, Loss_2: 0.0069, Acc_1: 0.7812, Acc_2: 0.6719, 
2023-03-08 17:39:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0040, Loss_2: 0.0068, Acc_1: 0.7578, Acc_2: 0.6797, 
2023-03-08 17:39:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0035, Loss_2: 0.0066, Acc_1: 0.8125, Acc_2: 0.6719, 
2023-03-08 17:39:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0036, Loss_2: 0.0074, Acc_1: 0.8047, Acc_2: 0.6406, 
2023-03-08 17:39:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0038, Loss_2: 0.0058, Acc_1: 0.8359, Acc_2: 0.6797, 
2023-03-08 17:39:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0028, Loss_2: 0.0065, Acc_1: 0.8359, Acc_2: 0.6875, 
2023-03-08 17:39:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0031, Loss_2: 0.0062, Acc_1: 0.7891, Acc_2: 0.6250, 
2023-03-08 17:39:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0047, Loss_2: 0.0065, Acc_1: 0.7891, Acc_2: 0.6719, 
2023-03-08 17:39:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0042, Loss_2: 0.0068, Acc_1: 0.7578, Acc_2: 0.6406, 
2023-03-08 17:40:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0057, Loss_2: 0.0178, Acc_1: 0.7492, Acc_2: 0.4203, F1-score_1: 0.6851, F1-score_2: 0.3361
2023-03-08 17:40:01 - __main__ - INFO - Epoch [8/100]
2023-03-08 17:40:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0020, Loss_2: 0.0050, Acc_1: 0.8594, Acc_2: 0.7422, 
2023-03-08 17:40:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0038, Loss_2: 0.0060, Acc_1: 0.8047, Acc_2: 0.7188, 
2023-03-08 17:40:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0031, Loss_2: 0.0063, Acc_1: 0.8125, Acc_2: 0.6797, 
2023-03-08 17:40:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0028, Loss_2: 0.0052, Acc_1: 0.7656, Acc_2: 0.7031, 
2023-03-08 17:40:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0032, Loss_2: 0.0051, Acc_1: 0.7812, Acc_2: 0.6875, 
2023-03-08 17:40:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0032, Loss_2: 0.0053, Acc_1: 0.7891, Acc_2: 0.6797, 
2023-03-08 17:40:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0049, Loss_2: 0.0062, Acc_1: 0.7578, Acc_2: 0.6875, 
2023-03-08 17:40:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0049, Loss_2: 0.0060, Acc_1: 0.7734, Acc_2: 0.6719, 
2023-03-08 17:40:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0036, Loss_2: 0.0065, Acc_1: 0.7812, Acc_2: 0.6484, 
2023-03-08 17:40:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0034, Loss_2: 0.0042, Acc_1: 0.8281, Acc_2: 0.7422, 
2023-03-08 17:40:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0034, Loss_2: 0.0056, Acc_1: 0.7891, Acc_2: 0.6562, 
2023-03-08 17:40:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0029, Loss_2: 0.0052, Acc_1: 0.7891, Acc_2: 0.6953, 
2023-03-08 17:40:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0059, Loss_2: 0.0197, Acc_1: 0.7492, Acc_2: 0.4215, F1-score_1: 0.6851, F1-score_2: 0.3337
2023-03-08 17:40:54 - __main__ - INFO - Epoch [9/100]
2023-03-08 17:40:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0019, Loss_2: 0.0039, Acc_1: 0.7969, Acc_2: 0.7500, 
2023-03-08 17:41:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0023, Loss_2: 0.0045, Acc_1: 0.8281, Acc_2: 0.7422, 
2023-03-08 17:41:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0023, Loss_2: 0.0042, Acc_1: 0.8203, Acc_2: 0.7344, 
2023-03-08 17:41:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0017, Loss_2: 0.0053, Acc_1: 0.8281, Acc_2: 0.6875, 
2023-03-08 17:41:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0026, Loss_2: 0.0055, Acc_1: 0.7969, Acc_2: 0.7188, 
2023-03-08 17:41:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0031, Loss_2: 0.0055, Acc_1: 0.7578, Acc_2: 0.6797, 
2023-03-08 17:41:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0013, Loss_2: 0.0054, Acc_1: 0.8672, Acc_2: 0.7344, 
2023-03-08 17:41:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0026, Loss_2: 0.0064, Acc_1: 0.8359, Acc_2: 0.6797, 
2023-03-08 17:41:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0026, Loss_2: 0.0055, Acc_1: 0.7969, Acc_2: 0.7109, 
2023-03-08 17:41:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0029, Loss_2: 0.0066, Acc_1: 0.8438, Acc_2: 0.6406, 
2023-03-08 17:41:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0036, Loss_2: 0.0078, Acc_1: 0.7578, Acc_2: 0.6172, 
2023-03-08 17:41:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0027, Loss_2: 0.0042, Acc_1: 0.8047, Acc_2: 0.7266, 
2023-03-08 17:41:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0074, Loss_2: 0.0209, Acc_1: 0.7508, Acc_2: 0.4153, F1-score_1: 0.6726, F1-score_2: 0.3247
2023-03-08 17:41:47 - __main__ - INFO - Epoch [10/100]
2023-03-08 17:41:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0021, Loss_2: 0.0038, Acc_1: 0.8594, Acc_2: 0.7578, 
2023-03-08 17:41:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0010, Loss_2: 0.0038, Acc_1: 0.8750, Acc_2: 0.7734, 
2023-03-08 17:41:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0027, Loss_2: 0.0050, Acc_1: 0.8203, Acc_2: 0.7109, 
2023-03-08 17:42:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0036, Loss_2: 0.0044, Acc_1: 0.7812, Acc_2: 0.7266, 
2023-03-08 17:42:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0014, Loss_2: 0.0042, Acc_1: 0.8438, Acc_2: 0.7188, 
2023-03-08 17:42:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0025, Loss_2: 0.0040, Acc_1: 0.8125, Acc_2: 0.7109, 
2023-03-08 17:42:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0019, Loss_2: 0.0043, Acc_1: 0.8281, Acc_2: 0.7266, 
2023-03-08 17:42:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0014, Loss_2: 0.0055, Acc_1: 0.8438, Acc_2: 0.6953, 
2023-03-08 17:42:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0026, Loss_2: 0.0044, Acc_1: 0.7891, Acc_2: 0.6641, 
2023-03-08 17:42:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0029, Loss_2: 0.0048, Acc_1: 0.8047, Acc_2: 0.7266, 
2023-03-08 17:42:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0030, Loss_2: 0.0049, Acc_1: 0.8125, Acc_2: 0.7109, 
2023-03-08 17:42:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0017, Loss_2: 0.0048, Acc_1: 0.9062, Acc_2: 0.7578, 
2023-03-08 17:42:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0068, Loss_2: 0.0248, Acc_1: 0.7442, Acc_2: 0.4051, F1-score_1: 0.6836, F1-score_2: 0.3321
2023-03-08 17:42:41 - __main__ - INFO - Epoch [11/100]
2023-03-08 17:42:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0015, Loss_2: 0.0031, Acc_1: 0.8359, Acc_2: 0.7578, 
2023-03-08 17:42:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0013, Loss_2: 0.0035, Acc_1: 0.8516, Acc_2: 0.7734, 
2023-03-08 17:42:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0020, Loss_2: 0.0040, Acc_1: 0.8516, Acc_2: 0.7422, 
2023-03-08 17:42:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0012, Loss_2: 0.0039, Acc_1: 0.8438, Acc_2: 0.7344, 
2023-03-08 17:43:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0019, Loss_2: 0.0039, Acc_1: 0.8203, Acc_2: 0.7578, 
2023-03-08 17:43:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0019, Loss_2: 0.0027, Acc_1: 0.8672, Acc_2: 0.7969, 
2023-03-08 17:43:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0015, Loss_2: 0.0042, Acc_1: 0.8750, Acc_2: 0.7422, 
2023-03-08 17:43:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0019, Loss_2: 0.0035, Acc_1: 0.8594, Acc_2: 0.7656, 
2023-03-08 17:43:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0016, Loss_2: 0.0040, Acc_1: 0.8672, Acc_2: 0.7656, 
2023-03-08 17:43:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0017, Loss_2: 0.0037, Acc_1: 0.7969, Acc_2: 0.7266, 
2023-03-08 17:43:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0015, Loss_2: 0.0043, Acc_1: 0.8125, Acc_2: 0.7109, 
2023-03-08 17:43:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0014, Loss_2: 0.0037, Acc_1: 0.8750, Acc_2: 0.7891, 
2023-03-08 17:43:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0077, Loss_2: 0.0222, Acc_1: 0.7529, Acc_2: 0.4074, F1-score_1: 0.6881, F1-score_2: 0.3291
2023-03-08 17:43:34 - __main__ - INFO - Epoch [12/100]
2023-03-08 17:43:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0045, Acc_1: 0.8594, Acc_2: 0.7422, 
2023-03-08 17:43:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0019, Loss_2: 0.0034, Acc_1: 0.8359, Acc_2: 0.7500, 
2023-03-08 17:43:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0009, Loss_2: 0.0034, Acc_1: 0.8906, Acc_2: 0.7969, 
2023-03-08 17:43:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0028, Acc_1: 0.8438, Acc_2: 0.7891, 
2023-03-08 17:43:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0011, Loss_2: 0.0045, Acc_1: 0.9141, Acc_2: 0.7656, 
2023-03-08 17:43:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0016, Loss_2: 0.0036, Acc_1: 0.8281, Acc_2: 0.7578, 
2023-03-08 17:44:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0035, Acc_1: 0.8594, Acc_2: 0.7656, 
2023-03-08 17:44:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0025, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 17:44:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0019, Loss_2: 0.0026, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 17:44:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0028, Loss_2: 0.0053, Acc_1: 0.8516, Acc_2: 0.7344, 
2023-03-08 17:44:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0019, Loss_2: 0.0032, Acc_1: 0.8359, Acc_2: 0.7891, 
2023-03-08 17:44:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0016, Loss_2: 0.0034, Acc_1: 0.8750, Acc_2: 0.8125, 
2023-03-08 17:44:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0079, Loss_2: 0.0265, Acc_1: 0.7542, Acc_2: 0.3986, F1-score_1: 0.6846, F1-score_2: 0.3224
2023-03-08 17:44:27 - __main__ - INFO - Epoch [13/100]
2023-03-08 17:44:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0020, Loss_2: 0.0033, Acc_1: 0.8125, Acc_2: 0.7734, 
2023-03-08 17:44:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0020, Loss_2: 0.0042, Acc_1: 0.8359, Acc_2: 0.7891, 
2023-03-08 17:44:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0010, Loss_2: 0.0028, Acc_1: 0.8438, Acc_2: 0.7578, 
2023-03-08 17:44:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0032, Loss_2: 0.0052, Acc_1: 0.7969, Acc_2: 0.6641, 
2023-03-08 17:44:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0018, Loss_2: 0.0027, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 17:44:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0015, Loss_2: 0.0033, Acc_1: 0.8516, Acc_2: 0.7891, 
2023-03-08 17:44:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0023, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 17:44:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0014, Loss_2: 0.0026, Acc_1: 0.8281, Acc_2: 0.7891, 
2023-03-08 17:45:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0033, Loss_2: 0.0046, Acc_1: 0.8047, Acc_2: 0.7188, 
2023-03-08 17:45:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0027, Acc_1: 0.8594, Acc_2: 0.7734, 
2023-03-08 17:45:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0015, Loss_2: 0.0050, Acc_1: 0.7969, Acc_2: 0.6406, 
2023-03-08 17:45:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0016, Loss_2: 0.0034, Acc_1: 0.8359, Acc_2: 0.7891, 
2023-03-08 17:45:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0078, Loss_2: 0.0259, Acc_1: 0.7507, Acc_2: 0.4102, F1-score_1: 0.6818, F1-score_2: 0.3207
2023-03-08 17:45:20 - __main__ - INFO - Epoch [14/100]
2023-03-08 17:45:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0017, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 17:45:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0024, Acc_1: 0.8516, Acc_2: 0.7812, 
2023-03-08 17:45:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0010, Loss_2: 0.0020, Acc_1: 0.8516, Acc_2: 0.7969, 
2023-03-08 17:45:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0016, Loss_2: 0.0021, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 17:45:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0036, Acc_1: 0.8281, Acc_2: 0.7891, 
2023-03-08 17:45:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0018, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 17:45:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0010, Loss_2: 0.0026, Acc_1: 0.8516, Acc_2: 0.7891, 
2023-03-08 17:45:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0012, Loss_2: 0.0024, Acc_1: 0.8438, Acc_2: 0.7812, 
2023-03-08 17:45:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0011, Loss_2: 0.0026, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 17:45:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0027, Acc_1: 0.8828, Acc_2: 0.7969, 
2023-03-08 17:46:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0026, Loss_2: 0.0025, Acc_1: 0.8281, Acc_2: 0.7812, 
2023-03-08 17:46:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0016, Loss_2: 0.0031, Acc_1: 0.7969, Acc_2: 0.7188, 
2023-03-08 17:46:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0083, Loss_2: 0.0278, Acc_1: 0.7617, Acc_2: 0.4137, F1-score_1: 0.6963, F1-score_2: 0.3273
2023-03-08 17:46:13 - __main__ - INFO - Epoch [15/100]
2023-03-08 17:46:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0023, Acc_1: 0.8750, Acc_2: 0.7891, 
2023-03-08 17:46:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0027, Acc_1: 0.8672, Acc_2: 0.8047, 
2023-03-08 17:46:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0018, Acc_1: 0.8516, Acc_2: 0.7969, 
2023-03-08 17:46:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0018, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 17:46:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0029, Acc_1: 0.9062, Acc_2: 0.8203, 
2023-03-08 17:46:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0015, Acc_1: 0.8203, Acc_2: 0.7812, 
2023-03-08 17:46:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0014, Loss_2: 0.0026, Acc_1: 0.8516, Acc_2: 0.7812, 
2023-03-08 17:46:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0018, Loss_2: 0.0021, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-08 17:46:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0024, Acc_1: 0.8672, Acc_2: 0.7891, 
2023-03-08 17:46:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0013, Loss_2: 0.0024, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 17:46:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0012, Loss_2: 0.0028, Acc_1: 0.7891, Acc_2: 0.7500, 
2023-03-08 17:46:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0012, Loss_2: 0.0031, Acc_1: 0.8281, Acc_2: 0.7891, 
2023-03-08 17:47:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0084, Loss_2: 0.0289, Acc_1: 0.7447, Acc_2: 0.3891, F1-score_1: 0.6678, F1-score_2: 0.3182
2023-03-08 17:47:07 - __main__ - INFO - Epoch [16/100]
2023-03-08 17:47:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0026, Acc_1: 0.8594, Acc_2: 0.7734, 
2023-03-08 17:47:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0015, Acc_1: 0.9219, Acc_2: 0.8672, 
2023-03-08 17:47:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0014, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-08 17:47:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0017, Acc_1: 0.8281, Acc_2: 0.7656, 
2023-03-08 17:47:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0015, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 17:47:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0022, Loss_2: 0.0023, Acc_1: 0.7812, Acc_2: 0.7500, 
2023-03-08 17:47:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0022, Acc_1: 0.8359, Acc_2: 0.7578, 
2023-03-08 17:47:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0025, Acc_1: 0.8281, Acc_2: 0.7812, 
2023-03-08 17:47:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0026, Acc_1: 0.8750, Acc_2: 0.7891, 
2023-03-08 17:47:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0022, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 17:47:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0028, Acc_1: 0.8750, Acc_2: 0.8125, 
2023-03-08 17:47:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0027, Acc_1: 0.8281, Acc_2: 0.7734, 
2023-03-08 17:48:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0082, Loss_2: 0.0289, Acc_1: 0.7500, Acc_2: 0.3988, F1-score_1: 0.6843, F1-score_2: 0.3181
2023-03-08 17:48:00 - __main__ - INFO - Epoch [17/100]
2023-03-08 17:48:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0020, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-08 17:48:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0019, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 17:48:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0017, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 17:48:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0013, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 17:48:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0019, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 17:48:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0018, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-08 17:48:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0019, Acc_1: 0.8359, Acc_2: 0.7891, 
2023-03-08 17:48:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0011, Loss_2: 0.0013, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 17:48:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0014, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:48:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0018, Acc_1: 0.8281, Acc_2: 0.7734, 
2023-03-08 17:48:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0024, Acc_1: 0.8125, Acc_2: 0.7344, 
2023-03-08 17:48:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0024, Acc_1: 0.7969, Acc_2: 0.7656, 
2023-03-08 17:48:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0100, Loss_2: 0.0315, Acc_1: 0.7578, Acc_2: 0.4079, F1-score_1: 0.6831, F1-score_2: 0.3258
2023-03-08 17:48:53 - __main__ - INFO - Epoch [18/100]
2023-03-08 17:48:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0020, Acc_1: 0.8438, Acc_2: 0.7578, 
2023-03-08 17:49:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0018, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 17:49:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 17:49:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:49:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0013, Loss_2: 0.0034, Acc_1: 0.8750, Acc_2: 0.8203, 
2023-03-08 17:49:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0026, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-08 17:49:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0022, Acc_1: 0.8906, Acc_2: 0.8125, 
2023-03-08 17:49:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0011, Loss_2: 0.0028, Acc_1: 0.8516, Acc_2: 0.7422, 
2023-03-08 17:49:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0029, Loss_2: 0.0022, Acc_1: 0.7969, Acc_2: 0.8281, 
2023-03-08 17:49:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0015, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-08 17:49:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0014, Loss_2: 0.0019, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 17:49:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0021, Acc_1: 0.8359, Acc_2: 0.7734, 
2023-03-08 17:49:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0085, Loss_2: 0.0310, Acc_1: 0.7303, Acc_2: 0.4156, F1-score_1: 0.6606, F1-score_2: 0.3303
2023-03-08 17:49:46 - __main__ - INFO - Epoch [19/100]
2023-03-08 17:49:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0012, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 17:49:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0018, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 17:49:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0015, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 17:50:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0012, Loss_2: 0.0019, Acc_1: 0.8125, Acc_2: 0.7578, 
2023-03-08 17:50:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0018, Acc_1: 0.8750, Acc_2: 0.7969, 
2023-03-08 17:50:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 17:50:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0016, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 17:50:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0012, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 17:50:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0010, Loss_2: 0.0020, Acc_1: 0.8281, Acc_2: 0.7734, 
2023-03-08 17:50:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0015, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-08 17:50:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0017, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-08 17:50:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0017, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 17:50:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0091, Loss_2: 0.0336, Acc_1: 0.7534, Acc_2: 0.4032, F1-score_1: 0.6832, F1-score_2: 0.3289
2023-03-08 17:50:39 - __main__ - INFO - Epoch [20/100]
2023-03-08 17:50:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 17:50:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0018, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-08 17:50:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 17:50:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 17:50:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0013, Loss_2: 0.0030, Acc_1: 0.7969, Acc_2: 0.7500, 
2023-03-08 17:51:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0032, Acc_1: 0.8750, Acc_2: 0.7734, 
2023-03-08 17:51:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0012, Loss_2: 0.0014, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 17:51:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0017, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-08 17:51:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0012, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 17:51:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.9453, Acc_2: 0.8984, 
2023-03-08 17:51:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0017, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 17:51:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0013, Loss_2: 0.0022, Acc_1: 0.8594, Acc_2: 0.7891, 
2023-03-08 17:51:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0108, Loss_2: 0.0301, Acc_1: 0.7505, Acc_2: 0.4136, F1-score_1: 0.6842, F1-score_2: 0.3262
2023-03-08 17:51:33 - __main__ - INFO - Epoch [21/100]
2023-03-08 17:51:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0014, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 17:51:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 17:51:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-08 17:51:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.9375, Acc_2: 0.8984, 
2023-03-08 17:51:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 17:51:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0017, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-08 17:51:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0018, Acc_1: 0.8594, Acc_2: 0.7578, 
2023-03-08 17:52:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0019, Acc_1: 0.9062, Acc_2: 0.8438, 
2023-03-08 17:52:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0011, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 17:52:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0013, Acc_1: 0.8438, Acc_2: 0.7891, 
2023-03-08 17:52:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0025, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 17:52:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 17:52:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0107, Loss_2: 0.0358, Acc_1: 0.7614, Acc_2: 0.4003, F1-score_1: 0.6896, F1-score_2: 0.3241
2023-03-08 17:52:26 - __main__ - INFO - Epoch [22/100]
2023-03-08 17:52:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 17:52:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 17:52:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0021, Acc_1: 0.8359, Acc_2: 0.7812, 
2023-03-08 17:52:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0015, Acc_1: 0.8594, Acc_2: 0.7891, 
2023-03-08 17:52:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0018, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 17:52:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0014, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 17:52:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0010, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:52:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0014, Acc_1: 0.8750, Acc_2: 0.8047, 
2023-03-08 17:52:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0018, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 17:53:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0020, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-08 17:53:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0014, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 17:53:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0014, Acc_1: 0.8438, Acc_2: 0.7969, 
2023-03-08 17:53:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0097, Loss_2: 0.0335, Acc_1: 0.7602, Acc_2: 0.4008, F1-score_1: 0.6918, F1-score_2: 0.3254
2023-03-08 17:53:19 - __main__ - INFO - Epoch [23/100]
2023-03-08 17:53:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 17:53:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0016, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 17:53:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 17:53:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 17:53:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 17:53:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0016, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 17:53:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0013, Acc_1: 0.8516, Acc_2: 0.7891, 
2023-03-08 17:53:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 17:53:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-08 17:53:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 17:53:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:54:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0028, Acc_1: 0.8672, Acc_2: 0.7578, 
2023-03-08 17:54:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0106, Loss_2: 0.0353, Acc_1: 0.7410, Acc_2: 0.4020, F1-score_1: 0.6696, F1-score_2: 0.3214
2023-03-08 17:54:12 - __main__ - INFO - Epoch [24/100]
2023-03-08 17:54:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 17:54:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 17:54:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-08 17:54:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 17:54:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-08 17:54:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 17:54:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 17:54:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 17:54:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 17:54:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 17:54:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 17:54:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0010, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 17:55:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0129, Loss_2: 0.0356, Acc_1: 0.7542, Acc_2: 0.3998, F1-score_1: 0.6859, F1-score_2: 0.3186
2023-03-08 17:55:05 - __main__ - INFO - Epoch [25/100]
2023-03-08 17:55:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0011, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 17:55:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 17:55:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:55:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0015, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 17:55:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 17:55:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-08 17:55:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 17:55:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8828, Acc_2: 0.8203, 
2023-03-08 17:55:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 17:55:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:55:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 17:55:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 17:55:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0119, Loss_2: 0.0324, Acc_1: 0.7551, Acc_2: 0.4098, F1-score_1: 0.6852, F1-score_2: 0.3160
2023-03-08 17:55:59 - __main__ - INFO - Epoch [26/100]
2023-03-08 17:56:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 17:56:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 17:56:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 17:56:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 17:56:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8203, 
2023-03-08 17:56:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 17:56:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 17:56:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8672, Acc_2: 0.7969, 
2023-03-08 17:56:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 17:56:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 17:56:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0015, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 17:56:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0014, Loss_2: 0.0009, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 17:56:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0116, Loss_2: 0.0368, Acc_1: 0.7461, Acc_2: 0.4006, F1-score_1: 0.6785, F1-score_2: 0.3223
2023-03-08 17:56:52 - __main__ - INFO - Epoch [27/100]
2023-03-08 17:56:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 17:57:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-08 17:57:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 17:57:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 17:57:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 17:57:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 17:57:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 17:57:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 17:57:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0010, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 17:57:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 17:57:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 17:57:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.9062, 
2023-03-08 17:57:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0107, Loss_2: 0.0363, Acc_1: 0.7447, Acc_2: 0.4015, F1-score_1: 0.6799, F1-score_2: 0.3216
2023-03-08 17:57:45 - __main__ - INFO - Epoch [28/100]
2023-03-08 17:57:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 17:57:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0017, Loss_2: 0.0030, Acc_1: 0.7734, Acc_2: 0.7578, 
2023-03-08 17:57:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 17:58:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 17:58:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 17:58:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 17:58:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0011, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 17:58:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8359, Acc_2: 0.7891, 
2023-03-08 17:58:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-08 17:58:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 17:58:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 17:58:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0011, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 17:58:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0104, Loss_2: 0.0383, Acc_1: 0.7544, Acc_2: 0.3983, F1-score_1: 0.6777, F1-score_2: 0.3164
2023-03-08 17:58:38 - __main__ - INFO - Epoch [29/100]
2023-03-08 17:58:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-08 17:58:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 17:58:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-08 17:58:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 17:58:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 17:59:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 17:59:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 17:59:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-08 17:59:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 17:59:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 17:59:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0009, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 17:59:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0017, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 17:59:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0113, Loss_2: 0.0401, Acc_1: 0.7548, Acc_2: 0.4000, F1-score_1: 0.6889, F1-score_2: 0.3288
2023-03-08 17:59:31 - __main__ - INFO - Epoch [30/100]
2023-03-08 17:59:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 17:59:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 17:59:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 17:59:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 17:59:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 17:59:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 17:59:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0012, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-08 18:00:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 18:00:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 18:00:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0016, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 18:00:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-08 18:00:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-08 18:00:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0115, Loss_2: 0.0372, Acc_1: 0.7551, Acc_2: 0.4127, F1-score_1: 0.6829, F1-score_2: 0.3281
2023-03-08 18:00:24 - __main__ - INFO - Epoch [31/100]
2023-03-08 18:00:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 18:00:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 18:00:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:00:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:00:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 18:00:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:00:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0010, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 18:00:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:00:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 18:01:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-08 18:01:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-08 18:01:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:01:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0135, Loss_2: 0.0371, Acc_1: 0.7566, Acc_2: 0.3944, F1-score_1: 0.6871, F1-score_2: 0.3256
2023-03-08 18:01:18 - __main__ - INFO - Epoch [32/100]
2023-03-08 18:01:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 18:01:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:01:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-08 18:01:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:01:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 18:01:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 18:01:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:01:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:01:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 18:01:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:01:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:02:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:02:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0109, Loss_2: 0.0408, Acc_1: 0.7621, Acc_2: 0.4142, F1-score_1: 0.6916, F1-score_2: 0.3396
2023-03-08 18:02:11 - __main__ - INFO - Epoch [33/100]
2023-03-08 18:02:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-08 18:02:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 18:02:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:02:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:02:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 18:02:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 18:02:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 18:02:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-08 18:02:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:02:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 18:02:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 18:02:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0013, Loss_2: 0.0021, Acc_1: 0.8828, Acc_2: 0.7891, 
2023-03-08 18:03:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0358, Acc_1: 0.7296, Acc_2: 0.4029, F1-score_1: 0.6639, F1-score_2: 0.3247
2023-03-08 18:03:04 - __main__ - INFO - Epoch [34/100]
2023-03-08 18:03:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:03:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:03:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:03:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 18:03:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 18:03:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:03:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 18:03:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:03:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 18:03:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:03:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 18:03:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 18:03:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0384, Acc_1: 0.7532, Acc_2: 0.3927, F1-score_1: 0.6820, F1-score_2: 0.3197
2023-03-08 18:03:57 - __main__ - INFO - Epoch [35/100]
2023-03-08 18:04:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-08 18:04:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-08 18:04:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8203, Acc_2: 0.7734, 
2023-03-08 18:04:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 18:04:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0010, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:04:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0016, Loss_2: 0.0022, Acc_1: 0.7500, Acc_2: 0.7422, 
2023-03-08 18:04:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 18:04:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 18:04:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 18:04:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 18:04:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:04:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 18:04:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0098, Loss_2: 0.0412, Acc_1: 0.7500, Acc_2: 0.4039, F1-score_1: 0.6734, F1-score_2: 0.3304
2023-03-08 18:04:51 - __main__ - INFO - Epoch [36/100]
2023-03-08 18:04:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:04:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 18:05:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 18:05:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0011, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 18:05:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 18:05:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:05:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 18:05:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 18:05:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 18:05:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-08 18:05:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:05:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-08 18:05:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0094, Loss_2: 0.0384, Acc_1: 0.7306, Acc_2: 0.3925, F1-score_1: 0.6625, F1-score_2: 0.3248
2023-03-08 18:05:44 - __main__ - INFO - Epoch [37/100]
2023-03-08 18:05:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 18:05:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:05:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 18:05:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:06:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 18:06:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 18:06:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0011, Loss_2: 0.0010, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 18:06:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0016, Acc_1: 0.9219, Acc_2: 0.8594, 
2023-03-08 18:06:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 18:06:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0011, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-08 18:06:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 18:06:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 18:06:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0100, Loss_2: 0.0393, Acc_1: 0.7352, Acc_2: 0.4090, F1-score_1: 0.6692, F1-score_2: 0.3308
2023-03-08 18:06:37 - __main__ - INFO - Epoch [38/100]
2023-03-08 18:06:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:06:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 18:06:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 18:06:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 18:06:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 18:06:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8359, 
2023-03-08 18:07:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 18:07:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:07:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 18:07:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 18:07:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0021, Acc_1: 0.8516, Acc_2: 0.7891, 
2023-03-08 18:07:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 18:07:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0106, Loss_2: 0.0400, Acc_1: 0.7519, Acc_2: 0.4057, F1-score_1: 0.6851, F1-score_2: 0.3330
2023-03-08 18:07:30 - __main__ - INFO - Epoch [39/100]
2023-03-08 18:07:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 18:07:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0025, Loss_2: 0.0032, Acc_1: 0.7812, Acc_2: 0.7266, 
2023-03-08 18:07:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 18:07:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 18:07:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:07:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:07:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:08:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:08:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:08:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 18:08:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 18:08:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0013, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 18:08:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0109, Loss_2: 0.0423, Acc_1: 0.7451, Acc_2: 0.4129, F1-score_1: 0.6764, F1-score_2: 0.3365
2023-03-08 18:08:23 - __main__ - INFO - Epoch [40/100]
2023-03-08 18:08:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:08:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:08:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:08:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 18:08:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 18:08:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:08:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 18:08:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 18:08:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:09:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:09:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:09:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 18:09:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0108, Loss_2: 0.0390, Acc_1: 0.7441, Acc_2: 0.3954, F1-score_1: 0.6725, F1-score_2: 0.3198
2023-03-08 18:09:16 - __main__ - INFO - Epoch [41/100]
2023-03-08 18:09:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 18:09:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:09:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 18:09:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 18:09:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:09:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:09:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:09:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:09:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 18:09:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:09:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 18:09:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 18:10:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0142, Loss_2: 0.0424, Acc_1: 0.7587, Acc_2: 0.4108, F1-score_1: 0.6884, F1-score_2: 0.3358
2023-03-08 18:10:10 - __main__ - INFO - Epoch [42/100]
2023-03-08 18:10:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 18:10:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 18:10:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 18:10:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:10:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:10:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:10:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 18:10:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:10:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0021, Loss_2: 0.0013, Acc_1: 0.8125, Acc_2: 0.7656, 
2023-03-08 18:10:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 18:10:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 18:10:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 18:11:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0127, Loss_2: 0.0387, Acc_1: 0.7541, Acc_2: 0.4107, F1-score_1: 0.6833, F1-score_2: 0.3286
2023-03-08 18:11:03 - __main__ - INFO - Epoch [43/100]
2023-03-08 18:11:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:11:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.8281, Acc_2: 0.7812, 
2023-03-08 18:11:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:11:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 18:11:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 18:11:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 18:11:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:11:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 18:11:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 18:11:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:11:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 18:11:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-08 18:11:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0121, Loss_2: 0.0428, Acc_1: 0.7424, Acc_2: 0.3993, F1-score_1: 0.6782, F1-score_2: 0.3310
2023-03-08 18:11:56 - __main__ - INFO - Epoch [44/100]
2023-03-08 18:12:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 18:12:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:12:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:12:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 18:12:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:12:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 18:12:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 18:12:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 18:12:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 18:12:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 18:12:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:12:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 18:12:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0116, Loss_2: 0.0396, Acc_1: 0.7563, Acc_2: 0.3882, F1-score_1: 0.6878, F1-score_2: 0.3127
2023-03-08 18:12:49 - __main__ - INFO - Epoch [45/100]
2023-03-08 18:12:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 18:12:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:13:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 18:13:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:13:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 18:13:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8047, 
2023-03-08 18:13:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0012, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:13:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 18:13:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9375, Acc_2: 0.8828, 
2023-03-08 18:13:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0018, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 18:13:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:13:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:13:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0124, Loss_2: 0.0427, Acc_1: 0.7407, Acc_2: 0.3993, F1-score_1: 0.6748, F1-score_2: 0.3154
2023-03-08 18:13:43 - __main__ - INFO - Epoch [46/100]
2023-03-08 18:13:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 18:13:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 18:13:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:13:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 18:14:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 18:14:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 18:14:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 18:14:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 18:14:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0015, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 18:14:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 18:14:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 18:14:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 18:14:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0121, Loss_2: 0.0429, Acc_1: 0.7459, Acc_2: 0.3939, F1-score_1: 0.6828, F1-score_2: 0.3142
2023-03-08 18:14:36 - __main__ - INFO - Epoch [47/100]
2023-03-08 18:14:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:14:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-08 18:14:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:14:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 18:14:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 18:14:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-08 18:15:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:15:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 18:15:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0012, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:15:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 18:15:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 18:15:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 18:15:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0101, Loss_2: 0.0437, Acc_1: 0.7417, Acc_2: 0.4108, F1-score_1: 0.6705, F1-score_2: 0.3352
2023-03-08 18:15:29 - __main__ - INFO - Epoch [48/100]
2023-03-08 18:15:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:15:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 18:15:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:15:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 18:15:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0011, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 18:15:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 18:15:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:15:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:16:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 18:16:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0022, Acc_1: 0.8125, Acc_2: 0.7812, 
2023-03-08 18:16:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0026, Acc_1: 0.9219, Acc_2: 0.8281, 
2023-03-08 18:16:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 18:16:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0143, Loss_2: 0.0416, Acc_1: 0.7435, Acc_2: 0.3978, F1-score_1: 0.6757, F1-score_2: 0.3273
2023-03-08 18:16:23 - __main__ - INFO - Epoch [49/100]
2023-03-08 18:16:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 18:16:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:16:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 18:16:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0012, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 18:16:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.9219, 
2023-03-08 18:16:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 18:16:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.9062, Acc_2: 0.8438, 
2023-03-08 18:16:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:16:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:16:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 18:17:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 18:17:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 18:17:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0135, Loss_2: 0.0461, Acc_1: 0.7376, Acc_2: 0.4017, F1-score_1: 0.6706, F1-score_2: 0.3267
2023-03-08 18:17:16 - __main__ - INFO - Epoch [50/100]
2023-03-08 18:17:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 18:17:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 18:17:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:17:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-08 18:17:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-08 18:17:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 18:17:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9453, Acc_2: 0.9141, 
2023-03-08 18:17:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0021, Acc_1: 0.8750, Acc_2: 0.7734, 
2023-03-08 18:17:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 18:17:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 18:17:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-08 18:17:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 18:18:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0137, Loss_2: 0.0475, Acc_1: 0.7573, Acc_2: 0.4030, F1-score_1: 0.6849, F1-score_2: 0.3276
2023-03-08 18:18:09 - __main__ - INFO - Epoch [51/100]
2023-03-08 18:18:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 18:18:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:18:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:18:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 18:18:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 18:18:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:18:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 18:18:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:18:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 18:18:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 18:18:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:18:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 18:19:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0133, Loss_2: 0.0454, Acc_1: 0.7582, Acc_2: 0.3916, F1-score_1: 0.6877, F1-score_2: 0.3208
2023-03-08 18:19:02 - __main__ - INFO - Epoch [52/100]
2023-03-08 18:19:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:19:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 18:19:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:19:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 18:19:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 18:19:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 18:19:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 18:19:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:19:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:19:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 18:19:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:19:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:19:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0134, Loss_2: 0.0496, Acc_1: 0.7600, Acc_2: 0.3882, F1-score_1: 0.6863, F1-score_2: 0.3166
2023-03-08 18:19:55 - __main__ - INFO - Epoch [53/100]
2023-03-08 18:20:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 18:20:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:20:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 18:20:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 18:20:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 18:20:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:20:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9609, Acc_2: 0.9531, 
2023-03-08 18:20:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0013, Loss_2: 0.0007, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 18:20:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 18:20:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:20:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 18:20:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:20:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0148, Loss_2: 0.0439, Acc_1: 0.7573, Acc_2: 0.4006, F1-score_1: 0.6899, F1-score_2: 0.3208
2023-03-08 18:20:49 - __main__ - INFO - Epoch [54/100]
2023-03-08 18:20:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:20:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 18:21:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:21:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:21:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 18:21:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:21:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:21:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:21:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:21:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:21:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 18:21:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 18:21:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0149, Loss_2: 0.0489, Acc_1: 0.7561, Acc_2: 0.4017, F1-score_1: 0.6850, F1-score_2: 0.3229
2023-03-08 18:21:42 - __main__ - INFO - Epoch [55/100]
2023-03-08 18:21:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 18:21:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 18:21:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 18:21:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:22:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 18:22:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:22:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:22:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 18:22:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 18:22:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 18:22:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 18:22:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:22:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0146, Loss_2: 0.0516, Acc_1: 0.7519, Acc_2: 0.4029, F1-score_1: 0.6826, F1-score_2: 0.3254
2023-03-08 18:22:35 - __main__ - INFO - Epoch [56/100]
2023-03-08 18:22:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 18:22:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:22:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 18:22:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 18:22:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:22:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 18:23:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:23:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 18:23:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 18:23:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:23:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 18:23:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 18:23:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0141, Loss_2: 0.0461, Acc_1: 0.7310, Acc_2: 0.4010, F1-score_1: 0.6620, F1-score_2: 0.3352
2023-03-08 18:23:28 - __main__ - INFO - Epoch [57/100]
2023-03-08 18:23:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 18:23:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:23:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 18:23:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:23:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:23:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:23:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:23:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:24:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 18:24:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 18:24:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 18:24:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 18:24:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0465, Acc_1: 0.7425, Acc_2: 0.4083, F1-score_1: 0.6763, F1-score_2: 0.3248
2023-03-08 18:24:22 - __main__ - INFO - Epoch [58/100]
2023-03-08 18:24:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-08 18:24:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-08 18:24:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:24:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 18:24:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 18:24:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0012, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 18:24:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 18:24:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 18:24:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 18:24:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.9375, Acc_2: 0.9141, 
2023-03-08 18:25:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 18:25:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:25:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0122, Loss_2: 0.0497, Acc_1: 0.7503, Acc_2: 0.4115, F1-score_1: 0.6764, F1-score_2: 0.3340
2023-03-08 18:25:15 - __main__ - INFO - Epoch [59/100]
2023-03-08 18:25:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 18:25:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:25:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 18:25:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:25:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8281, Acc_2: 0.7812, 
2023-03-08 18:25:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0011, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-08 18:25:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 18:25:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 18:25:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 18:25:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:25:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 18:25:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:26:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0147, Loss_2: 0.0518, Acc_1: 0.7536, Acc_2: 0.4039, F1-score_1: 0.6857, F1-score_2: 0.3231
2023-03-08 18:26:08 - __main__ - INFO - Epoch [60/100]
2023-03-08 18:26:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 18:26:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:26:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 18:26:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 18:26:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 18:26:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 18:26:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 18:26:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 18:26:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0011, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 18:26:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0014, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-08 18:26:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 18:26:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:27:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0134, Loss_2: 0.0474, Acc_1: 0.7131, Acc_2: 0.4044, F1-score_1: 0.6508, F1-score_2: 0.3271
2023-03-08 18:27:02 - __main__ - INFO - Epoch [61/100]
2023-03-08 18:27:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 18:27:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 18:27:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 18:27:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0010, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:27:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 18:27:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:27:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:27:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 18:27:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:27:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:27:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 18:27:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:27:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0137, Loss_2: 0.0475, Acc_1: 0.7463, Acc_2: 0.4005, F1-score_1: 0.6723, F1-score_2: 0.3287
2023-03-08 18:27:55 - __main__ - INFO - Epoch [62/100]
2023-03-08 18:28:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-08 18:28:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:28:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 18:28:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 18:28:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:28:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:28:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-08 18:28:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 18:28:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 18:28:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 18:28:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:28:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:28:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0449, Acc_1: 0.7374, Acc_2: 0.4122, F1-score_1: 0.6615, F1-score_2: 0.3256
2023-03-08 18:28:49 - __main__ - INFO - Epoch [63/100]
2023-03-08 18:28:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:28:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-08 18:29:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:29:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 18:29:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:29:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 18:29:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 18:29:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:29:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:29:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 18:29:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 18:29:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 18:29:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0113, Loss_2: 0.0452, Acc_1: 0.7447, Acc_2: 0.4025, F1-score_1: 0.6701, F1-score_2: 0.3290
2023-03-08 18:29:42 - __main__ - INFO - Epoch [64/100]
2023-03-08 18:29:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:29:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:29:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:29:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:30:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:30:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 18:30:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 18:30:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 18:30:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:30:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-08 18:30:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 18:30:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 18:30:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0467, Acc_1: 0.7296, Acc_2: 0.4064, F1-score_1: 0.6632, F1-score_2: 0.3292
2023-03-08 18:30:35 - __main__ - INFO - Epoch [65/100]
2023-03-08 18:30:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:30:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 18:30:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:30:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:30:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8516, 
2023-03-08 18:30:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:31:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:31:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:31:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:31:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 18:31:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 18:31:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 18:31:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0129, Loss_2: 0.0446, Acc_1: 0.7463, Acc_2: 0.4051, F1-score_1: 0.6683, F1-score_2: 0.3324
2023-03-08 18:31:29 - __main__ - INFO - Epoch [66/100]
2023-03-08 18:31:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:31:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:31:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:31:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 18:31:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 18:31:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 18:31:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-08 18:31:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 18:32:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:32:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:32:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:32:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:32:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0133, Loss_2: 0.0452, Acc_1: 0.7488, Acc_2: 0.4029, F1-score_1: 0.6720, F1-score_2: 0.3259
2023-03-08 18:32:22 - __main__ - INFO - Epoch [67/100]
2023-03-08 18:32:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:32:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 18:32:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:32:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:32:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:32:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 18:32:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 18:32:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 18:32:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 18:32:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:33:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:33:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:33:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0126, Loss_2: 0.0462, Acc_1: 0.7413, Acc_2: 0.4023, F1-score_1: 0.6726, F1-score_2: 0.3252
2023-03-08 18:33:15 - __main__ - INFO - Epoch [68/100]
2023-03-08 18:33:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 18:33:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 18:33:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 18:33:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 18:33:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:33:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 18:33:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 18:33:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:33:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:33:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 18:33:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:33:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:34:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0148, Loss_2: 0.0492, Acc_1: 0.7427, Acc_2: 0.3961, F1-score_1: 0.6738, F1-score_2: 0.3242
2023-03-08 18:34:08 - __main__ - INFO - Epoch [69/100]
2023-03-08 18:34:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 18:34:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:34:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:34:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 18:34:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 18:34:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:34:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:34:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-08 18:34:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-08 18:34:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:34:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:34:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 18:35:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0160, Loss_2: 0.0478, Acc_1: 0.7407, Acc_2: 0.4022, F1-score_1: 0.6636, F1-score_2: 0.3219
2023-03-08 18:35:02 - __main__ - INFO - Epoch [70/100]
2023-03-08 18:35:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:35:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:35:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 18:35:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 18:35:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:35:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:35:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:35:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:35:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 18:35:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:35:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 18:35:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 18:35:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0139, Loss_2: 0.0480, Acc_1: 0.7403, Acc_2: 0.3967, F1-score_1: 0.6650, F1-score_2: 0.3225
2023-03-08 18:35:55 - __main__ - INFO - Epoch [71/100]
2023-03-08 18:36:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:36:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:36:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 18:36:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 18:36:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:36:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:36:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 18:36:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 18:36:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-08 18:36:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 18:36:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 18:36:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 18:36:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0133, Loss_2: 0.0503, Acc_1: 0.7412, Acc_2: 0.3949, F1-score_1: 0.6739, F1-score_2: 0.3274
2023-03-08 18:36:48 - __main__ - INFO - Epoch [72/100]
2023-03-08 18:36:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 18:36:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.8906, Acc_2: 0.7969, 
2023-03-08 18:37:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 18:37:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-08 18:37:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 18:37:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 18:37:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0014, Acc_1: 0.8906, Acc_2: 0.8125, 
2023-03-08 18:37:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 18:37:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 18:37:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 18:37:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:37:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 18:37:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0127, Loss_2: 0.0424, Acc_1: 0.7374, Acc_2: 0.3979, F1-score_1: 0.6563, F1-score_2: 0.3223
2023-03-08 18:37:42 - __main__ - INFO - Epoch [73/100]
2023-03-08 18:37:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 18:37:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0009, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:37:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 18:37:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 18:38:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.8359, Acc_2: 0.7656, 
2023-03-08 18:38:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 18:38:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:38:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 18:38:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0012, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 18:38:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8203, 
2023-03-08 18:38:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 18:38:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 18:38:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0126, Loss_2: 0.0368, Acc_1: 0.7488, Acc_2: 0.4049, F1-score_1: 0.6648, F1-score_2: 0.3264
2023-03-08 18:38:35 - __main__ - INFO - Epoch [74/100]
2023-03-08 18:38:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:38:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 18:38:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 18:38:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 18:38:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:38:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:39:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 18:39:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 18:39:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:39:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:39:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:39:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:39:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0167, Loss_2: 0.0428, Acc_1: 0.7328, Acc_2: 0.4119, F1-score_1: 0.6568, F1-score_2: 0.3365
2023-03-08 18:39:28 - __main__ - INFO - Epoch [75/100]
2023-03-08 18:39:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 18:39:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 18:39:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 18:39:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 18:39:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 18:39:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 18:39:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 18:39:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:40:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 18:40:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 18:40:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:40:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:40:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0142, Loss_2: 0.0428, Acc_1: 0.7424, Acc_2: 0.4151, F1-score_1: 0.6727, F1-score_2: 0.3369
2023-03-08 18:40:21 - __main__ - INFO - Epoch [76/100]
2023-03-08 18:40:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:40:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:40:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 18:40:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 18:40:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 18:40:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:40:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-08 18:40:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:40:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:40:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:41:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 18:41:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 18:41:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0134, Loss_2: 0.0428, Acc_1: 0.7441, Acc_2: 0.4119, F1-score_1: 0.6692, F1-score_2: 0.3352
2023-03-08 18:41:15 - __main__ - INFO - Epoch [77/100]
2023-03-08 18:41:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:41:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 18:41:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 18:41:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:41:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 18:41:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:41:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:41:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 18:41:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 18:41:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 18:41:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 18:41:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:42:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0119, Loss_2: 0.0435, Acc_1: 0.7507, Acc_2: 0.4061, F1-score_1: 0.6763, F1-score_2: 0.3334
2023-03-08 18:42:08 - __main__ - INFO - Epoch [78/100]
2023-03-08 18:42:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:42:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:42:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:42:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:42:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 18:42:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:42:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:42:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 18:42:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 18:42:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:42:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:42:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 18:43:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0460, Acc_1: 0.7463, Acc_2: 0.4037, F1-score_1: 0.6732, F1-score_2: 0.3246
2023-03-08 18:43:01 - __main__ - INFO - Epoch [79/100]
2023-03-08 18:43:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 18:43:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 18:43:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:43:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:43:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 18:43:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:43:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:43:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:43:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 18:43:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 18:43:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 18:43:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 18:43:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0124, Loss_2: 0.0476, Acc_1: 0.7444, Acc_2: 0.3939, F1-score_1: 0.6741, F1-score_2: 0.3188
2023-03-08 18:43:55 - __main__ - INFO - Epoch [80/100]
2023-03-08 18:44:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 18:44:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:44:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:44:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 18:44:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 18:44:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:44:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:44:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:44:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 18:44:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:44:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0051, Acc_1: 0.8906, Acc_2: 0.7812, 
2023-03-08 18:44:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:44:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0438, Acc_1: 0.7541, Acc_2: 0.4035, F1-score_1: 0.6847, F1-score_2: 0.3269
2023-03-08 18:44:48 - __main__ - INFO - Epoch [81/100]
2023-03-08 18:44:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 18:44:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:45:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 18:45:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:45:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:45:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 18:45:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 18:45:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:45:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 18:45:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 18:45:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 18:45:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:45:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0126, Loss_2: 0.0442, Acc_1: 0.7452, Acc_2: 0.4039, F1-score_1: 0.6764, F1-score_2: 0.3234
2023-03-08 18:45:41 - __main__ - INFO - Epoch [82/100]
2023-03-08 18:45:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:45:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 18:45:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 18:45:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 18:46:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 18:46:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-08 18:46:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 18:46:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:46:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:46:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:46:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:46:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 18:46:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0449, Acc_1: 0.7522, Acc_2: 0.4030, F1-score_1: 0.6827, F1-score_2: 0.3206
2023-03-08 18:46:34 - __main__ - INFO - Epoch [83/100]
2023-03-08 18:46:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 18:46:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 18:46:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 18:46:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 18:46:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 18:46:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:47:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:47:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-08 18:47:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:47:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:47:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:47:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:47:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0440, Acc_1: 0.7539, Acc_2: 0.4023, F1-score_1: 0.6822, F1-score_2: 0.3226
2023-03-08 18:47:27 - __main__ - INFO - Epoch [84/100]
2023-03-08 18:47:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:47:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:47:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 18:47:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:47:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:47:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 18:47:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 18:47:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 18:48:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:48:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 18:48:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:48:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 18:48:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0126, Loss_2: 0.0461, Acc_1: 0.7529, Acc_2: 0.4037, F1-score_1: 0.6826, F1-score_2: 0.3201
2023-03-08 18:48:20 - __main__ - INFO - Epoch [85/100]
2023-03-08 18:48:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 18:48:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:48:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:48:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:48:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 18:48:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 18:48:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 18:48:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:48:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:48:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 18:49:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 18:49:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 18:49:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0119, Loss_2: 0.0463, Acc_1: 0.7573, Acc_2: 0.4013, F1-score_1: 0.6844, F1-score_2: 0.3214
2023-03-08 18:49:14 - __main__ - INFO - Epoch [86/100]
2023-03-08 18:49:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 18:49:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:49:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 18:49:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 18:49:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 18:49:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:49:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:49:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:49:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:49:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 18:49:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:49:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:50:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0127, Loss_2: 0.0473, Acc_1: 0.7534, Acc_2: 0.4054, F1-score_1: 0.6837, F1-score_2: 0.3258
2023-03-08 18:50:07 - __main__ - INFO - Epoch [87/100]
2023-03-08 18:50:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:50:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:50:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:50:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:50:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 18:50:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 18:50:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:50:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 18:50:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 18:50:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:50:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 18:50:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:51:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0131, Loss_2: 0.0471, Acc_1: 0.7568, Acc_2: 0.4073, F1-score_1: 0.6874, F1-score_2: 0.3258
2023-03-08 18:51:00 - __main__ - INFO - Epoch [88/100]
2023-03-08 18:51:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:51:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:51:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 18:51:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:51:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:51:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:51:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:51:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 18:51:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 18:51:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 18:51:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 18:51:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:51:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0135, Loss_2: 0.0474, Acc_1: 0.7561, Acc_2: 0.4042, F1-score_1: 0.6852, F1-score_2: 0.3222
2023-03-08 18:51:53 - __main__ - INFO - Epoch [89/100]
2023-03-08 18:51:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:52:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:52:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:52:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:52:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 18:52:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:52:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:52:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 18:52:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 18:52:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 18:52:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:52:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:52:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0136, Loss_2: 0.0483, Acc_1: 0.7570, Acc_2: 0.4057, F1-score_1: 0.6865, F1-score_2: 0.3239
2023-03-08 18:52:47 - __main__ - INFO - Epoch [90/100]
2023-03-08 18:52:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 18:52:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 18:52:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:53:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 18:53:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 18:53:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 18:53:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 18:53:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:53:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 18:53:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 18:53:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:53:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 18:53:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0137, Loss_2: 0.0480, Acc_1: 0.7588, Acc_2: 0.4051, F1-score_1: 0.6869, F1-score_2: 0.3258
2023-03-08 18:53:40 - __main__ - INFO - Epoch [91/100]
2023-03-08 18:53:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 18:53:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 18:53:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:53:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:53:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:54:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 18:54:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:54:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:54:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 18:54:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 18:54:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 18:54:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 18:54:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0140, Loss_2: 0.0481, Acc_1: 0.7587, Acc_2: 0.4020, F1-score_1: 0.6859, F1-score_2: 0.3240
2023-03-08 18:54:33 - __main__ - INFO - Epoch [92/100]
2023-03-08 18:54:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 18:54:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 18:54:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 18:54:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 18:54:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:54:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:54:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:55:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 18:55:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:55:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:55:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:55:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:55:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0158, Loss_2: 0.0456, Acc_1: 0.7546, Acc_2: 0.4044, F1-score_1: 0.6809, F1-score_2: 0.3234
2023-03-08 18:55:26 - __main__ - INFO - Epoch [93/100]
2023-03-08 18:55:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:55:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:55:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 18:55:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:55:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 18:55:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 18:55:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 18:55:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:55:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:56:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 18:56:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 18:56:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 18:56:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0135, Loss_2: 0.0440, Acc_1: 0.7568, Acc_2: 0.4005, F1-score_1: 0.6804, F1-score_2: 0.3230
2023-03-08 18:56:19 - __main__ - INFO - Epoch [94/100]
2023-03-08 18:56:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:56:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 18:56:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:56:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:56:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 18:56:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:56:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 18:56:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:56:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:56:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:56:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 18:57:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 18:57:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0139, Loss_2: 0.0443, Acc_1: 0.7575, Acc_2: 0.3986, F1-score_1: 0.6815, F1-score_2: 0.3201
2023-03-08 18:57:13 - __main__ - INFO - Epoch [95/100]
2023-03-08 18:57:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 18:57:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 18:57:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:57:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:57:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 18:57:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 18:57:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:57:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:57:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:57:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 18:57:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 18:57:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 18:58:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0140, Loss_2: 0.0444, Acc_1: 0.7580, Acc_2: 0.3998, F1-score_1: 0.6812, F1-score_2: 0.3223
2023-03-08 18:58:06 - __main__ - INFO - Epoch [96/100]
2023-03-08 18:58:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 18:58:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:58:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 18:58:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 18:58:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-08 18:58:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 18:58:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 18:58:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 18:58:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-08 18:58:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 18:58:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:58:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 18:58:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0142, Loss_2: 0.0449, Acc_1: 0.7580, Acc_2: 0.3998, F1-score_1: 0.6812, F1-score_2: 0.3226
2023-03-08 18:58:59 - __main__ - INFO - Epoch [97/100]
2023-03-08 18:59:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 18:59:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:59:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 18:59:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 18:59:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 18:59:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:59:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 18:59:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 18:59:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 18:59:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 18:59:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 18:59:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 18:59:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0145, Loss_2: 0.0442, Acc_1: 0.7559, Acc_2: 0.4039, F1-score_1: 0.6801, F1-score_2: 0.3244
2023-03-08 18:59:52 - __main__ - INFO - Epoch [98/100]
2023-03-08 18:59:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 19:00:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 19:00:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 19:00:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 19:00:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 19:00:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 19:00:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 19:00:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 19:00:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-08 19:00:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-08 19:00:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 19:00:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 19:00:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0156, Loss_2: 0.0447, Acc_1: 0.7563, Acc_2: 0.3978, F1-score_1: 0.6804, F1-score_2: 0.3195
2023-03-08 19:00:46 - __main__ - INFO - Epoch [99/100]
2023-03-08 19:00:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 19:00:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 19:00:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 19:01:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 19:01:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-08 19:01:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 19:01:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 19:01:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 19:01:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 19:01:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 19:01:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 19:01:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 19:01:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0143, Loss_2: 0.0438, Acc_1: 0.7559, Acc_2: 0.4039, F1-score_1: 0.6798, F1-score_2: 0.3241
2023-03-08 19:01:41 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 19:01:41 - utils._noise - DEBUG - 6, 7
2023-03-08 19:01:41 - utils._noise - DEBUG - 13997
2023-03-08 19:01:41 - utils._noise - INFO - Actual noise 0.20
2023-03-08 19:01:41 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-08 19:01:41 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-08 19:01:43 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 19:01:43 - __main__ - INFO - Loading dataset...
2023-03-08 19:01:43 - __main__ - INFO - Building model...
2023-03-08 19:01:43 - __main__ - INFO - <bound method Module.parameters of NewsNetLSTM(
  (embedding): Embedding(20000, 300)
  (bi_lstm): LSTM(300, 300, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=600, out_features=7, bias=True)
)>
2023-03-08 19:01:43 - __main__ - INFO - <bound method Module.parameters of NewsNet(
  (embedding): Embedding(20000, 300)
  (avgpool): AdaptiveAvgPool1d(output_size=4800)
  (fc1): Linear(in_features=4800, out_features=1200, bias=True)
  (bn1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ac): Softsign()
  (fc2): Linear(in_features=1200, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=7, bias=True)
)>
2023-03-08 19:01:43 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-08 19:01:43 - __main__ - INFO - Start train & evaluate
2023-03-08 19:01:43 - __main__ - INFO - Epoch [0/100]
2023-03-08 19:01:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0153, Loss_2: 0.0156, Acc_1: 0.0781, Acc_2: 0.1094, 
2023-03-08 19:01:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0142, Loss_2: 0.0141, Acc_1: 0.2500, Acc_2: 0.3281, 
2023-03-08 19:01:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0144, Loss_2: 0.0136, Acc_1: 0.2109, Acc_2: 0.3359, 
2023-03-08 19:01:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0135, Loss_2: 0.0133, Acc_1: 0.3359, Acc_2: 0.3203, 
2023-03-08 19:02:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0137, Loss_2: 0.0138, Acc_1: 0.3750, Acc_2: 0.3047, 
2023-03-08 19:02:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0129, Loss_2: 0.0130, Acc_1: 0.2969, Acc_2: 0.3672, 
2023-03-08 19:02:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0138, Loss_2: 0.0133, Acc_1: 0.3047, Acc_2: 0.3281, 
2023-03-08 19:02:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0133, Loss_2: 0.0125, Acc_1: 0.3906, Acc_2: 0.4297, 
2023-03-08 19:02:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0135, Loss_2: 0.0144, Acc_1: 0.3047, Acc_2: 0.3125, 
2023-03-08 19:02:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0124, Loss_2: 0.0135, Acc_1: 0.4453, Acc_2: 0.3672, 
2023-03-08 19:02:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0122, Loss_2: 0.0132, Acc_1: 0.4609, Acc_2: 0.4297, 
2023-03-08 19:02:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0123, Loss_2: 0.0130, Acc_1: 0.3906, Acc_2: 0.3359, 
2023-03-08 19:02:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0109, Loss_2: 0.0124, Acc_1: 0.5165, Acc_2: 0.4501, F1-score_1: 0.2908, F1-score_2: 0.2760
2023-03-08 19:02:37 - __main__ - INFO - Epoch [1/100]
2023-03-08 19:02:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0128, Loss_2: 0.0125, Acc_1: 0.3750, Acc_2: 0.3906, 
2023-03-08 19:02:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0120, Loss_2: 0.0115, Acc_1: 0.4844, Acc_2: 0.5234, 
2023-03-08 19:02:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0140, Loss_2: 0.0123, Acc_1: 0.3984, Acc_2: 0.4609, 
2023-03-08 19:02:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0107, Loss_2: 0.0108, Acc_1: 0.5703, Acc_2: 0.4844, 
2023-03-08 19:02:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0118, Loss_2: 0.0122, Acc_1: 0.5000, Acc_2: 0.4297, 
2023-03-08 19:02:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0106, Loss_2: 0.0114, Acc_1: 0.5156, Acc_2: 0.4531, 
2023-03-08 19:03:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0100, Loss_2: 0.0119, Acc_1: 0.6094, Acc_2: 0.4766, 
2023-03-08 19:03:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0116, Loss_2: 0.0124, Acc_1: 0.5000, Acc_2: 0.4453, 
2023-03-08 19:03:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0109, Loss_2: 0.0124, Acc_1: 0.5391, Acc_2: 0.4688, 
2023-03-08 19:03:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0122, Loss_2: 0.0118, Acc_1: 0.5000, Acc_2: 0.4219, 
2023-03-08 19:03:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0115, Loss_2: 0.0117, Acc_1: 0.5000, Acc_2: 0.5234, 
2023-03-08 19:03:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0126, Loss_2: 0.0114, Acc_1: 0.3906, Acc_2: 0.4297, 
2023-03-08 19:03:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0102, Loss_2: 0.0119, Acc_1: 0.5379, Acc_2: 0.4569, F1-score_1: 0.4773, F1-score_2: 0.3321
2023-03-08 19:03:30 - __main__ - INFO - Epoch [2/100]
2023-03-08 19:03:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0117, Loss_2: 0.0107, Acc_1: 0.5312, Acc_2: 0.5000, 
2023-03-08 19:03:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0125, Loss_2: 0.0111, Acc_1: 0.4219, Acc_2: 0.4766, 
2023-03-08 19:03:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0114, Loss_2: 0.0105, Acc_1: 0.4766, Acc_2: 0.5000, 
2023-03-08 19:03:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0096, Loss_2: 0.0101, Acc_1: 0.5938, Acc_2: 0.5312, 
2023-03-08 19:03:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0112, Loss_2: 0.0110, Acc_1: 0.4922, Acc_2: 0.5391, 
2023-03-08 19:03:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0103, Loss_2: 0.0117, Acc_1: 0.5859, Acc_2: 0.3984, 
2023-03-08 19:03:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0081, Loss_2: 0.0104, Acc_1: 0.6875, Acc_2: 0.5000, 
2023-03-08 19:03:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0087, Loss_2: 0.0111, Acc_1: 0.6328, Acc_2: 0.4844, 
2023-03-08 19:04:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0109, Loss_2: 0.0122, Acc_1: 0.5625, Acc_2: 0.4922, 
2023-03-08 19:04:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0085, Loss_2: 0.0107, Acc_1: 0.6250, Acc_2: 0.4844, 
2023-03-08 19:04:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0087, Loss_2: 0.0115, Acc_1: 0.6250, Acc_2: 0.4609, 
2023-03-08 19:04:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0091, Loss_2: 0.0110, Acc_1: 0.6016, Acc_2: 0.4688, 
2023-03-08 19:04:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0062, Loss_2: 0.0120, Acc_1: 0.7456, Acc_2: 0.4429, F1-score_1: 0.6500, F1-score_2: 0.3323
2023-03-08 19:04:23 - __main__ - INFO - Epoch [3/100]
2023-03-08 19:04:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0075, Loss_2: 0.0089, Acc_1: 0.6719, Acc_2: 0.6172, 
2023-03-08 19:04:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0073, Loss_2: 0.0081, Acc_1: 0.6641, Acc_2: 0.6562, 
2023-03-08 19:04:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0081, Loss_2: 0.0083, Acc_1: 0.6875, Acc_2: 0.6406, 
2023-03-08 19:04:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0066, Loss_2: 0.0086, Acc_1: 0.7656, Acc_2: 0.6328, 
2023-03-08 19:04:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0080, Loss_2: 0.0077, Acc_1: 0.6641, Acc_2: 0.6484, 
2023-03-08 19:04:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0094, Loss_2: 0.0106, Acc_1: 0.6016, Acc_2: 0.5078, 
2023-03-08 19:04:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0085, Loss_2: 0.0112, Acc_1: 0.6406, Acc_2: 0.5156, 
2023-03-08 19:04:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0086, Loss_2: 0.0093, Acc_1: 0.6328, Acc_2: 0.5312, 
2023-03-08 19:04:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0092, Loss_2: 0.0112, Acc_1: 0.5859, Acc_2: 0.4844, 
2023-03-08 19:05:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0082, Loss_2: 0.0107, Acc_1: 0.6719, Acc_2: 0.5234, 
2023-03-08 19:05:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0072, Loss_2: 0.0082, Acc_1: 0.7188, Acc_2: 0.5859, 
2023-03-08 19:05:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0076, Loss_2: 0.0095, Acc_1: 0.6797, Acc_2: 0.5625, 
2023-03-08 19:05:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0061, Loss_2: 0.0130, Acc_1: 0.7418, Acc_2: 0.4368, F1-score_1: 0.6574, F1-score_2: 0.3252
2023-03-08 19:05:16 - __main__ - INFO - Epoch [4/100]
2023-03-08 19:05:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0071, Loss_2: 0.0087, Acc_1: 0.7031, Acc_2: 0.6328, 
2023-03-08 19:05:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0080, Loss_2: 0.0089, Acc_1: 0.6562, Acc_2: 0.6172, 
2023-03-08 19:05:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0081, Loss_2: 0.0089, Acc_1: 0.6172, Acc_2: 0.6250, 
2023-03-08 19:05:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0079, Loss_2: 0.0083, Acc_1: 0.6641, Acc_2: 0.5938, 
2023-03-08 19:05:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0066, Loss_2: 0.0091, Acc_1: 0.7188, Acc_2: 0.5781, 
2023-03-08 19:05:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0090, Loss_2: 0.0097, Acc_1: 0.6562, Acc_2: 0.5547, 
2023-03-08 19:05:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0078, Loss_2: 0.0090, Acc_1: 0.6641, Acc_2: 0.5547, 
2023-03-08 19:05:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0063, Loss_2: 0.0086, Acc_1: 0.7344, Acc_2: 0.5859, 
2023-03-08 19:05:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0072, Loss_2: 0.0095, Acc_1: 0.7266, Acc_2: 0.5391, 
2023-03-08 19:05:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0070, Loss_2: 0.0094, Acc_1: 0.7188, Acc_2: 0.5625, 
2023-03-08 19:05:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0064, Loss_2: 0.0103, Acc_1: 0.7109, Acc_2: 0.5312, 
2023-03-08 19:05:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0061, Loss_2: 0.0091, Acc_1: 0.7344, Acc_2: 0.5469, 
2023-03-08 19:06:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0050, Loss_2: 0.0143, Acc_1: 0.7981, Acc_2: 0.4299, F1-score_1: 0.7330, F1-score_2: 0.3369
2023-03-08 19:06:10 - __main__ - INFO - Epoch [5/100]
2023-03-08 19:06:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0048, Loss_2: 0.0071, Acc_1: 0.7969, Acc_2: 0.6328, 
2023-03-08 19:06:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0052, Loss_2: 0.0073, Acc_1: 0.7734, Acc_2: 0.6719, 
2023-03-08 19:06:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0055, Loss_2: 0.0068, Acc_1: 0.7500, Acc_2: 0.6641, 
2023-03-08 19:06:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0042, Loss_2: 0.0080, Acc_1: 0.7578, Acc_2: 0.5938, 
2023-03-08 19:06:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0058, Loss_2: 0.0070, Acc_1: 0.7812, Acc_2: 0.6406, 
2023-03-08 19:06:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0053, Loss_2: 0.0091, Acc_1: 0.7656, Acc_2: 0.5859, 
2023-03-08 19:06:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0054, Loss_2: 0.0081, Acc_1: 0.7500, Acc_2: 0.6328, 
2023-03-08 19:06:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0057, Loss_2: 0.0084, Acc_1: 0.7188, Acc_2: 0.6250, 
2023-03-08 19:06:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0061, Loss_2: 0.0095, Acc_1: 0.7422, Acc_2: 0.5391, 
2023-03-08 19:06:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0058, Loss_2: 0.0081, Acc_1: 0.7188, Acc_2: 0.5859, 
2023-03-08 19:06:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0060, Loss_2: 0.0085, Acc_1: 0.7344, Acc_2: 0.5391, 
2023-03-08 19:06:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0041, Loss_2: 0.0078, Acc_1: 0.8203, Acc_2: 0.6094, 
2023-03-08 19:07:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0051, Loss_2: 0.0152, Acc_1: 0.7925, Acc_2: 0.4287, F1-score_1: 0.7237, F1-score_2: 0.3241
2023-03-08 19:07:03 - __main__ - INFO - Epoch [6/100]
2023-03-08 19:07:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0049, Loss_2: 0.0075, Acc_1: 0.7656, Acc_2: 0.6328, 
2023-03-08 19:07:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0044, Loss_2: 0.0069, Acc_1: 0.7734, Acc_2: 0.6953, 
2023-03-08 19:07:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0052, Loss_2: 0.0080, Acc_1: 0.7578, Acc_2: 0.5781, 
2023-03-08 19:07:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0036, Loss_2: 0.0062, Acc_1: 0.7656, Acc_2: 0.6797, 
2023-03-08 19:07:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0042, Loss_2: 0.0072, Acc_1: 0.7734, Acc_2: 0.6172, 
2023-03-08 19:07:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0032, Loss_2: 0.0066, Acc_1: 0.8125, Acc_2: 0.6328, 
2023-03-08 19:07:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0028, Loss_2: 0.0063, Acc_1: 0.8203, Acc_2: 0.6641, 
2023-03-08 19:07:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0052, Loss_2: 0.0097, Acc_1: 0.7344, Acc_2: 0.5547, 
2023-03-08 19:07:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0039, Loss_2: 0.0075, Acc_1: 0.8438, Acc_2: 0.6406, 
2023-03-08 19:07:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0060, Loss_2: 0.0081, Acc_1: 0.7500, Acc_2: 0.5781, 
2023-03-08 19:07:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0055, Loss_2: 0.0083, Acc_1: 0.7500, Acc_2: 0.5781, 
2023-03-08 19:07:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0037, Loss_2: 0.0074, Acc_1: 0.8047, Acc_2: 0.6328, 
2023-03-08 19:07:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0056, Loss_2: 0.0161, Acc_1: 0.7889, Acc_2: 0.4254, F1-score_1: 0.7255, F1-score_2: 0.3302
2023-03-08 19:07:56 - __main__ - INFO - Epoch [7/100]
2023-03-08 19:08:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0032, Loss_2: 0.0056, Acc_1: 0.8281, Acc_2: 0.7422, 
2023-03-08 19:08:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0024, Loss_2: 0.0053, Acc_1: 0.8828, Acc_2: 0.6953, 
2023-03-08 19:08:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0038, Loss_2: 0.0057, Acc_1: 0.7734, Acc_2: 0.6875, 
2023-03-08 19:08:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0041, Loss_2: 0.0065, Acc_1: 0.7891, Acc_2: 0.6719, 
2023-03-08 19:08:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0029, Loss_2: 0.0055, Acc_1: 0.7969, Acc_2: 0.6719, 
2023-03-08 19:08:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0034, Loss_2: 0.0072, Acc_1: 0.7734, Acc_2: 0.6406, 
2023-03-08 19:08:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0046, Loss_2: 0.0063, Acc_1: 0.7734, Acc_2: 0.7031, 
2023-03-08 19:08:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0043, Loss_2: 0.0075, Acc_1: 0.7734, Acc_2: 0.6406, 
2023-03-08 19:08:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0026, Loss_2: 0.0067, Acc_1: 0.8594, Acc_2: 0.6641, 
2023-03-08 19:08:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0045, Loss_2: 0.0074, Acc_1: 0.7656, Acc_2: 0.6094, 
2023-03-08 19:08:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0023, Loss_2: 0.0052, Acc_1: 0.8594, Acc_2: 0.6875, 
2023-03-08 19:08:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0017, Loss_2: 0.0048, Acc_1: 0.8906, Acc_2: 0.7500, 
2023-03-08 19:08:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0055, Loss_2: 0.0169, Acc_1: 0.7745, Acc_2: 0.4193, F1-score_1: 0.7079, F1-score_2: 0.3302
2023-03-08 19:08:49 - __main__ - INFO - Epoch [8/100]
2023-03-08 19:08:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0048, Loss_2: 0.0058, Acc_1: 0.7656, Acc_2: 0.6484, 
2023-03-08 19:08:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0029, Loss_2: 0.0065, Acc_1: 0.7969, Acc_2: 0.6406, 
2023-03-08 19:09:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0020, Loss_2: 0.0049, Acc_1: 0.8750, Acc_2: 0.7266, 
2023-03-08 19:09:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0024, Loss_2: 0.0053, Acc_1: 0.8359, Acc_2: 0.6797, 
2023-03-08 19:09:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0022, Loss_2: 0.0055, Acc_1: 0.8359, Acc_2: 0.7031, 
2023-03-08 19:09:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0014, Loss_2: 0.0049, Acc_1: 0.8516, Acc_2: 0.7031, 
2023-03-08 19:09:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0017, Loss_2: 0.0065, Acc_1: 0.8281, Acc_2: 0.6875, 
2023-03-08 19:09:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0061, Acc_1: 0.8750, Acc_2: 0.6562, 
2023-03-08 19:09:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0028, Loss_2: 0.0061, Acc_1: 0.8359, Acc_2: 0.6875, 
2023-03-08 19:09:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0016, Loss_2: 0.0060, Acc_1: 0.8828, Acc_2: 0.6406, 
2023-03-08 19:09:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0027, Loss_2: 0.0062, Acc_1: 0.8516, Acc_2: 0.6406, 
2023-03-08 19:09:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0024, Loss_2: 0.0065, Acc_1: 0.8125, Acc_2: 0.6172, 
2023-03-08 19:09:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0068, Loss_2: 0.0185, Acc_1: 0.7614, Acc_2: 0.4146, F1-score_1: 0.6996, F1-score_2: 0.3242
2023-03-08 19:09:43 - __main__ - INFO - Epoch [9/100]
2023-03-08 19:09:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0018, Loss_2: 0.0043, Acc_1: 0.8125, Acc_2: 0.7500, 
2023-03-08 19:09:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0021, Loss_2: 0.0049, Acc_1: 0.8203, Acc_2: 0.7109, 
2023-03-08 19:09:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0018, Loss_2: 0.0053, Acc_1: 0.8281, Acc_2: 0.6797, 
2023-03-08 19:09:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0016, Loss_2: 0.0049, Acc_1: 0.8281, Acc_2: 0.6719, 
2023-03-08 19:10:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0026, Loss_2: 0.0065, Acc_1: 0.8203, Acc_2: 0.7266, 
2023-03-08 19:10:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0018, Loss_2: 0.0043, Acc_1: 0.8125, Acc_2: 0.7500, 
2023-03-08 19:10:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0019, Loss_2: 0.0056, Acc_1: 0.8594, Acc_2: 0.7188, 
2023-03-08 19:10:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0024, Loss_2: 0.0062, Acc_1: 0.8359, Acc_2: 0.6797, 
2023-03-08 19:10:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0020, Loss_2: 0.0051, Acc_1: 0.8281, Acc_2: 0.7109, 
2023-03-08 19:10:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0026, Loss_2: 0.0071, Acc_1: 0.7812, Acc_2: 0.5938, 
2023-03-08 19:10:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0014, Loss_2: 0.0044, Acc_1: 0.8672, Acc_2: 0.7422, 
2023-03-08 19:10:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0019, Loss_2: 0.0050, Acc_1: 0.8125, Acc_2: 0.6953, 
2023-03-08 19:10:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0071, Loss_2: 0.0201, Acc_1: 0.7672, Acc_2: 0.4137, F1-score_1: 0.6979, F1-score_2: 0.3280
2023-03-08 19:10:36 - __main__ - INFO - Epoch [10/100]
2023-03-08 19:10:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0013, Loss_2: 0.0041, Acc_1: 0.8516, Acc_2: 0.7656, 
2023-03-08 19:10:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0017, Loss_2: 0.0046, Acc_1: 0.8672, Acc_2: 0.7656, 
2023-03-08 19:10:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0022, Loss_2: 0.0035, Acc_1: 0.8047, Acc_2: 0.7500, 
2023-03-08 19:10:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0016, Loss_2: 0.0058, Acc_1: 0.8516, Acc_2: 0.7266, 
2023-03-08 19:10:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0020, Loss_2: 0.0038, Acc_1: 0.8203, Acc_2: 0.7266, 
2023-03-08 19:10:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0010, Loss_2: 0.0046, Acc_1: 0.8359, Acc_2: 0.7266, 
2023-03-08 19:11:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0041, Acc_1: 0.8516, Acc_2: 0.7422, 
2023-03-08 19:11:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0033, Loss_2: 0.0050, Acc_1: 0.8438, Acc_2: 0.6953, 
2023-03-08 19:11:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0014, Loss_2: 0.0044, Acc_1: 0.8984, Acc_2: 0.7578, 
2023-03-08 19:11:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0016, Loss_2: 0.0059, Acc_1: 0.8516, Acc_2: 0.7266, 
2023-03-08 19:11:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0023, Loss_2: 0.0060, Acc_1: 0.8672, Acc_2: 0.6953, 
2023-03-08 19:11:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0024, Loss_2: 0.0059, Acc_1: 0.8047, Acc_2: 0.6250, 
2023-03-08 19:11:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0069, Loss_2: 0.0213, Acc_1: 0.7707, Acc_2: 0.4173, F1-score_1: 0.7098, F1-score_2: 0.3316
2023-03-08 19:11:29 - __main__ - INFO - Epoch [11/100]
2023-03-08 19:11:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0039, Acc_1: 0.9062, Acc_2: 0.7969, 
2023-03-08 19:11:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0018, Loss_2: 0.0051, Acc_1: 0.8516, Acc_2: 0.6875, 
2023-03-08 19:11:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0042, Acc_1: 0.8906, Acc_2: 0.7422, 
2023-03-08 19:11:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0036, Acc_1: 0.8359, Acc_2: 0.7344, 
2023-03-08 19:11:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0014, Loss_2: 0.0035, Acc_1: 0.8359, Acc_2: 0.7734, 
2023-03-08 19:11:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0015, Loss_2: 0.0034, Acc_1: 0.8906, Acc_2: 0.8125, 
2023-03-08 19:11:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0015, Loss_2: 0.0044, Acc_1: 0.8516, Acc_2: 0.7109, 
2023-03-08 19:11:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0042, Acc_1: 0.8594, Acc_2: 0.7344, 
2023-03-08 19:12:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0012, Loss_2: 0.0054, Acc_1: 0.8281, Acc_2: 0.6797, 
2023-03-08 19:12:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0014, Loss_2: 0.0045, Acc_1: 0.8203, Acc_2: 0.6719, 
2023-03-08 19:12:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0052, Acc_1: 0.8359, Acc_2: 0.6797, 
2023-03-08 19:12:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0018, Loss_2: 0.0042, Acc_1: 0.7891, Acc_2: 0.7266, 
2023-03-08 19:12:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0067, Loss_2: 0.0225, Acc_1: 0.7580, Acc_2: 0.4022, F1-score_1: 0.6946, F1-score_2: 0.3354
2023-03-08 19:12:22 - __main__ - INFO - Epoch [12/100]
2023-03-08 19:12:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0009, Loss_2: 0.0025, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 19:12:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0028, Acc_1: 0.8750, Acc_2: 0.7422, 
2023-03-08 19:12:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0023, Loss_2: 0.0038, Acc_1: 0.8516, Acc_2: 0.7578, 
2023-03-08 19:12:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0030, Acc_1: 0.8672, Acc_2: 0.7734, 
2023-03-08 19:12:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0012, Loss_2: 0.0034, Acc_1: 0.9062, Acc_2: 0.8203, 
2023-03-08 19:12:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0024, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 19:12:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0034, Acc_1: 0.8906, Acc_2: 0.7969, 
2023-03-08 19:12:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0026, Loss_2: 0.0046, Acc_1: 0.8203, Acc_2: 0.6875, 
2023-03-08 19:12:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0033, Acc_1: 0.8203, Acc_2: 0.7109, 
2023-03-08 19:12:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0016, Loss_2: 0.0022, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 19:13:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0014, Loss_2: 0.0037, Acc_1: 0.8203, Acc_2: 0.7422, 
2023-03-08 19:13:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0045, Acc_1: 0.8906, Acc_2: 0.7188, 
2023-03-08 19:13:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0080, Loss_2: 0.0230, Acc_1: 0.7850, Acc_2: 0.4103, F1-score_1: 0.7131, F1-score_2: 0.3250
2023-03-08 19:13:15 - __main__ - INFO - Epoch [13/100]
2023-03-08 19:13:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0035, Acc_1: 0.9062, Acc_2: 0.7969, 
2023-03-08 19:13:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0017, Loss_2: 0.0033, Acc_1: 0.8281, Acc_2: 0.7188, 
2023-03-08 19:13:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0010, Loss_2: 0.0039, Acc_1: 0.8906, Acc_2: 0.7656, 
2023-03-08 19:13:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0022, Acc_1: 0.8828, Acc_2: 0.8203, 
2023-03-08 19:13:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0028, Acc_1: 0.9062, Acc_2: 0.8203, 
2023-03-08 19:13:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0020, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-08 19:13:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0031, Acc_1: 0.8984, Acc_2: 0.8125, 
2023-03-08 19:13:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0033, Acc_1: 0.8984, Acc_2: 0.7891, 
2023-03-08 19:13:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0011, Loss_2: 0.0027, Acc_1: 0.8281, Acc_2: 0.7656, 
2023-03-08 19:13:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0018, Loss_2: 0.0040, Acc_1: 0.8672, Acc_2: 0.7500, 
2023-03-08 19:13:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0016, Loss_2: 0.0036, Acc_1: 0.8438, Acc_2: 0.7500, 
2023-03-08 19:13:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0029, Acc_1: 0.8438, Acc_2: 0.7656, 
2023-03-08 19:14:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0085, Loss_2: 0.0266, Acc_1: 0.7502, Acc_2: 0.4029, F1-score_1: 0.6883, F1-score_2: 0.3252
2023-03-08 19:14:09 - __main__ - INFO - Epoch [14/100]
2023-03-08 19:14:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0031, Acc_1: 0.8828, Acc_2: 0.7734, 
2023-03-08 19:14:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0019, Acc_1: 0.8984, Acc_2: 0.8281, 
2023-03-08 19:14:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0025, Acc_1: 0.8359, Acc_2: 0.7656, 
2023-03-08 19:14:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0025, Acc_1: 0.8750, Acc_2: 0.8203, 
2023-03-08 19:14:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0031, Acc_1: 0.8438, Acc_2: 0.7266, 
2023-03-08 19:14:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0018, Loss_2: 0.0034, Acc_1: 0.7812, Acc_2: 0.7266, 
2023-03-08 19:14:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0032, Acc_1: 0.8438, Acc_2: 0.7578, 
2023-03-08 19:14:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0034, Acc_1: 0.8516, Acc_2: 0.7500, 
2023-03-08 19:14:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0019, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 19:14:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0025, Acc_1: 0.8750, Acc_2: 0.7734, 
2023-03-08 19:14:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0031, Acc_1: 0.8828, Acc_2: 0.7656, 
2023-03-08 19:14:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0028, Acc_1: 0.8984, Acc_2: 0.8281, 
2023-03-08 19:15:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0096, Loss_2: 0.0277, Acc_1: 0.7806, Acc_2: 0.4068, F1-score_1: 0.7119, F1-score_2: 0.3269
2023-03-08 19:15:02 - __main__ - INFO - Epoch [15/100]
2023-03-08 19:15:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0028, Acc_1: 0.8516, Acc_2: 0.7422, 
2023-03-08 19:15:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0014, Loss_2: 0.0035, Acc_1: 0.8203, Acc_2: 0.7422, 
2023-03-08 19:15:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0025, Acc_1: 0.8906, Acc_2: 0.7891, 
2023-03-08 19:15:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0022, Acc_1: 0.8359, Acc_2: 0.7891, 
2023-03-08 19:15:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0018, Loss_2: 0.0022, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 19:15:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0014, Loss_2: 0.0024, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 19:15:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0017, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-08 19:15:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0033, Acc_1: 0.9141, Acc_2: 0.8047, 
2023-03-08 19:15:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0017, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 19:15:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 19:15:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0026, Acc_1: 0.9141, Acc_2: 0.8125, 
2023-03-08 19:15:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0023, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-08 19:15:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0104, Loss_2: 0.0307, Acc_1: 0.7711, Acc_2: 0.3998, F1-score_1: 0.7014, F1-score_2: 0.3230
2023-03-08 19:15:55 - __main__ - INFO - Epoch [16/100]
2023-03-08 19:16:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0018, Acc_1: 0.8594, Acc_2: 0.7969, 
2023-03-08 19:16:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0028, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 19:16:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0016, Acc_1: 0.8828, Acc_2: 0.8281, 
2023-03-08 19:16:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0026, Acc_1: 0.8828, Acc_2: 0.8203, 
2023-03-08 19:16:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0012, Loss_2: 0.0025, Acc_1: 0.8125, Acc_2: 0.7500, 
2023-03-08 19:16:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0020, Acc_1: 0.8438, Acc_2: 0.7812, 
2023-03-08 19:16:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0026, Acc_1: 0.9062, Acc_2: 0.7891, 
2023-03-08 19:16:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0021, Acc_1: 0.8281, Acc_2: 0.7734, 
2023-03-08 19:16:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0029, Acc_1: 0.8438, Acc_2: 0.7578, 
2023-03-08 19:16:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0019, Loss_2: 0.0036, Acc_1: 0.8281, Acc_2: 0.7500, 
2023-03-08 19:16:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0022, Acc_1: 0.8984, Acc_2: 0.8203, 
2023-03-08 19:16:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0019, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 19:16:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0111, Loss_2: 0.0313, Acc_1: 0.7621, Acc_2: 0.4064, F1-score_1: 0.6946, F1-score_2: 0.3263
2023-03-08 19:16:48 - __main__ - INFO - Epoch [17/100]
2023-03-08 19:16:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0020, Acc_1: 0.9062, Acc_2: 0.8047, 
2023-03-08 19:16:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 19:17:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-08 19:17:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0013, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 19:17:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0016, Acc_1: 0.8828, Acc_2: 0.7969, 
2023-03-08 19:17:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-08 19:17:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 19:17:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0016, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-08 19:17:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0015, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 19:17:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-08 19:17:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0012, Loss_2: 0.0025, Acc_1: 0.8047, Acc_2: 0.7578, 
2023-03-08 19:17:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0019, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-08 19:17:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0315, Acc_1: 0.7809, Acc_2: 0.4056, F1-score_1: 0.7128, F1-score_2: 0.3262
2023-03-08 19:17:42 - __main__ - INFO - Epoch [18/100]
2023-03-08 19:17:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 19:17:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0018, Acc_1: 0.9141, Acc_2: 0.8125, 
2023-03-08 19:17:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0016, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-08 19:17:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-08 19:18:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8984, Acc_2: 0.8281, 
2023-03-08 19:18:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0016, Acc_1: 0.8906, Acc_2: 0.8438, 
2023-03-08 19:18:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0011, Loss_2: 0.0022, Acc_1: 0.9062, Acc_2: 0.8125, 
2023-03-08 19:18:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0018, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-08 19:18:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0011, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 19:18:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0028, Acc_1: 0.8984, Acc_2: 0.7734, 
2023-03-08 19:18:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0020, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 19:18:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0016, Acc_1: 0.8516, Acc_2: 0.7812, 
2023-03-08 19:18:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0115, Loss_2: 0.0307, Acc_1: 0.7629, Acc_2: 0.4078, F1-score_1: 0.6927, F1-score_2: 0.3309
2023-03-08 19:18:35 - __main__ - INFO - Epoch [19/100]
2023-03-08 19:18:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0017, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 19:18:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8281, Acc_2: 0.7812, 
2023-03-08 19:18:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 19:18:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 19:18:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0019, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 19:18:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-08 19:19:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-08 19:19:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.7891, 
2023-03-08 19:19:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0018, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 19:19:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0026, Acc_1: 0.8047, Acc_2: 0.7188, 
2023-03-08 19:19:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0014, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 19:19:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0015, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-08 19:19:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0137, Loss_2: 0.0349, Acc_1: 0.7677, Acc_2: 0.4129, F1-score_1: 0.7033, F1-score_2: 0.3320
2023-03-08 19:19:28 - __main__ - INFO - Epoch [20/100]
2023-03-08 19:19:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-08 19:19:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:19:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 19:19:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:19:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0012, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 19:19:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0023, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 19:19:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0014, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 19:19:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0015, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 19:20:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0014, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 19:20:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0010, Loss_2: 0.0014, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 19:20:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0015, Loss_2: 0.0013, Acc_1: 0.8438, Acc_2: 0.7891, 
2023-03-08 19:20:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0022, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 19:20:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0113, Loss_2: 0.0342, Acc_1: 0.7546, Acc_2: 0.4095, F1-score_1: 0.6860, F1-score_2: 0.3244
2023-03-08 19:20:22 - __main__ - INFO - Epoch [21/100]
2023-03-08 19:20:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 19:20:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0017, Acc_1: 0.8750, Acc_2: 0.8203, 
2023-03-08 19:20:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 19:20:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0013, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 19:20:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9531, Acc_2: 0.9062, 
2023-03-08 19:20:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 19:20:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 19:20:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0011, Acc_1: 0.8438, Acc_2: 0.7969, 
2023-03-08 19:20:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 19:20:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 19:21:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-08 19:21:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-08 19:21:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0114, Loss_2: 0.0330, Acc_1: 0.7714, Acc_2: 0.4000, F1-score_1: 0.6972, F1-score_2: 0.3263
2023-03-08 19:21:15 - __main__ - INFO - Epoch [22/100]
2023-03-08 19:21:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8125, 
2023-03-08 19:21:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8828, Acc_2: 0.8125, 
2023-03-08 19:21:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 19:21:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0012, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 19:21:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0011, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 19:21:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-08 19:21:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 19:21:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0024, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-08 19:21:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 19:21:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0015, Loss_2: 0.0020, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 19:21:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0019, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 19:21:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0016, Loss_2: 0.0014, Acc_1: 0.8047, Acc_2: 0.7812, 
2023-03-08 19:22:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0110, Loss_2: 0.0347, Acc_1: 0.7480, Acc_2: 0.3935, F1-score_1: 0.6814, F1-score_2: 0.3228
2023-03-08 19:22:08 - __main__ - INFO - Epoch [23/100]
2023-03-08 19:22:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0012, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-08 19:22:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0017, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 19:22:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8750, Acc_2: 0.8125, 
2023-03-08 19:22:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-08 19:22:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0018, Acc_1: 0.8281, Acc_2: 0.7578, 
2023-03-08 19:22:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0013, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 19:22:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 19:22:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0020, Acc_1: 0.8984, Acc_2: 0.8359, 
2023-03-08 19:22:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0012, Loss_2: 0.0020, Acc_1: 0.8047, Acc_2: 0.7656, 
2023-03-08 19:22:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 19:22:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0016, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 19:22:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 19:23:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0140, Loss_2: 0.0340, Acc_1: 0.7126, Acc_2: 0.4030, F1-score_1: 0.6347, F1-score_2: 0.3193
2023-03-08 19:23:01 - __main__ - INFO - Epoch [24/100]
2023-03-08 19:23:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0009, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 19:23:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0009, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 19:23:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:23:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0017, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 19:23:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 19:23:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 19:23:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 19:23:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0009, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 19:23:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 19:23:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0014, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 19:23:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0012, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 19:23:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 19:23:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0122, Loss_2: 0.0343, Acc_1: 0.7722, Acc_2: 0.4046, F1-score_1: 0.6942, F1-score_2: 0.3221
2023-03-08 19:23:55 - __main__ - INFO - Epoch [25/100]
2023-03-08 19:24:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 19:24:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 19:24:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 19:24:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 19:24:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0016, Loss_2: 0.0012, Acc_1: 0.8125, Acc_2: 0.7734, 
2023-03-08 19:24:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 19:24:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0015, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 19:24:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0012, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 19:24:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-08 19:24:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 19:24:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-08 19:24:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.8281, Acc_2: 0.7891, 
2023-03-08 19:24:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0135, Loss_2: 0.0362, Acc_1: 0.7666, Acc_2: 0.4029, F1-score_1: 0.7004, F1-score_2: 0.3204
2023-03-08 19:24:48 - __main__ - INFO - Epoch [26/100]
2023-03-08 19:24:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 19:24:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0021, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 19:25:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 19:25:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 19:25:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0010, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 19:25:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 19:25:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 19:25:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 19:25:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 19:25:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0016, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 19:25:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 19:25:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-08 19:25:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0159, Loss_2: 0.0331, Acc_1: 0.7673, Acc_2: 0.4059, F1-score_1: 0.7025, F1-score_2: 0.3256
2023-03-08 19:25:41 - __main__ - INFO - Epoch [27/100]
2023-03-08 19:25:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 19:25:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-08 19:25:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-08 19:25:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8203, 
2023-03-08 19:26:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-08 19:26:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 19:26:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0012, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 19:26:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 19:26:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0019, Acc_1: 0.8750, Acc_2: 0.8203, 
2023-03-08 19:26:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 19:26:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0013, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 19:26:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 19:26:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0124, Loss_2: 0.0337, Acc_1: 0.7736, Acc_2: 0.4003, F1-score_1: 0.7081, F1-score_2: 0.3225
2023-03-08 19:26:35 - __main__ - INFO - Epoch [28/100]
2023-03-08 19:26:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 19:26:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-08 19:26:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.8281, Acc_2: 0.7812, 
2023-03-08 19:26:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 19:26:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 19:26:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 19:27:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 19:27:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0023, Acc_1: 0.8906, Acc_2: 0.7812, 
2023-03-08 19:27:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-08 19:27:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0011, Loss_2: 0.0021, Acc_1: 0.8359, Acc_2: 0.7734, 
2023-03-08 19:27:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 19:27:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-08 19:27:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0136, Loss_2: 0.0317, Acc_1: 0.7615, Acc_2: 0.3988, F1-score_1: 0.6985, F1-score_2: 0.3272
2023-03-08 19:27:28 - __main__ - INFO - Epoch [29/100]
2023-03-08 19:27:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 19:27:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 19:27:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 19:27:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 19:27:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 19:27:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 19:27:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 19:27:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 19:28:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8438, Acc_2: 0.7969, 
2023-03-08 19:28:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-08 19:28:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0013, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 19:28:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0014, Acc_1: 0.8203, Acc_2: 0.7812, 
2023-03-08 19:28:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0131, Loss_2: 0.0335, Acc_1: 0.7709, Acc_2: 0.3988, F1-score_1: 0.7030, F1-score_2: 0.3210
2023-03-08 19:28:21 - __main__ - INFO - Epoch [30/100]
2023-03-08 19:28:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 19:28:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9375, Acc_2: 0.8906, 
2023-03-08 19:28:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 19:28:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 19:28:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 19:28:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 19:28:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 19:28:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 19:28:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 19:28:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 19:29:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:29:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 19:29:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0141, Loss_2: 0.0299, Acc_1: 0.7519, Acc_2: 0.4083, F1-score_1: 0.6883, F1-score_2: 0.3322
2023-03-08 19:29:14 - __main__ - INFO - Epoch [31/100]
2023-03-08 19:29:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0013, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 19:29:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 19:29:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 19:29:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 19:29:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-08 19:29:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8047, 
2023-03-08 19:29:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 19:29:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 19:29:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:29:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 19:29:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 19:29:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 19:30:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0155, Loss_2: 0.0317, Acc_1: 0.7721, Acc_2: 0.3989, F1-score_1: 0.7044, F1-score_2: 0.3225
2023-03-08 19:30:08 - __main__ - INFO - Epoch [32/100]
2023-03-08 19:30:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8203, Acc_2: 0.7734, 
2023-03-08 19:30:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 19:30:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 19:30:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 19:30:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 19:30:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 19:30:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-08 19:30:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 19:30:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 19:30:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 19:30:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 19:30:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 19:31:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0122, Loss_2: 0.0317, Acc_1: 0.7622, Acc_2: 0.3952, F1-score_1: 0.6970, F1-score_2: 0.3288
2023-03-08 19:31:01 - __main__ - INFO - Epoch [33/100]
2023-03-08 19:31:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:31:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9219, Acc_2: 0.8594, 
2023-03-08 19:31:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8047, 
2023-03-08 19:31:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8281, 
2023-03-08 19:31:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 19:31:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 19:31:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 19:31:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 19:31:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 19:31:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 19:31:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:31:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 19:31:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0159, Loss_2: 0.0340, Acc_1: 0.7610, Acc_2: 0.3937, F1-score_1: 0.6964, F1-score_2: 0.3222
2023-03-08 19:31:54 - __main__ - INFO - Epoch [34/100]
2023-03-08 19:31:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 19:32:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 19:32:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-08 19:32:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 19:32:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-08 19:32:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0014, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-08 19:32:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 19:32:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9062, Acc_2: 0.8438, 
2023-03-08 19:32:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 19:32:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 19:32:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 19:32:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 19:32:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0129, Loss_2: 0.0360, Acc_1: 0.7643, Acc_2: 0.3937, F1-score_1: 0.6920, F1-score_2: 0.3236
2023-03-08 19:32:48 - __main__ - INFO - Epoch [35/100]
2023-03-08 19:32:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 19:32:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-08 19:33:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 19:33:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 19:33:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 19:33:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 19:33:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 19:33:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-08 19:33:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0009, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 19:33:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 19:33:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 19:33:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 19:33:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0106, Loss_2: 0.0327, Acc_1: 0.7678, Acc_2: 0.4052, F1-score_1: 0.6955, F1-score_2: 0.3223
2023-03-08 19:33:41 - __main__ - INFO - Epoch [36/100]
2023-03-08 19:33:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 19:33:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0019, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8750, 
2023-03-08 19:33:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 19:33:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 19:34:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 19:34:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 19:34:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 19:34:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0022, Acc_1: 0.9141, Acc_2: 0.8672, 
2023-03-08 19:34:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-08 19:34:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 19:34:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0015, Acc_1: 0.8594, Acc_2: 0.8047, 
2023-03-08 19:34:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-08 19:34:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0129, Loss_2: 0.0325, Acc_1: 0.7672, Acc_2: 0.4003, F1-score_1: 0.6979, F1-score_2: 0.3237
2023-03-08 19:34:34 - __main__ - INFO - Epoch [37/100]
2023-03-08 19:34:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0014, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-08 19:34:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:34:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 19:34:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 19:34:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-08 19:34:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:35:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 19:35:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 19:35:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0023, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 19:35:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 19:35:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 19:35:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 19:35:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0140, Loss_2: 0.0374, Acc_1: 0.7614, Acc_2: 0.4027, F1-score_1: 0.6932, F1-score_2: 0.3318
2023-03-08 19:35:27 - __main__ - INFO - Epoch [38/100]
2023-03-08 19:35:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9297, Acc_2: 0.8906, 
2023-03-08 19:35:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 19:35:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 19:35:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 19:35:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:35:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 19:35:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 19:35:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 19:36:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 19:36:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 19:36:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 19:36:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 19:36:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0141, Loss_2: 0.0389, Acc_1: 0.7651, Acc_2: 0.3967, F1-score_1: 0.6969, F1-score_2: 0.3166
2023-03-08 19:36:20 - __main__ - INFO - Epoch [39/100]
2023-03-08 19:36:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 19:36:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 19:36:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 19:36:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 19:36:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8516, 
2023-03-08 19:36:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 19:36:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:36:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-08 19:36:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 19:36:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 19:37:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-08 19:37:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 19:37:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0129, Loss_2: 0.0381, Acc_1: 0.7675, Acc_2: 0.3964, F1-score_1: 0.6988, F1-score_2: 0.3224
2023-03-08 19:37:14 - __main__ - INFO - Epoch [40/100]
2023-03-08 19:37:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 19:37:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 19:37:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 19:37:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 19:37:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 19:37:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 19:37:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:37:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 19:37:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 19:37:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9609, Acc_2: 0.8984, 
2023-03-08 19:37:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 19:37:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 19:38:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0138, Loss_2: 0.0400, Acc_1: 0.7731, Acc_2: 0.3922, F1-score_1: 0.6994, F1-score_2: 0.3172
2023-03-08 19:38:08 - __main__ - INFO - Epoch [41/100]
2023-03-08 19:38:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 19:38:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 19:38:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 19:38:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 19:38:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0026, Loss_2: 0.0032, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-08 19:38:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 19:38:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 19:38:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 19:38:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 19:38:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 19:38:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 19:38:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 19:39:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0133, Loss_2: 0.0424, Acc_1: 0.7697, Acc_2: 0.3905, F1-score_1: 0.6977, F1-score_2: 0.3123
2023-03-08 19:39:01 - __main__ - INFO - Epoch [42/100]
2023-03-08 19:39:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 19:39:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 19:39:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0016, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 19:39:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0029, Loss_2: 0.0028, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 19:39:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.7969, 
2023-03-08 19:39:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8594, 
2023-03-08 19:39:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 19:39:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 19:39:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.7969, 
2023-03-08 19:39:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:39:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 19:39:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 19:39:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0152, Loss_2: 0.0401, Acc_1: 0.7631, Acc_2: 0.3942, F1-score_1: 0.6898, F1-score_2: 0.3156
2023-03-08 19:39:55 - __main__ - INFO - Epoch [43/100]
2023-03-08 19:40:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 19:40:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 19:40:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 19:40:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 19:40:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 19:40:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:40:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:40:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 19:40:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:40:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 19:40:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 19:40:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 19:40:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0128, Loss_2: 0.0391, Acc_1: 0.7670, Acc_2: 0.3915, F1-score_1: 0.7005, F1-score_2: 0.3272
2023-03-08 19:40:48 - __main__ - INFO - Epoch [44/100]
2023-03-08 19:40:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 19:40:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-08 19:41:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 19:41:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 19:41:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8672, 
2023-03-08 19:41:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 19:41:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 19:41:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 19:41:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0009, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-08 19:41:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 19:41:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 19:41:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 19:41:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0145, Loss_2: 0.0372, Acc_1: 0.7672, Acc_2: 0.3916, F1-score_1: 0.6966, F1-score_2: 0.3162
2023-03-08 19:41:41 - __main__ - INFO - Epoch [45/100]
2023-03-08 19:41:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 19:41:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:41:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 19:41:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0010, Loss_2: 0.0015, Acc_1: 0.7891, Acc_2: 0.7578, 
2023-03-08 19:42:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 19:42:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 19:42:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 19:42:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 19:42:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 19:42:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 19:42:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 19:42:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 19:42:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0142, Loss_2: 0.0437, Acc_1: 0.7722, Acc_2: 0.3911, F1-score_1: 0.6977, F1-score_2: 0.3194
2023-03-08 19:42:35 - __main__ - INFO - Epoch [46/100]
2023-03-08 19:42:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 19:42:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 19:42:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 19:42:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 19:42:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 19:42:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 19:43:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0016, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:43:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 19:43:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0013, Loss_2: 0.0028, Acc_1: 0.7891, Acc_2: 0.7734, 
2023-03-08 19:43:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:43:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:43:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 19:43:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0142, Loss_2: 0.0374, Acc_1: 0.7697, Acc_2: 0.3945, F1-score_1: 0.6954, F1-score_2: 0.3324
2023-03-08 19:43:28 - __main__ - INFO - Epoch [47/100]
2023-03-08 19:43:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0016, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 19:43:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:43:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 19:43:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 19:43:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 19:43:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 19:43:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 19:43:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:44:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 19:44:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 19:44:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 19:44:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:44:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0147, Loss_2: 0.0432, Acc_1: 0.7670, Acc_2: 0.4022, F1-score_1: 0.7008, F1-score_2: 0.3278
2023-03-08 19:44:21 - __main__ - INFO - Epoch [48/100]
2023-03-08 19:44:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 19:44:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 19:44:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:44:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 19:44:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8359, 
2023-03-08 19:44:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 19:44:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 19:44:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 19:44:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8516, 
2023-03-08 19:44:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 19:45:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 19:45:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 19:45:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0154, Loss_2: 0.0423, Acc_1: 0.7638, Acc_2: 0.4006, F1-score_1: 0.6943, F1-score_2: 0.3247
2023-03-08 19:45:15 - __main__ - INFO - Epoch [49/100]
2023-03-08 19:45:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 19:45:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 19:45:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 19:45:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 19:45:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 19:45:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-08 19:45:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 19:45:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 19:45:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 19:45:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 19:45:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:45:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 19:46:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0140, Loss_2: 0.0408, Acc_1: 0.7592, Acc_2: 0.4027, F1-score_1: 0.6896, F1-score_2: 0.3281
2023-03-08 19:46:08 - __main__ - INFO - Epoch [50/100]
2023-03-08 19:46:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 19:46:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 19:46:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 19:46:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 19:46:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 19:46:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-08 19:46:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 19:46:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 19:46:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 19:46:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.8438, Acc_2: 0.7969, 
2023-03-08 19:46:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 19:46:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 19:47:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0149, Loss_2: 0.0423, Acc_1: 0.7553, Acc_2: 0.4064, F1-score_1: 0.6825, F1-score_2: 0.3250
2023-03-08 19:47:01 - __main__ - INFO - Epoch [51/100]
2023-03-08 19:47:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 19:47:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-08 19:47:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 19:47:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9141, Acc_2: 0.8516, 
2023-03-08 19:47:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 19:47:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 19:47:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:47:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 19:47:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 19:47:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:47:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 19:47:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9141, Acc_2: 0.8750, 
2023-03-08 19:47:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0138, Loss_2: 0.0408, Acc_1: 0.7663, Acc_2: 0.4022, F1-score_1: 0.6940, F1-score_2: 0.3297
2023-03-08 19:47:54 - __main__ - INFO - Epoch [52/100]
2023-03-08 19:47:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 19:48:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 19:48:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 19:48:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-08 19:48:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-08 19:48:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 19:48:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 19:48:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 19:48:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-08 19:48:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8984, Acc_2: 0.8125, 
2023-03-08 19:48:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 19:48:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 19:48:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0135, Loss_2: 0.0409, Acc_1: 0.7734, Acc_2: 0.4096, F1-score_1: 0.7047, F1-score_2: 0.3255
2023-03-08 19:48:48 - __main__ - INFO - Epoch [53/100]
2023-03-08 19:48:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 19:48:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 19:49:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 19:49:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 19:49:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 19:49:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0015, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 19:49:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 19:49:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 19:49:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9375, Acc_2: 0.9062, 
2023-03-08 19:49:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 19:49:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:49:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:49:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0124, Loss_2: 0.0401, Acc_1: 0.7422, Acc_2: 0.4010, F1-score_1: 0.6770, F1-score_2: 0.3267
2023-03-08 19:49:41 - __main__ - INFO - Epoch [54/100]
2023-03-08 19:49:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 19:49:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 19:49:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 19:49:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0010, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 19:50:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-08 19:50:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 19:50:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 19:50:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 19:50:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 19:50:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 19:50:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 19:50:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 19:50:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0132, Loss_2: 0.0440, Acc_1: 0.7576, Acc_2: 0.4032, F1-score_1: 0.6871, F1-score_2: 0.3254
2023-03-08 19:50:34 - __main__ - INFO - Epoch [55/100]
2023-03-08 19:50:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 19:50:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 19:50:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 19:50:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 19:50:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 19:50:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 19:51:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 19:51:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:51:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 19:51:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 19:51:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 19:51:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 19:51:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0122, Loss_2: 0.0440, Acc_1: 0.7575, Acc_2: 0.3940, F1-score_1: 0.6883, F1-score_2: 0.3181
2023-03-08 19:51:28 - __main__ - INFO - Epoch [56/100]
2023-03-08 19:51:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 19:51:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 19:51:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 19:51:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:51:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 19:51:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 19:51:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 19:51:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:52:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 19:52:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 19:52:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:52:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 19:52:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0127, Loss_2: 0.0465, Acc_1: 0.7615, Acc_2: 0.4064, F1-score_1: 0.6953, F1-score_2: 0.3270
2023-03-08 19:52:21 - __main__ - INFO - Epoch [57/100]
2023-03-08 19:52:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 19:52:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 19:52:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 19:52:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:52:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 19:52:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 19:52:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 19:52:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 19:52:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 19:52:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0015, Loss_2: 0.0021, Acc_1: 0.8125, Acc_2: 0.7812, 
2023-03-08 19:53:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 19:53:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 19:53:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0133, Loss_2: 0.0435, Acc_1: 0.7575, Acc_2: 0.4037, F1-score_1: 0.6897, F1-score_2: 0.3221
2023-03-08 19:53:15 - __main__ - INFO - Epoch [58/100]
2023-03-08 19:53:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 19:53:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 19:53:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 19:53:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-08 19:53:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 19:53:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 19:53:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 19:53:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:53:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-08 19:53:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 19:53:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 19:53:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 19:54:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0147, Loss_2: 0.0452, Acc_1: 0.7593, Acc_2: 0.4015, F1-score_1: 0.6956, F1-score_2: 0.3258
2023-03-08 19:54:08 - __main__ - INFO - Epoch [59/100]
2023-03-08 19:54:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 19:54:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 19:54:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:54:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 19:54:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 19:54:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 19:54:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 19:54:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 19:54:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 19:54:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 19:54:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 19:54:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 19:55:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0136, Loss_2: 0.0455, Acc_1: 0.7607, Acc_2: 0.3962, F1-score_1: 0.6965, F1-score_2: 0.3264
2023-03-08 19:55:01 - __main__ - INFO - Epoch [60/100]
2023-03-08 19:55:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 19:55:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 19:55:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 19:55:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 19:55:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 19:55:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 19:55:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 19:55:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 19:55:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:55:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 19:55:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:55:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 19:55:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0124, Loss_2: 0.0484, Acc_1: 0.7590, Acc_2: 0.4119, F1-score_1: 0.6894, F1-score_2: 0.3333
2023-03-08 19:55:55 - __main__ - INFO - Epoch [61/100]
2023-03-08 19:56:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:56:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 19:56:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 19:56:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 19:56:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 19:56:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 19:56:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 19:56:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 19:56:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:56:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 19:56:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 19:56:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 19:56:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0140, Loss_2: 0.0503, Acc_1: 0.7631, Acc_2: 0.4100, F1-score_1: 0.6940, F1-score_2: 0.3293
2023-03-08 19:56:48 - __main__ - INFO - Epoch [62/100]
2023-03-08 19:56:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 19:56:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 19:57:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 19:57:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 19:57:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 19:57:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 19:57:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 19:57:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 19:57:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 19:57:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 19:57:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 19:57:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 19:57:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0168, Loss_2: 0.0515, Acc_1: 0.7493, Acc_2: 0.3910, F1-score_1: 0.6792, F1-score_2: 0.3233
2023-03-08 19:57:41 - __main__ - INFO - Epoch [63/100]
2023-03-08 19:57:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 19:57:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 19:57:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 19:57:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 19:58:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 19:58:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 19:58:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8203, 
2023-03-08 19:58:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 19:58:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0012, Acc_1: 0.9219, Acc_2: 0.8828, 
2023-03-08 19:58:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 19:58:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.8828, Acc_2: 0.8359, 
2023-03-08 19:58:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 19:58:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0129, Loss_2: 0.0476, Acc_1: 0.7483, Acc_2: 0.3954, F1-score_1: 0.6785, F1-score_2: 0.3284
2023-03-08 19:58:34 - __main__ - INFO - Epoch [64/100]
2023-03-08 19:58:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9375, Acc_2: 0.8906, 
2023-03-08 19:58:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 19:58:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 19:58:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 19:58:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 19:58:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0025, Acc_1: 0.8047, Acc_2: 0.7812, 
2023-03-08 19:59:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 19:59:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-08 19:59:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 19:59:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 19:59:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 19:59:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 19:59:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0147, Loss_2: 0.0461, Acc_1: 0.7621, Acc_2: 0.3998, F1-score_1: 0.6919, F1-score_2: 0.3237
2023-03-08 19:59:28 - __main__ - INFO - Epoch [65/100]
2023-03-08 19:59:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 19:59:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 19:59:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8906, 
2023-03-08 19:59:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 19:59:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 19:59:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 19:59:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 19:59:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 20:00:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 20:00:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 20:00:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:00:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:00:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0132, Loss_2: 0.0452, Acc_1: 0.7514, Acc_2: 0.4119, F1-score_1: 0.6845, F1-score_2: 0.3243
2023-03-08 20:00:21 - __main__ - INFO - Epoch [66/100]
2023-03-08 20:00:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0019, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:00:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 20:00:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 20:00:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 20:00:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 20:00:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:00:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:00:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:00:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 20:00:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 20:01:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:01:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:01:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0127, Loss_2: 0.0483, Acc_1: 0.7683, Acc_2: 0.3932, F1-score_1: 0.7014, F1-score_2: 0.3188
2023-03-08 20:01:14 - __main__ - INFO - Epoch [67/100]
2023-03-08 20:01:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-08 20:01:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 20:01:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:01:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:01:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 20:01:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:01:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 20:01:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:01:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:01:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:01:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:01:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 20:02:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0139, Loss_2: 0.0452, Acc_1: 0.7656, Acc_2: 0.3956, F1-score_1: 0.6996, F1-score_2: 0.3203
2023-03-08 20:02:08 - __main__ - INFO - Epoch [68/100]
2023-03-08 20:02:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:02:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:02:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 20:02:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 20:02:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 20:02:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 20:02:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:02:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:02:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 20:02:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 20:02:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:02:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 20:03:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0138, Loss_2: 0.0429, Acc_1: 0.7480, Acc_2: 0.3860, F1-score_1: 0.6859, F1-score_2: 0.3136
2023-03-08 20:03:01 - __main__ - INFO - Epoch [69/100]
2023-03-08 20:03:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 20:03:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9609, Acc_2: 0.9297, 
2023-03-08 20:03:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:03:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 20:03:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 20:03:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:03:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:03:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 20:03:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 20:03:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 20:03:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:03:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:03:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0133, Loss_2: 0.0461, Acc_1: 0.7532, Acc_2: 0.3945, F1-score_1: 0.6864, F1-score_2: 0.3139
2023-03-08 20:03:54 - __main__ - INFO - Epoch [70/100]
2023-03-08 20:03:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:04:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0019, Loss_2: 0.0028, Acc_1: 0.7891, Acc_2: 0.7734, 
2023-03-08 20:04:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 20:04:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:04:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 20:04:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:04:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 20:04:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:04:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:04:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:04:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:04:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 20:04:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0490, Acc_1: 0.7527, Acc_2: 0.3879, F1-score_1: 0.6853, F1-score_2: 0.3208
2023-03-08 20:04:47 - __main__ - INFO - Epoch [71/100]
2023-03-08 20:04:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:04:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 20:04:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.9141, Acc_2: 0.8828, 
2023-03-08 20:05:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 20:05:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 20:05:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:05:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 20:05:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 20:05:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:05:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 20:05:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 20:05:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:05:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0123, Loss_2: 0.0490, Acc_1: 0.7549, Acc_2: 0.4044, F1-score_1: 0.6864, F1-score_2: 0.3222
2023-03-08 20:05:41 - __main__ - INFO - Epoch [72/100]
2023-03-08 20:05:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:05:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 20:05:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 20:05:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:06:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 20:06:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 20:06:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:06:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0011, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:06:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 20:06:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 20:06:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:06:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 20:06:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0127, Loss_2: 0.0476, Acc_1: 0.7631, Acc_2: 0.3891, F1-score_1: 0.6935, F1-score_2: 0.3145
2023-03-08 20:06:34 - __main__ - INFO - Epoch [73/100]
2023-03-08 20:06:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 20:06:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:06:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 20:06:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:06:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:06:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 20:07:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 20:07:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:07:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:07:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:07:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 20:07:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:07:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0128, Loss_2: 0.0463, Acc_1: 0.7587, Acc_2: 0.4003, F1-score_1: 0.6879, F1-score_2: 0.3223
2023-03-08 20:07:28 - __main__ - INFO - Epoch [74/100]
2023-03-08 20:07:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 20:07:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:07:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-08 20:07:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 20:07:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:07:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 20:07:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9297, 
2023-03-08 20:07:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 20:08:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:08:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:08:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9219, 
2023-03-08 20:08:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 20:08:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0122, Loss_2: 0.0481, Acc_1: 0.7514, Acc_2: 0.3922, F1-score_1: 0.6818, F1-score_2: 0.3116
2023-03-08 20:08:21 - __main__ - INFO - Epoch [75/100]
2023-03-08 20:08:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8984, Acc_2: 0.8438, 
2023-03-08 20:08:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:08:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:08:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 20:08:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:08:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 20:08:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 20:08:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 20:08:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:08:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 20:09:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:09:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 20:09:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0105, Loss_2: 0.0503, Acc_1: 0.7643, Acc_2: 0.3932, F1-score_1: 0.6919, F1-score_2: 0.3139
2023-03-08 20:09:14 - __main__ - INFO - Epoch [76/100]
2023-03-08 20:09:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 20:09:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 20:09:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-08 20:09:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-08 20:09:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:09:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 20:09:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:09:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:09:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9453, Acc_2: 0.9219, 
2023-03-08 20:09:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:09:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 20:09:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:10:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0505, Acc_1: 0.7666, Acc_2: 0.3984, F1-score_1: 0.6937, F1-score_2: 0.3159
2023-03-08 20:10:07 - __main__ - INFO - Epoch [77/100]
2023-03-08 20:10:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 20:10:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:10:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:10:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:10:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:10:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 20:10:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:10:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:10:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 20:10:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 20:10:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 20:10:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 20:11:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0113, Loss_2: 0.0525, Acc_1: 0.7656, Acc_2: 0.3913, F1-score_1: 0.6918, F1-score_2: 0.3185
2023-03-08 20:11:01 - __main__ - INFO - Epoch [78/100]
2023-03-08 20:11:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 20:11:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:11:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 20:11:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:11:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:11:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:11:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:11:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:11:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:11:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 20:11:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:11:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:11:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0540, Acc_1: 0.7685, Acc_2: 0.3898, F1-score_1: 0.6950, F1-score_2: 0.3166
2023-03-08 20:11:54 - __main__ - INFO - Epoch [79/100]
2023-03-08 20:11:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:12:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:12:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 20:12:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 20:12:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:12:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:12:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 20:12:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:12:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:12:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 20:12:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:12:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 20:12:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0133, Loss_2: 0.0512, Acc_1: 0.7697, Acc_2: 0.4025, F1-score_1: 0.6955, F1-score_2: 0.3216
2023-03-08 20:12:48 - __main__ - INFO - Epoch [80/100]
2023-03-08 20:12:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:12:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 20:13:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:13:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:13:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 20:13:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 20:13:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:13:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0200, Acc_1: 0.8984, Acc_2: 0.6406, 
2023-03-08 20:13:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0015, Loss_2: 0.0028, Acc_1: 0.8984, Acc_2: 0.7500, 
2023-03-08 20:13:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0011, Acc_1: 0.9375, Acc_2: 0.8828, 
2023-03-08 20:13:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0018, Acc_1: 0.8828, Acc_2: 0.8047, 
2023-03-08 20:13:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0028, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 20:13:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0092, Loss_2: 0.0376, Acc_1: 0.7592, Acc_2: 0.3884, F1-score_1: 0.6879, F1-score_2: 0.3218
2023-03-08 20:13:41 - __main__ - INFO - Epoch [81/100]
2023-03-08 20:13:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 20:13:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 20:13:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:13:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8750, 
2023-03-08 20:14:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-08 20:14:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.8594, 
2023-03-08 20:14:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 20:14:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0011, Acc_1: 0.9375, Acc_2: 0.8906, 
2023-03-08 20:14:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 20:14:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 20:14:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:14:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:14:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0093, Loss_2: 0.0407, Acc_1: 0.7643, Acc_2: 0.3922, F1-score_1: 0.6913, F1-score_2: 0.3144
2023-03-08 20:14:34 - __main__ - INFO - Epoch [82/100]
2023-03-08 20:14:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:14:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:14:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:14:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 20:14:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:14:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 20:15:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 20:15:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 20:15:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:15:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 20:15:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:15:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 20:15:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0095, Loss_2: 0.0440, Acc_1: 0.7522, Acc_2: 0.3935, F1-score_1: 0.6819, F1-score_2: 0.3149
2023-03-08 20:15:27 - __main__ - INFO - Epoch [83/100]
2023-03-08 20:15:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 20:15:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:15:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 20:15:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:15:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0011, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 20:15:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:15:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 20:15:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 20:16:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 20:16:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-08 20:16:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:16:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:16:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0109, Loss_2: 0.0460, Acc_1: 0.7653, Acc_2: 0.4000, F1-score_1: 0.6933, F1-score_2: 0.3211
2023-03-08 20:16:21 - __main__ - INFO - Epoch [84/100]
2023-03-08 20:16:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 20:16:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 20:16:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:16:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 20:16:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:16:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 20:16:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:16:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:16:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:16:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:17:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:17:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:17:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0100, Loss_2: 0.0475, Acc_1: 0.7658, Acc_2: 0.3901, F1-score_1: 0.6947, F1-score_2: 0.3165
2023-03-08 20:17:14 - __main__ - INFO - Epoch [85/100]
2023-03-08 20:17:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:17:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:17:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:17:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:17:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:17:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 20:17:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:17:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:17:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:17:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 20:17:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 20:17:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:18:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0115, Loss_2: 0.0465, Acc_1: 0.7699, Acc_2: 0.3996, F1-score_1: 0.6983, F1-score_2: 0.3202
2023-03-08 20:18:07 - __main__ - INFO - Epoch [86/100]
2023-03-08 20:18:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8672, 
2023-03-08 20:18:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 20:18:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:18:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:18:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:18:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:18:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:18:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:18:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 20:18:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:18:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:18:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 20:19:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0105, Loss_2: 0.0466, Acc_1: 0.7716, Acc_2: 0.3940, F1-score_1: 0.7004, F1-score_2: 0.3192
2023-03-08 20:19:01 - __main__ - INFO - Epoch [87/100]
2023-03-08 20:19:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:19:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 20:19:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:19:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:19:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 20:19:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:19:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:19:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 20:19:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-08 20:19:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 20:19:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:19:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:19:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0471, Acc_1: 0.7733, Acc_2: 0.3947, F1-score_1: 0.7019, F1-score_2: 0.3178
2023-03-08 20:19:54 - __main__ - INFO - Epoch [88/100]
2023-03-08 20:19:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:20:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:20:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:20:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 20:20:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:20:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 20:20:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:20:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:20:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:20:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:20:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:20:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 20:20:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0116, Loss_2: 0.0488, Acc_1: 0.7665, Acc_2: 0.3933, F1-score_1: 0.6960, F1-score_2: 0.3168
2023-03-08 20:20:47 - __main__ - INFO - Epoch [89/100]
2023-03-08 20:20:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:20:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:20:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:21:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:21:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:21:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:21:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:21:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 20:21:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:21:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:21:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 20:21:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 20:21:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0109, Loss_2: 0.0472, Acc_1: 0.7714, Acc_2: 0.3952, F1-score_1: 0.7010, F1-score_2: 0.3168
2023-03-08 20:21:41 - __main__ - INFO - Epoch [90/100]
2023-03-08 20:21:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:21:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:21:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:21:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 20:22:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:22:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 20:22:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:22:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9062, 
2023-03-08 20:22:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:22:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:22:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:22:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:22:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0099, Loss_2: 0.0454, Acc_1: 0.7706, Acc_2: 0.3947, F1-score_1: 0.7000, F1-score_2: 0.3186
2023-03-08 20:22:34 - __main__ - INFO - Epoch [91/100]
2023-03-08 20:22:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:22:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:22:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:22:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-08 20:22:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:22:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:23:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:23:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:23:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-08 20:23:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:23:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 20:23:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:23:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0110, Loss_2: 0.0472, Acc_1: 0.7697, Acc_2: 0.3940, F1-score_1: 0.6980, F1-score_2: 0.3175
2023-03-08 20:23:28 - __main__ - INFO - Epoch [92/100]
2023-03-08 20:23:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:23:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:23:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:23:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 20:23:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 20:23:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:23:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:23:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:24:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 20:24:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:24:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 20:24:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 20:24:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0117, Loss_2: 0.0470, Acc_1: 0.7706, Acc_2: 0.3911, F1-score_1: 0.6993, F1-score_2: 0.3159
2023-03-08 20:24:21 - __main__ - INFO - Epoch [93/100]
2023-03-08 20:24:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:24:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 20:24:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:24:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 20:24:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 20:24:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:24:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 20:24:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:24:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:24:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 20:25:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:25:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:25:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0114, Loss_2: 0.0474, Acc_1: 0.7689, Acc_2: 0.3972, F1-score_1: 0.6970, F1-score_2: 0.3192
2023-03-08 20:25:14 - __main__ - INFO - Epoch [94/100]
2023-03-08 20:25:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:25:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:25:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:25:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:25:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 20:25:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 20:25:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:25:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 20:25:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:25:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:25:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 20:25:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 20:26:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0476, Acc_1: 0.7694, Acc_2: 0.3950, F1-score_1: 0.6970, F1-score_2: 0.3168
2023-03-08 20:26:08 - __main__ - INFO - Epoch [95/100]
2023-03-08 20:26:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:26:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:26:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:26:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9297, 
2023-03-08 20:26:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 20:26:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:26:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:26:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:26:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:26:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:26:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:26:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 20:27:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0131, Loss_2: 0.0482, Acc_1: 0.7700, Acc_2: 0.3928, F1-score_1: 0.6984, F1-score_2: 0.3176
2023-03-08 20:27:01 - __main__ - INFO - Epoch [96/100]
2023-03-08 20:27:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:27:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:27:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 20:27:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:27:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:27:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 20:27:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:27:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:27:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 20:27:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:27:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:27:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:27:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0476, Acc_1: 0.7706, Acc_2: 0.3933, F1-score_1: 0.6994, F1-score_2: 0.3171
2023-03-08 20:27:54 - __main__ - INFO - Epoch [97/100]
2023-03-08 20:27:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:28:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:28:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:28:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:28:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:28:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:28:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9375, Acc_2: 0.9297, 
2023-03-08 20:28:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:28:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:28:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:28:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 20:28:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 20:28:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0126, Loss_2: 0.0483, Acc_1: 0.7709, Acc_2: 0.3930, F1-score_1: 0.6999, F1-score_2: 0.3181
2023-03-08 20:28:48 - __main__ - INFO - Epoch [98/100]
2023-03-08 20:28:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:28:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 20:29:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:29:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 20:29:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:29:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:29:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 20:29:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:29:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:29:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 20:29:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:29:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.8984, 
2023-03-08 20:29:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0116, Loss_2: 0.0473, Acc_1: 0.7690, Acc_2: 0.3978, F1-score_1: 0.6962, F1-score_2: 0.3157
2023-03-08 20:29:41 - __main__ - INFO - Epoch [99/100]
2023-03-08 20:29:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:29:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:29:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 20:29:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:30:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9141, 
2023-03-08 20:30:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 20:30:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:30:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:30:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:30:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:30:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:30:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:30:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0130, Loss_2: 0.0484, Acc_1: 0.7689, Acc_2: 0.3911, F1-score_1: 0.6958, F1-score_2: 0.3162
2023-03-08 20:30:37 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 20:30:37 - utils._noise - DEBUG - 6, 7
2023-03-08 20:30:37 - utils._noise - DEBUG - 13997
2023-03-08 20:30:37 - utils._noise - INFO - Actual noise 0.20
2023-03-08 20:30:37 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-08 20:30:37 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-08 20:30:39 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 20:30:39 - __main__ - INFO - Loading dataset...
2023-03-08 20:30:39 - __main__ - INFO - Building model...
2023-03-08 20:30:39 - __main__ - INFO - <bound method Module.parameters of NewsNet(
  (embedding): Embedding(20000, 300)
  (avgpool): AdaptiveAvgPool1d(output_size=4800)
  (fc1): Linear(in_features=4800, out_features=1200, bias=True)
  (bn1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ac): Softsign()
  (fc2): Linear(in_features=1200, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=7, bias=True)
)>
2023-03-08 20:30:39 - __main__ - INFO - <bound method Module.parameters of NewsNet(
  (embedding): Embedding(20000, 300)
  (avgpool): AdaptiveAvgPool1d(output_size=4800)
  (fc1): Linear(in_features=4800, out_features=1200, bias=True)
  (bn1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ac): Softsign()
  (fc2): Linear(in_features=1200, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=7, bias=True)
)>
2023-03-08 20:30:39 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-08 20:30:39 - __main__ - INFO - Start train & evaluate
2023-03-08 20:30:39 - __main__ - INFO - Epoch [0/100]
2023-03-08 20:30:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0155, Loss_2: 0.0157, Acc_1: 0.1172, Acc_2: 0.0938, 
2023-03-08 20:30:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0146, Loss_2: 0.0144, Acc_1: 0.3125, Acc_2: 0.3281, 
2023-03-08 20:30:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0137, Loss_2: 0.0137, Acc_1: 0.3516, Acc_2: 0.3672, 
2023-03-08 20:30:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0142, Loss_2: 0.0143, Acc_1: 0.2891, Acc_2: 0.3203, 
2023-03-08 20:30:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0133, Loss_2: 0.0133, Acc_1: 0.3203, Acc_2: 0.3203, 
2023-03-08 20:30:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0129, Loss_2: 0.0130, Acc_1: 0.3594, Acc_2: 0.3594, 
2023-03-08 20:30:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0134, Loss_2: 0.0133, Acc_1: 0.3672, Acc_2: 0.3750, 
2023-03-08 20:30:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0137, Loss_2: 0.0137, Acc_1: 0.3125, Acc_2: 0.3125, 
2023-03-08 20:30:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0130, Loss_2: 0.0130, Acc_1: 0.3359, Acc_2: 0.3438, 
2023-03-08 20:30:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0128, Loss_2: 0.0128, Acc_1: 0.3828, Acc_2: 0.3672, 
2023-03-08 20:30:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0136, Loss_2: 0.0136, Acc_1: 0.3281, Acc_2: 0.3203, 
2023-03-08 20:30:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0125, Loss_2: 0.0126, Acc_1: 0.3906, Acc_2: 0.3828, 
2023-03-08 20:30:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0126, Acc_1: 0.4582, Acc_2: 0.4538, F1-score_1: 0.2877, F1-score_2: 0.2929
2023-03-08 20:30:53 - __main__ - INFO - Epoch [1/100]
2023-03-08 20:30:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0112, Loss_2: 0.0113, Acc_1: 0.4844, Acc_2: 0.4844, 
2023-03-08 20:30:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0111, Loss_2: 0.0111, Acc_1: 0.4453, Acc_2: 0.4609, 
2023-03-08 20:30:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0116, Loss_2: 0.0115, Acc_1: 0.4453, Acc_2: 0.4609, 
2023-03-08 20:30:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0117, Loss_2: 0.0118, Acc_1: 0.4141, Acc_2: 0.4453, 
2023-03-08 20:30:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0118, Loss_2: 0.0119, Acc_1: 0.4453, Acc_2: 0.3984, 
2023-03-08 20:30:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0118, Loss_2: 0.0118, Acc_1: 0.4375, Acc_2: 0.4297, 
2023-03-08 20:30:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0116, Loss_2: 0.0115, Acc_1: 0.4062, Acc_2: 0.4297, 
2023-03-08 20:30:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0113, Loss_2: 0.0113, Acc_1: 0.4609, Acc_2: 0.4766, 
2023-03-08 20:30:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0118, Loss_2: 0.0118, Acc_1: 0.4141, Acc_2: 0.4219, 
2023-03-08 20:31:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0124, Loss_2: 0.0125, Acc_1: 0.3984, Acc_2: 0.3906, 
2023-03-08 20:31:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0125, Loss_2: 0.0124, Acc_1: 0.3984, Acc_2: 0.4297, 
2023-03-08 20:31:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0125, Loss_2: 0.0124, Acc_1: 0.3984, Acc_2: 0.4062, 
2023-03-08 20:31:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0120, Acc_1: 0.4589, Acc_2: 0.4560, F1-score_1: 0.3495, F1-score_2: 0.3468
2023-03-08 20:31:06 - __main__ - INFO - Epoch [2/100]
2023-03-08 20:31:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0101, Loss_2: 0.0101, Acc_1: 0.5312, Acc_2: 0.5547, 
2023-03-08 20:31:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0092, Loss_2: 0.0090, Acc_1: 0.5391, Acc_2: 0.5859, 
2023-03-08 20:31:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0090, Loss_2: 0.0092, Acc_1: 0.5781, Acc_2: 0.5547, 
2023-03-08 20:31:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0101, Loss_2: 0.0102, Acc_1: 0.5391, Acc_2: 0.5469, 
2023-03-08 20:31:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0085, Loss_2: 0.0084, Acc_1: 0.5859, Acc_2: 0.5781, 
2023-03-08 20:31:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0104, Loss_2: 0.0106, Acc_1: 0.4688, Acc_2: 0.4609, 
2023-03-08 20:31:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0108, Loss_2: 0.0111, Acc_1: 0.4844, Acc_2: 0.4766, 
2023-03-08 20:31:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0105, Loss_2: 0.0103, Acc_1: 0.4609, Acc_2: 0.4609, 
2023-03-08 20:31:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0108, Loss_2: 0.0109, Acc_1: 0.4141, Acc_2: 0.4531, 
2023-03-08 20:31:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0111, Loss_2: 0.0112, Acc_1: 0.4375, Acc_2: 0.4375, 
2023-03-08 20:31:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0106, Loss_2: 0.0106, Acc_1: 0.5156, Acc_2: 0.5156, 
2023-03-08 20:31:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0115, Loss_2: 0.0117, Acc_1: 0.4688, Acc_2: 0.4141, 
2023-03-08 20:31:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0122, Loss_2: 0.0122, Acc_1: 0.4375, Acc_2: 0.4377, F1-score_1: 0.3393, F1-score_2: 0.3366
2023-03-08 20:31:20 - __main__ - INFO - Epoch [3/100]
2023-03-08 20:31:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0075, Loss_2: 0.0076, Acc_1: 0.6875, Acc_2: 0.6484, 
2023-03-08 20:31:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0074, Loss_2: 0.0076, Acc_1: 0.6484, Acc_2: 0.6484, 
2023-03-08 20:31:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0079, Loss_2: 0.0080, Acc_1: 0.5938, Acc_2: 0.5703, 
2023-03-08 20:31:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0092, Loss_2: 0.0091, Acc_1: 0.5391, Acc_2: 0.5312, 
2023-03-08 20:31:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0086, Loss_2: 0.0086, Acc_1: 0.5391, Acc_2: 0.5781, 
2023-03-08 20:31:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0091, Loss_2: 0.0091, Acc_1: 0.5000, Acc_2: 0.5234, 
2023-03-08 20:31:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0088, Loss_2: 0.0091, Acc_1: 0.5938, Acc_2: 0.5859, 
2023-03-08 20:31:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0083, Loss_2: 0.0085, Acc_1: 0.5469, Acc_2: 0.5469, 
2023-03-08 20:31:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0087, Loss_2: 0.0089, Acc_1: 0.6016, Acc_2: 0.6016, 
2023-03-08 20:31:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0095, Loss_2: 0.0094, Acc_1: 0.5000, Acc_2: 0.4922, 
2023-03-08 20:31:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0094, Loss_2: 0.0092, Acc_1: 0.5156, Acc_2: 0.5625, 
2023-03-08 20:31:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0095, Loss_2: 0.0096, Acc_1: 0.5078, Acc_2: 0.5000, 
2023-03-08 20:31:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0125, Loss_2: 0.0128, Acc_1: 0.4217, Acc_2: 0.4193, F1-score_1: 0.3299, F1-score_2: 0.3319
2023-03-08 20:31:33 - __main__ - INFO - Epoch [4/100]
2023-03-08 20:31:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0071, Loss_2: 0.0072, Acc_1: 0.5938, Acc_2: 0.5938, 
2023-03-08 20:31:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0073, Loss_2: 0.0076, Acc_1: 0.6250, Acc_2: 0.6250, 
2023-03-08 20:31:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0070, Loss_2: 0.0070, Acc_1: 0.6094, Acc_2: 0.6172, 
2023-03-08 20:31:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0083, Loss_2: 0.0083, Acc_1: 0.5469, Acc_2: 0.5781, 
2023-03-08 20:31:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0086, Loss_2: 0.0087, Acc_1: 0.5312, Acc_2: 0.5391, 
2023-03-08 20:31:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0078, Loss_2: 0.0077, Acc_1: 0.5547, Acc_2: 0.5391, 
2023-03-08 20:31:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0076, Loss_2: 0.0075, Acc_1: 0.6406, Acc_2: 0.6250, 
2023-03-08 20:31:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0074, Loss_2: 0.0074, Acc_1: 0.5938, Acc_2: 0.5781, 
2023-03-08 20:31:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0075, Loss_2: 0.0076, Acc_1: 0.5938, Acc_2: 0.6172, 
2023-03-08 20:31:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0086, Loss_2: 0.0085, Acc_1: 0.4844, Acc_2: 0.4922, 
2023-03-08 20:31:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0094, Loss_2: 0.0096, Acc_1: 0.5625, Acc_2: 0.5469, 
2023-03-08 20:31:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0071, Loss_2: 0.0071, Acc_1: 0.5859, Acc_2: 0.6016, 
2023-03-08 20:31:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0128, Loss_2: 0.0127, Acc_1: 0.4079, Acc_2: 0.4061, F1-score_1: 0.3162, F1-score_2: 0.3082
2023-03-08 20:31:47 - __main__ - INFO - Epoch [5/100]
2023-03-08 20:31:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0060, Loss_2: 0.0058, Acc_1: 0.6953, Acc_2: 0.7188, 
2023-03-08 20:31:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0053, Loss_2: 0.0053, Acc_1: 0.6797, Acc_2: 0.6875, 
2023-03-08 20:31:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0069, Loss_2: 0.0070, Acc_1: 0.6016, Acc_2: 0.6328, 
2023-03-08 20:31:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0053, Loss_2: 0.0052, Acc_1: 0.7031, Acc_2: 0.6953, 
2023-03-08 20:31:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0056, Loss_2: 0.0056, Acc_1: 0.6484, Acc_2: 0.6562, 
2023-03-08 20:31:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0080, Loss_2: 0.0080, Acc_1: 0.5469, Acc_2: 0.5547, 
2023-03-08 20:31:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0084, Loss_2: 0.0080, Acc_1: 0.5703, Acc_2: 0.6094, 
2023-03-08 20:31:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0052, Loss_2: 0.0053, Acc_1: 0.7188, Acc_2: 0.6484, 
2023-03-08 20:31:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0067, Loss_2: 0.0065, Acc_1: 0.6328, Acc_2: 0.6641, 
2023-03-08 20:31:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0059, Loss_2: 0.0054, Acc_1: 0.6562, Acc_2: 0.6875, 
2023-03-08 20:31:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0074, Loss_2: 0.0075, Acc_1: 0.5859, Acc_2: 0.5625, 
2023-03-08 20:31:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0080, Loss_2: 0.0083, Acc_1: 0.5547, Acc_2: 0.5234, 
2023-03-08 20:32:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0139, Loss_2: 0.0138, Acc_1: 0.4076, Acc_2: 0.3989, F1-score_1: 0.3317, F1-score_2: 0.3297
2023-03-08 20:32:00 - __main__ - INFO - Epoch [6/100]
2023-03-08 20:32:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0040, Loss_2: 0.0043, Acc_1: 0.7344, Acc_2: 0.7344, 
2023-03-08 20:32:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0035, Loss_2: 0.0035, Acc_1: 0.7422, Acc_2: 0.7344, 
2023-03-08 20:32:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0040, Loss_2: 0.0040, Acc_1: 0.7266, Acc_2: 0.7109, 
2023-03-08 20:32:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0052, Loss_2: 0.0052, Acc_1: 0.6328, Acc_2: 0.6250, 
2023-03-08 20:32:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0058, Loss_2: 0.0059, Acc_1: 0.6562, Acc_2: 0.6094, 
2023-03-08 20:32:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0045, Loss_2: 0.0046, Acc_1: 0.7031, Acc_2: 0.7031, 
2023-03-08 20:32:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0060, Loss_2: 0.0064, Acc_1: 0.6406, Acc_2: 0.6172, 
2023-03-08 20:32:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0044, Loss_2: 0.0044, Acc_1: 0.6641, Acc_2: 0.6641, 
2023-03-08 20:32:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0073, Loss_2: 0.0074, Acc_1: 0.5781, Acc_2: 0.5781, 
2023-03-08 20:32:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0048, Loss_2: 0.0048, Acc_1: 0.6641, Acc_2: 0.6797, 
2023-03-08 20:32:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0058, Loss_2: 0.0058, Acc_1: 0.6250, Acc_2: 0.6250, 
2023-03-08 20:32:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0074, Loss_2: 0.0075, Acc_1: 0.6328, Acc_2: 0.5859, 
2023-03-08 20:32:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0161, Loss_2: 0.0155, Acc_1: 0.4034, Acc_2: 0.4017, F1-score_1: 0.3200, F1-score_2: 0.3183
2023-03-08 20:32:14 - __main__ - INFO - Epoch [7/100]
2023-03-08 20:32:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0026, Loss_2: 0.0029, Acc_1: 0.8047, Acc_2: 0.7422, 
2023-03-08 20:32:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0045, Loss_2: 0.0048, Acc_1: 0.7031, Acc_2: 0.6875, 
2023-03-08 20:32:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0045, Loss_2: 0.0047, Acc_1: 0.6953, Acc_2: 0.6797, 
2023-03-08 20:32:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0055, Loss_2: 0.0052, Acc_1: 0.6094, Acc_2: 0.6094, 
2023-03-08 20:32:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0049, Loss_2: 0.0048, Acc_1: 0.6484, Acc_2: 0.6562, 
2023-03-08 20:32:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0047, Loss_2: 0.0043, Acc_1: 0.6797, Acc_2: 0.6953, 
2023-03-08 20:32:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0043, Loss_2: 0.0044, Acc_1: 0.6875, Acc_2: 0.6953, 
2023-03-08 20:32:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0032, Loss_2: 0.0037, Acc_1: 0.7500, Acc_2: 0.7266, 
2023-03-08 20:32:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0037, Loss_2: 0.0034, Acc_1: 0.7109, Acc_2: 0.7266, 
2023-03-08 20:32:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0060, Loss_2: 0.0057, Acc_1: 0.6094, Acc_2: 0.6641, 
2023-03-08 20:32:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0051, Loss_2: 0.0053, Acc_1: 0.6562, Acc_2: 0.6328, 
2023-03-08 20:32:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0065, Loss_2: 0.0059, Acc_1: 0.6328, Acc_2: 0.6328, 
2023-03-08 20:32:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0155, Loss_2: 0.0158, Acc_1: 0.4071, Acc_2: 0.4149, F1-score_1: 0.3240, F1-score_2: 0.3351
2023-03-08 20:32:27 - __main__ - INFO - Epoch [8/100]
2023-03-08 20:32:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0033, Loss_2: 0.0032, Acc_1: 0.7188, Acc_2: 0.6953, 
2023-03-08 20:32:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0031, Loss_2: 0.0027, Acc_1: 0.7109, Acc_2: 0.7578, 
2023-03-08 20:32:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0043, Loss_2: 0.0041, Acc_1: 0.6328, Acc_2: 0.6484, 
2023-03-08 20:32:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0042, Loss_2: 0.0036, Acc_1: 0.6875, Acc_2: 0.7031, 
2023-03-08 20:32:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0039, Loss_2: 0.0033, Acc_1: 0.6875, Acc_2: 0.6953, 
2023-03-08 20:32:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0048, Loss_2: 0.0048, Acc_1: 0.6641, Acc_2: 0.6406, 
2023-03-08 20:32:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0045, Loss_2: 0.0046, Acc_1: 0.6719, Acc_2: 0.6875, 
2023-03-08 20:32:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0032, Loss_2: 0.0037, Acc_1: 0.7188, Acc_2: 0.7188, 
2023-03-08 20:32:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0060, Loss_2: 0.0056, Acc_1: 0.6172, Acc_2: 0.6328, 
2023-03-08 20:32:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0046, Loss_2: 0.0046, Acc_1: 0.6172, Acc_2: 0.6641, 
2023-03-08 20:32:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0041, Loss_2: 0.0044, Acc_1: 0.6953, Acc_2: 0.6719, 
2023-03-08 20:32:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0046, Loss_2: 0.0046, Acc_1: 0.6562, Acc_2: 0.6719, 
2023-03-08 20:32:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0164, Loss_2: 0.0168, Acc_1: 0.4046, Acc_2: 0.3996, F1-score_1: 0.3147, F1-score_2: 0.3134
2023-03-08 20:32:40 - __main__ - INFO - Epoch [9/100]
2023-03-08 20:32:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0021, Loss_2: 0.0022, Acc_1: 0.7500, Acc_2: 0.7500, 
2023-03-08 20:32:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0027, Loss_2: 0.0024, Acc_1: 0.7344, Acc_2: 0.7266, 
2023-03-08 20:32:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0034, Loss_2: 0.0030, Acc_1: 0.7031, Acc_2: 0.7266, 
2023-03-08 20:32:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0012, Loss_2: 0.0013, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 20:32:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0028, Loss_2: 0.0032, Acc_1: 0.7188, Acc_2: 0.6953, 
2023-03-08 20:32:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0038, Loss_2: 0.0048, Acc_1: 0.6641, Acc_2: 0.6328, 
2023-03-08 20:32:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0036, Loss_2: 0.0028, Acc_1: 0.7500, Acc_2: 0.7344, 
2023-03-08 20:32:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0023, Loss_2: 0.0030, Acc_1: 0.7266, Acc_2: 0.7188, 
2023-03-08 20:32:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0033, Loss_2: 0.0037, Acc_1: 0.7109, Acc_2: 0.6641, 
2023-03-08 20:32:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0043, Loss_2: 0.0039, Acc_1: 0.6562, Acc_2: 0.6797, 
2023-03-08 20:32:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0039, Loss_2: 0.0040, Acc_1: 0.6875, Acc_2: 0.6797, 
2023-03-08 20:32:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0032, Loss_2: 0.0029, Acc_1: 0.6562, Acc_2: 0.7266, 
2023-03-08 20:32:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0180, Loss_2: 0.0185, Acc_1: 0.3993, Acc_2: 0.3947, F1-score_1: 0.3179, F1-score_2: 0.3167
2023-03-08 20:32:54 - __main__ - INFO - Epoch [10/100]
2023-03-08 20:32:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0042, Loss_2: 0.0049, Acc_1: 0.6641, Acc_2: 0.6016, 
2023-03-08 20:32:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0019, Loss_2: 0.0018, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 20:32:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0017, Loss_2: 0.0020, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-08 20:32:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0019, Loss_2: 0.0021, Acc_1: 0.7422, Acc_2: 0.7422, 
2023-03-08 20:33:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0018, Loss_2: 0.0017, Acc_1: 0.7812, Acc_2: 0.8047, 
2023-03-08 20:33:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0019, Loss_2: 0.0031, Acc_1: 0.7656, Acc_2: 0.7344, 
2023-03-08 20:33:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0028, Loss_2: 0.0028, Acc_1: 0.7344, Acc_2: 0.7188, 
2023-03-08 20:33:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0029, Loss_2: 0.0030, Acc_1: 0.7031, Acc_2: 0.7422, 
2023-03-08 20:33:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0037, Loss_2: 0.0039, Acc_1: 0.6875, Acc_2: 0.6797, 
2023-03-08 20:33:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0029, Loss_2: 0.0030, Acc_1: 0.7422, Acc_2: 0.7266, 
2023-03-08 20:33:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0030, Loss_2: 0.0035, Acc_1: 0.7266, Acc_2: 0.6953, 
2023-03-08 20:33:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0027, Loss_2: 0.0025, Acc_1: 0.7344, Acc_2: 0.7500, 
2023-03-08 20:33:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0187, Loss_2: 0.0195, Acc_1: 0.4029, Acc_2: 0.4054, F1-score_1: 0.3150, F1-score_2: 0.3166
2023-03-08 20:33:07 - __main__ - INFO - Epoch [11/100]
2023-03-08 20:33:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0018, Loss_2: 0.0014, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 20:33:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0014, Loss_2: 0.0012, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:33:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0013, Loss_2: 0.0012, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 20:33:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0025, Loss_2: 0.0027, Acc_1: 0.7422, Acc_2: 0.7188, 
2023-03-08 20:33:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0028, Loss_2: 0.0024, Acc_1: 0.7188, Acc_2: 0.7500, 
2023-03-08 20:33:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0029, Loss_2: 0.0025, Acc_1: 0.7188, Acc_2: 0.7188, 
2023-03-08 20:33:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0019, Loss_2: 0.0021, Acc_1: 0.7812, Acc_2: 0.7422, 
2023-03-08 20:33:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0036, Loss_2: 0.0053, Acc_1: 0.6875, Acc_2: 0.6250, 
2023-03-08 20:33:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0017, Loss_2: 0.0023, Acc_1: 0.7734, Acc_2: 0.6953, 
2023-03-08 20:33:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0022, Loss_2: 0.0021, Acc_1: 0.7656, Acc_2: 0.7500, 
2023-03-08 20:33:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0036, Loss_2: 0.0041, Acc_1: 0.6953, Acc_2: 0.6797, 
2023-03-08 20:33:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0052, Loss_2: 0.0048, Acc_1: 0.6328, Acc_2: 0.6328, 
2023-03-08 20:33:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0202, Loss_2: 0.0208, Acc_1: 0.4039, Acc_2: 0.4039, F1-score_1: 0.3224, F1-score_2: 0.3266
2023-03-08 20:33:21 - __main__ - INFO - Epoch [12/100]
2023-03-08 20:33:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0010, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 20:33:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0020, Loss_2: 0.0017, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-08 20:33:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0012, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 20:33:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0014, Loss_2: 0.0012, Acc_1: 0.7812, Acc_2: 0.7578, 
2023-03-08 20:33:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0015, Loss_2: 0.0014, Acc_1: 0.7578, Acc_2: 0.7891, 
2023-03-08 20:33:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0011, Acc_1: 0.7969, Acc_2: 0.7734, 
2023-03-08 20:33:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0012, Loss_2: 0.0015, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-08 20:33:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0013, Loss_2: 0.0012, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:33:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0021, Loss_2: 0.0013, Acc_1: 0.7578, Acc_2: 0.7812, 
2023-03-08 20:33:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0016, Loss_2: 0.0018, Acc_1: 0.8047, Acc_2: 0.7656, 
2023-03-08 20:33:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0033, Loss_2: 0.0022, Acc_1: 0.7266, Acc_2: 0.7656, 
2023-03-08 20:33:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0012, Loss_2: 0.0014, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 20:33:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0234, Loss_2: 0.0228, Acc_1: 0.3989, Acc_2: 0.4040, F1-score_1: 0.3311, F1-score_2: 0.3222
2023-03-08 20:33:34 - __main__ - INFO - Epoch [13/100]
2023-03-08 20:33:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:33:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0012, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 20:33:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0010, Loss_2: 0.0009, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-08 20:33:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0023, Loss_2: 0.0030, Acc_1: 0.7578, Acc_2: 0.6875, 
2023-03-08 20:33:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0011, Loss_2: 0.0013, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-08 20:33:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0010, Loss_2: 0.0013, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-08 20:33:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:33:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0023, Loss_2: 0.0022, Acc_1: 0.7266, Acc_2: 0.7188, 
2023-03-08 20:33:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0016, Loss_2: 0.0015, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-08 20:33:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0016, Loss_2: 0.0021, Acc_1: 0.7422, Acc_2: 0.7578, 
2023-03-08 20:33:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 20:33:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0016, Loss_2: 0.0022, Acc_1: 0.7656, Acc_2: 0.7344, 
2023-03-08 20:33:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0248, Loss_2: 0.0213, Acc_1: 0.4083, Acc_2: 0.4117, F1-score_1: 0.3258, F1-score_2: 0.3364
2023-03-08 20:33:48 - __main__ - INFO - Epoch [14/100]
2023-03-08 20:33:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 20:33:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:33:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0013, Loss_2: 0.0013, Acc_1: 0.7734, Acc_2: 0.8047, 
2023-03-08 20:33:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 20:33:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0011, Loss_2: 0.0010, Acc_1: 0.7656, Acc_2: 0.7891, 
2023-03-08 20:33:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0024, Loss_2: 0.0019, Acc_1: 0.7344, Acc_2: 0.7266, 
2023-03-08 20:33:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0014, Loss_2: 0.0009, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 20:33:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0013, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:33:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.8203, 
2023-03-08 20:33:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0014, Loss_2: 0.0011, Acc_1: 0.7812, Acc_2: 0.8281, 
2023-03-08 20:33:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0027, Loss_2: 0.0033, Acc_1: 0.7188, Acc_2: 0.7188, 
2023-03-08 20:33:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0022, Loss_2: 0.0019, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-08 20:34:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0278, Loss_2: 0.0239, Acc_1: 0.3972, Acc_2: 0.3996, F1-score_1: 0.3183, F1-score_2: 0.3233
2023-03-08 20:34:01 - __main__ - INFO - Epoch [15/100]
2023-03-08 20:34:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:34:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0017, Loss_2: 0.0013, Acc_1: 0.7500, Acc_2: 0.7500, 
2023-03-08 20:34:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0014, Loss_2: 0.0012, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 20:34:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0035, Loss_2: 0.0028, Acc_1: 0.7344, Acc_2: 0.7500, 
2023-03-08 20:34:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:34:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0016, Loss_2: 0.0027, Acc_1: 0.7578, Acc_2: 0.7500, 
2023-03-08 20:34:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.7656, Acc_2: 0.8125, 
2023-03-08 20:34:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0020, Acc_1: 0.7578, Acc_2: 0.7422, 
2023-03-08 20:34:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0010, Acc_1: 0.8203, Acc_2: 0.7812, 
2023-03-08 20:34:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 20:34:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0021, Loss_2: 0.0021, Acc_1: 0.7422, Acc_2: 0.7500, 
2023-03-08 20:34:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 20:34:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0267, Loss_2: 0.0229, Acc_1: 0.3945, Acc_2: 0.4049, F1-score_1: 0.3135, F1-score_2: 0.3231
2023-03-08 20:34:15 - __main__ - INFO - Epoch [16/100]
2023-03-08 20:34:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0019, Loss_2: 0.0015, Acc_1: 0.7422, Acc_2: 0.7578, 
2023-03-08 20:34:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0019, Loss_2: 0.0015, Acc_1: 0.7422, Acc_2: 0.7422, 
2023-03-08 20:34:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0010, Loss_2: 0.0025, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 20:34:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0013, Loss_2: 0.0021, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 20:34:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0019, Loss_2: 0.0016, Acc_1: 0.7344, Acc_2: 0.7500, 
2023-03-08 20:34:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0010, Loss_2: 0.0012, Acc_1: 0.7891, Acc_2: 0.7656, 
2023-03-08 20:34:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 20:34:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0033, Loss_2: 0.0022, Acc_1: 0.7266, Acc_2: 0.7266, 
2023-03-08 20:34:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 20:34:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 20:34:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0009, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 20:34:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0012, Acc_1: 0.7656, Acc_2: 0.7578, 
2023-03-08 20:34:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0267, Loss_2: 0.0256, Acc_1: 0.4001, Acc_2: 0.3896, F1-score_1: 0.3152, F1-score_2: 0.3159
2023-03-08 20:34:28 - __main__ - INFO - Epoch [17/100]
2023-03-08 20:34:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0011, Acc_1: 0.7812, Acc_2: 0.8047, 
2023-03-08 20:34:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:34:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 20:34:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0034, Loss_2: 0.0026, Acc_1: 0.7344, Acc_2: 0.7188, 
2023-03-08 20:34:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.8359, 
2023-03-08 20:34:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 20:34:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0010, Loss_2: 0.0010, Acc_1: 0.8047, Acc_2: 0.7812, 
2023-03-08 20:34:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0019, Loss_2: 0.0016, Acc_1: 0.7656, Acc_2: 0.7578, 
2023-03-08 20:34:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0019, Loss_2: 0.0012, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 20:34:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 20:34:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0024, Loss_2: 0.0019, Acc_1: 0.7266, Acc_2: 0.7266, 
2023-03-08 20:34:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 20:34:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0302, Loss_2: 0.0256, Acc_1: 0.4017, Acc_2: 0.4025, F1-score_1: 0.3212, F1-score_2: 0.3199
2023-03-08 20:34:41 - __main__ - INFO - Epoch [18/100]
2023-03-08 20:34:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:34:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0027, Loss_2: 0.0032, Acc_1: 0.7422, Acc_2: 0.7109, 
2023-03-08 20:34:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 20:34:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0045, Loss_2: 0.0051, Acc_1: 0.7109, Acc_2: 0.7188, 
2023-03-08 20:34:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0010, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 20:34:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0013, Acc_1: 0.7578, Acc_2: 0.7578, 
2023-03-08 20:34:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0008, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:34:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:34:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.7734, Acc_2: 0.7969, 
2023-03-08 20:34:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:34:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:34:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:34:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0261, Loss_2: 0.0259, Acc_1: 0.4066, Acc_2: 0.3898, F1-score_1: 0.3256, F1-score_2: 0.3153
2023-03-08 20:34:55 - __main__ - INFO - Epoch [19/100]
2023-03-08 20:35:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 20:35:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 20:35:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:35:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0015, Loss_2: 0.0012, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 20:35:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0020, Loss_2: 0.0018, Acc_1: 0.7812, Acc_2: 0.7578, 
2023-03-08 20:35:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 20:35:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:35:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:35:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 20:35:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 20:35:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 20:35:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0022, Loss_2: 0.0021, Acc_1: 0.7422, Acc_2: 0.7344, 
2023-03-08 20:35:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0305, Loss_2: 0.0275, Acc_1: 0.4012, Acc_2: 0.3867, F1-score_1: 0.3262, F1-score_2: 0.3123
2023-03-08 20:35:08 - __main__ - INFO - Epoch [20/100]
2023-03-08 20:35:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0009, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 20:35:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.7734, Acc_2: 0.7969, 
2023-03-08 20:35:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0021, Loss_2: 0.0025, Acc_1: 0.7266, Acc_2: 0.7422, 
2023-03-08 20:35:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:35:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.7891, Acc_2: 0.7734, 
2023-03-08 20:35:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 20:35:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 20:35:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 20:35:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 20:35:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0017, Loss_2: 0.0014, Acc_1: 0.7812, Acc_2: 0.7578, 
2023-03-08 20:35:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:35:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 20:35:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0276, Loss_2: 0.0281, Acc_1: 0.4013, Acc_2: 0.4003, F1-score_1: 0.3230, F1-score_2: 0.3278
2023-03-08 20:35:22 - __main__ - INFO - Epoch [21/100]
2023-03-08 20:35:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 20:35:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 20:35:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 20:35:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-08 20:35:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0012, Loss_2: 0.0010, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 20:35:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:35:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 20:35:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 20:35:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 20:35:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0016, Loss_2: 0.0009, Acc_1: 0.7812, Acc_2: 0.8047, 
2023-03-08 20:35:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.8047, Acc_2: 0.7656, 
2023-03-08 20:35:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0015, Loss_2: 0.0018, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 20:35:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0287, Loss_2: 0.0262, Acc_1: 0.3971, Acc_2: 0.3918, F1-score_1: 0.3285, F1-score_2: 0.3222
2023-03-08 20:35:35 - __main__ - INFO - Epoch [22/100]
2023-03-08 20:35:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0013, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 20:35:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0009, Loss_2: 0.0011, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 20:35:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 20:35:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:35:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:35:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:35:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:35:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:35:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 20:35:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 20:35:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0013, Loss_2: 0.0011, Acc_1: 0.7500, Acc_2: 0.7656, 
2023-03-08 20:35:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0016, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 20:35:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0286, Loss_2: 0.0278, Acc_1: 0.4040, Acc_2: 0.3901, F1-score_1: 0.3252, F1-score_2: 0.3108
2023-03-08 20:35:49 - __main__ - INFO - Epoch [23/100]
2023-03-08 20:35:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:35:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 20:35:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 20:35:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:35:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:35:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 20:35:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8438, 
2023-03-08 20:35:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0020, Loss_2: 0.0016, Acc_1: 0.7500, Acc_2: 0.7656, 
2023-03-08 20:35:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 20:35:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:35:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:35:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 20:36:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0272, Loss_2: 0.0279, Acc_1: 0.4001, Acc_2: 0.4023, F1-score_1: 0.3268, F1-score_2: 0.3243
2023-03-08 20:36:02 - __main__ - INFO - Epoch [24/100]
2023-03-08 20:36:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0011, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-08 20:36:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:36:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:36:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0012, Loss_2: 0.0007, Acc_1: 0.7578, Acc_2: 0.7734, 
2023-03-08 20:36:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0013, Loss_2: 0.0013, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-08 20:36:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0012, Loss_2: 0.0010, Acc_1: 0.7656, Acc_2: 0.7578, 
2023-03-08 20:36:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0016, Loss_2: 0.0013, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-08 20:36:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:36:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0041, Loss_2: 0.0037, Acc_1: 0.7266, Acc_2: 0.7344, 
2023-03-08 20:36:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 20:36:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 20:36:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.7656, 
2023-03-08 20:36:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0300, Loss_2: 0.0250, Acc_1: 0.3954, Acc_2: 0.3972, F1-score_1: 0.3280, F1-score_2: 0.3178
2023-03-08 20:36:15 - __main__ - INFO - Epoch [25/100]
2023-03-08 20:36:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:36:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:36:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0016, Loss_2: 0.0019, Acc_1: 0.7500, Acc_2: 0.7344, 
2023-03-08 20:36:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:36:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:36:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0016, Acc_1: 0.8516, Acc_2: 0.7734, 
2023-03-08 20:36:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0010, Loss_2: 0.0012, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 20:36:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 20:36:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 20:36:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:36:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 20:36:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:36:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0301, Loss_2: 0.0289, Acc_1: 0.4025, Acc_2: 0.3945, F1-score_1: 0.3284, F1-score_2: 0.3190
2023-03-08 20:36:29 - __main__ - INFO - Epoch [26/100]
2023-03-08 20:36:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 20:36:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0012, Loss_2: 0.0008, Acc_1: 0.8125, Acc_2: 0.8516, 
2023-03-08 20:36:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0009, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-08 20:36:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:36:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:36:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.7734, Acc_2: 0.7891, 
2023-03-08 20:36:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:36:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 20:36:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:36:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:36:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0015, Loss_2: 0.0021, Acc_1: 0.7500, Acc_2: 0.7812, 
2023-03-08 20:36:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0008, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-08 20:36:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0287, Loss_2: 0.0295, Acc_1: 0.3906, Acc_2: 0.3911, F1-score_1: 0.3158, F1-score_2: 0.3158
2023-03-08 20:36:42 - __main__ - INFO - Epoch [27/100]
2023-03-08 20:36:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0016, Loss_2: 0.0022, Acc_1: 0.7734, Acc_2: 0.7578, 
2023-03-08 20:36:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:36:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:36:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.7656, Acc_2: 0.7969, 
2023-03-08 20:36:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:36:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:36:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:36:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 20:36:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 20:36:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:36:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:36:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:36:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0310, Loss_2: 0.0326, Acc_1: 0.3950, Acc_2: 0.3884, F1-score_1: 0.3287, F1-score_2: 0.3144
2023-03-08 20:36:56 - __main__ - INFO - Epoch [28/100]
2023-03-08 20:37:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:37:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0010, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 20:37:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8438, 
2023-03-08 20:37:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.7578, Acc_2: 0.7969, 
2023-03-08 20:37:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:37:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:37:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:37:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:37:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:37:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 20:37:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 20:37:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:37:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0319, Loss_2: 0.0332, Acc_1: 0.3898, Acc_2: 0.3959, F1-score_1: 0.3111, F1-score_2: 0.3120
2023-03-08 20:37:09 - __main__ - INFO - Epoch [29/100]
2023-03-08 20:37:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:37:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 20:37:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0010, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 20:37:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:37:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:37:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8984, 
2023-03-08 20:37:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 20:37:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:37:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:37:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 20:37:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 20:37:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 20:37:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0348, Loss_2: 0.0314, Acc_1: 0.3964, Acc_2: 0.3957, F1-score_1: 0.3225, F1-score_2: 0.3165
2023-03-08 20:37:23 - __main__ - INFO - Epoch [30/100]
2023-03-08 20:37:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:37:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:37:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:37:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0012, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 20:37:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0014, Loss_2: 0.0015, Acc_1: 0.7734, Acc_2: 0.7500, 
2023-03-08 20:37:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:37:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 20:37:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:37:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 20:37:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 20:37:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0012, Loss_2: 0.0019, Acc_1: 0.7578, Acc_2: 0.7344, 
2023-03-08 20:37:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0008, Acc_1: 0.7734, Acc_2: 0.7969, 
2023-03-08 20:37:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0344, Loss_2: 0.0306, Acc_1: 0.3945, Acc_2: 0.4051, F1-score_1: 0.3135, F1-score_2: 0.3168
2023-03-08 20:37:36 - __main__ - INFO - Epoch [31/100]
2023-03-08 20:37:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:37:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 20:37:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8750, 
2023-03-08 20:37:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 20:37:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:37:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 20:37:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 20:37:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0027, Loss_2: 0.0033, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-08 20:37:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0012, Acc_1: 0.7969, Acc_2: 0.7734, 
2023-03-08 20:37:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:37:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0009, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 20:37:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 20:37:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0306, Loss_2: 0.0329, Acc_1: 0.3944, Acc_2: 0.3952, F1-score_1: 0.3161, F1-score_2: 0.3186
2023-03-08 20:37:50 - __main__ - INFO - Epoch [32/100]
2023-03-08 20:37:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:37:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.7656, Acc_2: 0.7969, 
2023-03-08 20:37:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 20:37:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:37:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0017, Loss_2: 0.0015, Acc_1: 0.7500, Acc_2: 0.7969, 
2023-03-08 20:37:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 20:37:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0021, Loss_2: 0.0022, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 20:37:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0012, Acc_1: 0.7812, Acc_2: 0.7578, 
2023-03-08 20:37:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:37:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0012, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 20:37:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0008, Acc_1: 0.7734, Acc_2: 0.7969, 
2023-03-08 20:37:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:38:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0312, Loss_2: 0.0295, Acc_1: 0.3923, Acc_2: 0.4034, F1-score_1: 0.3218, F1-score_2: 0.3199
2023-03-08 20:38:03 - __main__ - INFO - Epoch [33/100]
2023-03-08 20:38:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:38:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-08 20:38:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:38:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 20:38:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:38:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:38:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:38:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:38:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:38:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 20:38:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0011, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:38:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:38:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0358, Loss_2: 0.0331, Acc_1: 0.3957, Acc_2: 0.4012, F1-score_1: 0.3235, F1-score_2: 0.3267
2023-03-08 20:38:17 - __main__ - INFO - Epoch [34/100]
2023-03-08 20:38:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:38:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:38:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 20:38:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:38:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:38:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8438, 
2023-03-08 20:38:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:38:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:38:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0013, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 20:38:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8516, 
2023-03-08 20:38:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 20:38:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 20:38:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0320, Loss_2: 0.0352, Acc_1: 0.4052, Acc_2: 0.4032, F1-score_1: 0.3366, F1-score_2: 0.3219
2023-03-08 20:38:30 - __main__ - INFO - Epoch [35/100]
2023-03-08 20:38:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:38:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0012, Acc_1: 0.7500, Acc_2: 0.7734, 
2023-03-08 20:38:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:38:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-08 20:38:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:38:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:38:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 20:38:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:38:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:38:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-08 20:38:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 20:38:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:38:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0305, Loss_2: 0.0331, Acc_1: 0.4013, Acc_2: 0.4051, F1-score_1: 0.3233, F1-score_2: 0.3238
2023-03-08 20:38:43 - __main__ - INFO - Epoch [36/100]
2023-03-08 20:38:48 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:38:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:38:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 20:38:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 20:38:49 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:38:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:38:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:38:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:38:50 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0007, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 20:38:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:38:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:38:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:38:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0325, Loss_2: 0.0354, Acc_1: 0.3944, Acc_2: 0.3937, F1-score_1: 0.3245, F1-score_2: 0.3216
2023-03-08 20:38:57 - __main__ - INFO - Epoch [37/100]
2023-03-08 20:39:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:39:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:39:02 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 20:39:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:39:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:39:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:39:03 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.7812, Acc_2: 0.8047, 
2023-03-08 20:39:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:39:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:39:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:39:04 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 20:39:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:39:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0344, Loss_2: 0.0370, Acc_1: 0.3995, Acc_2: 0.3991, F1-score_1: 0.3199, F1-score_2: 0.3172
2023-03-08 20:39:10 - __main__ - INFO - Epoch [38/100]
2023-03-08 20:39:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:39:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 20:39:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:39:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8750, 
2023-03-08 20:39:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:39:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:39:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:39:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 20:39:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:39:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0010, Loss_2: 0.0006, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 20:39:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 20:39:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:39:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0372, Loss_2: 0.0367, Acc_1: 0.3932, Acc_2: 0.3913, F1-score_1: 0.3170, F1-score_2: 0.3195
2023-03-08 20:39:24 - __main__ - INFO - Epoch [39/100]
2023-03-08 20:39:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:39:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:39:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:39:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:39:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0016, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8672, 
2023-03-08 20:39:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0007, Acc_1: 0.7734, Acc_2: 0.8125, 
2023-03-08 20:39:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:39:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:39:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0013, Loss_2: 0.0008, Acc_1: 0.7734, Acc_2: 0.8047, 
2023-03-08 20:39:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8438, 
2023-03-08 20:39:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0013, Loss_2: 0.0009, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 20:39:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 20:39:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0355, Loss_2: 0.0345, Acc_1: 0.3930, Acc_2: 0.3952, F1-score_1: 0.3206, F1-score_2: 0.3182
2023-03-08 20:39:37 - __main__ - INFO - Epoch [40/100]
2023-03-08 20:39:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:39:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:39:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 20:39:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:39:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:39:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 20:39:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:39:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:39:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8594, 
2023-03-08 20:39:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:39:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 20:39:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:39:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0383, Loss_2: 0.0346, Acc_1: 0.3908, Acc_2: 0.3899, F1-score_1: 0.3156, F1-score_2: 0.3159
2023-03-08 20:39:51 - __main__ - INFO - Epoch [41/100]
2023-03-08 20:39:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 20:39:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0008, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 20:39:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:39:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:39:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8359, 
2023-03-08 20:39:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8594, 
2023-03-08 20:39:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0010, Loss_2: 0.0007, Acc_1: 0.7734, Acc_2: 0.7969, 
2023-03-08 20:39:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:39:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 20:39:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 20:39:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:39:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:40:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0401, Loss_2: 0.0357, Acc_1: 0.3947, Acc_2: 0.3978, F1-score_1: 0.3240, F1-score_2: 0.3136
2023-03-08 20:40:04 - __main__ - INFO - Epoch [42/100]
2023-03-08 20:40:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8906, 
2023-03-08 20:40:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0015, Loss_2: 0.0009, Acc_1: 0.7344, Acc_2: 0.7734, 
2023-03-08 20:40:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0011, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.8203, 
2023-03-08 20:40:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.7578, Acc_2: 0.7500, 
2023-03-08 20:40:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:40:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0010, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 20:40:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0012, Acc_1: 0.9062, Acc_2: 0.8516, 
2023-03-08 20:40:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:40:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:40:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 20:40:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 20:40:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0009, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-08 20:40:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0394, Loss_2: 0.0379, Acc_1: 0.3820, Acc_2: 0.3838, F1-score_1: 0.3086, F1-score_2: 0.3166
2023-03-08 20:40:18 - __main__ - INFO - Epoch [43/100]
2023-03-08 20:40:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 20:40:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:40:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:40:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 20:40:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:40:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 20:40:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:40:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0017, Acc_1: 0.7500, Acc_2: 0.7578, 
2023-03-08 20:40:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:40:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.7812, 
2023-03-08 20:40:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0020, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 20:40:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:40:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0355, Loss_2: 0.0349, Acc_1: 0.3976, Acc_2: 0.3933, F1-score_1: 0.3216, F1-score_2: 0.3175
2023-03-08 20:40:31 - __main__ - INFO - Epoch [44/100]
2023-03-08 20:40:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:40:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:40:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 20:40:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 20:40:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 20:40:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:40:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:40:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:40:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 20:40:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:40:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:40:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:40:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0374, Loss_2: 0.0332, Acc_1: 0.4015, Acc_2: 0.4040, F1-score_1: 0.3209, F1-score_2: 0.3201
2023-03-08 20:40:45 - __main__ - INFO - Epoch [45/100]
2023-03-08 20:40:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:40:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 20:40:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 20:40:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 20:40:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:40:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:40:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-08 20:40:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:40:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:40:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 20:40:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8438, 
2023-03-08 20:40:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:40:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0386, Loss_2: 0.0391, Acc_1: 0.4103, Acc_2: 0.3920, F1-score_1: 0.3231, F1-score_2: 0.3199
2023-03-08 20:40:58 - __main__ - INFO - Epoch [46/100]
2023-03-08 20:41:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 20:41:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 20:41:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:41:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 20:41:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:41:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0028, Loss_2: 0.0032, Acc_1: 0.7578, Acc_2: 0.7578, 
2023-03-08 20:41:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 20:41:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:41:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:41:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 20:41:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 20:41:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:41:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0411, Loss_2: 0.0379, Acc_1: 0.4000, Acc_2: 0.3937, F1-score_1: 0.3234, F1-score_2: 0.3163
2023-03-08 20:41:12 - __main__ - INFO - Epoch [47/100]
2023-03-08 20:41:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:41:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:41:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8281, 
2023-03-08 20:41:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:41:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 20:41:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 20:41:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:41:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:41:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:41:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-08 20:41:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:41:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:41:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0412, Loss_2: 0.0367, Acc_1: 0.3962, Acc_2: 0.3905, F1-score_1: 0.3206, F1-score_2: 0.3216
2023-03-08 20:41:25 - __main__ - INFO - Epoch [48/100]
2023-03-08 20:41:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:41:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:41:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 20:41:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:41:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:41:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:41:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:41:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:41:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 20:41:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 20:41:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:41:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:41:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0401, Loss_2: 0.0401, Acc_1: 0.3981, Acc_2: 0.3925, F1-score_1: 0.3223, F1-score_2: 0.3204
2023-03-08 20:41:39 - __main__ - INFO - Epoch [49/100]
2023-03-08 20:41:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 20:41:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:41:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:41:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:41:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 20:41:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:41:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 20:41:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:41:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:41:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:41:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0023, Loss_2: 0.0043, Acc_1: 0.7578, Acc_2: 0.7422, 
2023-03-08 20:41:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:41:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0393, Loss_2: 0.0380, Acc_1: 0.4017, Acc_2: 0.4017, F1-score_1: 0.3216, F1-score_2: 0.3245
2023-03-08 20:41:52 - __main__ - INFO - Epoch [50/100]
2023-03-08 20:41:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 20:41:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:41:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0012, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 20:41:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:41:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 20:41:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:41:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:41:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 20:41:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0013, Loss_2: 0.0008, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 20:41:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:41:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:41:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:42:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0378, Loss_2: 0.0390, Acc_1: 0.4039, Acc_2: 0.4006, F1-score_1: 0.3273, F1-score_2: 0.3232
2023-03-08 20:42:05 - __main__ - INFO - Epoch [51/100]
2023-03-08 20:42:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:42:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 20:42:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 20:42:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 20:42:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 20:42:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:42:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:42:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0011, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 20:42:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0010, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:42:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:42:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-08 20:42:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:42:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0409, Loss_2: 0.0411, Acc_1: 0.4061, Acc_2: 0.3913, F1-score_1: 0.3248, F1-score_2: 0.3161
2023-03-08 20:42:19 - __main__ - INFO - Epoch [52/100]
2023-03-08 20:42:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 20:42:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:42:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0016, Loss_2: 0.0010, Acc_1: 0.7578, Acc_2: 0.7578, 
2023-03-08 20:42:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0059, Loss_2: 0.0087, Acc_1: 0.7188, Acc_2: 0.7031, 
2023-03-08 20:42:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:42:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:42:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:42:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8203, 
2023-03-08 20:42:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.7812, Acc_2: 0.8047, 
2023-03-08 20:42:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:42:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0017, Loss_2: 0.0010, Acc_1: 0.7500, Acc_2: 0.7734, 
2023-03-08 20:42:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:42:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0419, Loss_2: 0.0376, Acc_1: 0.3969, Acc_2: 0.3957, F1-score_1: 0.3225, F1-score_2: 0.3221
2023-03-08 20:42:32 - __main__ - INFO - Epoch [53/100]
2023-03-08 20:42:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:42:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:42:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:42:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 20:42:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-08 20:42:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 20:42:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 20:42:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 20:42:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:42:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 20:42:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:42:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:42:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0360, Loss_2: 0.0387, Acc_1: 0.3986, Acc_2: 0.3915, F1-score_1: 0.3282, F1-score_2: 0.3128
2023-03-08 20:42:46 - __main__ - INFO - Epoch [54/100]
2023-03-08 20:42:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:42:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:42:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0010, Loss_2: 0.0013, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 20:42:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0012, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 20:42:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0015, Loss_2: 0.0013, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-08 20:42:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0016, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:42:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.7656, Acc_2: 0.7891, 
2023-03-08 20:42:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0012, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-08 20:42:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 20:42:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:42:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0017, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:42:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.7891, Acc_2: 0.7734, 
2023-03-08 20:42:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0342, Loss_2: 0.0325, Acc_1: 0.3952, Acc_2: 0.3979, F1-score_1: 0.3175, F1-score_2: 0.3177
2023-03-08 20:42:59 - __main__ - INFO - Epoch [55/100]
2023-03-08 20:43:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0025, Acc_1: 0.7578, Acc_2: 0.7266, 
2023-03-08 20:43:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0025, Loss_2: 0.0035, Acc_1: 0.7344, Acc_2: 0.7344, 
2023-03-08 20:43:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0014, Loss_2: 0.0003, Acc_1: 0.7578, Acc_2: 0.7969, 
2023-03-08 20:43:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.8203, 
2023-03-08 20:43:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0012, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:43:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 20:43:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0023, Loss_2: 0.0039, Acc_1: 0.7578, Acc_2: 0.7266, 
2023-03-08 20:43:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:43:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:43:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:43:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:43:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 20:43:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0376, Loss_2: 0.0360, Acc_1: 0.4034, Acc_2: 0.3998, F1-score_1: 0.3222, F1-score_2: 0.3229
2023-03-08 20:43:13 - __main__ - INFO - Epoch [56/100]
2023-03-08 20:43:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 20:43:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:43:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 20:43:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:43:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.7969, Acc_2: 0.7656, 
2023-03-08 20:43:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:43:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0018, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:43:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:43:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:43:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 20:43:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 20:43:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:43:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0401, Loss_2: 0.0363, Acc_1: 0.4015, Acc_2: 0.3915, F1-score_1: 0.3209, F1-score_2: 0.3149
2023-03-08 20:43:26 - __main__ - INFO - Epoch [57/100]
2023-03-08 20:43:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:43:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:43:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 20:43:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 20:43:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 20:43:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 20:43:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:43:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 20:43:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:43:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 20:43:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 20:43:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:43:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0352, Loss_2: 0.0337, Acc_1: 0.3979, Acc_2: 0.3950, F1-score_1: 0.3198, F1-score_2: 0.3178
2023-03-08 20:43:40 - __main__ - INFO - Epoch [58/100]
2023-03-08 20:43:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0020, Loss_2: 0.0018, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-08 20:43:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:43:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:43:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:43:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:43:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 20:43:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.7812, 
2023-03-08 20:43:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 20:43:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:43:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:43:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:43:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 20:43:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0373, Loss_2: 0.0369, Acc_1: 0.4039, Acc_2: 0.3954, F1-score_1: 0.3312, F1-score_2: 0.3203
2023-03-08 20:43:53 - __main__ - INFO - Epoch [59/100]
2023-03-08 20:43:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:43:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:43:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:43:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 20:43:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:44:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:44:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:44:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 20:44:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:44:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 20:44:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:44:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 20:44:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0386, Loss_2: 0.0364, Acc_1: 0.3998, Acc_2: 0.3954, F1-score_1: 0.3239, F1-score_2: 0.3160
2023-03-08 20:44:07 - __main__ - INFO - Epoch [60/100]
2023-03-08 20:44:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:44:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:44:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:44:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:44:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 20:44:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:44:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:44:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8359, 
2023-03-08 20:44:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:44:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:44:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 20:44:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-08 20:44:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0400, Loss_2: 0.0381, Acc_1: 0.4074, Acc_2: 0.3927, F1-score_1: 0.3303, F1-score_2: 0.3142
2023-03-08 20:44:21 - __main__ - INFO - Epoch [61/100]
2023-03-08 20:44:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:44:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:44:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:44:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:44:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 20:44:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:44:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:44:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 20:44:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:44:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 20:44:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:44:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:44:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0389, Loss_2: 0.0368, Acc_1: 0.4023, Acc_2: 0.3947, F1-score_1: 0.3245, F1-score_2: 0.3188
2023-03-08 20:44:34 - __main__ - INFO - Epoch [62/100]
2023-03-08 20:44:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:44:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 20:44:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:44:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 20:44:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 20:44:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:44:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:44:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 20:44:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0011, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8594, 
2023-03-08 20:44:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0030, Loss_2: 0.0018, Acc_1: 0.7344, Acc_2: 0.7812, 
2023-03-08 20:44:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0010, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 20:44:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 20:44:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0372, Loss_2: 0.0394, Acc_1: 0.3925, Acc_2: 0.3859, F1-score_1: 0.3199, F1-score_2: 0.3141
2023-03-08 20:44:48 - __main__ - INFO - Epoch [63/100]
2023-03-08 20:44:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:44:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:44:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:44:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:44:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:44:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 20:44:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 20:44:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 20:44:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:44:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:44:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:44:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0012, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:45:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0391, Loss_2: 0.0381, Acc_1: 0.4023, Acc_2: 0.3988, F1-score_1: 0.3259, F1-score_2: 0.3138
2023-03-08 20:45:01 - __main__ - INFO - Epoch [64/100]
2023-03-08 20:45:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:45:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8828, 
2023-03-08 20:45:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 20:45:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:45:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:45:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:45:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:45:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:45:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 20:45:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8828, 
2023-03-08 20:45:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0021, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:45:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 20:45:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0354, Loss_2: 0.0375, Acc_1: 0.3935, Acc_2: 0.3967, F1-score_1: 0.3138, F1-score_2: 0.3179
2023-03-08 20:45:15 - __main__ - INFO - Epoch [65/100]
2023-03-08 20:45:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 20:45:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 20:45:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:45:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0020, Loss_2: 0.0020, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 20:45:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:45:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 20:45:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 20:45:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:45:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:45:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:45:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 20:45:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:45:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0396, Loss_2: 0.0381, Acc_1: 0.3928, Acc_2: 0.3979, F1-score_1: 0.3202, F1-score_2: 0.3199
2023-03-08 20:45:29 - __main__ - INFO - Epoch [66/100]
2023-03-08 20:45:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-08 20:45:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:45:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:45:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 20:45:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 20:45:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 20:45:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:45:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:45:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:45:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 20:45:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:45:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 20:45:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0395, Loss_2: 0.0379, Acc_1: 0.3935, Acc_2: 0.4003, F1-score_1: 0.3216, F1-score_2: 0.3230
2023-03-08 20:45:42 - __main__ - INFO - Epoch [67/100]
2023-03-08 20:45:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:45:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 20:45:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:45:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 20:45:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:45:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 20:45:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:45:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:45:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 20:45:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.7812, 
2023-03-08 20:45:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:45:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:45:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0412, Loss_2: 0.0404, Acc_1: 0.3978, Acc_2: 0.3886, F1-score_1: 0.3209, F1-score_2: 0.3136
2023-03-08 20:45:56 - __main__ - INFO - Epoch [68/100]
2023-03-08 20:46:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 20:46:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 20:46:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:46:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 20:46:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0011, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 20:46:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:46:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 20:46:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:46:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:46:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 20:46:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0015, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 20:46:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:46:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0412, Loss_2: 0.0379, Acc_1: 0.4025, Acc_2: 0.4020, F1-score_1: 0.3236, F1-score_2: 0.3192
2023-03-08 20:46:09 - __main__ - INFO - Epoch [69/100]
2023-03-08 20:46:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 20:46:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:46:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 20:46:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:46:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 20:46:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:46:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0010, Loss_2: 0.0012, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 20:46:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 20:46:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:46:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:46:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:46:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 20:46:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0386, Loss_2: 0.0417, Acc_1: 0.4052, Acc_2: 0.3787, F1-score_1: 0.3232, F1-score_2: 0.3092
2023-03-08 20:46:23 - __main__ - INFO - Epoch [70/100]
2023-03-08 20:46:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:46:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:46:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:46:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 20:46:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:46:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:46:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:46:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8203, 
2023-03-08 20:46:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:46:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:46:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:46:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:46:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0355, Loss_2: 0.0367, Acc_1: 0.4018, Acc_2: 0.4013, F1-score_1: 0.3197, F1-score_2: 0.3219
2023-03-08 20:46:37 - __main__ - INFO - Epoch [71/100]
2023-03-08 20:46:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:46:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:46:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:46:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:46:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 20:46:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 20:46:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:46:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 20:46:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:46:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:46:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:46:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9141, Acc_2: 0.8906, 
2023-03-08 20:46:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0383, Loss_2: 0.0391, Acc_1: 0.4049, Acc_2: 0.3996, F1-score_1: 0.3222, F1-score_2: 0.3229
2023-03-08 20:46:50 - __main__ - INFO - Epoch [72/100]
2023-03-08 20:46:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-08 20:46:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:46:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:46:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:46:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:46:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:46:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:46:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:46:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:46:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 20:46:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 20:46:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 20:47:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0370, Loss_2: 0.0394, Acc_1: 0.3891, Acc_2: 0.3932, F1-score_1: 0.3175, F1-score_2: 0.3265
2023-03-08 20:47:04 - __main__ - INFO - Epoch [73/100]
2023-03-08 20:47:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:47:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 20:47:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:47:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:47:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:47:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:47:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:47:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:47:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:47:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:47:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:47:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:47:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0366, Loss_2: 0.0380, Acc_1: 0.4046, Acc_2: 0.3978, F1-score_1: 0.3257, F1-score_2: 0.3182
2023-03-08 20:47:18 - __main__ - INFO - Epoch [74/100]
2023-03-08 20:47:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 20:47:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:47:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:47:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 20:47:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 20:47:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 20:47:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:47:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:47:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:47:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:47:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:47:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:47:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0428, Loss_2: 0.0389, Acc_1: 0.4029, Acc_2: 0.3865, F1-score_1: 0.3265, F1-score_2: 0.3154
2023-03-08 20:47:31 - __main__ - INFO - Epoch [75/100]
2023-03-08 20:47:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:47:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:47:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:47:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:47:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 20:47:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:47:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 20:47:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:47:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 20:47:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0011, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 20:47:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-08 20:47:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 20:47:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0368, Loss_2: 0.0384, Acc_1: 0.3971, Acc_2: 0.3954, F1-score_1: 0.3203, F1-score_2: 0.3180
2023-03-08 20:47:44 - __main__ - INFO - Epoch [76/100]
2023-03-08 20:47:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:47:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 20:47:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:47:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:47:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 20:47:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 20:47:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:47:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 20:47:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:47:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:47:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:47:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 20:47:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0398, Loss_2: 0.0395, Acc_1: 0.3972, Acc_2: 0.3884, F1-score_1: 0.3203, F1-score_2: 0.3171
2023-03-08 20:47:58 - __main__ - INFO - Epoch [77/100]
2023-03-08 20:48:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 20:48:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:48:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-08 20:48:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:48:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:48:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0014, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-08 20:48:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 20:48:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0021, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8594, 
2023-03-08 20:48:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0023, Loss_2: 0.0013, Acc_1: 0.7422, Acc_2: 0.7734, 
2023-03-08 20:48:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 20:48:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8750, 
2023-03-08 20:48:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 20:48:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0360, Loss_2: 0.0422, Acc_1: 0.4037, Acc_2: 0.3874, F1-score_1: 0.3297, F1-score_2: 0.3179
2023-03-08 20:48:11 - __main__ - INFO - Epoch [78/100]
2023-03-08 20:48:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0025, Loss_2: 0.0044, Acc_1: 0.7422, Acc_2: 0.7578, 
2023-03-08 20:48:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 20:48:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:48:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:48:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:48:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:48:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:48:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 20:48:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0015, Loss_2: 0.0012, Acc_1: 0.7812, Acc_2: 0.8125, 
2023-03-08 20:48:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.7812, 
2023-03-08 20:48:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:48:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-08 20:48:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0367, Loss_2: 0.0428, Acc_1: 0.4032, Acc_2: 0.4006, F1-score_1: 0.3225, F1-score_2: 0.3242
2023-03-08 20:48:25 - __main__ - INFO - Epoch [79/100]
2023-03-08 20:48:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 20:48:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:48:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:48:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 20:48:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 20:48:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 20:48:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:48:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8594, 
2023-03-08 20:48:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:48:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:48:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 20:48:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:48:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0373, Loss_2: 0.0426, Acc_1: 0.4066, Acc_2: 0.3962, F1-score_1: 0.3230, F1-score_2: 0.3186
2023-03-08 20:48:38 - __main__ - INFO - Epoch [80/100]
2023-03-08 20:48:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:48:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:48:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:48:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:48:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:48:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0017, Loss_2: 0.0013, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 20:48:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 20:48:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:48:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0017, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 20:48:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0014, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:48:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8906, Acc_2: 0.8594, 
2023-03-08 20:48:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0015, Loss_2: 0.0012, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-08 20:48:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0415, Loss_2: 0.0418, Acc_1: 0.3908, Acc_2: 0.3983, F1-score_1: 0.3185, F1-score_2: 0.3232
2023-03-08 20:48:52 - __main__ - INFO - Epoch [81/100]
2023-03-08 20:48:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:48:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:48:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-08 20:48:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:48:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:48:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:48:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:48:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:48:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:48:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:48:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:48:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:49:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0388, Loss_2: 0.0379, Acc_1: 0.4010, Acc_2: 0.3940, F1-score_1: 0.3254, F1-score_2: 0.3209
2023-03-08 20:49:05 - __main__ - INFO - Epoch [82/100]
2023-03-08 20:49:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 20:49:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 20:49:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:49:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:49:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:49:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9062, 
2023-03-08 20:49:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:49:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:49:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:49:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:49:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:49:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0013, Acc_1: 0.8828, Acc_2: 0.8516, 
2023-03-08 20:49:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0389, Loss_2: 0.0365, Acc_1: 0.3923, Acc_2: 0.4000, F1-score_1: 0.3189, F1-score_2: 0.3226
2023-03-08 20:49:19 - __main__ - INFO - Epoch [83/100]
2023-03-08 20:49:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:49:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 20:49:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 20:49:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:49:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:49:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:49:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:49:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:49:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-08 20:49:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:49:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:49:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:49:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0350, Loss_2: 0.0354, Acc_1: 0.4137, Acc_2: 0.4017, F1-score_1: 0.3329, F1-score_2: 0.3212
2023-03-08 20:49:33 - __main__ - INFO - Epoch [84/100]
2023-03-08 20:49:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:49:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:49:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 20:49:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:49:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 20:49:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:49:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:49:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:49:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 20:49:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 20:49:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 20:49:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:49:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0384, Loss_2: 0.0363, Acc_1: 0.4035, Acc_2: 0.4025, F1-score_1: 0.3257, F1-score_2: 0.3227
2023-03-08 20:49:46 - __main__ - INFO - Epoch [85/100]
2023-03-08 20:49:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:49:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 20:49:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 20:49:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:49:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:49:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:49:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:49:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:49:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:49:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:49:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 20:49:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:50:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0384, Loss_2: 0.0368, Acc_1: 0.4006, Acc_2: 0.4012, F1-score_1: 0.3273, F1-score_2: 0.3235
2023-03-08 20:50:00 - __main__ - INFO - Epoch [86/100]
2023-03-08 20:50:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:50:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:50:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:50:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:50:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:50:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 20:50:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:50:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:50:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:50:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:50:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:50:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:50:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0373, Loss_2: 0.0365, Acc_1: 0.3988, Acc_2: 0.4020, F1-score_1: 0.3198, F1-score_2: 0.3223
2023-03-08 20:50:13 - __main__ - INFO - Epoch [87/100]
2023-03-08 20:50:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 20:50:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 20:50:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 20:50:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 20:50:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:50:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:50:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 20:50:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8672, 
2023-03-08 20:50:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:50:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 20:50:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:50:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:50:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0379, Loss_2: 0.0380, Acc_1: 0.4022, Acc_2: 0.3978, F1-score_1: 0.3232, F1-score_2: 0.3210
2023-03-08 20:50:27 - __main__ - INFO - Epoch [88/100]
2023-03-08 20:50:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:50:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 20:50:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:50:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:50:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 20:50:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:50:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 20:50:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:50:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:50:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:50:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 20:50:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:50:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0389, Loss_2: 0.0373, Acc_1: 0.4025, Acc_2: 0.4000, F1-score_1: 0.3225, F1-score_2: 0.3220
2023-03-08 20:50:40 - __main__ - INFO - Epoch [89/100]
2023-03-08 20:50:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:50:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:50:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:50:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:50:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:50:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:50:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:50:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:50:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:50:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:50:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 20:50:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:50:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0399, Loss_2: 0.0376, Acc_1: 0.4003, Acc_2: 0.3971, F1-score_1: 0.3205, F1-score_2: 0.3224
2023-03-08 20:50:53 - __main__ - INFO - Epoch [90/100]
2023-03-08 20:50:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:50:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:50:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 20:50:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:50:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:51:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 20:51:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:51:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:51:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:51:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:51:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:51:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:51:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0396, Loss_2: 0.0368, Acc_1: 0.4022, Acc_2: 0.4034, F1-score_1: 0.3186, F1-score_2: 0.3220
2023-03-08 20:51:07 - __main__ - INFO - Epoch [91/100]
2023-03-08 20:51:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 20:51:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0016, Loss_2: 0.0014, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-08 20:51:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:51:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:51:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:51:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 20:51:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:51:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:51:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:51:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 20:51:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 20:51:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 20:51:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0407, Loss_2: 0.0377, Acc_1: 0.3983, Acc_2: 0.3972, F1-score_1: 0.3220, F1-score_2: 0.3192
2023-03-08 20:51:21 - __main__ - INFO - Epoch [92/100]
2023-03-08 20:51:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:51:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:51:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:51:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:51:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:51:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 20:51:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:51:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:51:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:51:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 20:51:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:51:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0010, Acc_1: 0.7891, Acc_2: 0.7734, 
2023-03-08 20:51:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0426, Loss_2: 0.0390, Acc_1: 0.3981, Acc_2: 0.3964, F1-score_1: 0.3226, F1-score_2: 0.3237
2023-03-08 20:51:34 - __main__ - INFO - Epoch [93/100]
2023-03-08 20:51:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:51:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:51:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:51:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 20:51:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 20:51:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:51:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 20:51:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:51:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:51:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:51:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:51:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:51:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0409, Loss_2: 0.0372, Acc_1: 0.3957, Acc_2: 0.3957, F1-score_1: 0.3180, F1-score_2: 0.3202
2023-03-08 20:51:48 - __main__ - INFO - Epoch [94/100]
2023-03-08 20:51:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 20:51:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:51:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:51:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:51:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:51:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 20:51:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:51:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 20:51:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:51:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:51:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 20:51:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:52:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0418, Loss_2: 0.0379, Acc_1: 0.3995, Acc_2: 0.3961, F1-score_1: 0.3187, F1-score_2: 0.3192
2023-03-08 20:52:01 - __main__ - INFO - Epoch [95/100]
2023-03-08 20:52:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:52:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:52:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 20:52:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:52:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:52:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:52:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:52:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 20:52:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:52:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 20:52:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:52:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:52:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0397, Loss_2: 0.0362, Acc_1: 0.4035, Acc_2: 0.3986, F1-score_1: 0.3212, F1-score_2: 0.3191
2023-03-08 20:52:15 - __main__ - INFO - Epoch [96/100]
2023-03-08 20:52:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 20:52:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:52:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:52:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:52:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:52:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:52:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0012, Loss_2: 0.0006, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 20:52:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:52:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 20:52:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:52:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:52:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:52:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0395, Loss_2: 0.0372, Acc_1: 0.3972, Acc_2: 0.3962, F1-score_1: 0.3200, F1-score_2: 0.3231
2023-03-08 20:52:28 - __main__ - INFO - Epoch [97/100]
2023-03-08 20:52:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:52:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 20:52:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 20:52:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:52:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:52:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:52:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:52:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:52:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:52:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:52:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:52:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:52:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0402, Loss_2: 0.0383, Acc_1: 0.4012, Acc_2: 0.3988, F1-score_1: 0.3215, F1-score_2: 0.3210
2023-03-08 20:52:42 - __main__ - INFO - Epoch [98/100]
2023-03-08 20:52:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:52:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 20:52:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:52:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:52:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:52:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:52:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 20:52:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9453, Acc_2: 0.9453, 
2023-03-08 20:52:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 20:52:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:52:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 20:52:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:52:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0397, Loss_2: 0.0375, Acc_1: 0.3989, Acc_2: 0.3976, F1-score_1: 0.3213, F1-score_2: 0.3215
2023-03-08 20:52:55 - __main__ - INFO - Epoch [99/100]
2023-03-08 20:53:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:53:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 20:53:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:53:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:53:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:53:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:53:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:53:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 20:53:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 20:53:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 20:53:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:53:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:53:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0393, Loss_2: 0.0378, Acc_1: 0.3995, Acc_2: 0.3991, F1-score_1: 0.3205, F1-score_2: 0.3220
2023-03-08 20:53:11 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 20:53:11 - utils._noise - DEBUG - 6, 7
2023-03-08 20:53:11 - utils._noise - DEBUG - 13997
2023-03-08 20:53:11 - utils._noise - INFO - Actual noise 0.20
2023-03-08 20:53:11 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-08 20:53:11 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-08 20:53:13 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 20:53:13 - __main__ - INFO - Loading dataset...
2023-03-08 20:53:13 - __main__ - INFO - Building model...
2023-03-08 20:53:13 - __main__ - INFO - <bound method Module.parameters of NewsNet(
  (embedding): Embedding(20000, 300)
  (avgpool): AdaptiveAvgPool1d(output_size=4800)
  (fc1): Linear(in_features=4800, out_features=1200, bias=True)
  (bn1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ac): Softsign()
  (fc2): Linear(in_features=1200, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=7, bias=True)
)>
2023-03-08 20:53:13 - __main__ - INFO - <bound method Module.parameters of NewsNet(
  (embedding): Embedding(20000, 300)
  (avgpool): AdaptiveAvgPool1d(output_size=4800)
  (fc1): Linear(in_features=4800, out_features=1200, bias=True)
  (bn1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ac): Softsign()
  (fc2): Linear(in_features=1200, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=7, bias=True)
)>
2023-03-08 20:53:13 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-08 20:53:13 - __main__ - INFO - Start train & evaluate
2023-03-08 20:53:13 - __main__ - INFO - Epoch [0/100]
2023-03-08 20:53:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0152, Loss_2: 0.0154, Acc_1: 0.1484, Acc_2: 0.1172, 
2023-03-08 20:53:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0135, Loss_2: 0.0135, Acc_1: 0.3438, Acc_2: 0.3828, 
2023-03-08 20:53:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0140, Loss_2: 0.0141, Acc_1: 0.3672, Acc_2: 0.3672, 
2023-03-08 20:53:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0131, Loss_2: 0.0132, Acc_1: 0.4062, Acc_2: 0.3828, 
2023-03-08 20:53:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0143, Loss_2: 0.0143, Acc_1: 0.2578, Acc_2: 0.2578, 
2023-03-08 20:53:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0131, Loss_2: 0.0131, Acc_1: 0.3984, Acc_2: 0.4141, 
2023-03-08 20:53:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0132, Loss_2: 0.0133, Acc_1: 0.3672, Acc_2: 0.3750, 
2023-03-08 20:53:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0128, Loss_2: 0.0127, Acc_1: 0.4062, Acc_2: 0.4297, 
2023-03-08 20:53:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0130, Loss_2: 0.0130, Acc_1: 0.3672, Acc_2: 0.3750, 
2023-03-08 20:53:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0136, Loss_2: 0.0136, Acc_1: 0.3359, Acc_2: 0.3125, 
2023-03-08 20:53:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0128, Loss_2: 0.0128, Acc_1: 0.3750, Acc_2: 0.3984, 
2023-03-08 20:53:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0132, Loss_2: 0.0133, Acc_1: 0.3438, Acc_2: 0.3516, 
2023-03-08 20:53:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0120, Acc_1: 0.4711, Acc_2: 0.4688, F1-score_1: 0.2857, F1-score_2: 0.2828
2023-03-08 20:53:27 - __main__ - INFO - Epoch [1/100]
2023-03-08 20:53:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0119, Loss_2: 0.0120, Acc_1: 0.4297, Acc_2: 0.4219, 
2023-03-08 20:53:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0100, Loss_2: 0.0100, Acc_1: 0.5625, Acc_2: 0.5625, 
2023-03-08 20:53:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0095, Loss_2: 0.0094, Acc_1: 0.5234, Acc_2: 0.5312, 
2023-03-08 20:53:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0102, Loss_2: 0.0103, Acc_1: 0.5156, Acc_2: 0.5156, 
2023-03-08 20:53:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0120, Loss_2: 0.0120, Acc_1: 0.3984, Acc_2: 0.4375, 
2023-03-08 20:53:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0113, Loss_2: 0.0112, Acc_1: 0.3984, Acc_2: 0.3984, 
2023-03-08 20:53:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0123, Loss_2: 0.0125, Acc_1: 0.4062, Acc_2: 0.3750, 
2023-03-08 20:53:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0126, Loss_2: 0.0126, Acc_1: 0.3906, Acc_2: 0.4062, 
2023-03-08 20:53:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0118, Loss_2: 0.0119, Acc_1: 0.4141, Acc_2: 0.4141, 
2023-03-08 20:53:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0113, Loss_2: 0.0115, Acc_1: 0.4609, Acc_2: 0.4375, 
2023-03-08 20:53:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0106, Loss_2: 0.0106, Acc_1: 0.4844, Acc_2: 0.4844, 
2023-03-08 20:53:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0128, Loss_2: 0.0128, Acc_1: 0.3984, Acc_2: 0.3984, 
2023-03-08 20:53:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0118, Loss_2: 0.0118, Acc_1: 0.4621, Acc_2: 0.4630, F1-score_1: 0.3153, F1-score_2: 0.3130
2023-03-08 20:53:41 - __main__ - INFO - Epoch [2/100]
2023-03-08 20:53:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0095, Loss_2: 0.0095, Acc_1: 0.5469, Acc_2: 0.5234, 
2023-03-08 20:53:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0089, Loss_2: 0.0088, Acc_1: 0.6328, Acc_2: 0.6484, 
2023-03-08 20:53:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0092, Loss_2: 0.0091, Acc_1: 0.5547, Acc_2: 0.5703, 
2023-03-08 20:53:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0096, Loss_2: 0.0096, Acc_1: 0.5703, Acc_2: 0.5859, 
2023-03-08 20:53:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0096, Loss_2: 0.0094, Acc_1: 0.4766, Acc_2: 0.5156, 
2023-03-08 20:53:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0095, Loss_2: 0.0096, Acc_1: 0.5859, Acc_2: 0.5469, 
2023-03-08 20:53:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0103, Loss_2: 0.0101, Acc_1: 0.5000, Acc_2: 0.5469, 
2023-03-08 20:53:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0104, Loss_2: 0.0102, Acc_1: 0.5156, Acc_2: 0.4922, 
2023-03-08 20:53:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0101, Loss_2: 0.0101, Acc_1: 0.4922, Acc_2: 0.5234, 
2023-03-08 20:53:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0108, Loss_2: 0.0108, Acc_1: 0.4609, Acc_2: 0.4453, 
2023-03-08 20:53:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0118, Loss_2: 0.0119, Acc_1: 0.4297, Acc_2: 0.4219, 
2023-03-08 20:53:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0100, Loss_2: 0.0099, Acc_1: 0.5469, Acc_2: 0.5312, 
2023-03-08 20:53:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0124, Loss_2: 0.0123, Acc_1: 0.4355, Acc_2: 0.4392, F1-score_1: 0.3268, F1-score_2: 0.3389
2023-03-08 20:53:54 - __main__ - INFO - Epoch [3/100]
2023-03-08 20:53:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0084, Loss_2: 0.0084, Acc_1: 0.6328, Acc_2: 0.6328, 
2023-03-08 20:53:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0086, Loss_2: 0.0085, Acc_1: 0.6016, Acc_2: 0.6016, 
2023-03-08 20:54:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0081, Loss_2: 0.0078, Acc_1: 0.6172, Acc_2: 0.6094, 
2023-03-08 20:54:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0075, Loss_2: 0.0074, Acc_1: 0.5547, Acc_2: 0.5938, 
2023-03-08 20:54:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0086, Loss_2: 0.0085, Acc_1: 0.5781, Acc_2: 0.5547, 
2023-03-08 20:54:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0087, Loss_2: 0.0086, Acc_1: 0.5625, Acc_2: 0.5391, 
2023-03-08 20:54:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0086, Loss_2: 0.0086, Acc_1: 0.5234, Acc_2: 0.5469, 
2023-03-08 20:54:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0100, Loss_2: 0.0101, Acc_1: 0.5312, Acc_2: 0.5078, 
2023-03-08 20:54:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0079, Loss_2: 0.0079, Acc_1: 0.6094, Acc_2: 0.5859, 
2023-03-08 20:54:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0098, Loss_2: 0.0098, Acc_1: 0.5156, Acc_2: 0.4922, 
2023-03-08 20:54:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0089, Loss_2: 0.0091, Acc_1: 0.5469, Acc_2: 0.5156, 
2023-03-08 20:54:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0110, Loss_2: 0.0110, Acc_1: 0.4453, Acc_2: 0.4688, 
2023-03-08 20:54:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0127, Loss_2: 0.0127, Acc_1: 0.4151, Acc_2: 0.4147, F1-score_1: 0.3121, F1-score_2: 0.3120
2023-03-08 20:54:08 - __main__ - INFO - Epoch [4/100]
2023-03-08 20:54:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0082, Loss_2: 0.0084, Acc_1: 0.5547, Acc_2: 0.5156, 
2023-03-08 20:54:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0077, Loss_2: 0.0078, Acc_1: 0.5859, Acc_2: 0.5781, 
2023-03-08 20:54:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0068, Loss_2: 0.0070, Acc_1: 0.6172, Acc_2: 0.6172, 
2023-03-08 20:54:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0082, Loss_2: 0.0083, Acc_1: 0.5703, Acc_2: 0.5547, 
2023-03-08 20:54:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0089, Loss_2: 0.0088, Acc_1: 0.5469, Acc_2: 0.5547, 
2023-03-08 20:54:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0078, Loss_2: 0.0079, Acc_1: 0.5781, Acc_2: 0.5938, 
2023-03-08 20:54:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0076, Loss_2: 0.0074, Acc_1: 0.6016, Acc_2: 0.6016, 
2023-03-08 20:54:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0085, Loss_2: 0.0085, Acc_1: 0.5703, Acc_2: 0.5391, 
2023-03-08 20:54:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0098, Loss_2: 0.0100, Acc_1: 0.5156, Acc_2: 0.5156, 
2023-03-08 20:54:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0080, Loss_2: 0.0078, Acc_1: 0.5938, Acc_2: 0.6094, 
2023-03-08 20:54:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0074, Loss_2: 0.0076, Acc_1: 0.6094, Acc_2: 0.5625, 
2023-03-08 20:54:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0087, Loss_2: 0.0086, Acc_1: 0.5000, Acc_2: 0.4922, 
2023-03-08 20:54:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0128, Loss_2: 0.0130, Acc_1: 0.4186, Acc_2: 0.4200, F1-score_1: 0.3253, F1-score_2: 0.3262
2023-03-08 20:54:21 - __main__ - INFO - Epoch [5/100]
2023-03-08 20:54:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0061, Loss_2: 0.0060, Acc_1: 0.6484, Acc_2: 0.6250, 
2023-03-08 20:54:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0059, Loss_2: 0.0060, Acc_1: 0.6719, Acc_2: 0.6719, 
2023-03-08 20:54:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0062, Loss_2: 0.0062, Acc_1: 0.6562, Acc_2: 0.6641, 
2023-03-08 20:54:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0059, Loss_2: 0.0059, Acc_1: 0.6484, Acc_2: 0.6250, 
2023-03-08 20:54:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0081, Loss_2: 0.0080, Acc_1: 0.5625, Acc_2: 0.5859, 
2023-03-08 20:54:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0072, Loss_2: 0.0075, Acc_1: 0.6172, Acc_2: 0.6250, 
2023-03-08 20:54:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0071, Loss_2: 0.0073, Acc_1: 0.5859, Acc_2: 0.5547, 
2023-03-08 20:54:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0063, Loss_2: 0.0068, Acc_1: 0.6328, Acc_2: 0.6016, 
2023-03-08 20:54:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0057, Loss_2: 0.0060, Acc_1: 0.6094, Acc_2: 0.6250, 
2023-03-08 20:54:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0061, Loss_2: 0.0057, Acc_1: 0.5938, Acc_2: 0.6406, 
2023-03-08 20:54:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0087, Loss_2: 0.0085, Acc_1: 0.5078, Acc_2: 0.5469, 
2023-03-08 20:54:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0067, Loss_2: 0.0067, Acc_1: 0.5938, Acc_2: 0.5859, 
2023-03-08 20:54:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0135, Loss_2: 0.0134, Acc_1: 0.4103, Acc_2: 0.4124, F1-score_1: 0.3185, F1-score_2: 0.3197
2023-03-08 20:54:35 - __main__ - INFO - Epoch [6/100]
2023-03-08 20:54:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0051, Loss_2: 0.0052, Acc_1: 0.6875, Acc_2: 0.6719, 
2023-03-08 20:54:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0051, Loss_2: 0.0047, Acc_1: 0.6719, Acc_2: 0.6719, 
2023-03-08 20:54:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0042, Loss_2: 0.0039, Acc_1: 0.6953, Acc_2: 0.6875, 
2023-03-08 20:54:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0043, Loss_2: 0.0045, Acc_1: 0.6562, Acc_2: 0.6719, 
2023-03-08 20:54:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0051, Loss_2: 0.0054, Acc_1: 0.6719, Acc_2: 0.6875, 
2023-03-08 20:54:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0052, Loss_2: 0.0053, Acc_1: 0.6562, Acc_2: 0.6484, 
2023-03-08 20:54:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0057, Loss_2: 0.0053, Acc_1: 0.6406, Acc_2: 0.6719, 
2023-03-08 20:54:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0048, Loss_2: 0.0047, Acc_1: 0.6875, Acc_2: 0.6797, 
2023-03-08 20:54:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0050, Loss_2: 0.0052, Acc_1: 0.6875, Acc_2: 0.6719, 
2023-03-08 20:54:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0054, Loss_2: 0.0054, Acc_1: 0.6641, Acc_2: 0.6953, 
2023-03-08 20:54:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0072, Loss_2: 0.0076, Acc_1: 0.6094, Acc_2: 0.5703, 
2023-03-08 20:54:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0051, Loss_2: 0.0048, Acc_1: 0.6719, Acc_2: 0.7031, 
2023-03-08 20:54:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0150, Loss_2: 0.0149, Acc_1: 0.4030, Acc_2: 0.4061, F1-score_1: 0.3247, F1-score_2: 0.3269
2023-03-08 20:54:49 - __main__ - INFO - Epoch [7/100]
2023-03-08 20:54:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0043, Loss_2: 0.0041, Acc_1: 0.7500, Acc_2: 0.7500, 
2023-03-08 20:54:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0039, Loss_2: 0.0043, Acc_1: 0.7188, Acc_2: 0.6797, 
2023-03-08 20:54:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0054, Loss_2: 0.0052, Acc_1: 0.6484, Acc_2: 0.6562, 
2023-03-08 20:54:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0043, Loss_2: 0.0043, Acc_1: 0.6953, Acc_2: 0.6797, 
2023-03-08 20:54:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0049, Loss_2: 0.0051, Acc_1: 0.6562, Acc_2: 0.6406, 
2023-03-08 20:54:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0047, Loss_2: 0.0045, Acc_1: 0.6641, Acc_2: 0.6875, 
2023-03-08 20:54:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0040, Loss_2: 0.0041, Acc_1: 0.7109, Acc_2: 0.7109, 
2023-03-08 20:54:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0064, Loss_2: 0.0064, Acc_1: 0.6328, Acc_2: 0.6484, 
2023-03-08 20:54:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0049, Loss_2: 0.0051, Acc_1: 0.6562, Acc_2: 0.6562, 
2023-03-08 20:54:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0055, Loss_2: 0.0056, Acc_1: 0.6406, Acc_2: 0.6250, 
2023-03-08 20:54:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0042, Loss_2: 0.0041, Acc_1: 0.7266, Acc_2: 0.7109, 
2023-03-08 20:54:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0079, Loss_2: 0.0076, Acc_1: 0.5703, Acc_2: 0.5625, 
2023-03-08 20:55:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0161, Loss_2: 0.0166, Acc_1: 0.4064, Acc_2: 0.4059, F1-score_1: 0.3340, F1-score_2: 0.3318
2023-03-08 20:55:02 - __main__ - INFO - Epoch [8/100]
2023-03-08 20:55:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0033, Loss_2: 0.0031, Acc_1: 0.7188, Acc_2: 0.7266, 
2023-03-08 20:55:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0025, Loss_2: 0.0024, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-08 20:55:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0019, Loss_2: 0.0019, Acc_1: 0.7891, Acc_2: 0.7578, 
2023-03-08 20:55:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0042, Loss_2: 0.0044, Acc_1: 0.6875, Acc_2: 0.6719, 
2023-03-08 20:55:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0032, Loss_2: 0.0029, Acc_1: 0.7188, Acc_2: 0.7266, 
2023-03-08 20:55:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0035, Loss_2: 0.0034, Acc_1: 0.7109, Acc_2: 0.6953, 
2023-03-08 20:55:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0048, Loss_2: 0.0048, Acc_1: 0.6562, Acc_2: 0.6328, 
2023-03-08 20:55:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0037, Loss_2: 0.0042, Acc_1: 0.7031, Acc_2: 0.6562, 
2023-03-08 20:55:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0058, Loss_2: 0.0057, Acc_1: 0.6094, Acc_2: 0.6250, 
2023-03-08 20:55:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0046, Loss_2: 0.0049, Acc_1: 0.6484, Acc_2: 0.6250, 
2023-03-08 20:55:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0029, Loss_2: 0.0032, Acc_1: 0.7188, Acc_2: 0.6953, 
2023-03-08 20:55:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0037, Loss_2: 0.0033, Acc_1: 0.7031, Acc_2: 0.7188, 
2023-03-08 20:55:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0169, Loss_2: 0.0165, Acc_1: 0.4100, Acc_2: 0.4141, F1-score_1: 0.3191, F1-score_2: 0.3174
2023-03-08 20:55:16 - __main__ - INFO - Epoch [9/100]
2023-03-08 20:55:21 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0035, Loss_2: 0.0038, Acc_1: 0.6953, Acc_2: 0.6719, 
2023-03-08 20:55:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0032, Loss_2: 0.0036, Acc_1: 0.6953, Acc_2: 0.6719, 
2023-03-08 20:55:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0026, Loss_2: 0.0027, Acc_1: 0.7422, Acc_2: 0.7188, 
2023-03-08 20:55:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0024, Loss_2: 0.0024, Acc_1: 0.7266, Acc_2: 0.7500, 
2023-03-08 20:55:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0029, Loss_2: 0.0032, Acc_1: 0.7188, Acc_2: 0.7031, 
2023-03-08 20:55:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0033, Loss_2: 0.0034, Acc_1: 0.7031, Acc_2: 0.6797, 
2023-03-08 20:55:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0018, Loss_2: 0.0019, Acc_1: 0.7734, Acc_2: 0.7500, 
2023-03-08 20:55:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0035, Loss_2: 0.0036, Acc_1: 0.6953, Acc_2: 0.6797, 
2023-03-08 20:55:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0029, Loss_2: 0.0028, Acc_1: 0.7031, Acc_2: 0.7188, 
2023-03-08 20:55:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0042, Loss_2: 0.0035, Acc_1: 0.6562, Acc_2: 0.7266, 
2023-03-08 20:55:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0024, Loss_2: 0.0023, Acc_1: 0.7344, Acc_2: 0.7266, 
2023-03-08 20:55:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0023, Loss_2: 0.0030, Acc_1: 0.7344, Acc_2: 0.6797, 
2023-03-08 20:55:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0204, Loss_2: 0.0204, Acc_1: 0.4013, Acc_2: 0.4062, F1-score_1: 0.3187, F1-score_2: 0.3213
2023-03-08 20:55:29 - __main__ - INFO - Epoch [10/100]
2023-03-08 20:55:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0021, Loss_2: 0.0026, Acc_1: 0.7500, Acc_2: 0.7188, 
2023-03-08 20:55:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0022, Loss_2: 0.0027, Acc_1: 0.7500, Acc_2: 0.7188, 
2023-03-08 20:55:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0044, Loss_2: 0.0053, Acc_1: 0.6797, Acc_2: 0.6562, 
2023-03-08 20:55:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0016, Loss_2: 0.0017, Acc_1: 0.7969, Acc_2: 0.7656, 
2023-03-08 20:55:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0027, Loss_2: 0.0032, Acc_1: 0.7188, Acc_2: 0.6953, 
2023-03-08 20:55:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0030, Loss_2: 0.0033, Acc_1: 0.7344, Acc_2: 0.7031, 
2023-03-08 20:55:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0027, Loss_2: 0.0031, Acc_1: 0.7188, Acc_2: 0.7031, 
2023-03-08 20:55:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0028, Loss_2: 0.0027, Acc_1: 0.7266, Acc_2: 0.7422, 
2023-03-08 20:55:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0023, Loss_2: 0.0022, Acc_1: 0.7500, Acc_2: 0.7656, 
2023-03-08 20:55:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0022, Loss_2: 0.0024, Acc_1: 0.7344, Acc_2: 0.7188, 
2023-03-08 20:55:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0031, Loss_2: 0.0029, Acc_1: 0.7188, Acc_2: 0.7578, 
2023-03-08 20:55:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0040, Loss_2: 0.0037, Acc_1: 0.6562, Acc_2: 0.6719, 
2023-03-08 20:55:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0219, Loss_2: 0.0197, Acc_1: 0.3935, Acc_2: 0.3937, F1-score_1: 0.3174, F1-score_2: 0.3023
2023-03-08 20:55:43 - __main__ - INFO - Epoch [11/100]
2023-03-08 20:55:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0018, Loss_2: 0.0026, Acc_1: 0.7656, Acc_2: 0.7500, 
2023-03-08 20:55:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0018, Loss_2: 0.0026, Acc_1: 0.7266, Acc_2: 0.7188, 
2023-03-08 20:55:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0014, Loss_2: 0.0013, Acc_1: 0.7891, Acc_2: 0.7734, 
2023-03-08 20:55:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0022, Loss_2: 0.0018, Acc_1: 0.7344, Acc_2: 0.7578, 
2023-03-08 20:55:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0026, Loss_2: 0.0023, Acc_1: 0.7188, Acc_2: 0.7344, 
2023-03-08 20:55:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0026, Loss_2: 0.0019, Acc_1: 0.7188, Acc_2: 0.7422, 
2023-03-08 20:55:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0024, Loss_2: 0.0029, Acc_1: 0.7422, Acc_2: 0.6875, 
2023-03-08 20:55:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0030, Loss_2: 0.0025, Acc_1: 0.7031, Acc_2: 0.7266, 
2023-03-08 20:55:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0024, Loss_2: 0.0028, Acc_1: 0.7266, Acc_2: 0.7188, 
2023-03-08 20:55:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0033, Loss_2: 0.0027, Acc_1: 0.7109, Acc_2: 0.7188, 
2023-03-08 20:55:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0025, Loss_2: 0.0025, Acc_1: 0.7188, Acc_2: 0.7266, 
2023-03-08 20:55:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0027, Loss_2: 0.0027, Acc_1: 0.7031, Acc_2: 0.7188, 
2023-03-08 20:55:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0197, Loss_2: 0.0190, Acc_1: 0.4054, Acc_2: 0.4066, F1-score_1: 0.3177, F1-score_2: 0.3212
2023-03-08 20:55:56 - __main__ - INFO - Epoch [12/100]
2023-03-08 20:56:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0016, Loss_2: 0.0012, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 20:56:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0016, Loss_2: 0.0020, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:56:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0016, Loss_2: 0.0017, Acc_1: 0.7891, Acc_2: 0.7656, 
2023-03-08 20:56:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0014, Loss_2: 0.0013, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 20:56:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0026, Loss_2: 0.0017, Acc_1: 0.7344, Acc_2: 0.7812, 
2023-03-08 20:56:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0015, Loss_2: 0.0011, Acc_1: 0.7656, Acc_2: 0.8047, 
2023-03-08 20:56:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0027, Loss_2: 0.0029, Acc_1: 0.7266, Acc_2: 0.7188, 
2023-03-08 20:56:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0022, Loss_2: 0.0022, Acc_1: 0.7422, Acc_2: 0.7266, 
2023-03-08 20:56:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0019, Loss_2: 0.0018, Acc_1: 0.7734, Acc_2: 0.7422, 
2023-03-08 20:56:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0025, Loss_2: 0.0023, Acc_1: 0.7266, Acc_2: 0.7266, 
2023-03-08 20:56:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0018, Loss_2: 0.0019, Acc_1: 0.7500, Acc_2: 0.7422, 
2023-03-08 20:56:04 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0024, Loss_2: 0.0029, Acc_1: 0.7266, Acc_2: 0.7109, 
2023-03-08 20:56:10 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0207, Loss_2: 0.0208, Acc_1: 0.4006, Acc_2: 0.3918, F1-score_1: 0.3234, F1-score_2: 0.3162
2023-03-08 20:56:10 - __main__ - INFO - Epoch [13/100]
2023-03-08 20:56:15 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0033, Loss_2: 0.0029, Acc_1: 0.7109, Acc_2: 0.7188, 
2023-03-08 20:56:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0018, Loss_2: 0.0021, Acc_1: 0.7500, Acc_2: 0.7188, 
2023-03-08 20:56:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0014, Loss_2: 0.0015, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-08 20:56:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.7578, 
2023-03-08 20:56:16 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:56:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:56:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0013, Loss_2: 0.0014, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 20:56:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0021, Loss_2: 0.0023, Acc_1: 0.7344, Acc_2: 0.6953, 
2023-03-08 20:56:17 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0013, Loss_2: 0.0012, Acc_1: 0.7734, Acc_2: 0.7578, 
2023-03-08 20:56:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0014, Loss_2: 0.0010, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:56:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0021, Loss_2: 0.0020, Acc_1: 0.7500, Acc_2: 0.7500, 
2023-03-08 20:56:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0051, Loss_2: 0.0047, Acc_1: 0.6562, Acc_2: 0.6562, 
2023-03-08 20:56:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0228, Loss_2: 0.0226, Acc_1: 0.3952, Acc_2: 0.3979, F1-score_1: 0.3116, F1-score_2: 0.3131
2023-03-08 20:56:23 - __main__ - INFO - Epoch [14/100]
2023-03-08 20:56:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0008, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:56:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0012, Loss_2: 0.0018, Acc_1: 0.7812, Acc_2: 0.7422, 
2023-03-08 20:56:29 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 20:56:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:56:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0012, Loss_2: 0.0014, Acc_1: 0.7891, Acc_2: 0.7578, 
2023-03-08 20:56:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0012, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 20:56:30 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 20:56:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0019, Loss_2: 0.0015, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-08 20:56:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0015, Loss_2: 0.0008, Acc_1: 0.7656, Acc_2: 0.8047, 
2023-03-08 20:56:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0015, Loss_2: 0.0012, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 20:56:31 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0015, Loss_2: 0.0006, Acc_1: 0.7656, Acc_2: 0.7891, 
2023-03-08 20:56:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0028, Loss_2: 0.0029, Acc_1: 0.7031, Acc_2: 0.7266, 
2023-03-08 20:56:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0215, Loss_2: 0.0215, Acc_1: 0.4005, Acc_2: 0.4064, F1-score_1: 0.3208, F1-score_2: 0.3216
2023-03-08 20:56:37 - __main__ - INFO - Epoch [15/100]
2023-03-08 20:56:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:56:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 20:56:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0018, Loss_2: 0.0012, Acc_1: 0.7266, Acc_2: 0.7578, 
2023-03-08 20:56:43 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0018, Loss_2: 0.0016, Acc_1: 0.7266, Acc_2: 0.7500, 
2023-03-08 20:56:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 20:56:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0013, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-08 20:56:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:56:44 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0031, Loss_2: 0.0052, Acc_1: 0.7266, Acc_2: 0.6484, 
2023-03-08 20:56:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0010, Loss_2: 0.0016, Acc_1: 0.8047, Acc_2: 0.7578, 
2023-03-08 20:56:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0010, Loss_2: 0.0009, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 20:56:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.7891, Acc_2: 0.7656, 
2023-03-08 20:56:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0029, Loss_2: 0.0024, Acc_1: 0.7188, Acc_2: 0.7344, 
2023-03-08 20:56:51 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0246, Loss_2: 0.0257, Acc_1: 0.3991, Acc_2: 0.3978, F1-score_1: 0.3197, F1-score_2: 0.3165
2023-03-08 20:56:51 - __main__ - INFO - Epoch [16/100]
2023-03-08 20:56:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:56:56 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 20:56:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0009, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 20:56:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 20:56:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:56:57 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 20:56:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:56:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-08 20:56:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 20:56:58 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0014, Loss_2: 0.0014, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 20:56:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-08 20:56:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 20:57:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0264, Loss_2: 0.0262, Acc_1: 0.3979, Acc_2: 0.3927, F1-score_1: 0.3144, F1-score_2: 0.3081
2023-03-08 20:57:04 - __main__ - INFO - Epoch [17/100]
2023-03-08 20:57:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 20:57:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0005, Acc_1: 0.7578, Acc_2: 0.7969, 
2023-03-08 20:57:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:57:10 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0010, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 20:57:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 20:57:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0010, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-08 20:57:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0024, Loss_2: 0.0023, Acc_1: 0.7188, Acc_2: 0.7344, 
2023-03-08 20:57:11 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0017, Loss_2: 0.0030, Acc_1: 0.7500, Acc_2: 0.7266, 
2023-03-08 20:57:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0019, Loss_2: 0.0015, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:57:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0021, Loss_2: 0.0025, Acc_1: 0.7422, Acc_2: 0.7422, 
2023-03-08 20:57:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0011, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:57:12 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:57:18 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0253, Loss_2: 0.0246, Acc_1: 0.4044, Acc_2: 0.3944, F1-score_1: 0.3277, F1-score_2: 0.3243
2023-03-08 20:57:18 - __main__ - INFO - Epoch [18/100]
2023-03-08 20:57:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0019, Acc_1: 0.7734, Acc_2: 0.7344, 
2023-03-08 20:57:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:57:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:57:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 20:57:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 20:57:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0014, Acc_1: 0.7812, Acc_2: 0.7578, 
2023-03-08 20:57:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:57:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0008, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 20:57:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0013, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.7734, 
2023-03-08 20:57:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 20:57:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0012, Loss_2: 0.0016, Acc_1: 0.7656, Acc_2: 0.7344, 
2023-03-08 20:57:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0015, Loss_2: 0.0015, Acc_1: 0.7578, Acc_2: 0.7500, 
2023-03-08 20:57:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0257, Loss_2: 0.0254, Acc_1: 0.3927, Acc_2: 0.4008, F1-score_1: 0.3173, F1-score_2: 0.3179
2023-03-08 20:57:32 - __main__ - INFO - Epoch [19/100]
2023-03-08 20:57:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:57:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:57:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 20:57:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 20:57:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0010, Loss_2: 0.0008, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 20:57:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0013, Loss_2: 0.0008, Acc_1: 0.7656, Acc_2: 0.7891, 
2023-03-08 20:57:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0015, Loss_2: 0.0011, Acc_1: 0.7422, Acc_2: 0.7656, 
2023-03-08 20:57:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0014, Loss_2: 0.0013, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 20:57:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:57:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 20:57:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0022, Loss_2: 0.0018, Acc_1: 0.7422, Acc_2: 0.7578, 
2023-03-08 20:57:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 20:57:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0284, Loss_2: 0.0291, Acc_1: 0.3889, Acc_2: 0.4047, F1-score_1: 0.3156, F1-score_2: 0.3203
2023-03-08 20:57:45 - __main__ - INFO - Epoch [20/100]
2023-03-08 20:57:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:57:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0010, Loss_2: 0.0009, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 20:57:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0012, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.8359, 
2023-03-08 20:57:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0011, Loss_2: 0.0008, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-08 20:57:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0017, Acc_1: 0.7656, Acc_2: 0.7422, 
2023-03-08 20:57:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0025, Loss_2: 0.0025, Acc_1: 0.7422, Acc_2: 0.7500, 
2023-03-08 20:57:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 20:57:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0012, Loss_2: 0.0008, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 20:57:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0011, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 20:57:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0022, Loss_2: 0.0020, Acc_1: 0.7344, Acc_2: 0.7422, 
2023-03-08 20:57:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 20:57:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 20:57:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0240, Loss_2: 0.0262, Acc_1: 0.3869, Acc_2: 0.3944, F1-score_1: 0.3170, F1-score_2: 0.3221
2023-03-08 20:57:58 - __main__ - INFO - Epoch [21/100]
2023-03-08 20:58:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0015, Loss_2: 0.0010, Acc_1: 0.7500, Acc_2: 0.7734, 
2023-03-08 20:58:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.8281, 
2023-03-08 20:58:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:58:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-08 20:58:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 20:58:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 20:58:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:58:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 20:58:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:58:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0023, Loss_2: 0.0017, Acc_1: 0.7578, Acc_2: 0.7891, 
2023-03-08 20:58:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0022, Loss_2: 0.0021, Acc_1: 0.7422, Acc_2: 0.7578, 
2023-03-08 20:58:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0027, Loss_2: 0.0024, Acc_1: 0.7031, Acc_2: 0.7188, 
2023-03-08 20:58:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0233, Loss_2: 0.0260, Acc_1: 0.3981, Acc_2: 0.3947, F1-score_1: 0.3247, F1-score_2: 0.3213
2023-03-08 20:58:12 - __main__ - INFO - Epoch [22/100]
2023-03-08 20:58:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 20:58:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0015, Loss_2: 0.0009, Acc_1: 0.7500, Acc_2: 0.7500, 
2023-03-08 20:58:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:58:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 20:58:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0011, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 20:58:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 20:58:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0010, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-08 20:58:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0037, Loss_2: 0.0041, Acc_1: 0.7109, Acc_2: 0.7188, 
2023-03-08 20:58:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0012, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:58:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:58:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 20:58:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0015, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:58:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0270, Loss_2: 0.0283, Acc_1: 0.4020, Acc_2: 0.4034, F1-score_1: 0.3228, F1-score_2: 0.3267
2023-03-08 20:58:25 - __main__ - INFO - Epoch [23/100]
2023-03-08 20:58:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 20:58:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 20:58:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 20:58:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:58:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 20:58:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 20:58:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:58:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0004, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 20:58:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:58:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 20:58:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0012, Loss_2: 0.0010, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 20:58:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0008, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 20:58:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0271, Loss_2: 0.0270, Acc_1: 0.3787, Acc_2: 0.4035, F1-score_1: 0.3120, F1-score_2: 0.3192
2023-03-08 20:58:39 - __main__ - INFO - Epoch [24/100]
2023-03-08 20:58:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0014, Loss_2: 0.0015, Acc_1: 0.7578, Acc_2: 0.7734, 
2023-03-08 20:58:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0016, Acc_1: 0.8047, Acc_2: 0.7812, 
2023-03-08 20:58:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0010, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-08 20:58:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:58:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 20:58:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:58:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 20:58:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:58:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 20:58:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 20:58:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8359, 
2023-03-08 20:58:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 20:58:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0261, Loss_2: 0.0249, Acc_1: 0.4017, Acc_2: 0.4044, F1-score_1: 0.3285, F1-score_2: 0.3288
2023-03-08 20:58:52 - __main__ - INFO - Epoch [25/100]
2023-03-08 20:58:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 20:58:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:58:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:58:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8047, Acc_2: 0.7734, 
2023-03-08 20:58:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 20:58:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0016, Loss_2: 0.0007, Acc_1: 0.7812, Acc_2: 0.8047, 
2023-03-08 20:58:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 20:58:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0014, Loss_2: 0.0008, Acc_1: 0.7500, Acc_2: 0.7969, 
2023-03-08 20:58:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0014, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 20:58:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0009, Acc_1: 0.8047, Acc_2: 0.7812, 
2023-03-08 20:59:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0011, Acc_1: 0.8984, Acc_2: 0.8594, 
2023-03-08 20:59:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0008, Loss_2: 0.0015, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 20:59:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0292, Loss_2: 0.0276, Acc_1: 0.3886, Acc_2: 0.3916, F1-score_1: 0.3124, F1-score_2: 0.3150
2023-03-08 20:59:06 - __main__ - INFO - Epoch [26/100]
2023-03-08 20:59:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 20:59:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0013, Loss_2: 0.0019, Acc_1: 0.7578, Acc_2: 0.7344, 
2023-03-08 20:59:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-08 20:59:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-08 20:59:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:59:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0023, Loss_2: 0.0022, Acc_1: 0.7578, Acc_2: 0.7578, 
2023-03-08 20:59:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 20:59:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0015, Acc_1: 0.7891, Acc_2: 0.7656, 
2023-03-08 20:59:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 20:59:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 20:59:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0013, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 20:59:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0012, Loss_2: 0.0014, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:59:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0301, Loss_2: 0.0294, Acc_1: 0.3864, Acc_2: 0.3942, F1-score_1: 0.3170, F1-score_2: 0.3180
2023-03-08 20:59:19 - __main__ - INFO - Epoch [27/100]
2023-03-08 20:59:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0012, Acc_1: 0.8359, Acc_2: 0.7891, 
2023-03-08 20:59:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:59:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:59:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 20:59:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 20:59:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0014, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 20:59:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:59:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0038, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:59:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0017, Loss_2: 0.0012, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 20:59:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 20:59:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 20:59:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:59:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0285, Loss_2: 0.0296, Acc_1: 0.3989, Acc_2: 0.3967, F1-score_1: 0.3241, F1-score_2: 0.3267
2023-03-08 20:59:33 - __main__ - INFO - Epoch [28/100]
2023-03-08 20:59:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 20:59:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0010, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:59:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 20:59:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0010, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 20:59:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 20:59:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0009, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 20:59:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 20:59:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 20:59:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 20:59:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 20:59:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 20:59:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0013, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:59:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0304, Loss_2: 0.0260, Acc_1: 0.3961, Acc_2: 0.3988, F1-score_1: 0.3207, F1-score_2: 0.3217
2023-03-08 20:59:47 - __main__ - INFO - Epoch [29/100]
2023-03-08 20:59:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 20:59:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 20:59:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 20:59:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 20:59:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 20:59:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 20:59:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 20:59:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-08 20:59:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 20:59:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 20:59:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 20:59:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 21:00:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0292, Loss_2: 0.0298, Acc_1: 0.3888, Acc_2: 0.4064, F1-score_1: 0.3172, F1-score_2: 0.3325
2023-03-08 21:00:00 - __main__ - INFO - Epoch [30/100]
2023-03-08 21:00:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:00:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 21:00:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:00:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:00:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:00:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 21:00:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0021, Acc_1: 0.8438, Acc_2: 0.7891, 
2023-03-08 21:00:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:00:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8125, 
2023-03-08 21:00:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:00:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:00:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 21:00:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0296, Loss_2: 0.0288, Acc_1: 0.4005, Acc_2: 0.4012, F1-score_1: 0.3259, F1-score_2: 0.3219
2023-03-08 21:00:14 - __main__ - INFO - Epoch [31/100]
2023-03-08 21:00:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:00:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:00:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:00:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:00:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0010, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 21:00:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 21:00:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:00:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:00:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:00:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0014, Loss_2: 0.0022, Acc_1: 0.7500, Acc_2: 0.7344, 
2023-03-08 21:00:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:00:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:00:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0286, Loss_2: 0.0296, Acc_1: 0.3976, Acc_2: 0.3852, F1-score_1: 0.3257, F1-score_2: 0.3183
2023-03-08 21:00:27 - __main__ - INFO - Epoch [32/100]
2023-03-08 21:00:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:00:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0010, Loss_2: 0.0014, Acc_1: 0.7656, Acc_2: 0.7422, 
2023-03-08 21:00:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0017, Loss_2: 0.0015, Acc_1: 0.7500, Acc_2: 0.7500, 
2023-03-08 21:00:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 21:00:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:00:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:00:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 21:00:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 21:00:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:00:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:00:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 21:00:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:00:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0311, Loss_2: 0.0307, Acc_1: 0.3974, Acc_2: 0.3915, F1-score_1: 0.3202, F1-score_2: 0.3158
2023-03-08 21:00:41 - __main__ - INFO - Epoch [33/100]
2023-03-08 21:00:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:00:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:00:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 21:00:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0016, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:00:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:00:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:00:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:00:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:00:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:00:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0002, Acc_1: 0.7734, Acc_2: 0.8047, 
2023-03-08 21:00:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-08 21:00:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:00:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0302, Loss_2: 0.0314, Acc_1: 0.3942, Acc_2: 0.3906, F1-score_1: 0.3181, F1-score_2: 0.3207
2023-03-08 21:00:55 - __main__ - INFO - Epoch [34/100]
2023-03-08 21:00:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0004, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 21:01:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 21:01:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:01:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 21:01:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 21:01:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:01:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:01:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:01:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:01:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0015, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-08 21:01:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 21:01:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:01:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0336, Loss_2: 0.0329, Acc_1: 0.3945, Acc_2: 0.3957, F1-score_1: 0.3164, F1-score_2: 0.3208
2023-03-08 21:01:08 - __main__ - INFO - Epoch [35/100]
2023-03-08 21:01:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 21:01:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:01:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9141, 
2023-03-08 21:01:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:01:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:01:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:01:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:01:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:01:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 21:01:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 21:01:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:01:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0005, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-08 21:01:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0297, Loss_2: 0.0320, Acc_1: 0.3981, Acc_2: 0.3899, F1-score_1: 0.3212, F1-score_2: 0.3161
2023-03-08 21:01:21 - __main__ - INFO - Epoch [36/100]
2023-03-08 21:01:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:01:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:01:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:01:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:01:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 21:01:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:01:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 21:01:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0012, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:01:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8594, 
2023-03-08 21:01:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 21:01:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 21:01:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 21:01:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0292, Loss_2: 0.0314, Acc_1: 0.3835, Acc_2: 0.3910, F1-score_1: 0.3120, F1-score_2: 0.3180
2023-03-08 21:01:35 - __main__ - INFO - Epoch [37/100]
2023-03-08 21:01:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:01:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:01:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:01:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:01:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 21:01:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.7734, 
2023-03-08 21:01:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:01:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8750, 
2023-03-08 21:01:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:01:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 21:01:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:01:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:01:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0312, Loss_2: 0.0309, Acc_1: 0.3894, Acc_2: 0.3954, F1-score_1: 0.3139, F1-score_2: 0.3208
2023-03-08 21:01:48 - __main__ - INFO - Epoch [38/100]
2023-03-08 21:01:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-08 21:01:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8906, 
2023-03-08 21:01:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 21:01:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:01:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0013, Loss_2: 0.0014, Acc_1: 0.7656, Acc_2: 0.7578, 
2023-03-08 21:01:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 21:01:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 21:01:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:01:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:01:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:01:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.7734, Acc_2: 0.8125, 
2023-03-08 21:01:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0012, Loss_2: 0.0015, Acc_1: 0.7734, Acc_2: 0.7500, 
2023-03-08 21:02:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0306, Loss_2: 0.0345, Acc_1: 0.3908, Acc_2: 0.3845, F1-score_1: 0.3162, F1-score_2: 0.3066
2023-03-08 21:02:02 - __main__ - INFO - Epoch [39/100]
2023-03-08 21:02:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:02:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0009, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:02:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:02:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:02:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 21:02:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:02:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:02:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:02:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:02:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:02:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:02:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0013, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 21:02:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0354, Loss_2: 0.0354, Acc_1: 0.3896, Acc_2: 0.3920, F1-score_1: 0.3127, F1-score_2: 0.3147
2023-03-08 21:02:15 - __main__ - INFO - Epoch [40/100]
2023-03-08 21:02:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:02:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-08 21:02:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:02:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0016, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 21:02:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:02:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:02:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0013, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:02:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:02:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:02:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:02:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 21:02:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-08 21:02:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0326, Loss_2: 0.0334, Acc_1: 0.3888, Acc_2: 0.3979, F1-score_1: 0.3094, F1-score_2: 0.3228
2023-03-08 21:02:29 - __main__ - INFO - Epoch [41/100]
2023-03-08 21:02:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:02:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:02:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 21:02:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 21:02:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0010, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 21:02:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:02:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:02:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:02:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:02:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8281, 
2023-03-08 21:02:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 21:02:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 21:02:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0352, Loss_2: 0.0347, Acc_1: 0.3950, Acc_2: 0.4020, F1-score_1: 0.3146, F1-score_2: 0.3275
2023-03-08 21:02:42 - __main__ - INFO - Epoch [42/100]
2023-03-08 21:02:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 21:02:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:02:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:02:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 21:02:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:02:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 21:02:48 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:02:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:02:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0011, Loss_2: 0.0009, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 21:02:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:02:49 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:02:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:02:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0349, Loss_2: 0.0351, Acc_1: 0.3896, Acc_2: 0.3945, F1-score_1: 0.3153, F1-score_2: 0.3220
2023-03-08 21:02:56 - __main__ - INFO - Epoch [43/100]
2023-03-08 21:03:00 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:03:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 21:03:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:03:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:03:01 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:03:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:03:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:03:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:03:02 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 21:03:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:03:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 21:03:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:03:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0338, Loss_2: 0.0334, Acc_1: 0.3925, Acc_2: 0.3978, F1-score_1: 0.3132, F1-score_2: 0.3233
2023-03-08 21:03:09 - __main__ - INFO - Epoch [44/100]
2023-03-08 21:03:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0011, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 21:03:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:03:14 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:03:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 21:03:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:03:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:03:15 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-08 21:03:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 21:03:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:03:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:03:16 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:03:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 21:03:22 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0325, Loss_2: 0.0330, Acc_1: 0.3944, Acc_2: 0.3961, F1-score_1: 0.3089, F1-score_2: 0.3180
2023-03-08 21:03:22 - __main__ - INFO - Epoch [45/100]
2023-03-08 21:03:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:03:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 21:03:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 21:03:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:03:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:03:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:03:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:03:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:03:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:03:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:03:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:03:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:03:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0379, Loss_2: 0.0344, Acc_1: 0.3983, Acc_2: 0.4035, F1-score_1: 0.3177, F1-score_2: 0.3240
2023-03-08 21:03:36 - __main__ - INFO - Epoch [46/100]
2023-03-08 21:03:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:03:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:03:41 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:03:41 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:03:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:03:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:03:42 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:03:42 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 21:03:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:03:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:03:43 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:03:43 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:03:49 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0336, Loss_2: 0.0336, Acc_1: 0.3952, Acc_2: 0.3879, F1-score_1: 0.3301, F1-score_2: 0.3147
2023-03-08 21:03:49 - __main__ - INFO - Epoch [47/100]
2023-03-08 21:03:54 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:03:54 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:03:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 21:03:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 21:03:55 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:03:55 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:03:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:03:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:03:56 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:03:56 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 21:03:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8359, 
2023-03-08 21:03:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:04:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0351, Loss_2: 0.0354, Acc_1: 0.3918, Acc_2: 0.3983, F1-score_1: 0.3232, F1-score_2: 0.3202
2023-03-08 21:04:02 - __main__ - INFO - Epoch [48/100]
2023-03-08 21:04:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.8203, 
2023-03-08 21:04:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:04:08 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:04:08 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:04:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 21:04:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:04:09 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:04:09 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 21:04:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:04:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:04:10 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:04:10 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 21:04:16 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0346, Loss_2: 0.0362, Acc_1: 0.3903, Acc_2: 0.3879, F1-score_1: 0.3170, F1-score_2: 0.3192
2023-03-08 21:04:16 - __main__ - INFO - Epoch [49/100]
2023-03-08 21:04:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:04:21 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0002, Acc_1: 0.7812, Acc_2: 0.8047, 
2023-03-08 21:04:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:04:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 21:04:22 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:04:22 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 21:04:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:04:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 21:04:23 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:04:23 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:04:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 21:04:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:04:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0315, Loss_2: 0.0326, Acc_1: 0.3950, Acc_2: 0.3905, F1-score_1: 0.3142, F1-score_2: 0.3101
2023-03-08 21:04:29 - __main__ - INFO - Epoch [50/100]
2023-03-08 21:04:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:04:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:04:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:04:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:04:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 21:04:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:04:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:04:36 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-08 21:04:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0014, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 21:04:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8438, 
2023-03-08 21:04:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:04:37 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 21:04:43 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0366, Loss_2: 0.0351, Acc_1: 0.3860, Acc_2: 0.3825, F1-score_1: 0.3144, F1-score_2: 0.3086
2023-03-08 21:04:43 - __main__ - INFO - Epoch [51/100]
2023-03-08 21:04:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 21:04:48 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:04:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 21:04:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:04:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:04:49 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 21:04:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0011, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 21:04:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 21:04:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 21:04:50 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 21:04:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 21:04:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:04:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0337, Loss_2: 0.0343, Acc_1: 0.3872, Acc_2: 0.4062, F1-score_1: 0.3123, F1-score_2: 0.3279
2023-03-08 21:04:56 - __main__ - INFO - Epoch [52/100]
2023-03-08 21:05:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:05:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 21:05:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0011, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 21:05:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:05:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:05:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0020, Loss_2: 0.0018, Acc_1: 0.7656, Acc_2: 0.7578, 
2023-03-08 21:05:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:05:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:05:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 21:05:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:05:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 21:05:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.8359, 
2023-03-08 21:05:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0351, Loss_2: 0.0371, Acc_1: 0.3954, Acc_2: 0.4006, F1-score_1: 0.3133, F1-score_2: 0.3273
2023-03-08 21:05:09 - __main__ - INFO - Epoch [53/100]
2023-03-08 21:05:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:05:14 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:05:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 21:05:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 21:05:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:05:15 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0007, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 21:05:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:05:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:05:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 21:05:16 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:05:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:05:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-08 21:05:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0340, Loss_2: 0.0348, Acc_1: 0.3959, Acc_2: 0.4013, F1-score_1: 0.3105, F1-score_2: 0.3246
2023-03-08 21:05:23 - __main__ - INFO - Epoch [54/100]
2023-03-08 21:05:27 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:05:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:05:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:05:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0011, Acc_1: 0.8047, Acc_2: 0.7812, 
2023-03-08 21:05:28 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 21:05:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:05:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 21:05:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0012, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 21:05:29 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-08 21:05:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:05:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0013, Loss_2: 0.0014, Acc_1: 0.7578, Acc_2: 0.7500, 
2023-03-08 21:05:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 21:05:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0337, Loss_2: 0.0363, Acc_1: 0.3995, Acc_2: 0.3838, F1-score_1: 0.3186, F1-score_2: 0.3166
2023-03-08 21:05:36 - __main__ - INFO - Epoch [55/100]
2023-03-08 21:05:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:05:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 21:05:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 21:05:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 21:05:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:05:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:05:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:05:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:05:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0005, Acc_1: 0.7812, Acc_2: 0.8047, 
2023-03-08 21:05:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:05:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0012, Loss_2: 0.0016, Acc_1: 0.7500, Acc_2: 0.7578, 
2023-03-08 21:05:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:05:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0335, Loss_2: 0.0382, Acc_1: 0.4005, Acc_2: 0.3932, F1-score_1: 0.3213, F1-score_2: 0.3225
2023-03-08 21:05:50 - __main__ - INFO - Epoch [56/100]
2023-03-08 21:05:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0013, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 21:05:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 21:05:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 21:05:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 21:05:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 21:05:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.9219, Acc_2: 0.8984, 
2023-03-08 21:05:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:05:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:05:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:05:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 21:05:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:05:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 21:06:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0308, Loss_2: 0.0354, Acc_1: 0.3945, Acc_2: 0.3954, F1-score_1: 0.3107, F1-score_2: 0.3103
2023-03-08 21:06:03 - __main__ - INFO - Epoch [57/100]
2023-03-08 21:06:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:06:08 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:06:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:06:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:06:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 21:06:09 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 21:06:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 21:06:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8828, 
2023-03-08 21:06:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:06:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 21:06:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:06:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:06:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0398, Loss_2: 0.0385, Acc_1: 0.3933, Acc_2: 0.4008, F1-score_1: 0.3210, F1-score_2: 0.3235
2023-03-08 21:06:17 - __main__ - INFO - Epoch [58/100]
2023-03-08 21:06:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:06:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:06:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:06:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:06:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:06:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 21:06:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:06:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 21:06:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:06:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:06:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:06:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 21:06:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0333, Loss_2: 0.0320, Acc_1: 0.4005, Acc_2: 0.3908, F1-score_1: 0.3270, F1-score_2: 0.3219
2023-03-08 21:06:30 - __main__ - INFO - Epoch [59/100]
2023-03-08 21:06:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:06:35 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:06:35 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8125, Acc_2: 0.7812, 
2023-03-08 21:06:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:06:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:06:36 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:06:36 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:06:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:06:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:06:37 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 21:06:37 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:06:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:06:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0344, Loss_2: 0.0354, Acc_1: 0.3905, Acc_2: 0.3874, F1-score_1: 0.3179, F1-score_2: 0.3153
2023-03-08 21:06:44 - __main__ - INFO - Epoch [60/100]
2023-03-08 21:06:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:06:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:06:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:06:49 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 21:06:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:06:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:06:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:06:50 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:06:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 21:06:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 21:06:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:06:51 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:06:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0350, Loss_2: 0.0368, Acc_1: 0.3969, Acc_2: 0.3967, F1-score_1: 0.3195, F1-score_2: 0.3202
2023-03-08 21:06:57 - __main__ - INFO - Epoch [61/100]
2023-03-08 21:07:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:07:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:07:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:07:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:07:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:07:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:07:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:07:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:07:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:07:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 21:07:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 21:07:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:07:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0367, Loss_2: 0.0364, Acc_1: 0.3928, Acc_2: 0.3971, F1-score_1: 0.3146, F1-score_2: 0.3168
2023-03-08 21:07:11 - __main__ - INFO - Epoch [62/100]
2023-03-08 21:07:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:07:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 21:07:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:07:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 21:07:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:07:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:07:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0030, Loss_2: 0.0024, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-08 21:07:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:07:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 21:07:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 21:07:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 21:07:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:07:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0357, Loss_2: 0.0396, Acc_1: 0.3833, Acc_2: 0.3804, F1-score_1: 0.3047, F1-score_2: 0.3110
2023-03-08 21:07:24 - __main__ - INFO - Epoch [63/100]
2023-03-08 21:07:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 21:07:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0039, Loss_2: 0.0040, Acc_1: 0.7578, Acc_2: 0.7500, 
2023-03-08 21:07:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:07:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:07:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:07:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 21:07:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:07:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8672, 
2023-03-08 21:07:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.7656, Acc_2: 0.7891, 
2023-03-08 21:07:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8359, 
2023-03-08 21:07:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:07:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 21:07:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0343, Loss_2: 0.0418, Acc_1: 0.3962, Acc_2: 0.3942, F1-score_1: 0.3224, F1-score_2: 0.3161
2023-03-08 21:07:38 - __main__ - INFO - Epoch [64/100]
2023-03-08 21:07:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 21:07:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 21:07:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:07:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 21:07:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9375, Acc_2: 0.9375, 
2023-03-08 21:07:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:07:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:07:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:07:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:07:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 21:07:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:07:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:07:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0339, Loss_2: 0.0381, Acc_1: 0.3996, Acc_2: 0.3942, F1-score_1: 0.3194, F1-score_2: 0.3193
2023-03-08 21:07:52 - __main__ - INFO - Epoch [65/100]
2023-03-08 21:07:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:07:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:07:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:07:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:07:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0008, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 21:07:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:07:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 21:07:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.8203, 
2023-03-08 21:07:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0010, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8516, 
2023-03-08 21:07:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:07:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8281, 
2023-03-08 21:07:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:08:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0381, Loss_2: 0.0401, Acc_1: 0.3920, Acc_2: 0.3984, F1-score_1: 0.3162, F1-score_2: 0.3180
2023-03-08 21:08:05 - __main__ - INFO - Epoch [66/100]
2023-03-08 21:08:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:08:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:08:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:08:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 21:08:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:08:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:08:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:08:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0016, Loss_2: 0.0016, Acc_1: 0.7656, Acc_2: 0.7578, 
2023-03-08 21:08:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:08:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 21:08:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:08:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:08:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0417, Loss_2: 0.0388, Acc_1: 0.3889, Acc_2: 0.3915, F1-score_1: 0.3132, F1-score_2: 0.3156
2023-03-08 21:08:19 - __main__ - INFO - Epoch [67/100]
2023-03-08 21:08:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 21:08:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:08:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:08:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:08:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:08:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:08:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:08:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:08:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:08:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:08:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:08:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:08:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0349, Loss_2: 0.0372, Acc_1: 0.4068, Acc_2: 0.3991, F1-score_1: 0.3249, F1-score_2: 0.3224
2023-03-08 21:08:32 - __main__ - INFO - Epoch [68/100]
2023-03-08 21:08:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:08:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 21:08:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:08:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8281, 
2023-03-08 21:08:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 21:08:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:08:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:08:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 21:08:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:08:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:08:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:08:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8672, 
2023-03-08 21:08:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0350, Loss_2: 0.0362, Acc_1: 0.4025, Acc_2: 0.3957, F1-score_1: 0.3257, F1-score_2: 0.3201
2023-03-08 21:08:46 - __main__ - INFO - Epoch [69/100]
2023-03-08 21:08:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:08:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 21:08:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:08:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:08:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:08:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:08:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:08:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:08:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:08:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 21:08:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:08:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:08:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0368, Loss_2: 0.0391, Acc_1: 0.3933, Acc_2: 0.3935, F1-score_1: 0.3198, F1-score_2: 0.3176
2023-03-08 21:08:59 - __main__ - INFO - Epoch [70/100]
2023-03-08 21:09:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:09:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 21:09:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:09:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:09:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:09:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:09:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:09:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 21:09:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 21:09:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:09:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8672, 
2023-03-08 21:09:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:09:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0373, Loss_2: 0.0373, Acc_1: 0.4071, Acc_2: 0.3993, F1-score_1: 0.3218, F1-score_2: 0.3185
2023-03-08 21:09:13 - __main__ - INFO - Epoch [71/100]
2023-03-08 21:09:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0009, Loss_2: 0.0005, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 21:09:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:09:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0012, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 21:09:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:09:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:09:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 21:09:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:09:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-08 21:09:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:09:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.9062, Acc_2: 0.8828, 
2023-03-08 21:09:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:09:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:09:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0382, Loss_2: 0.0375, Acc_1: 0.4061, Acc_2: 0.3950, F1-score_1: 0.3259, F1-score_2: 0.3204
2023-03-08 21:09:26 - __main__ - INFO - Epoch [72/100]
2023-03-08 21:09:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:09:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:09:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:09:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:09:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 21:09:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:09:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:09:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:09:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:09:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:09:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9375, 
2023-03-08 21:09:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 21:09:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0361, Loss_2: 0.0380, Acc_1: 0.3972, Acc_2: 0.3937, F1-score_1: 0.3233, F1-score_2: 0.3194
2023-03-08 21:09:40 - __main__ - INFO - Epoch [73/100]
2023-03-08 21:09:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:09:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 21:09:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:09:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 21:09:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0012, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 21:09:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:09:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8672, 
2023-03-08 21:09:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-08 21:09:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-08 21:09:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-08 21:09:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:09:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:09:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0349, Loss_2: 0.0381, Acc_1: 0.3984, Acc_2: 0.3959, F1-score_1: 0.3221, F1-score_2: 0.3204
2023-03-08 21:09:53 - __main__ - INFO - Epoch [74/100]
2023-03-08 21:09:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:09:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:09:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 21:09:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:09:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 21:09:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:09:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 21:10:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:10:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:10:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:10:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:10:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:10:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0327, Loss_2: 0.0374, Acc_1: 0.3826, Acc_2: 0.3837, F1-score_1: 0.3150, F1-score_2: 0.3141
2023-03-08 21:10:07 - __main__ - INFO - Epoch [75/100]
2023-03-08 21:10:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:10:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 21:10:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:10:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:10:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:10:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:10:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:10:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:10:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:10:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:10:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:10:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:10:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0380, Loss_2: 0.0406, Acc_1: 0.3974, Acc_2: 0.3967, F1-score_1: 0.3178, F1-score_2: 0.3231
2023-03-08 21:10:20 - __main__ - INFO - Epoch [76/100]
2023-03-08 21:10:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:10:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:10:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 21:10:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:10:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:10:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:10:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 21:10:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 21:10:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 21:10:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:10:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 21:10:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9375, 
2023-03-08 21:10:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0359, Loss_2: 0.0401, Acc_1: 0.3928, Acc_2: 0.3804, F1-score_1: 0.3226, F1-score_2: 0.3117
2023-03-08 21:10:33 - __main__ - INFO - Epoch [77/100]
2023-03-08 21:10:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 21:10:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:10:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0027, Loss_2: 0.0035, Acc_1: 0.7500, Acc_2: 0.7422, 
2023-03-08 21:10:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:10:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:10:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 21:10:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 21:10:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 21:10:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:10:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:10:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 21:10:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:10:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0407, Loss_2: 0.0392, Acc_1: 0.3986, Acc_2: 0.3891, F1-score_1: 0.3161, F1-score_2: 0.3185
2023-03-08 21:10:47 - __main__ - INFO - Epoch [78/100]
2023-03-08 21:10:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:10:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:10:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 21:10:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8828, 
2023-03-08 21:10:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:10:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:10:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9297, Acc_2: 0.9219, 
2023-03-08 21:10:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:10:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:10:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:10:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 21:10:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:11:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0368, Loss_2: 0.0376, Acc_1: 0.3959, Acc_2: 0.3871, F1-score_1: 0.3151, F1-score_2: 0.3099
2023-03-08 21:11:00 - __main__ - INFO - Epoch [79/100]
2023-03-08 21:11:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:11:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:11:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:11:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:11:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:11:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:11:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:11:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:11:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 21:11:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:11:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:11:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:11:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0370, Loss_2: 0.0431, Acc_1: 0.3891, Acc_2: 0.3857, F1-score_1: 0.3202, F1-score_2: 0.3103
2023-03-08 21:11:14 - __main__ - INFO - Epoch [80/100]
2023-03-08 21:11:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:11:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:11:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 21:11:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0014, Acc_1: 0.8516, Acc_2: 0.7969, 
2023-03-08 21:11:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:11:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0013, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 21:11:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:11:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0004, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 21:11:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 21:11:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:11:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8750, 
2023-03-08 21:11:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:11:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0388, Loss_2: 0.0395, Acc_1: 0.3981, Acc_2: 0.3937, F1-score_1: 0.3237, F1-score_2: 0.3189
2023-03-08 21:11:27 - __main__ - INFO - Epoch [81/100]
2023-03-08 21:11:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:11:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 21:11:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:11:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8828, 
2023-03-08 21:11:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:11:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:11:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 21:11:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:11:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:11:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 21:11:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:11:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:11:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0393, Loss_2: 0.0427, Acc_1: 0.3928, Acc_2: 0.3825, F1-score_1: 0.3213, F1-score_2: 0.3113
2023-03-08 21:11:41 - __main__ - INFO - Epoch [82/100]
2023-03-08 21:11:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:11:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 21:11:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 21:11:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:11:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:11:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:11:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 21:11:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:11:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 21:11:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:11:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:11:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 21:11:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0356, Loss_2: 0.0409, Acc_1: 0.3957, Acc_2: 0.3893, F1-score_1: 0.3174, F1-score_2: 0.3146
2023-03-08 21:11:54 - __main__ - INFO - Epoch [83/100]
2023-03-08 21:11:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:11:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:11:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:12:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:12:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:12:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:12:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 21:12:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:12:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:12:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 21:12:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 21:12:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:12:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0378, Loss_2: 0.0445, Acc_1: 0.4005, Acc_2: 0.3923, F1-score_1: 0.3174, F1-score_2: 0.3129
2023-03-08 21:12:07 - __main__ - INFO - Epoch [84/100]
2023-03-08 21:12:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:12:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:12:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 21:12:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:12:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:12:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:12:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 21:12:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:12:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 21:12:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:12:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:12:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:12:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0359, Loss_2: 0.0396, Acc_1: 0.3954, Acc_2: 0.3939, F1-score_1: 0.3166, F1-score_2: 0.3143
2023-03-08 21:12:21 - __main__ - INFO - Epoch [85/100]
2023-03-08 21:12:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 21:12:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 21:12:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:12:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:12:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:12:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:12:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 21:12:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:12:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:12:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:12:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:12:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:12:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0386, Loss_2: 0.0421, Acc_1: 0.3954, Acc_2: 0.3869, F1-score_1: 0.3148, F1-score_2: 0.3143
2023-03-08 21:12:34 - __main__ - INFO - Epoch [86/100]
2023-03-08 21:12:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 21:12:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:12:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:12:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:12:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:12:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:12:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:12:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:12:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:12:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 21:12:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:12:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8359, 
2023-03-08 21:12:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0389, Loss_2: 0.0408, Acc_1: 0.3961, Acc_2: 0.3850, F1-score_1: 0.3163, F1-score_2: 0.3121
2023-03-08 21:12:48 - __main__ - INFO - Epoch [87/100]
2023-03-08 21:12:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:12:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:12:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:12:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:12:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:12:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:12:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:12:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:12:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:12:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:12:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 21:12:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:13:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0376, Loss_2: 0.0422, Acc_1: 0.3961, Acc_2: 0.3872, F1-score_1: 0.3179, F1-score_2: 0.3143
2023-03-08 21:13:01 - __main__ - INFO - Epoch [88/100]
2023-03-08 21:13:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:13:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:13:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:13:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:13:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:13:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:13:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:13:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:13:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:13:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:13:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:13:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:13:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0394, Loss_2: 0.0430, Acc_1: 0.4020, Acc_2: 0.3920, F1-score_1: 0.3189, F1-score_2: 0.3123
2023-03-08 21:13:15 - __main__ - INFO - Epoch [89/100]
2023-03-08 21:13:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:13:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 21:13:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:13:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:13:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:13:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:13:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:13:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:13:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:13:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:13:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:13:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:13:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0392, Loss_2: 0.0449, Acc_1: 0.3991, Acc_2: 0.3852, F1-score_1: 0.3183, F1-score_2: 0.3099
2023-03-08 21:13:28 - __main__ - INFO - Epoch [90/100]
2023-03-08 21:13:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:13:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:13:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:13:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:13:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:13:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:13:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:13:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:13:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:13:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:13:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 21:13:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:13:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0386, Loss_2: 0.0423, Acc_1: 0.3957, Acc_2: 0.3865, F1-score_1: 0.3186, F1-score_2: 0.3120
2023-03-08 21:13:41 - __main__ - INFO - Epoch [91/100]
2023-03-08 21:13:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 21:13:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:13:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:13:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:13:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:13:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:13:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:13:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:13:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:13:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:13:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:13:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:13:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0375, Loss_2: 0.0439, Acc_1: 0.3995, Acc_2: 0.3854, F1-score_1: 0.3194, F1-score_2: 0.3098
2023-03-08 21:13:55 - __main__ - INFO - Epoch [92/100]
2023-03-08 21:13:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 21:14:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:14:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:14:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 21:14:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:14:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 21:14:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:14:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:14:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 21:14:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:14:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:14:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:14:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0387, Loss_2: 0.0427, Acc_1: 0.3952, Acc_2: 0.3867, F1-score_1: 0.3217, F1-score_2: 0.3145
2023-03-08 21:14:08 - __main__ - INFO - Epoch [93/100]
2023-03-08 21:14:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:14:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:14:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:14:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:14:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 21:14:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 21:14:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:14:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:14:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:14:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:14:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 21:14:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:14:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0384, Loss_2: 0.0418, Acc_1: 0.3962, Acc_2: 0.3877, F1-score_1: 0.3176, F1-score_2: 0.3146
2023-03-08 21:14:21 - __main__ - INFO - Epoch [94/100]
2023-03-08 21:14:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:14:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:14:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 21:14:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 21:14:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:14:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 21:14:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:14:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0007, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 21:14:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:14:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:14:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:14:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:14:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0389, Loss_2: 0.0423, Acc_1: 0.3956, Acc_2: 0.3879, F1-score_1: 0.3214, F1-score_2: 0.3154
2023-03-08 21:14:35 - __main__ - INFO - Epoch [95/100]
2023-03-08 21:14:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:14:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 21:14:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:14:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:14:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:14:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:14:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:14:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:14:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:14:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 21:14:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:14:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 21:14:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0397, Loss_2: 0.0427, Acc_1: 0.3998, Acc_2: 0.3871, F1-score_1: 0.3216, F1-score_2: 0.3122
2023-03-08 21:14:48 - __main__ - INFO - Epoch [96/100]
2023-03-08 21:14:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 21:14:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:14:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 21:14:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:14:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:14:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:14:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:14:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:14:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:14:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:14:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 21:14:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:15:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0406, Loss_2: 0.0444, Acc_1: 0.3964, Acc_2: 0.3852, F1-score_1: 0.3173, F1-score_2: 0.3090
2023-03-08 21:15:01 - __main__ - INFO - Epoch [97/100]
2023-03-08 21:15:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:15:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:15:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:15:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:15:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9141, 
2023-03-08 21:15:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:15:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:15:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:15:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:15:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:15:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0016, Loss_2: 0.0018, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-08 21:15:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:15:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0399, Loss_2: 0.0451, Acc_1: 0.3967, Acc_2: 0.3850, F1-score_1: 0.3215, F1-score_2: 0.3124
2023-03-08 21:15:15 - __main__ - INFO - Epoch [98/100]
2023-03-08 21:15:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 21:15:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:15:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 21:15:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:15:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:15:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:15:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:15:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 21:15:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:15:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:15:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:15:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:15:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0398, Loss_2: 0.0451, Acc_1: 0.3972, Acc_2: 0.3845, F1-score_1: 0.3195, F1-score_2: 0.3118
2023-03-08 21:15:28 - __main__ - INFO - Epoch [99/100]
2023-03-08 21:15:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 21:15:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:15:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:15:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 21:15:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 21:15:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:15:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:15:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:15:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:15:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:15:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:15:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:15:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0401, Loss_2: 0.0450, Acc_1: 0.3939, Acc_2: 0.3852, F1-score_1: 0.3195, F1-score_2: 0.3143
2023-03-08 21:15:43 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 21:15:43 - utils._noise - DEBUG - 6, 7
2023-03-08 21:15:43 - utils._noise - DEBUG - 13997
2023-03-08 21:15:44 - utils._noise - INFO - Actual noise 0.20
2023-03-08 21:15:44 - utils._noise - DEBUG - [[0.8        0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.8        0.03333333 0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.8        0.03333333 0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.8        0.03333333 0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.8        0.03333333
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.8
  0.03333333]
 [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333
  0.8       ]]
2023-03-08 21:15:44 - data.newsgroups - INFO - label precision: 0.8033149960705865
2023-03-08 21:15:46 - data.newsgroups - INFO - regrouped label (19997,)
2023-03-08 21:15:46 - __main__ - INFO - Loading dataset...
2023-03-08 21:15:46 - __main__ - INFO - Building model...
2023-03-08 21:15:46 - __main__ - INFO - <bound method Module.parameters of NewsNet(
  (embedding): Embedding(20000, 300)
  (avgpool): AdaptiveAvgPool1d(output_size=4800)
  (fc1): Linear(in_features=4800, out_features=1200, bias=True)
  (bn1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ac): Softsign()
  (fc2): Linear(in_features=1200, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=7, bias=True)
)>
2023-03-08 21:15:46 - __main__ - INFO - <bound method Module.parameters of NewsNet(
  (embedding): Embedding(20000, 300)
  (avgpool): AdaptiveAvgPool1d(output_size=4800)
  (fc1): Linear(in_features=4800, out_features=1200, bias=True)
  (bn1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (ac): Softsign()
  (fc2): Linear(in_features=1200, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=7, bias=True)
)>
2023-03-08 21:15:46 - __main__ - INFO - log directory : logs/\news\coteaching
2023-03-08 21:15:46 - __main__ - INFO - Start train & evaluate
2023-03-08 21:15:46 - __main__ - INFO - Epoch [0/100]
2023-03-08 21:15:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0154, Loss_2: 0.0156, Acc_1: 0.1250, Acc_2: 0.1172, 
2023-03-08 21:15:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0138, Loss_2: 0.0138, Acc_1: 0.4219, Acc_2: 0.3750, 
2023-03-08 21:15:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0140, Loss_2: 0.0141, Acc_1: 0.3359, Acc_2: 0.3125, 
2023-03-08 21:15:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0134, Loss_2: 0.0135, Acc_1: 0.3594, Acc_2: 0.3516, 
2023-03-08 21:15:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0150, Loss_2: 0.0150, Acc_1: 0.2578, Acc_2: 0.2500, 
2023-03-08 21:15:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0130, Loss_2: 0.0130, Acc_1: 0.3750, Acc_2: 0.3984, 
2023-03-08 21:15:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0121, Loss_2: 0.0120, Acc_1: 0.4219, Acc_2: 0.4062, 
2023-03-08 21:15:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0133, Loss_2: 0.0133, Acc_1: 0.3750, Acc_2: 0.3359, 
2023-03-08 21:15:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0133, Loss_2: 0.0134, Acc_1: 0.3750, Acc_2: 0.3594, 
2023-03-08 21:15:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0127, Loss_2: 0.0128, Acc_1: 0.4297, Acc_2: 0.4375, 
2023-03-08 21:15:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0128, Loss_2: 0.0128, Acc_1: 0.3438, Acc_2: 0.3281, 
2023-03-08 21:15:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0129, Loss_2: 0.0129, Acc_1: 0.4219, Acc_2: 0.4062, 
2023-03-08 21:15:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0120, Acc_1: 0.4470, Acc_2: 0.4412, F1-score_1: 0.2703, F1-score_2: 0.2661
2023-03-08 21:15:59 - __main__ - INFO - Epoch [1/100]
2023-03-08 21:16:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0117, Loss_2: 0.0118, Acc_1: 0.3984, Acc_2: 0.3672, 
2023-03-08 21:16:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0112, Loss_2: 0.0112, Acc_1: 0.4375, Acc_2: 0.4609, 
2023-03-08 21:16:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0128, Loss_2: 0.0125, Acc_1: 0.4219, Acc_2: 0.4297, 
2023-03-08 21:16:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0115, Loss_2: 0.0114, Acc_1: 0.4922, Acc_2: 0.4766, 
2023-03-08 21:16:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0113, Loss_2: 0.0113, Acc_1: 0.4375, Acc_2: 0.4453, 
2023-03-08 21:16:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0125, Loss_2: 0.0125, Acc_1: 0.3906, Acc_2: 0.3828, 
2023-03-08 21:16:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0120, Loss_2: 0.0121, Acc_1: 0.4141, Acc_2: 0.4297, 
2023-03-08 21:16:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0123, Loss_2: 0.0123, Acc_1: 0.3750, Acc_2: 0.3828, 
2023-03-08 21:16:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0139, Loss_2: 0.0138, Acc_1: 0.3281, Acc_2: 0.3438, 
2023-03-08 21:16:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0132, Loss_2: 0.0128, Acc_1: 0.3828, Acc_2: 0.4141, 
2023-03-08 21:16:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0120, Loss_2: 0.0121, Acc_1: 0.4297, Acc_2: 0.4375, 
2023-03-08 21:16:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0124, Loss_2: 0.0125, Acc_1: 0.3828, Acc_2: 0.3750, 
2023-03-08 21:16:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0120, Loss_2: 0.0120, Acc_1: 0.4440, Acc_2: 0.4485, F1-score_1: 0.3457, F1-score_2: 0.3382
2023-03-08 21:16:13 - __main__ - INFO - Epoch [2/100]
2023-03-08 21:16:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0098, Loss_2: 0.0098, Acc_1: 0.5000, Acc_2: 0.5312, 
2023-03-08 21:16:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0099, Loss_2: 0.0097, Acc_1: 0.4922, Acc_2: 0.5156, 
2023-03-08 21:16:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0114, Loss_2: 0.0115, Acc_1: 0.4297, Acc_2: 0.4688, 
2023-03-08 21:16:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0097, Loss_2: 0.0098, Acc_1: 0.5312, Acc_2: 0.5391, 
2023-03-08 21:16:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0093, Loss_2: 0.0095, Acc_1: 0.5547, Acc_2: 0.5234, 
2023-03-08 21:16:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0098, Loss_2: 0.0100, Acc_1: 0.5234, Acc_2: 0.5312, 
2023-03-08 21:16:19 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0114, Loss_2: 0.0115, Acc_1: 0.4766, Acc_2: 0.4766, 
2023-03-08 21:16:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0114, Loss_2: 0.0113, Acc_1: 0.3906, Acc_2: 0.4375, 
2023-03-08 21:16:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0119, Loss_2: 0.0119, Acc_1: 0.4531, Acc_2: 0.4453, 
2023-03-08 21:16:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0124, Loss_2: 0.0124, Acc_1: 0.3906, Acc_2: 0.4062, 
2023-03-08 21:16:20 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0116, Loss_2: 0.0115, Acc_1: 0.4297, Acc_2: 0.4531, 
2023-03-08 21:16:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0105, Loss_2: 0.0105, Acc_1: 0.5156, Acc_2: 0.5000, 
2023-03-08 21:16:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0121, Loss_2: 0.0121, Acc_1: 0.4484, Acc_2: 0.4462, F1-score_1: 0.3299, F1-score_2: 0.3223
2023-03-08 21:16:26 - __main__ - INFO - Epoch [3/100]
2023-03-08 21:16:31 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0079, Loss_2: 0.0079, Acc_1: 0.6562, Acc_2: 0.6328, 
2023-03-08 21:16:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0077, Loss_2: 0.0078, Acc_1: 0.6562, Acc_2: 0.6406, 
2023-03-08 21:16:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0094, Loss_2: 0.0095, Acc_1: 0.5547, Acc_2: 0.5156, 
2023-03-08 21:16:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0086, Loss_2: 0.0087, Acc_1: 0.5469, Acc_2: 0.5625, 
2023-03-08 21:16:32 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0085, Loss_2: 0.0085, Acc_1: 0.5469, Acc_2: 0.5391, 
2023-03-08 21:16:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0088, Loss_2: 0.0088, Acc_1: 0.5234, Acc_2: 0.5312, 
2023-03-08 21:16:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0090, Loss_2: 0.0090, Acc_1: 0.5312, Acc_2: 0.5156, 
2023-03-08 21:16:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0100, Loss_2: 0.0100, Acc_1: 0.5312, Acc_2: 0.5547, 
2023-03-08 21:16:33 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0081, Loss_2: 0.0082, Acc_1: 0.6406, Acc_2: 0.6094, 
2023-03-08 21:16:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0104, Loss_2: 0.0104, Acc_1: 0.4688, Acc_2: 0.4609, 
2023-03-08 21:16:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0099, Loss_2: 0.0099, Acc_1: 0.4844, Acc_2: 0.4922, 
2023-03-08 21:16:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0097, Loss_2: 0.0099, Acc_1: 0.5391, Acc_2: 0.5234, 
2023-03-08 21:16:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0123, Loss_2: 0.0122, Acc_1: 0.4285, Acc_2: 0.4248, F1-score_1: 0.3373, F1-score_2: 0.3365
2023-03-08 21:16:40 - __main__ - INFO - Epoch [4/100]
2023-03-08 21:16:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0068, Loss_2: 0.0067, Acc_1: 0.6328, Acc_2: 0.6562, 
2023-03-08 21:16:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0076, Loss_2: 0.0080, Acc_1: 0.5781, Acc_2: 0.5547, 
2023-03-08 21:16:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0062, Loss_2: 0.0061, Acc_1: 0.6406, Acc_2: 0.6484, 
2023-03-08 21:16:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0067, Loss_2: 0.0068, Acc_1: 0.6484, Acc_2: 0.6172, 
2023-03-08 21:16:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0075, Loss_2: 0.0076, Acc_1: 0.5859, Acc_2: 0.5625, 
2023-03-08 21:16:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0081, Loss_2: 0.0078, Acc_1: 0.5859, Acc_2: 0.5938, 
2023-03-08 21:16:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0079, Loss_2: 0.0080, Acc_1: 0.5703, Acc_2: 0.5625, 
2023-03-08 21:16:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0058, Loss_2: 0.0059, Acc_1: 0.6562, Acc_2: 0.6250, 
2023-03-08 21:16:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0100, Loss_2: 0.0101, Acc_1: 0.4922, Acc_2: 0.4766, 
2023-03-08 21:16:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0095, Loss_2: 0.0091, Acc_1: 0.4844, Acc_2: 0.4844, 
2023-03-08 21:16:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0081, Loss_2: 0.0079, Acc_1: 0.5547, Acc_2: 0.5625, 
2023-03-08 21:16:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0079, Loss_2: 0.0080, Acc_1: 0.6328, Acc_2: 0.6250, 
2023-03-08 21:16:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0132, Loss_2: 0.0134, Acc_1: 0.4231, Acc_2: 0.4229, F1-score_1: 0.3117, F1-score_2: 0.3119
2023-03-08 21:16:53 - __main__ - INFO - Epoch [5/100]
2023-03-08 21:16:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0062, Loss_2: 0.0064, Acc_1: 0.6562, Acc_2: 0.6484, 
2023-03-08 21:16:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0060, Loss_2: 0.0062, Acc_1: 0.6719, Acc_2: 0.6641, 
2023-03-08 21:16:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0056, Loss_2: 0.0057, Acc_1: 0.6484, Acc_2: 0.6250, 
2023-03-08 21:16:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0069, Loss_2: 0.0071, Acc_1: 0.6328, Acc_2: 0.6328, 
2023-03-08 21:16:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0060, Loss_2: 0.0061, Acc_1: 0.6250, Acc_2: 0.6328, 
2023-03-08 21:16:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0066, Loss_2: 0.0068, Acc_1: 0.5859, Acc_2: 0.5781, 
2023-03-08 21:16:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0058, Loss_2: 0.0055, Acc_1: 0.6562, Acc_2: 0.6953, 
2023-03-08 21:16:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0074, Loss_2: 0.0073, Acc_1: 0.5547, Acc_2: 0.5781, 
2023-03-08 21:17:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0079, Loss_2: 0.0080, Acc_1: 0.5547, Acc_2: 0.5703, 
2023-03-08 21:17:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0061, Loss_2: 0.0058, Acc_1: 0.6641, Acc_2: 0.6328, 
2023-03-08 21:17:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0072, Loss_2: 0.0071, Acc_1: 0.5859, Acc_2: 0.6094, 
2023-03-08 21:17:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0069, Loss_2: 0.0071, Acc_1: 0.6250, Acc_2: 0.6172, 
2023-03-08 21:17:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0135, Loss_2: 0.0134, Acc_1: 0.4083, Acc_2: 0.4068, F1-score_1: 0.3316, F1-score_2: 0.3282
2023-03-08 21:17:06 - __main__ - INFO - Epoch [6/100]
2023-03-08 21:17:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0056, Loss_2: 0.0054, Acc_1: 0.6562, Acc_2: 0.6719, 
2023-03-08 21:17:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0067, Loss_2: 0.0071, Acc_1: 0.5938, Acc_2: 0.6016, 
2023-03-08 21:17:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0057, Loss_2: 0.0058, Acc_1: 0.6562, Acc_2: 0.6406, 
2023-03-08 21:17:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0041, Loss_2: 0.0041, Acc_1: 0.7109, Acc_2: 0.7422, 
2023-03-08 21:17:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0059, Loss_2: 0.0065, Acc_1: 0.6641, Acc_2: 0.6719, 
2023-03-08 21:17:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0052, Loss_2: 0.0051, Acc_1: 0.6484, Acc_2: 0.6875, 
2023-03-08 21:17:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0051, Loss_2: 0.0052, Acc_1: 0.6250, Acc_2: 0.6484, 
2023-03-08 21:17:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0071, Loss_2: 0.0068, Acc_1: 0.5625, Acc_2: 0.5469, 
2023-03-08 21:17:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0054, Loss_2: 0.0051, Acc_1: 0.6328, Acc_2: 0.6484, 
2023-03-08 21:17:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0061, Loss_2: 0.0062, Acc_1: 0.6172, Acc_2: 0.6328, 
2023-03-08 21:17:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0063, Loss_2: 0.0062, Acc_1: 0.6172, Acc_2: 0.6094, 
2023-03-08 21:17:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0076, Loss_2: 0.0078, Acc_1: 0.5625, Acc_2: 0.5781, 
2023-03-08 21:17:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0152, Loss_2: 0.0149, Acc_1: 0.4013, Acc_2: 0.3962, F1-score_1: 0.3231, F1-score_2: 0.3182
2023-03-08 21:17:20 - __main__ - INFO - Epoch [7/100]
2023-03-08 21:17:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0048, Loss_2: 0.0049, Acc_1: 0.6562, Acc_2: 0.6719, 
2023-03-08 21:17:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0033, Loss_2: 0.0032, Acc_1: 0.7656, Acc_2: 0.7266, 
2023-03-08 21:17:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0046, Loss_2: 0.0050, Acc_1: 0.6875, Acc_2: 0.6719, 
2023-03-08 21:17:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0039, Loss_2: 0.0041, Acc_1: 0.7344, Acc_2: 0.7266, 
2023-03-08 21:17:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0050, Loss_2: 0.0048, Acc_1: 0.6641, Acc_2: 0.6484, 
2023-03-08 21:17:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0047, Loss_2: 0.0050, Acc_1: 0.7109, Acc_2: 0.7031, 
2023-03-08 21:17:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0054, Loss_2: 0.0052, Acc_1: 0.6562, Acc_2: 0.6797, 
2023-03-08 21:17:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0046, Loss_2: 0.0047, Acc_1: 0.6719, Acc_2: 0.6562, 
2023-03-08 21:17:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0060, Loss_2: 0.0064, Acc_1: 0.6172, Acc_2: 0.6172, 
2023-03-08 21:17:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0038, Loss_2: 0.0040, Acc_1: 0.7344, Acc_2: 0.7188, 
2023-03-08 21:17:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0049, Loss_2: 0.0050, Acc_1: 0.6953, Acc_2: 0.6797, 
2023-03-08 21:17:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0054, Loss_2: 0.0055, Acc_1: 0.6406, Acc_2: 0.6250, 
2023-03-08 21:17:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0159, Loss_2: 0.0170, Acc_1: 0.4139, Acc_2: 0.4105, F1-score_1: 0.3243, F1-score_2: 0.3226
2023-03-08 21:17:33 - __main__ - INFO - Epoch [8/100]
2023-03-08 21:17:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0025, Loss_2: 0.0026, Acc_1: 0.7500, Acc_2: 0.7344, 
2023-03-08 21:17:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0023, Loss_2: 0.0024, Acc_1: 0.7891, Acc_2: 0.7656, 
2023-03-08 21:17:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0051, Loss_2: 0.0045, Acc_1: 0.6328, Acc_2: 0.6875, 
2023-03-08 21:17:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0047, Loss_2: 0.0047, Acc_1: 0.6484, Acc_2: 0.6406, 
2023-03-08 21:17:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0041, Loss_2: 0.0049, Acc_1: 0.6719, Acc_2: 0.6641, 
2023-03-08 21:17:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0032, Loss_2: 0.0031, Acc_1: 0.7188, Acc_2: 0.7266, 
2023-03-08 21:17:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0040, Loss_2: 0.0036, Acc_1: 0.6719, Acc_2: 0.6875, 
2023-03-08 21:17:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0039, Loss_2: 0.0044, Acc_1: 0.7031, Acc_2: 0.6562, 
2023-03-08 21:17:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0036, Loss_2: 0.0032, Acc_1: 0.7109, Acc_2: 0.7344, 
2023-03-08 21:17:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0042, Loss_2: 0.0044, Acc_1: 0.6875, Acc_2: 0.6562, 
2023-03-08 21:17:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0037, Loss_2: 0.0042, Acc_1: 0.7031, Acc_2: 0.6719, 
2023-03-08 21:17:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0038, Loss_2: 0.0035, Acc_1: 0.6719, Acc_2: 0.6641, 
2023-03-08 21:17:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0162, Loss_2: 0.0173, Acc_1: 0.4178, Acc_2: 0.4253, F1-score_1: 0.3292, F1-score_2: 0.3315
2023-03-08 21:17:47 - __main__ - INFO - Epoch [9/100]
2023-03-08 21:17:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0026, Loss_2: 0.0028, Acc_1: 0.7422, Acc_2: 0.7344, 
2023-03-08 21:17:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0020, Loss_2: 0.0020, Acc_1: 0.7500, Acc_2: 0.7578, 
2023-03-08 21:17:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0025, Loss_2: 0.0027, Acc_1: 0.7422, Acc_2: 0.7109, 
2023-03-08 21:17:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0022, Loss_2: 0.0024, Acc_1: 0.7422, Acc_2: 0.7188, 
2023-03-08 21:17:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0041, Loss_2: 0.0048, Acc_1: 0.7109, Acc_2: 0.6641, 
2023-03-08 21:17:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0053, Loss_2: 0.0057, Acc_1: 0.6406, Acc_2: 0.6484, 
2023-03-08 21:17:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0032, Loss_2: 0.0031, Acc_1: 0.7344, Acc_2: 0.7500, 
2023-03-08 21:17:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0021, Loss_2: 0.0024, Acc_1: 0.7422, Acc_2: 0.7109, 
2023-03-08 21:17:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0052, Loss_2: 0.0054, Acc_1: 0.6328, Acc_2: 0.6328, 
2023-03-08 21:17:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0032, Loss_2: 0.0037, Acc_1: 0.7188, Acc_2: 0.6953, 
2023-03-08 21:17:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0049, Loss_2: 0.0042, Acc_1: 0.6641, Acc_2: 0.6562, 
2023-03-08 21:17:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0031, Loss_2: 0.0032, Acc_1: 0.7344, Acc_2: 0.6953, 
2023-03-08 21:18:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0188, Loss_2: 0.0186, Acc_1: 0.3898, Acc_2: 0.3896, F1-score_1: 0.3230, F1-score_2: 0.3192
2023-03-08 21:18:01 - __main__ - INFO - Epoch [10/100]
2023-03-08 21:18:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0024, Loss_2: 0.0030, Acc_1: 0.7578, Acc_2: 0.7188, 
2023-03-08 21:18:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0029, Loss_2: 0.0028, Acc_1: 0.6875, Acc_2: 0.7109, 
2023-03-08 21:18:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0020, Loss_2: 0.0020, Acc_1: 0.7656, Acc_2: 0.7500, 
2023-03-08 21:18:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0033, Loss_2: 0.0033, Acc_1: 0.6641, Acc_2: 0.7109, 
2023-03-08 21:18:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0027, Loss_2: 0.0028, Acc_1: 0.7422, Acc_2: 0.7422, 
2023-03-08 21:18:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0028, Loss_2: 0.0031, Acc_1: 0.7031, Acc_2: 0.7109, 
2023-03-08 21:18:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0022, Loss_2: 0.0016, Acc_1: 0.7422, Acc_2: 0.7656, 
2023-03-08 21:18:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0028, Loss_2: 0.0027, Acc_1: 0.7344, Acc_2: 0.7031, 
2023-03-08 21:18:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0034, Loss_2: 0.0039, Acc_1: 0.7031, Acc_2: 0.6719, 
2023-03-08 21:18:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0027, Loss_2: 0.0028, Acc_1: 0.7266, Acc_2: 0.7031, 
2023-03-08 21:18:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0027, Loss_2: 0.0021, Acc_1: 0.7188, Acc_2: 0.7656, 
2023-03-08 21:18:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0024, Loss_2: 0.0029, Acc_1: 0.7500, Acc_2: 0.6875, 
2023-03-08 21:18:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0186, Loss_2: 0.0192, Acc_1: 0.4202, Acc_2: 0.4125, F1-score_1: 0.3367, F1-score_2: 0.3199
2023-03-08 21:18:14 - __main__ - INFO - Epoch [11/100]
2023-03-08 21:18:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0021, Loss_2: 0.0023, Acc_1: 0.7578, Acc_2: 0.7422, 
2023-03-08 21:18:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0021, Loss_2: 0.0022, Acc_1: 0.7344, Acc_2: 0.7266, 
2023-03-08 21:18:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0038, Loss_2: 0.0041, Acc_1: 0.7031, Acc_2: 0.6875, 
2023-03-08 21:18:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0026, Loss_2: 0.0036, Acc_1: 0.7188, Acc_2: 0.6641, 
2023-03-08 21:18:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0011, Loss_2: 0.0014, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:18:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0033, Loss_2: 0.0021, Acc_1: 0.6875, Acc_2: 0.7578, 
2023-03-08 21:18:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0010, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:18:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0019, Loss_2: 0.0018, Acc_1: 0.7500, Acc_2: 0.7578, 
2023-03-08 21:18:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0022, Loss_2: 0.0027, Acc_1: 0.7422, Acc_2: 0.7188, 
2023-03-08 21:18:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0037, Loss_2: 0.0040, Acc_1: 0.6797, Acc_2: 0.6875, 
2023-03-08 21:18:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0017, Loss_2: 0.0021, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-08 21:18:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0027, Loss_2: 0.0023, Acc_1: 0.7500, Acc_2: 0.7266, 
2023-03-08 21:18:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0202, Loss_2: 0.0194, Acc_1: 0.4146, Acc_2: 0.4198, F1-score_1: 0.3235, F1-score_2: 0.3285
2023-03-08 21:18:28 - __main__ - INFO - Epoch [12/100]
2023-03-08 21:18:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0025, Loss_2: 0.0014, Acc_1: 0.7344, Acc_2: 0.7812, 
2023-03-08 21:18:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0013, Loss_2: 0.0013, Acc_1: 0.7422, Acc_2: 0.7578, 
2023-03-08 21:18:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0025, Loss_2: 0.0032, Acc_1: 0.7109, Acc_2: 0.7188, 
2023-03-08 21:18:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0009, Loss_2: 0.0010, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:18:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0020, Loss_2: 0.0027, Acc_1: 0.7656, Acc_2: 0.7188, 
2023-03-08 21:18:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0024, Loss_2: 0.0019, Acc_1: 0.7266, Acc_2: 0.7578, 
2023-03-08 21:18:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0010, Loss_2: 0.0010, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 21:18:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0017, Loss_2: 0.0013, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 21:18:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0020, Loss_2: 0.0022, Acc_1: 0.7656, Acc_2: 0.7422, 
2023-03-08 21:18:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0037, Loss_2: 0.0037, Acc_1: 0.6875, Acc_2: 0.7109, 
2023-03-08 21:18:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0029, Loss_2: 0.0026, Acc_1: 0.7031, Acc_2: 0.6953, 
2023-03-08 21:18:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0033, Loss_2: 0.0029, Acc_1: 0.7344, Acc_2: 0.7188, 
2023-03-08 21:18:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0214, Loss_2: 0.0201, Acc_1: 0.3954, Acc_2: 0.4034, F1-score_1: 0.3190, F1-score_2: 0.3211
2023-03-08 21:18:41 - __main__ - INFO - Epoch [13/100]
2023-03-08 21:18:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0013, Acc_1: 0.7891, Acc_2: 0.7578, 
2023-03-08 21:18:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0016, Loss_2: 0.0014, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 21:18:47 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0009, Loss_2: 0.0012, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:18:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0019, Loss_2: 0.0013, Acc_1: 0.7500, Acc_2: 0.7578, 
2023-03-08 21:18:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0012, Loss_2: 0.0013, Acc_1: 0.7812, Acc_2: 0.7578, 
2023-03-08 21:18:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0015, Loss_2: 0.0012, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 21:18:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0023, Loss_2: 0.0022, Acc_1: 0.7500, Acc_2: 0.7266, 
2023-03-08 21:18:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:18:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0016, Loss_2: 0.0014, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 21:18:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0014, Loss_2: 0.0016, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 21:18:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0033, Loss_2: 0.0036, Acc_1: 0.7109, Acc_2: 0.7031, 
2023-03-08 21:18:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0016, Loss_2: 0.0012, Acc_1: 0.7500, Acc_2: 0.7734, 
2023-03-08 21:18:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0258, Loss_2: 0.0240, Acc_1: 0.4081, Acc_2: 0.4086, F1-score_1: 0.3176, F1-score_2: 0.3166
2023-03-08 21:18:55 - __main__ - INFO - Epoch [14/100]
2023-03-08 21:18:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0015, Acc_1: 0.7969, Acc_2: 0.7734, 
2023-03-08 21:19:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.8359, 
2023-03-08 21:19:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:19:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0054, Loss_2: 0.0053, Acc_1: 0.6484, Acc_2: 0.6875, 
2023-03-08 21:19:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0010, Loss_2: 0.0008, Acc_1: 0.7734, Acc_2: 0.7891, 
2023-03-08 21:19:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 21:19:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0017, Loss_2: 0.0016, Acc_1: 0.7500, Acc_2: 0.7422, 
2023-03-08 21:19:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0033, Loss_2: 0.0033, Acc_1: 0.7031, Acc_2: 0.7109, 
2023-03-08 21:19:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 21:19:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 21:19:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0013, Loss_2: 0.0011, Acc_1: 0.7734, Acc_2: 0.7891, 
2023-03-08 21:19:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0015, Loss_2: 0.0023, Acc_1: 0.7656, Acc_2: 0.7500, 
2023-03-08 21:19:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0204, Loss_2: 0.0242, Acc_1: 0.4122, Acc_2: 0.4000, F1-score_1: 0.3317, F1-score_2: 0.3197
2023-03-08 21:19:08 - __main__ - INFO - Epoch [15/100]
2023-03-08 21:19:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:19:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0012, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 21:19:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 21:19:14 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:19:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8516, 
2023-03-08 21:19:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0013, Loss_2: 0.0012, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 21:19:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 21:19:15 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 21:19:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0021, Loss_2: 0.0020, Acc_1: 0.7734, Acc_2: 0.7578, 
2023-03-08 21:19:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0011, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 21:19:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0039, Loss_2: 0.0032, Acc_1: 0.6953, Acc_2: 0.6953, 
2023-03-08 21:19:16 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0020, Acc_1: 0.8359, Acc_2: 0.7969, 
2023-03-08 21:19:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0227, Loss_2: 0.0229, Acc_1: 0.4006, Acc_2: 0.4018, F1-score_1: 0.3243, F1-score_2: 0.3150
2023-03-08 21:19:21 - __main__ - INFO - Epoch [16/100]
2023-03-08 21:19:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0012, Loss_2: 0.0013, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-08 21:19:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0010, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 21:19:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 21:19:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0013, Loss_2: 0.0008, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:19:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0024, Loss_2: 0.0025, Acc_1: 0.7656, Acc_2: 0.7188, 
2023-03-08 21:19:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0010, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 21:19:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0040, Loss_2: 0.0034, Acc_1: 0.6797, Acc_2: 0.7109, 
2023-03-08 21:19:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0017, Loss_2: 0.0012, Acc_1: 0.7656, Acc_2: 0.8125, 
2023-03-08 21:19:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0017, Loss_2: 0.0016, Acc_1: 0.7578, Acc_2: 0.7812, 
2023-03-08 21:19:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8125, 
2023-03-08 21:19:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0016, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-08 21:19:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0011, Loss_2: 0.0013, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-08 21:19:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0244, Loss_2: 0.0259, Acc_1: 0.4000, Acc_2: 0.3935, F1-score_1: 0.3183, F1-score_2: 0.3099
2023-03-08 21:19:35 - __main__ - INFO - Epoch [17/100]
2023-03-08 21:19:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0014, Loss_2: 0.0018, Acc_1: 0.7578, Acc_2: 0.7500, 
2023-03-08 21:19:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 21:19:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0010, Loss_2: 0.0006, Acc_1: 0.7656, Acc_2: 0.7969, 
2023-03-08 21:19:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0011, Loss_2: 0.0012, Acc_1: 0.7891, Acc_2: 0.7656, 
2023-03-08 21:19:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:19:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 21:19:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.8203, 
2023-03-08 21:19:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0011, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 21:19:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0010, Acc_1: 0.8203, Acc_2: 0.7891, 
2023-03-08 21:19:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:19:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-08 21:19:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0014, Loss_2: 0.0018, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 21:19:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0245, Loss_2: 0.0249, Acc_1: 0.3903, Acc_2: 0.3923, F1-score_1: 0.3205, F1-score_2: 0.3212
2023-03-08 21:19:48 - __main__ - INFO - Epoch [18/100]
2023-03-08 21:19:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:19:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0025, Loss_2: 0.0027, Acc_1: 0.7266, Acc_2: 0.7422, 
2023-03-08 21:19:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 21:19:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:19:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0017, Loss_2: 0.0021, Acc_1: 0.7734, Acc_2: 0.7578, 
2023-03-08 21:19:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:19:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 21:19:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 21:19:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-08 21:19:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 21:19:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0016, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:19:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0012, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 21:20:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0260, Loss_2: 0.0266, Acc_1: 0.3983, Acc_2: 0.3995, F1-score_1: 0.3211, F1-score_2: 0.3238
2023-03-08 21:20:02 - __main__ - INFO - Epoch [19/100]
2023-03-08 21:20:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:20:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0020, Loss_2: 0.0018, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-08 21:20:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0009, Loss_2: 0.0008, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 21:20:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:20:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0017, Loss_2: 0.0009, Acc_1: 0.7656, Acc_2: 0.7891, 
2023-03-08 21:20:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0011, Loss_2: 0.0011, Acc_1: 0.7656, Acc_2: 0.7578, 
2023-03-08 21:20:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0011, Loss_2: 0.0014, Acc_1: 0.7969, Acc_2: 0.7734, 
2023-03-08 21:20:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0011, Loss_2: 0.0010, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 21:20:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:20:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0025, Loss_2: 0.0028, Acc_1: 0.7422, Acc_2: 0.7031, 
2023-03-08 21:20:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0015, Loss_2: 0.0010, Acc_1: 0.7578, Acc_2: 0.8125, 
2023-03-08 21:20:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:20:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0273, Loss_2: 0.0296, Acc_1: 0.3983, Acc_2: 0.3882, F1-score_1: 0.3138, F1-score_2: 0.3132
2023-03-08 21:20:15 - __main__ - INFO - Epoch [20/100]
2023-03-08 21:20:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 21:20:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:20:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 21:20:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-08 21:20:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:20:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:20:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:20:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0017, Loss_2: 0.0016, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 21:20:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.8203, 
2023-03-08 21:20:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:20:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0022, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 21:20:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.7969, 
2023-03-08 21:20:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0279, Loss_2: 0.0284, Acc_1: 0.3906, Acc_2: 0.3874, F1-score_1: 0.3191, F1-score_2: 0.3182
2023-03-08 21:20:29 - __main__ - INFO - Epoch [21/100]
2023-03-08 21:20:33 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:20:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0008, Loss_2: 0.0013, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 21:20:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:20:34 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-08 21:20:34 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:20:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:20:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:20:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 21:20:35 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0011, Loss_2: 0.0009, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:20:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0011, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:20:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.8125, Acc_2: 0.7734, 
2023-03-08 21:20:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0012, Loss_2: 0.0012, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-08 21:20:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0285, Loss_2: 0.0276, Acc_1: 0.3862, Acc_2: 0.3962, F1-score_1: 0.3183, F1-score_2: 0.3244
2023-03-08 21:20:42 - __main__ - INFO - Epoch [22/100]
2023-03-08 21:20:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:20:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 21:20:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0010, Acc_1: 0.7734, Acc_2: 0.7891, 
2023-03-08 21:20:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:20:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0009, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 21:20:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 21:20:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:20:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:20:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0022, Loss_2: 0.0027, Acc_1: 0.7734, Acc_2: 0.7344, 
2023-03-08 21:20:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0024, Loss_2: 0.0019, Acc_1: 0.7344, Acc_2: 0.7500, 
2023-03-08 21:20:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0045, Loss_2: 0.0043, Acc_1: 0.7109, Acc_2: 0.7188, 
2023-03-08 21:20:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0013, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 21:20:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0269, Loss_2: 0.0289, Acc_1: 0.3928, Acc_2: 0.3933, F1-score_1: 0.3180, F1-score_2: 0.3165
2023-03-08 21:20:56 - __main__ - INFO - Epoch [23/100]
2023-03-08 21:21:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:21:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:21:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 21:21:01 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0016, Loss_2: 0.0020, Acc_1: 0.7656, Acc_2: 0.7422, 
2023-03-08 21:21:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 21:21:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 21:21:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:21:02 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0015, Loss_2: 0.0015, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 21:21:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0016, Acc_1: 0.8281, Acc_2: 0.7812, 
2023-03-08 21:21:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-08 21:21:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:21:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 21:21:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0299, Loss_2: 0.0302, Acc_1: 0.3957, Acc_2: 0.4020, F1-score_1: 0.3237, F1-score_2: 0.3227
2023-03-08 21:21:09 - __main__ - INFO - Epoch [24/100]
2023-03-08 21:21:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 21:21:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:21:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0012, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 21:21:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:21:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:21:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 21:21:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.7812, Acc_2: 0.8047, 
2023-03-08 21:21:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0021, Loss_2: 0.0017, Acc_1: 0.7422, Acc_2: 0.7500, 
2023-03-08 21:21:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 21:21:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:21:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0008, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 21:21:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:21:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0288, Loss_2: 0.0307, Acc_1: 0.4032, Acc_2: 0.3894, F1-score_1: 0.3272, F1-score_2: 0.3174
2023-03-08 21:21:23 - __main__ - INFO - Epoch [25/100]
2023-03-08 21:21:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.7969, Acc_2: 0.7734, 
2023-03-08 21:21:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:21:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0011, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:21:29 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:21:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 21:21:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:21:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:21:30 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:21:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 21:21:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0010, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:21:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:21:31 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:21:37 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0288, Loss_2: 0.0323, Acc_1: 0.3950, Acc_2: 0.4032, F1-score_1: 0.3224, F1-score_2: 0.3254
2023-03-08 21:21:37 - __main__ - INFO - Epoch [26/100]
2023-03-08 21:21:42 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 21:21:42 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0014, Loss_2: 0.0010, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-08 21:21:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0015, Loss_2: 0.0010, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-08 21:21:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:21:43 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0007, Acc_1: 0.7734, Acc_2: 0.7891, 
2023-03-08 21:21:43 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:21:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 21:21:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8438, 
2023-03-08 21:21:44 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:21:44 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8594, 
2023-03-08 21:21:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0012, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 21:21:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0021, Loss_2: 0.0016, Acc_1: 0.7578, Acc_2: 0.7656, 
2023-03-08 21:21:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0324, Loss_2: 0.0318, Acc_1: 0.3899, Acc_2: 0.3949, F1-score_1: 0.3195, F1-score_2: 0.3280
2023-03-08 21:21:50 - __main__ - INFO - Epoch [27/100]
2023-03-08 21:21:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:21:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0012, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.8359, 
2023-03-08 21:21:56 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0010, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 21:21:56 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:21:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:21:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0012, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 21:21:57 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0011, Loss_2: 0.0003, Acc_1: 0.7734, Acc_2: 0.8359, 
2023-03-08 21:21:57 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 21:21:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 21:21:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0018, Loss_2: 0.0011, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 21:21:58 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0006, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 21:21:58 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0009, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:22:04 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0292, Loss_2: 0.0330, Acc_1: 0.4035, Acc_2: 0.4018, F1-score_1: 0.3208, F1-score_2: 0.3180
2023-03-08 21:22:04 - __main__ - INFO - Epoch [28/100]
2023-03-08 21:22:09 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:22:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0009, Acc_1: 0.8047, Acc_2: 0.8203, 
2023-03-08 21:22:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0013, Loss_2: 0.0009, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-08 21:22:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0019, Loss_2: 0.0017, Acc_1: 0.7344, Acc_2: 0.7812, 
2023-03-08 21:22:10 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0017, Acc_1: 0.7734, Acc_2: 0.7578, 
2023-03-08 21:22:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0015, Loss_2: 0.0012, Acc_1: 0.7578, Acc_2: 0.7578, 
2023-03-08 21:22:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:22:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:22:11 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0019, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8516, 
2023-03-08 21:22:11 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:22:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:22:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:22:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0303, Loss_2: 0.0333, Acc_1: 0.3930, Acc_2: 0.4022, F1-score_1: 0.3201, F1-score_2: 0.3185
2023-03-08 21:22:17 - __main__ - INFO - Epoch [29/100]
2023-03-08 21:22:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:22:23 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:22:23 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-08 21:22:23 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 21:22:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:22:24 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 21:22:24 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 21:22:24 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 21:22:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 21:22:25 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:22:25 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0013, Acc_1: 0.8203, Acc_2: 0.7734, 
2023-03-08 21:22:25 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:22:31 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0283, Loss_2: 0.0306, Acc_1: 0.4018, Acc_2: 0.4120, F1-score_1: 0.3201, F1-score_2: 0.3205
2023-03-08 21:22:31 - __main__ - INFO - Epoch [30/100]
2023-03-08 21:22:36 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0010, Loss_2: 0.0004, Acc_1: 0.7656, Acc_2: 0.8047, 
2023-03-08 21:22:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:22:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-08 21:22:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 21:22:37 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 21:22:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0014, Loss_2: 0.0010, Acc_1: 0.7656, Acc_2: 0.7891, 
2023-03-08 21:22:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0011, Acc_1: 0.8281, Acc_2: 0.7812, 
2023-03-08 21:22:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0008, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:22:38 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0012, Loss_2: 0.0009, Acc_1: 0.7734, Acc_2: 0.7969, 
2023-03-08 21:22:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0009, Loss_2: 0.0012, Acc_1: 0.7969, Acc_2: 0.7656, 
2023-03-08 21:22:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:22:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:22:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0263, Loss_2: 0.0327, Acc_1: 0.3952, Acc_2: 0.4020, F1-score_1: 0.3114, F1-score_2: 0.3209
2023-03-08 21:22:45 - __main__ - INFO - Epoch [31/100]
2023-03-08 21:22:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 21:22:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0015, Loss_2: 0.0018, Acc_1: 0.7656, Acc_2: 0.7500, 
2023-03-08 21:22:50 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 21:22:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:22:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 21:22:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0017, Loss_2: 0.0013, Acc_1: 0.7344, Acc_2: 0.7656, 
2023-03-08 21:22:51 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0012, Loss_2: 0.0009, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 21:22:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:22:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0008, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:22:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8516, 
2023-03-08 21:22:52 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0010, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 21:22:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-08 21:22:58 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0325, Loss_2: 0.0334, Acc_1: 0.3964, Acc_2: 0.3922, F1-score_1: 0.3196, F1-score_2: 0.3174
2023-03-08 21:22:58 - __main__ - INFO - Epoch [32/100]
2023-03-08 21:23:03 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 21:23:03 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0010, Loss_2: 0.0010, Acc_1: 0.7656, Acc_2: 0.7812, 
2023-03-08 21:23:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 21:23:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 21:23:04 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:23:04 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:23:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:23:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 21:23:05 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:23:05 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 21:23:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0012, Loss_2: 0.0013, Acc_1: 0.7891, Acc_2: 0.7734, 
2023-03-08 21:23:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0025, Loss_2: 0.0031, Acc_1: 0.7500, Acc_2: 0.7109, 
2023-03-08 21:23:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0302, Loss_2: 0.0306, Acc_1: 0.3983, Acc_2: 0.4012, F1-score_1: 0.3189, F1-score_2: 0.3281
2023-03-08 21:23:12 - __main__ - INFO - Epoch [33/100]
2023-03-08 21:23:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:23:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:23:17 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 21:23:17 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:23:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 21:23:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:23:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0023, Loss_2: 0.0020, Acc_1: 0.7656, Acc_2: 0.7500, 
2023-03-08 21:23:18 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.7969, 
2023-03-08 21:23:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-08 21:23:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 21:23:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:23:19 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 21:23:25 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0307, Loss_2: 0.0326, Acc_1: 0.3896, Acc_2: 0.4052, F1-score_1: 0.3173, F1-score_2: 0.3262
2023-03-08 21:23:25 - __main__ - INFO - Epoch [34/100]
2023-03-08 21:23:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:23:30 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 21:23:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:23:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:23:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 21:23:31 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:23:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 21:23:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 21:23:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 21:23:32 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 21:23:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0010, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 21:23:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:23:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0314, Loss_2: 0.0339, Acc_1: 0.3983, Acc_2: 0.3959, F1-score_1: 0.3138, F1-score_2: 0.3220
2023-03-08 21:23:39 - __main__ - INFO - Epoch [35/100]
2023-03-08 21:23:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:23:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0010, Loss_2: 0.0007, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-08 21:23:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:23:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:23:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0018, Loss_2: 0.0018, Acc_1: 0.7422, Acc_2: 0.7578, 
2023-03-08 21:23:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:23:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:23:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:23:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:23:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:23:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:23:46 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 21:23:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0311, Loss_2: 0.0331, Acc_1: 0.4057, Acc_2: 0.4073, F1-score_1: 0.3218, F1-score_2: 0.3236
2023-03-08 21:23:52 - __main__ - INFO - Epoch [36/100]
2023-03-08 21:23:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:23:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 21:23:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:23:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 21:23:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:23:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:23:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0018, Loss_2: 0.0013, Acc_1: 0.7422, Acc_2: 0.7656, 
2023-03-08 21:23:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8047, 
2023-03-08 21:23:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:23:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:24:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0012, Loss_2: 0.0013, Acc_1: 0.7500, Acc_2: 0.7734, 
2023-03-08 21:24:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:24:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0301, Loss_2: 0.0329, Acc_1: 0.4069, Acc_2: 0.4102, F1-score_1: 0.3154, F1-score_2: 0.3332
2023-03-08 21:24:06 - __main__ - INFO - Epoch [37/100]
2023-03-08 21:24:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 21:24:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 21:24:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.7812, Acc_2: 0.7969, 
2023-03-08 21:24:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:24:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:24:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 21:24:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:24:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 21:24:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0010, Loss_2: 0.0009, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 21:24:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:24:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0013, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-08 21:24:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:24:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0339, Loss_2: 0.0333, Acc_1: 0.4047, Acc_2: 0.4012, F1-score_1: 0.3208, F1-score_2: 0.3250
2023-03-08 21:24:19 - __main__ - INFO - Epoch [38/100]
2023-03-08 21:24:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 21:24:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:24:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:24:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:24:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:24:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:24:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:24:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 21:24:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:24:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:24:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 21:24:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:24:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0342, Loss_2: 0.0311, Acc_1: 0.3988, Acc_2: 0.4057, F1-score_1: 0.3198, F1-score_2: 0.3196
2023-03-08 21:24:33 - __main__ - INFO - Epoch [39/100]
2023-03-08 21:24:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 21:24:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:24:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 21:24:38 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 21:24:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 21:24:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:24:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:24:39 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0010, Loss_2: 0.0006, Acc_1: 0.7734, Acc_2: 0.7969, 
2023-03-08 21:24:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0006, Loss_2: 0.0009, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:24:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0007, Loss_2: 0.0009, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:24:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0005, Loss_2: 0.0013, Acc_1: 0.8125, Acc_2: 0.7969, 
2023-03-08 21:24:40 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:24:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0321, Loss_2: 0.0380, Acc_1: 0.3945, Acc_2: 0.4035, F1-score_1: 0.3184, F1-score_2: 0.3295
2023-03-08 21:24:46 - __main__ - INFO - Epoch [40/100]
2023-03-08 21:24:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0014, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8438, 
2023-03-08 21:24:51 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0009, Loss_2: 0.0004, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 21:24:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 21:24:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 21:24:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:24:52 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0010, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8594, 
2023-03-08 21:24:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0010, Loss_2: 0.0005, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:24:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0008, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 21:24:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8516, 
2023-03-08 21:24:53 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:24:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:24:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:25:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0329, Loss_2: 0.0364, Acc_1: 0.4025, Acc_2: 0.3889, F1-score_1: 0.3229, F1-score_2: 0.3119
2023-03-08 21:25:00 - __main__ - INFO - Epoch [41/100]
2023-03-08 21:25:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:25:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0007, Loss_2: 0.0013, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 21:25:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:25:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 21:25:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:25:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:25:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:25:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:25:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.8984, 
2023-03-08 21:25:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:25:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:25:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:25:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0325, Loss_2: 0.0355, Acc_1: 0.4046, Acc_2: 0.3974, F1-score_1: 0.3245, F1-score_2: 0.3223
2023-03-08 21:25:13 - __main__ - INFO - Epoch [42/100]
2023-03-08 21:25:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:25:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-08 21:25:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 21:25:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:25:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 21:25:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:25:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0033, Loss_2: 0.0026, Acc_1: 0.7500, Acc_2: 0.7578, 
2023-03-08 21:25:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:25:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:25:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:25:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8672, Acc_2: 0.8125, 
2023-03-08 21:25:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 21:25:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0308, Loss_2: 0.0330, Acc_1: 0.4000, Acc_2: 0.4091, F1-score_1: 0.3192, F1-score_2: 0.3272
2023-03-08 21:25:27 - __main__ - INFO - Epoch [43/100]
2023-03-08 21:25:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:25:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:25:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 21:25:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:25:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:25:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0007, Loss_2: 0.0006, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:25:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:25:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:25:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:25:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:25:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8750, 
2023-03-08 21:25:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0012, Loss_2: 0.0009, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 21:25:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0299, Loss_2: 0.0363, Acc_1: 0.4083, Acc_2: 0.4057, F1-score_1: 0.3215, F1-score_2: 0.3323
2023-03-08 21:25:41 - __main__ - INFO - Epoch [44/100]
2023-03-08 21:25:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 21:25:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:25:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0007, Loss_2: 0.0005, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 21:25:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 21:25:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:25:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:25:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:25:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:25:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0021, Loss_2: 0.0011, Acc_1: 0.7422, Acc_2: 0.7656, 
2023-03-08 21:25:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:25:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:25:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:25:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0307, Loss_2: 0.0359, Acc_1: 0.4017, Acc_2: 0.3974, F1-score_1: 0.3175, F1-score_2: 0.3215
2023-03-08 21:25:54 - __main__ - INFO - Epoch [45/100]
2023-03-08 21:25:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-08 21:25:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 21:25:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 21:25:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:26:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:26:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:26:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-08 21:26:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:26:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:26:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:26:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:26:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0015, Acc_1: 0.8438, Acc_2: 0.8203, 
2023-03-08 21:26:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0307, Loss_2: 0.0348, Acc_1: 0.3881, Acc_2: 0.3998, F1-score_1: 0.3172, F1-score_2: 0.3265
2023-03-08 21:26:07 - __main__ - INFO - Epoch [46/100]
2023-03-08 21:26:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:26:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:26:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:26:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.8125, 
2023-03-08 21:26:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:26:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0025, Loss_2: 0.0028, Acc_1: 0.7578, Acc_2: 0.7500, 
2023-03-08 21:26:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 21:26:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:26:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:26:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 21:26:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0009, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 21:26:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:26:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0312, Loss_2: 0.0405, Acc_1: 0.3988, Acc_2: 0.4035, F1-score_1: 0.3167, F1-score_2: 0.3272
2023-03-08 21:26:21 - __main__ - INFO - Epoch [47/100]
2023-03-08 21:26:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:26:26 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:26:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:26:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:26:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:26:27 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 21:26:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:26:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:26:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 21:26:28 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8125, 
2023-03-08 21:26:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:26:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0014, Loss_2: 0.0010, Acc_1: 0.7578, Acc_2: 0.7891, 
2023-03-08 21:26:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0349, Loss_2: 0.0330, Acc_1: 0.4039, Acc_2: 0.3996, F1-score_1: 0.3262, F1-score_2: 0.3213
2023-03-08 21:26:35 - __main__ - INFO - Epoch [48/100]
2023-03-08 21:26:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:26:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:26:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:26:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:26:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:26:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:26:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.9453, Acc_2: 0.9375, 
2023-03-08 21:26:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:26:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:26:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 21:26:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:26:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:26:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0335, Loss_2: 0.0389, Acc_1: 0.4029, Acc_2: 0.3939, F1-score_1: 0.3234, F1-score_2: 0.3139
2023-03-08 21:26:48 - __main__ - INFO - Epoch [49/100]
2023-03-08 21:26:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 21:26:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:26:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:26:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:26:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:26:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:26:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:26:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:26:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:26:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0017, Loss_2: 0.0001, Acc_1: 0.7734, Acc_2: 0.8438, 
2023-03-08 21:26:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:26:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:27:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0299, Loss_2: 0.0340, Acc_1: 0.3964, Acc_2: 0.3903, F1-score_1: 0.3224, F1-score_2: 0.3120
2023-03-08 21:27:02 - __main__ - INFO - Epoch [50/100]
2023-03-08 21:27:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:27:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:27:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:27:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8203, 
2023-03-08 21:27:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:27:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 21:27:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 21:27:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:27:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8594, 
2023-03-08 21:27:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 21:27:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 21:27:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:27:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0353, Loss_2: 0.0353, Acc_1: 0.3935, Acc_2: 0.3925, F1-score_1: 0.3203, F1-score_2: 0.3242
2023-03-08 21:27:15 - __main__ - INFO - Epoch [51/100]
2023-03-08 21:27:20 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:27:20 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:27:21 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 21:27:21 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8594, 
2023-03-08 21:27:21 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:27:21 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:27:22 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 21:27:22 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:27:22 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0014, Loss_2: 0.0008, Acc_1: 0.7891, Acc_2: 0.7812, 
2023-03-08 21:27:22 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:27:23 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:27:23 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 21:27:29 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0322, Loss_2: 0.0357, Acc_1: 0.3967, Acc_2: 0.4040, F1-score_1: 0.3196, F1-score_2: 0.3259
2023-03-08 21:27:29 - __main__ - INFO - Epoch [52/100]
2023-03-08 21:27:34 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0007, Loss_2: 0.0008, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 21:27:34 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0011, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 21:27:34 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0009, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:27:35 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0007, Loss_2: 0.0012, Acc_1: 0.7891, Acc_2: 0.8203, 
2023-03-08 21:27:35 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:27:35 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8672, 
2023-03-08 21:27:35 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8203, 
2023-03-08 21:27:35 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8438, 
2023-03-08 21:27:36 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:27:36 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:27:36 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.8281, 
2023-03-08 21:27:36 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8906, 
2023-03-08 21:27:42 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0393, Loss_2: 0.0364, Acc_1: 0.3942, Acc_2: 0.4032, F1-score_1: 0.3247, F1-score_2: 0.3231
2023-03-08 21:27:42 - __main__ - INFO - Epoch [53/100]
2023-03-08 21:27:47 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:27:47 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0014, Loss_2: 0.0008, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 21:27:48 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0006, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:27:48 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 21:27:48 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:27:48 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:27:49 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0014, Loss_2: 0.0010, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 21:27:49 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:27:49 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0009, Loss_2: 0.0003, Acc_1: 0.8203, Acc_2: 0.8516, 
2023-03-08 21:27:49 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 21:27:50 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:27:50 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:27:56 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0357, Loss_2: 0.0377, Acc_1: 0.3939, Acc_2: 0.4018, F1-score_1: 0.3199, F1-score_2: 0.3303
2023-03-08 21:27:56 - __main__ - INFO - Epoch [54/100]
2023-03-08 21:28:01 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:28:01 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:28:01 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:28:02 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9062, 
2023-03-08 21:28:02 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:28:02 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:28:02 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:28:03 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0019, Loss_2: 0.0014, Acc_1: 0.7656, Acc_2: 0.7734, 
2023-03-08 21:28:03 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0005, Loss_2: 0.0002, Acc_1: 0.8125, Acc_2: 0.8438, 
2023-03-08 21:28:03 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:28:03 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:28:03 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:28:09 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0376, Loss_2: 0.0372, Acc_1: 0.3901, Acc_2: 0.4023, F1-score_1: 0.3214, F1-score_2: 0.3237
2023-03-08 21:28:09 - __main__ - INFO - Epoch [55/100]
2023-03-08 21:28:14 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0006, Loss_2: 0.0009, Acc_1: 0.7969, Acc_2: 0.7891, 
2023-03-08 21:28:15 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:28:15 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:28:15 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:28:15 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0008, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:28:16 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8359, 
2023-03-08 21:28:16 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:28:16 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:28:16 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:28:17 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:28:17 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 21:28:17 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:28:23 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0394, Loss_2: 0.0373, Acc_1: 0.3920, Acc_2: 0.3981, F1-score_1: 0.3221, F1-score_2: 0.3193
2023-03-08 21:28:23 - __main__ - INFO - Epoch [56/100]
2023-03-08 21:28:28 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0022, Loss_2: 0.0032, Acc_1: 0.7578, Acc_2: 0.7344, 
2023-03-08 21:28:28 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 21:28:28 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8672, 
2023-03-08 21:28:28 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:28:29 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0026, Loss_2: 0.0027, Acc_1: 0.7500, Acc_2: 0.7578, 
2023-03-08 21:28:29 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 21:28:29 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:28:29 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-08 21:28:30 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:28:30 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 21:28:30 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:28:30 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0004, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:28:36 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0388, Loss_2: 0.0414, Acc_1: 0.4017, Acc_2: 0.3981, F1-score_1: 0.3294, F1-score_2: 0.3224
2023-03-08 21:28:36 - __main__ - INFO - Epoch [57/100]
2023-03-08 21:28:41 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:28:41 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0006, Loss_2: 0.0002, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:28:42 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 21:28:42 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 21:28:42 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.7812, 
2023-03-08 21:28:42 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:28:43 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:28:43 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:28:43 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:28:43 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:28:44 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:28:44 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0011, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 21:28:50 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0411, Loss_2: 0.0423, Acc_1: 0.4029, Acc_2: 0.3998, F1-score_1: 0.3310, F1-score_2: 0.3255
2023-03-08 21:28:50 - __main__ - INFO - Epoch [58/100]
2023-03-08 21:28:55 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:28:55 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8516, 
2023-03-08 21:28:55 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:28:55 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 21:28:56 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 21:28:56 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:28:56 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:28:56 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:28:57 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:28:57 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:28:57 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:28:57 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.9141, Acc_2: 0.9062, 
2023-03-08 21:29:03 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0363, Loss_2: 0.0363, Acc_1: 0.3928, Acc_2: 0.4018, F1-score_1: 0.3192, F1-score_2: 0.3256
2023-03-08 21:29:03 - __main__ - INFO - Epoch [59/100]
2023-03-08 21:29:08 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:29:09 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:29:09 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 21:29:09 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:29:09 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8047, 
2023-03-08 21:29:10 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 21:29:10 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:29:10 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:29:10 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:29:10 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:29:11 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:29:11 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:29:17 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0406, Loss_2: 0.0375, Acc_1: 0.3945, Acc_2: 0.4052, F1-score_1: 0.3196, F1-score_2: 0.3268
2023-03-08 21:29:17 - __main__ - INFO - Epoch [60/100]
2023-03-08 21:29:22 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:29:22 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:29:22 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:29:22 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:29:23 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 21:29:23 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0009, Loss_2: 0.0009, Acc_1: 0.7734, Acc_2: 0.7734, 
2023-03-08 21:29:23 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:29:23 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:29:24 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:29:24 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:29:24 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:29:24 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:29:30 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0390, Loss_2: 0.0414, Acc_1: 0.3959, Acc_2: 0.3995, F1-score_1: 0.3171, F1-score_2: 0.3291
2023-03-08 21:29:30 - __main__ - INFO - Epoch [61/100]
2023-03-08 21:29:35 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 21:29:36 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:29:36 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:29:36 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:29:36 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:29:37 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:29:37 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:29:37 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:29:37 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 21:29:38 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:29:38 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:29:38 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:29:44 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0384, Loss_2: 0.0409, Acc_1: 0.3978, Acc_2: 0.3998, F1-score_1: 0.3219, F1-score_2: 0.3284
2023-03-08 21:29:44 - __main__ - INFO - Epoch [62/100]
2023-03-08 21:29:49 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:29:49 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:29:49 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:29:50 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:29:50 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:29:50 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:29:50 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:29:51 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:29:51 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:29:51 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:29:51 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0045, Loss_2: 0.0032, Acc_1: 0.7422, Acc_2: 0.7500, 
2023-03-08 21:29:52 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 21:29:57 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0403, Loss_2: 0.0427, Acc_1: 0.3922, Acc_2: 0.3966, F1-score_1: 0.3170, F1-score_2: 0.3254
2023-03-08 21:29:57 - __main__ - INFO - Epoch [63/100]
2023-03-08 21:30:02 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0008, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 21:30:02 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:30:03 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.9062, 
2023-03-08 21:30:03 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:30:03 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:30:03 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:30:04 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 21:30:04 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:30:04 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:30:04 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:30:05 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:30:05 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 21:30:11 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0370, Loss_2: 0.0436, Acc_1: 0.3954, Acc_2: 0.3986, F1-score_1: 0.3090, F1-score_2: 0.3215
2023-03-08 21:30:11 - __main__ - INFO - Epoch [64/100]
2023-03-08 21:30:16 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8359, 
2023-03-08 21:30:16 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:30:16 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:30:16 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.9141, 
2023-03-08 21:30:17 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:30:17 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8984, 
2023-03-08 21:30:17 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:30:17 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:30:18 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 21:30:18 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:30:18 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:30:18 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:30:24 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0403, Loss_2: 0.0471, Acc_1: 0.3949, Acc_2: 0.3818, F1-score_1: 0.3205, F1-score_2: 0.3169
2023-03-08 21:30:24 - __main__ - INFO - Epoch [65/100]
2023-03-08 21:30:29 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8125, 
2023-03-08 21:30:29 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:30:30 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8984, 
2023-03-08 21:30:30 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:30:30 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:30:30 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0004, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 21:30:31 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0004, Loss_2: 0.0006, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:30:31 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:30:31 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0004, Acc_1: 0.8984, Acc_2: 0.8750, 
2023-03-08 21:30:31 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:30:32 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 21:30:32 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0010, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 21:30:38 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0337, Loss_2: 0.0416, Acc_1: 0.3939, Acc_2: 0.4142, F1-score_1: 0.3197, F1-score_2: 0.3315
2023-03-08 21:30:38 - __main__ - INFO - Epoch [66/100]
2023-03-08 21:30:43 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:30:43 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 21:30:43 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8359, Acc_2: 0.8047, 
2023-03-08 21:30:44 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0002, Acc_1: 0.7891, Acc_2: 0.8125, 
2023-03-08 21:30:44 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:30:44 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0003, Loss_2: 0.0013, Acc_1: 0.8359, Acc_2: 0.8203, 
2023-03-08 21:30:44 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0009, Loss_2: 0.0001, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 21:30:45 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:30:45 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0020, Loss_2: 0.0013, Acc_1: 0.7656, Acc_2: 0.7656, 
2023-03-08 21:30:45 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:30:45 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0008, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:30:45 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0006, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 21:30:52 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0389, Loss_2: 0.0394, Acc_1: 0.3881, Acc_2: 0.3911, F1-score_1: 0.3214, F1-score_2: 0.3214
2023-03-08 21:30:52 - __main__ - INFO - Epoch [67/100]
2023-03-08 21:30:56 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 21:30:57 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:30:57 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:30:57 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8750, Acc_2: 0.8438, 
2023-03-08 21:30:57 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:30:58 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:30:58 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:30:58 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0023, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7969, 
2023-03-08 21:30:58 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:30:59 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:30:59 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0007, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:30:59 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.8594, Acc_2: 0.8281, 
2023-03-08 21:31:05 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0365, Loss_2: 0.0438, Acc_1: 0.3988, Acc_2: 0.3979, F1-score_1: 0.3217, F1-score_2: 0.3218
2023-03-08 21:31:05 - __main__ - INFO - Epoch [68/100]
2023-03-08 21:31:10 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8750, Acc_2: 0.8594, 
2023-03-08 21:31:10 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:31:10 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:31:11 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:31:11 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0004, Loss_2: 0.0007, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 21:31:11 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0005, Loss_2: 0.0012, Acc_1: 0.8281, Acc_2: 0.7969, 
2023-03-08 21:31:11 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:31:12 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0005, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 21:31:12 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0010, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 21:31:12 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0013, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 21:31:12 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0011, Acc_1: 0.8438, Acc_2: 0.8047, 
2023-03-08 21:31:13 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0010, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 21:31:19 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0397, Loss_2: 0.0430, Acc_1: 0.3871, Acc_2: 0.3809, F1-score_1: 0.3164, F1-score_2: 0.3170
2023-03-08 21:31:19 - __main__ - INFO - Epoch [69/100]
2023-03-08 21:31:23 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0004, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:31:24 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0009, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:31:24 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:31:24 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:31:24 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0008, Loss_2: 0.0006, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:31:25 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 21:31:25 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0005, Acc_1: 0.8828, Acc_2: 0.8438, 
2023-03-08 21:31:25 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 21:31:25 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:31:26 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:31:26 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:31:26 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 21:31:32 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0391, Loss_2: 0.0459, Acc_1: 0.3849, Acc_2: 0.3862, F1-score_1: 0.3162, F1-score_2: 0.3239
2023-03-08 21:31:32 - __main__ - INFO - Epoch [70/100]
2023-03-08 21:31:37 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:31:37 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:31:37 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:31:37 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:31:38 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:31:38 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:31:38 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0006, Loss_2: 0.0007, Acc_1: 0.7891, Acc_2: 0.8047, 
2023-03-08 21:31:38 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:31:39 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0007, Acc_1: 0.8047, Acc_2: 0.8281, 
2023-03-08 21:31:39 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0008, Loss_2: 0.0004, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:31:39 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:31:39 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0012, Loss_2: 0.0016, Acc_1: 0.7812, Acc_2: 0.7656, 
2023-03-08 21:31:45 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0392, Loss_2: 0.0398, Acc_1: 0.3979, Acc_2: 0.4025, F1-score_1: 0.3175, F1-score_2: 0.3256
2023-03-08 21:31:45 - __main__ - INFO - Epoch [71/100]
2023-03-08 21:31:50 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0005, Acc_1: 0.8672, Acc_2: 0.8438, 
2023-03-08 21:31:50 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:31:51 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:31:51 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0004, Loss_2: 0.0004, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:31:51 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:31:51 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:31:52 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0004, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 21:31:52 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:31:52 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0003, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 21:31:52 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:31:53 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0006, Acc_1: 0.8906, Acc_2: 0.8750, 
2023-03-08 21:31:53 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 21:31:59 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0391, Loss_2: 0.0421, Acc_1: 0.3928, Acc_2: 0.4051, F1-score_1: 0.3167, F1-score_2: 0.3248
2023-03-08 21:31:59 - __main__ - INFO - Epoch [72/100]
2023-03-08 21:32:04 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:32:04 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-08 21:32:04 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:32:04 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8672, 
2023-03-08 21:32:05 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8438, 
2023-03-08 21:32:05 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 21:32:05 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0003, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:32:05 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:32:06 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:32:06 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:32:06 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0007, Acc_1: 0.8125, Acc_2: 0.7891, 
2023-03-08 21:32:06 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8047, 
2023-03-08 21:32:12 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0426, Loss_2: 0.0449, Acc_1: 0.3976, Acc_2: 0.4005, F1-score_1: 0.3223, F1-score_2: 0.3224
2023-03-08 21:32:12 - __main__ - INFO - Epoch [73/100]
2023-03-08 21:32:17 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:32:17 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:32:18 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:32:18 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:32:18 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:32:18 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8594, 
2023-03-08 21:32:18 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.7969, Acc_2: 0.8047, 
2023-03-08 21:32:19 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 21:32:19 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:32:19 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:32:19 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0004, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 21:32:20 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0019, Loss_2: 0.0021, Acc_1: 0.7734, Acc_2: 0.7656, 
2023-03-08 21:32:26 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0413, Loss_2: 0.0455, Acc_1: 0.3989, Acc_2: 0.3986, F1-score_1: 0.3230, F1-score_2: 0.3291
2023-03-08 21:32:26 - __main__ - INFO - Epoch [74/100]
2023-03-08 21:32:30 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8516, 
2023-03-08 21:32:31 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8906, 
2023-03-08 21:32:31 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:32:31 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:32:31 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0007, Loss_2: 0.0011, Acc_1: 0.7812, Acc_2: 0.7734, 
2023-03-08 21:32:32 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:32:32 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:32:32 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:32:32 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 21:32:33 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.7891, 
2023-03-08 21:32:33 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 21:32:33 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0007, Loss_2: 0.0010, Acc_1: 0.7734, Acc_2: 0.7812, 
2023-03-08 21:32:39 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0415, Loss_2: 0.0477, Acc_1: 0.3971, Acc_2: 0.4022, F1-score_1: 0.3274, F1-score_2: 0.3294
2023-03-08 21:32:39 - __main__ - INFO - Epoch [75/100]
2023-03-08 21:32:44 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:32:44 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 21:32:44 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:32:45 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:32:45 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:32:45 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:32:45 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:32:46 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:32:46 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:32:46 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:32:46 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:32:47 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:32:53 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0392, Loss_2: 0.0444, Acc_1: 0.3978, Acc_2: 0.3989, F1-score_1: 0.3211, F1-score_2: 0.3265
2023-03-08 21:32:53 - __main__ - INFO - Epoch [76/100]
2023-03-08 21:32:57 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:32:58 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:32:58 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:32:58 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8438, 
2023-03-08 21:32:58 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:32:59 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:32:59 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:32:59 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0008, Loss_2: 0.0005, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 21:32:59 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.9062, 
2023-03-08 21:33:00 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 21:33:00 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:33:00 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:33:06 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0390, Loss_2: 0.0445, Acc_1: 0.3935, Acc_2: 0.3993, F1-score_1: 0.3191, F1-score_2: 0.3215
2023-03-08 21:33:06 - __main__ - INFO - Epoch [77/100]
2023-03-08 21:33:11 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.7969, Acc_2: 0.7812, 
2023-03-08 21:33:11 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:33:11 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:33:12 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:33:12 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:33:12 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:33:12 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8828, 
2023-03-08 21:33:13 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:33:13 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8516, 
2023-03-08 21:33:13 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0006, Acc_1: 0.8516, Acc_2: 0.8359, 
2023-03-08 21:33:13 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:33:14 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0003, Loss_2: 0.0004, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:33:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0422, Loss_2: 0.0475, Acc_1: 0.3976, Acc_2: 0.3961, F1-score_1: 0.3184, F1-score_2: 0.3246
2023-03-08 21:33:20 - __main__ - INFO - Epoch [78/100]
2023-03-08 21:33:24 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 21:33:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0003, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:33:25 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8359, 
2023-03-08 21:33:25 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:33:25 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0006, Loss_2: 0.0005, Acc_1: 0.7891, Acc_2: 0.7891, 
2023-03-08 21:33:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:33:26 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:33:26 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8672, 
2023-03-08 21:33:26 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 21:33:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:33:27 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:33:27 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:33:33 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0395, Loss_2: 0.0491, Acc_1: 0.3957, Acc_2: 0.3966, F1-score_1: 0.3117, F1-score_2: 0.3181
2023-03-08 21:33:33 - __main__ - INFO - Epoch [79/100]
2023-03-08 21:33:38 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:33:38 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:33:38 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:33:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:33:39 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:33:39 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:33:39 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 21:33:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8906, 
2023-03-08 21:33:40 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8203, 
2023-03-08 21:33:40 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 21:33:40 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8516, 
2023-03-08 21:33:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:33:46 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0373, Loss_2: 0.0455, Acc_1: 0.4001, Acc_2: 0.3932, F1-score_1: 0.3143, F1-score_2: 0.3161
2023-03-08 21:33:46 - __main__ - INFO - Epoch [80/100]
2023-03-08 21:33:51 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:33:52 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:33:52 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8906, 
2023-03-08 21:33:52 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:33:52 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0032, Loss_2: 0.0005, Acc_1: 0.7969, Acc_2: 0.8359, 
2023-03-08 21:33:53 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0040, Loss_2: 0.0028, Acc_1: 0.7656, Acc_2: 0.8438, 
2023-03-08 21:33:53 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0028, Loss_2: 0.0006, Acc_1: 0.7812, Acc_2: 0.8203, 
2023-03-08 21:33:53 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0004, Loss_2: 0.0003, Acc_1: 0.7969, Acc_2: 0.7969, 
2023-03-08 21:33:53 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0008, Loss_2: 0.0002, Acc_1: 0.8359, Acc_2: 0.8750, 
2023-03-08 21:33:54 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0004, Acc_1: 0.7891, Acc_2: 0.8203, 
2023-03-08 21:33:54 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0009, Loss_2: 0.0005, Acc_1: 0.8203, Acc_2: 0.8672, 
2023-03-08 21:33:54 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8281, 
2023-03-08 21:34:00 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0364, Loss_2: 0.0425, Acc_1: 0.3988, Acc_2: 0.3872, F1-score_1: 0.3265, F1-score_2: 0.3166
2023-03-08 21:34:00 - __main__ - INFO - Epoch [81/100]
2023-03-08 21:34:05 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:34:05 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 21:34:05 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 21:34:05 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8594, 
2023-03-08 21:34:06 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0005, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 21:34:06 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:34:06 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0005, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:34:06 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:34:07 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0007, Loss_2: 0.0003, Acc_1: 0.8125, Acc_2: 0.8281, 
2023-03-08 21:34:07 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0012, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.9141, 
2023-03-08 21:34:07 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0011, Loss_2: 0.0003, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:34:07 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:34:13 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0363, Loss_2: 0.0506, Acc_1: 0.4069, Acc_2: 0.3884, F1-score_1: 0.3219, F1-score_2: 0.3187
2023-03-08 21:34:13 - __main__ - INFO - Epoch [82/100]
2023-03-08 21:34:18 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:34:18 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 21:34:19 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:34:19 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8828, 
2023-03-08 21:34:19 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.9062, 
2023-03-08 21:34:19 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0004, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8828, 
2023-03-08 21:34:20 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:34:20 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:34:20 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 21:34:20 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:34:21 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0003, Loss_2: 0.0007, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:34:21 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:34:27 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0392, Loss_2: 0.0478, Acc_1: 0.4047, Acc_2: 0.4078, F1-score_1: 0.3335, F1-score_2: 0.3243
2023-03-08 21:34:27 - __main__ - INFO - Epoch [83/100]
2023-03-08 21:34:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:34:32 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0005, Loss_2: 0.0003, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:34:32 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0002, Loss_2: 0.0003, Acc_1: 0.8359, Acc_2: 0.8281, 
2023-03-08 21:34:32 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:34:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:34:33 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:34:33 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:34:33 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9141, 
2023-03-08 21:34:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8047, Acc_2: 0.7969, 
2023-03-08 21:34:34 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0003, Loss_2: 0.0003, Acc_1: 0.8516, Acc_2: 0.8672, 
2023-03-08 21:34:34 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:34:34 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8984, Acc_2: 0.8828, 
2023-03-08 21:34:40 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0389, Loss_2: 0.0463, Acc_1: 0.4029, Acc_2: 0.3949, F1-score_1: 0.3298, F1-score_2: 0.3145
2023-03-08 21:34:40 - __main__ - INFO - Epoch [84/100]
2023-03-08 21:34:45 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:34:45 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8984, Acc_2: 0.8906, 
2023-03-08 21:34:45 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0002, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:34:46 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 21:34:46 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:34:46 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:34:46 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8047, 
2023-03-08 21:34:47 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:34:47 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:34:47 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:34:47 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:34:48 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0002, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:34:54 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0378, Loss_2: 0.0471, Acc_1: 0.4051, Acc_2: 0.3933, F1-score_1: 0.3292, F1-score_2: 0.3226
2023-03-08 21:34:54 - __main__ - INFO - Epoch [85/100]
2023-03-08 21:34:58 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:34:59 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0004, Loss_2: 0.0008, Acc_1: 0.7812, Acc_2: 0.7500, 
2023-03-08 21:34:59 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:34:59 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:34:59 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:35:00 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:35:00 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:35:00 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:35:00 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8750, 
2023-03-08 21:35:01 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:35:01 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:35:01 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0014, Loss_2: 0.0009, Acc_1: 0.7812, Acc_2: 0.7891, 
2023-03-08 21:35:07 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0391, Loss_2: 0.0476, Acc_1: 0.4005, Acc_2: 0.3957, F1-score_1: 0.3251, F1-score_2: 0.3186
2023-03-08 21:35:07 - __main__ - INFO - Epoch [86/100]
2023-03-08 21:35:12 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8203, 
2023-03-08 21:35:12 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:35:12 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:35:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:35:13 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0002, Loss_2: 0.0001, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:35:13 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:35:13 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:35:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:35:14 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:35:14 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:35:14 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:35:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:35:20 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0382, Loss_2: 0.0462, Acc_1: 0.3989, Acc_2: 0.3956, F1-score_1: 0.3237, F1-score_2: 0.3190
2023-03-08 21:35:20 - __main__ - INFO - Epoch [87/100]
2023-03-08 21:35:25 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:35:25 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.8984, 
2023-03-08 21:35:26 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:35:26 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0012, Loss_2: 0.0015, Acc_1: 0.7812, Acc_2: 0.7812, 
2023-03-08 21:35:26 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:35:26 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:35:27 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:35:27 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9141, 
2023-03-08 21:35:27 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:35:27 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0002, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:35:28 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8125, 
2023-03-08 21:35:28 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:35:34 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0372, Loss_2: 0.0472, Acc_1: 0.4006, Acc_2: 0.3954, F1-score_1: 0.3300, F1-score_2: 0.3226
2023-03-08 21:35:34 - __main__ - INFO - Epoch [88/100]
2023-03-08 21:35:39 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8516, Acc_2: 0.8438, 
2023-03-08 21:35:39 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:35:39 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:35:39 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:35:40 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:35:40 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:35:40 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:35:40 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:35:41 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:35:41 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:35:41 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:35:41 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:35:47 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0378, Loss_2: 0.0450, Acc_1: 0.4069, Acc_2: 0.3995, F1-score_1: 0.3314, F1-score_2: 0.3209
2023-03-08 21:35:47 - __main__ - INFO - Epoch [89/100]
2023-03-08 21:35:52 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:35:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:35:53 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:35:53 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:35:53 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:35:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8359, 
2023-03-08 21:35:54 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:35:54 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:35:54 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:35:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:35:55 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:35:55 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:36:01 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0405, Loss_2: 0.0463, Acc_1: 0.4006, Acc_2: 0.3972, F1-score_1: 0.3289, F1-score_2: 0.3210
2023-03-08 21:36:01 - __main__ - INFO - Epoch [90/100]
2023-03-08 21:36:06 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:36:06 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:36:06 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:36:06 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:36:07 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:36:07 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:36:07 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8516, 
2023-03-08 21:36:07 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:36:08 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:36:08 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 21:36:08 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0001, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:36:08 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:36:14 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0357, Loss_2: 0.0428, Acc_1: 0.4017, Acc_2: 0.4034, F1-score_1: 0.3258, F1-score_2: 0.3271
2023-03-08 21:36:14 - __main__ - INFO - Epoch [91/100]
2023-03-08 21:36:19 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:36:19 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:36:20 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:36:20 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:36:20 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:36:20 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:36:21 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:36:21 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:36:21 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:36:21 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:36:22 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:36:22 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:36:28 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0358, Loss_2: 0.0426, Acc_1: 0.4000, Acc_2: 0.3981, F1-score_1: 0.3254, F1-score_2: 0.3227
2023-03-08 21:36:28 - __main__ - INFO - Epoch [92/100]
2023-03-08 21:36:32 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:36:33 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:36:33 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:36:33 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:36:33 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:36:34 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8594, 
2023-03-08 21:36:34 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:36:34 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:36:34 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:36:35 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:36:35 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:36:35 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:36:41 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0374, Loss_2: 0.0434, Acc_1: 0.4015, Acc_2: 0.3981, F1-score_1: 0.3301, F1-score_2: 0.3236
2023-03-08 21:36:41 - __main__ - INFO - Epoch [93/100]
2023-03-08 21:36:46 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8750, 
2023-03-08 21:36:46 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:36:46 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:36:47 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:36:47 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0003, Loss_2: 0.0001, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 21:36:47 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:36:47 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:36:48 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:36:48 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8672, 
2023-03-08 21:36:48 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:36:48 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 21:36:49 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8125, Acc_2: 0.8125, 
2023-03-08 21:36:55 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0371, Loss_2: 0.0441, Acc_1: 0.3989, Acc_2: 0.3952, F1-score_1: 0.3250, F1-score_2: 0.3237
2023-03-08 21:36:55 - __main__ - INFO - Epoch [94/100]
2023-03-08 21:36:59 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:37:00 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:37:00 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:37:00 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:37:00 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:37:01 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8672, 
2023-03-08 21:37:01 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:37:01 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:37:01 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:37:02 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8281, 
2023-03-08 21:37:02 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8516, 
2023-03-08 21:37:02 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:37:08 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0375, Loss_2: 0.0446, Acc_1: 0.4013, Acc_2: 0.3961, F1-score_1: 0.3268, F1-score_2: 0.3192
2023-03-08 21:37:08 - __main__ - INFO - Epoch [95/100]
2023-03-08 21:37:13 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 21:37:13 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:37:13 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:37:13 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:37:14 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8828, 
2023-03-08 21:37:14 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8438, 
2023-03-08 21:37:14 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:37:14 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:37:15 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8750, 
2023-03-08 21:37:15 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:37:15 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:37:15 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:37:21 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0383, Loss_2: 0.0450, Acc_1: 0.3991, Acc_2: 0.3957, F1-score_1: 0.3257, F1-score_2: 0.3193
2023-03-08 21:37:21 - __main__ - INFO - Epoch [96/100]
2023-03-08 21:37:26 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8047, Acc_2: 0.8125, 
2023-03-08 21:37:27 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:37:27 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8359, 
2023-03-08 21:37:27 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:37:27 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:37:28 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:37:28 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0001, Loss_2: 0.0001, Acc_1: 0.8047, Acc_2: 0.8047, 
2023-03-08 21:37:28 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9219, Acc_2: 0.9219, 
2023-03-08 21:37:28 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:37:29 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:37:29 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 21:37:29 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:37:35 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0385, Loss_2: 0.0444, Acc_1: 0.3978, Acc_2: 0.3915, F1-score_1: 0.3284, F1-score_2: 0.3180
2023-03-08 21:37:35 - __main__ - INFO - Epoch [97/100]
2023-03-08 21:37:40 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 21:37:40 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:37:40 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:37:40 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:37:41 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:37:41 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8516, Acc_2: 0.8516, 
2023-03-08 21:37:41 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:37:41 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:37:42 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:37:42 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:37:42 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:37:42 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9297, Acc_2: 0.9297, 
2023-03-08 21:37:48 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0365, Loss_2: 0.0451, Acc_1: 0.4013, Acc_2: 0.3983, F1-score_1: 0.3286, F1-score_2: 0.3208
2023-03-08 21:37:48 - __main__ - INFO - Epoch [98/100]
2023-03-08 21:37:53 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9062, Acc_2: 0.9062, 
2023-03-08 21:37:53 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:37:54 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8359, Acc_2: 0.8359, 
2023-03-08 21:37:54 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:37:54 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:37:54 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:37:55 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8984, 
2023-03-08 21:37:55 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0001, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8125, 
2023-03-08 21:37:55 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8750, Acc_2: 0.8750, 
2023-03-08 21:37:55 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8594, 
2023-03-08 21:37:56 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8672, 
2023-03-08 21:37:56 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8906, Acc_2: 0.8906, 
2023-03-08 21:38:02 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0368, Loss_2: 0.0450, Acc_1: 0.3974, Acc_2: 0.3971, F1-score_1: 0.3266, F1-score_2: 0.3216
2023-03-08 21:38:02 - __main__ - INFO - Epoch [99/100]
2023-03-08 21:38:07 - trainer._trainer - INFO - 	Step [001/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8281, Acc_2: 0.8281, 
2023-03-08 21:38:07 - trainer._trainer - INFO - 	Step [011/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:38:07 - trainer._trainer - INFO - 	Step [021/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:38:07 - trainer._trainer - INFO - 	Step [031/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.9141, Acc_2: 0.9219, 
2023-03-08 21:38:08 - trainer._trainer - INFO - 	Step [041/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8281, 
2023-03-08 21:38:08 - trainer._trainer - INFO - 	Step [051/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8672, Acc_2: 0.8594, 
2023-03-08 21:38:08 - trainer._trainer - INFO - 	Step [061/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8438, Acc_2: 0.8438, 
2023-03-08 21:38:08 - trainer._trainer - INFO - 	Step [071/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8203, Acc_2: 0.8203, 
2023-03-08 21:38:09 - trainer._trainer - INFO - 	Step [081/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8828, 
2023-03-08 21:38:09 - trainer._trainer - INFO - 	Step [091/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8594, Acc_2: 0.8516, 
2023-03-08 21:38:09 - trainer._trainer - INFO - 	Step [101/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8828, Acc_2: 0.8906, 
2023-03-08 21:38:09 - trainer._trainer - INFO - 	Step [109/109] Loss_1: 0.0000, Loss_2: 0.0000, Acc_1: 0.8984, Acc_2: 0.8984, 
2023-03-08 21:38:15 - trainer._trainer - INFO - 	[Test results] Loss_1: 0.0374, Loss_2: 0.0450, Acc_1: 0.3961, Acc_2: 0.3949, F1-score_1: 0.3255, F1-score_2: 0.3198
